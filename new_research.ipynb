{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "id": "b5b45ce66797d3e3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import  RepeatedStratifiedKFold\n",
    "import kagglehub\n",
    "from ResNet34 import ResNetTrainer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from DatasetClasses import CapsuleDataset\n",
    "from wrappers import CNNVAEResNetEstimator,CNNVAEWrapper, CNNGANWrapper, CNNGANResNetEstimator\n",
    "from scipy.stats import shapiro, bartlett, f_oneway\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7df5141f3b6e3302"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b1269c1580bb28a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Parametry modelu\n",
    "IMG_SIZE = 128\n",
    "CHANNELS = 3\n",
    "LATENT_DIM = 64\n",
    "HIDDEN_DIM = 512\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "\n",
    "# Konfiguracja\n",
    "result_dir = 'results/'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "result_dir = 'results/GAN'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "result_dir = 'results/CNNGAN'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "result_dir = 'results/VAE'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "result_dir = 'results/CNNVAE'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "\n",
    "device = (\n",
    "    torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "    else torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "\n",
    "print(f\"Training device: {device}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52982b9c166d855c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rskf = RepeatedStratifiedKFold(\n",
    "    n_splits=5,\n",
    "    n_repeats=2,\n",
    "    random_state=42\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14db26df085d4145"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset preparing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a20401972f3bd62f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# your augmentations + normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.05,0.05), scale=(1.1,1.15), fill=255),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])   \n",
    "\n",
    "path = kagglehub.dataset_download(\"tladilebohang/capsule-defects\")\n",
    "# download or mount your Kaggle data however you like; suppose:\n",
    "# path = \".../capsule-defects\"\n",
    "pos_folder = os.path.join(path, \"capsule/positive\")\n",
    "neg_folder = os.path.join(path, \"capsule/negative\")\n",
    "pos_len=len(glob.glob(os.path.join(pos_folder, \"*\")))\n",
    "print(pos_len)\n",
    "neg_len=len(glob.glob(os.path.join(neg_folder, \"*\")))\n",
    "print(neg_len)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ee141eeaf8fbbe3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Eksperyment na datasecie bez oversamplingu"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e3c154ceb4b7a0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "IMG_SIZE   = 128\n",
    "BATCH_SIZE = 16\n",
    "CHANNELS   = 3\n",
    "EPOCHS = 25\n",
    "\n",
    "dataset = CapsuleDataset(pos_dir=pos_folder, neg_dirs=neg_folder, transform=transform)\n",
    "print(dataset.__len__())\n",
    "\n",
    "labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(rskf.split(X=np.zeros(len(labels)), y=labels), start=1):\n",
    "    print(f\"===== Fold {fold_idx} =====\")\n",
    "\n",
    "    # Subset + DataLoader\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    test_ds  = Subset(dataset, test_idx)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=True)\n",
    "    trainer = ResNetTrainer()\n",
    "    \n",
    "    trainer.train(\n",
    "        train_loader,\n",
    "        num_epochs=EPOCHS,\n",
    "    )\n",
    "\n",
    "    f2, bal_acc, recall, specificity = trainer.validate(test_loader)\n",
    "    print(f\"Fold {fold_idx} Test Accuracy: {bal_acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'fold': fold_idx,\n",
    "        'f2_score': f2,\n",
    "        'balanced_accuracy': bal_acc,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity\n",
    "    })\n",
    "\n",
    "#Zapis wyników z każdego folda\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('without_oversampling_cross_validation_results.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5cbf1ed99498bd0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNNVAE: Ekperyment "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2604f21333d5a679"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE   = 128\n",
    "BATCH_SIZE = 16\n",
    "CHANNELS   = 3\n",
    "CLASSIFIER_EPOCHS = 25\n",
    "OVERSAMPLER_EPOCHS = 200\n",
    "\n",
    "dataset = CapsuleDataset(pos_dir=pos_folder, neg_dirs=neg_folder, transform=transform)\n",
    "print(dataset.__len__())\n",
    "\n",
    "labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(rskf.split(X=np.zeros(len(labels)), y=labels), start=1):\n",
    "    print(f\"===== Fold {fold_idx} =====\")\n",
    "\n",
    "    \n",
    "    CnnVae = CNNVAEWrapper(dataset,device,BATCH_SIZE,OVERSAMPLER_EPOCHS)\n",
    "    \n",
    "    CnnVae.fit(train_idx)\n",
    "\n",
    "\n",
    "    estimator = CNNVAEResNetEstimator(\n",
    "        dataset=dataset,\n",
    "        vae_model=CnnVae.vae_model,\n",
    "        device=device,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        classifier_epochs=CLASSIFIER_EPOCHS\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'mu_multiplier': [0.8, 1.2],\n",
    "        'logvar_multiplier': [0.5, 1.5],\n",
    "        'multiplier_generated_samples': [1/2,1, 2]\n",
    "    }\n",
    "\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=8, \n",
    "        cv=None,\n",
    "        verbose=2,\n",
    "        n_jobs=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    random_search.fit(train_idx)\n",
    "\n",
    "    best_estimator = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    test_ds = Subset(dataset, test_idx)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    f2, bal_acc, recall, specificity = best_estimator.trainer.validate(test_loader)\n",
    "    print(f\"Fold {fold_idx} Test Accuracy: {bal_acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'fold': fold_idx,\n",
    "        'f2_score': f2,\n",
    "        'balanced_accuracy': bal_acc,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        **best_params  \n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Zapis wyników z każdego folda\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('CNNVAE_cross_validation_results.csv', index=False)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b8f65864217dffe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNNGAN: Eksperyment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbcd19f4b365c92a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE   = 128\n",
    "BATCH_SIZE = 16\n",
    "CHANNELS   = 3\n",
    "CLASSIFIER_EPOCHS = 15\n",
    "OVERSAMPLER_EPOCHS = 250\n",
    "\n",
    "dataset = CapsuleDataset(pos_dir=pos_folder, neg_dirs=neg_folder, transform=transform)\n",
    "print(dataset.__len__())\n",
    "\n",
    "labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(rskf.split(X=np.zeros(len(labels)), y=labels), start=1):\n",
    "    print(f\"===== Fold {fold_idx} =====\")\n",
    "\n",
    "\n",
    "    CnnGan = CNNGANWrapper(dataset,device,BATCH_SIZE,OVERSAMPLER_EPOCHS)\n",
    "\n",
    "    CnnGan.fit(train_idx)\n",
    "\n",
    "\n",
    "    estimator = CNNGANResNetEstimator(\n",
    "        dataset=dataset,\n",
    "        gan_model=CnnGan.gan_model,\n",
    "        device=device,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        classifier_epochs=CLASSIFIER_EPOCHS\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'scale_factor': [0.5, 1, 1.5],  # Czynnik skalujący szum w GAN\n",
    "        'multiplier_generated_samples': [1/2,1, 2]\n",
    "    }\n",
    "\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=6,\n",
    "        cv=None,\n",
    "        verbose=2,\n",
    "        n_jobs=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    random_search.fit(train_idx)\n",
    "\n",
    "    best_estimator = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    test_ds = Subset(dataset, test_idx)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    f2, bal_acc, recall, specificity = best_estimator.trainer.validate(test_loader)\n",
    "    print(f\"Fold {fold_idx} Test Accuracy: {bal_acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'fold': fold_idx,\n",
    "        'f2_score': f2,\n",
    "        'balanced_accuracy': bal_acc,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        **best_params\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Zapis wyników z każdego folda\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('CNNGAN_cross_validation_results.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ab0749c44a3298b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNNGAN: Generowanie jedynie syntetycznego zbioru"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c36e1802029d801"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "IMG_SIZE   = 128\n",
    "BATCH_SIZE = 16\n",
    "CHANNELS   = 3\n",
    "CLASSIFIER_EPOCHS = 20\n",
    "OVERSAMPLER_EPOCHS = 200\n",
    "\n",
    "dataset = CapsuleDataset(pos_dir=pos_folder, neg_dirs=neg_folder, transform=transform)\n",
    "print(dataset.__len__())\n",
    "\n",
    "labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(rskf.split(X=np.zeros(len(labels)), y=labels), start=1):\n",
    "    print(f\"===== Fold {fold_idx} =====\")\n",
    "\n",
    "\n",
    "    CnnGan = CNNGANWrapper(dataset,device,BATCH_SIZE,OVERSAMPLER_EPOCHS)\n",
    "\n",
    "    CnnGan.fit(train_idx)\n",
    "\n",
    "\n",
    "    estimator = CNNGANResNetEstimator(\n",
    "        dataset=dataset,\n",
    "        gan_model=CnnGan.gan_model,\n",
    "        device=device,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        classifier_epochs=CLASSIFIER_EPOCHS,\n",
    "        multiplier_generated_samples='synthetic'\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'scale_factor': [0.5, 1, 1.5]  # Czynnik skalujący szum w GAN\n",
    "    }\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=2,\n",
    "        cv=None,\n",
    "        verbose=2,\n",
    "        n_jobs=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    random_search.fit(train_idx)\n",
    "\n",
    "    best_estimator = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    test_ds = Subset(dataset, test_idx)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    f2, bal_acc, recall, specificity = best_estimator.trainer.validate(test_loader)\n",
    "    print(f\"Fold {fold_idx} Test Accuracy: {bal_acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'fold': fold_idx,\n",
    "        'f2_score': f2,\n",
    "        'balanced_accuracy': bal_acc,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        **best_params\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Zapis wyników z każdego folda\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('CNNGAN_synthetic_cross_validation_results.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2784458e729dfae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNNVAE: Generowanie jedynie syntetycznego zbioru"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c186d74ffc9bd59"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "IMG_SIZE   = 128\n",
    "BATCH_SIZE = 16\n",
    "CHANNELS   = 3\n",
    "CLASSIFIER_EPOCHS = 20\n",
    "OVERSAMPLER_EPOCHS = 200\n",
    "\n",
    "dataset = CapsuleDataset(pos_dir=pos_folder, neg_dirs=neg_folder, transform=transform)\n",
    "print(dataset.__len__())\n",
    "\n",
    "labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(rskf.split(X=np.zeros(len(labels)), y=labels), start=1):\n",
    "    print(f\"===== Fold {fold_idx} =====\")\n",
    "\n",
    "\n",
    "    CnnVae = CNNVAEWrapper(dataset,device,BATCH_SIZE,OVERSAMPLER_EPOCHS)\n",
    "\n",
    "    CnnVae.fit(train_idx)\n",
    "\n",
    "\n",
    "    estimator = CNNVAEResNetEstimator(\n",
    "        dataset=dataset,\n",
    "        vae_model=CnnVae.vae_model,\n",
    "        device=device,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        classifier_epochs=CLASSIFIER_EPOCHS,\n",
    "        multiplier_generated_samples='synthetic'\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'mu_multiplier': [0.8, 1.2],\n",
    "        'logvar_multiplier': [0.5, 1.5]\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=3,\n",
    "        cv=None,\n",
    "        verbose=2,\n",
    "        n_jobs=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    random_search.fit(train_idx)\n",
    "\n",
    "    best_estimator = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    test_ds = Subset(dataset, test_idx)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    f2, bal_acc, recall, specificity = best_estimator.trainer.validate(test_loader)\n",
    "    print(f\"Fold {fold_idx} Test Accuracy: {bal_acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'fold': fold_idx,\n",
    "        'f2_score': f2,\n",
    "        'balanced_accuracy': bal_acc,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        **best_params\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Zapis wyników z każdego folda\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('CNNVAE_synthetic_cross_validation_results.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faf5398e6c2f6550"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
