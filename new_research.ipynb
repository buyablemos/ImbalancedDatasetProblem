{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "id": "b5b45ce66797d3e3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-28T19:12:51.625192Z",
     "start_time": "2025-05-28T19:12:51.271945Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import  RepeatedStratifiedKFold\n",
    "import kagglehub\n",
    "from ResNet34 import ResNetTrainer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from DatasetClasses import CapsuleDataset\n",
    "from wrappers import CNNVAEResNetEstimator,CNNVAEWrapper, CNNGANWrapper, CNNGANResNetEstimator"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [],
   "id": "1f4ed156edf08d68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:12:53.241855Z",
     "start_time": "2025-05-28T19:12:53.001945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parametry modelu\n",
    "IMG_SIZE = 128\n",
    "CHANNELS = 3\n",
    "LATENT_DIM = 64\n",
    "HIDDEN_DIM = 512\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "\n",
    "# Konfiguracja\n",
    "result_dir = 'results/'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "result_dir = 'results/GAN'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "result_dir = 'results/CNNGAN'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "result_dir = 'results/VAE'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "result_dir = 'results/CNNVAE'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "\n",
    "device = (\n",
    "    torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "    else torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "\n",
    "print(f\"Training device: {device}\")"
   ],
   "id": "a9b7e818fa133d69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cpu\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:12:54.599618Z",
     "start_time": "2025-05-28T19:12:54.387671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rskf = RepeatedStratifiedKFold(\n",
    "    n_splits=5,\n",
    "    n_repeats=2,\n",
    "    random_state=42\n",
    ")"
   ],
   "id": "d01b8d11acc24a78",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset preparing"
   ],
   "id": "d786c4936b0c30fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:12:29.633779Z",
     "start_time": "2025-05-28T19:12:27.254590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# your augmentations + normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.05,0.05), scale=(1.1,1.15), fill=255),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])   \n",
    "\n",
    "path = kagglehub.dataset_download(\"tladilebohang/capsule-defects\")\n",
    "# download or mount your Kaggle data however you like; suppose:\n",
    "# path = \".../capsule-defects\"\n",
    "pos_folder = os.path.join(path, \"capsule/positive\")\n",
    "neg_folder = os.path.join(path, \"capsule/negative\")\n",
    "pos_len=len(glob.glob(os.path.join(pos_folder, \"*\")))\n",
    "print(pos_len)\n",
    "neg_len=len(glob.glob(os.path.join(neg_folder, \"*\")))\n",
    "print(neg_len)"
   ],
   "id": "f4f67cd272e76c4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n",
      "109\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Eksperyment na datasecie bez oversamplingu"
   ],
   "id": "229a9ecbb8592ea8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T19:02:37.125127Z",
     "start_time": "2025-05-24T18:59:04.380062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "IMG_SIZE   = 128\n",
    "BATCH_SIZE = 16\n",
    "CHANNELS   = 3\n",
    "EPOCHS = 25\n",
    "\n",
    "dataset = CapsuleDataset(pos_dir=pos_folder, neg_dirs=neg_folder, transform=transform)\n",
    "print(dataset.__len__())\n",
    "\n",
    "labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(rskf.split(X=np.zeros(len(labels)), y=labels), start=1):\n",
    "    print(f\"===== Fold {fold_idx} =====\")\n",
    "\n",
    "    # Subset + DataLoader\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    test_ds  = Subset(dataset, test_idx)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=True)\n",
    "    trainer = ResNetTrainer()\n",
    "    \n",
    "    trainer.train(\n",
    "        train_loader,\n",
    "        num_epochs=EPOCHS,\n",
    "    )\n",
    "\n",
    "    f2, bal_acc, recall, specificity = trainer.validate(test_loader)\n",
    "    print(f\"Fold {fold_idx} Test Accuracy: {bal_acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'fold': fold_idx,\n",
    "        'f2_score': f2,\n",
    "        'balanced_accuracy': bal_acc,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity\n",
    "    })\n",
    "\n",
    "#Zapis wyników z każdego folda\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('without_oversampling_cross_validation_results.csv', index=False)\n"
   ],
   "id": "f168eff86851b0f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n",
      "===== Fold 1 =====\n",
      "Epoch 1/25 | Train Loss: 0.7442 Acc: 0.6336\n",
      "Epoch 2/25 | Train Loss: 0.6194 Acc: 0.7023\n",
      "Epoch 3/25 | Train Loss: 0.6195 Acc: 0.6908\n",
      "Epoch 4/25 | Train Loss: 0.5723 Acc: 0.7176\n",
      "Epoch 5/25 | Train Loss: 0.4970 Acc: 0.7786\n",
      "Epoch 6/25 | Train Loss: 0.6026 Acc: 0.7290\n",
      "Epoch 7/25 | Train Loss: 0.5569 Acc: 0.7366\n",
      "Epoch 8/25 | Train Loss: 0.4960 Acc: 0.7672\n",
      "Epoch 9/25 | Train Loss: 0.4983 Acc: 0.7557\n",
      "Epoch 10/25 | Train Loss: 0.4775 Acc: 0.7672\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 23\u001B[0m\n\u001B[1;32m     20\u001B[0m test_loader  \u001B[38;5;241m=\u001B[39m DataLoader(test_ds,  batch_size\u001B[38;5;241m=\u001B[39mBATCH_SIZE, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     21\u001B[0m trainer \u001B[38;5;241m=\u001B[39m ResNetTrainer()\n\u001B[0;32m---> 23\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m f2, bal_acc, recall, specificity \u001B[38;5;241m=\u001B[39m trainer\u001B[38;5;241m.\u001B[39mvalidate(test_loader)\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFold \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfold_idx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Test Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbal_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/ResNet34.py:82\u001B[0m, in \u001B[0;36mResNetTrainer.train\u001B[0;34m(self, train_loader, num_epochs)\u001B[0m\n\u001B[1;32m     79\u001B[0m inputs_resnet \u001B[38;5;241m=\u001B[39m (inputs \u001B[38;5;241m-\u001B[39m imagenet_mean) \u001B[38;5;241m/\u001B[39m imagenet_std\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 82\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs_resnet\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     83\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcriterion(outputs, labels)\n\u001B[1;32m     84\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/torchvision/models/resnet.py:285\u001B[0m, in \u001B[0;36mResNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 285\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/torchvision/models/resnet.py:273\u001B[0m, in \u001B[0;36mResNet._forward_impl\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    270\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(x)\n\u001B[1;32m    271\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmaxpool(x)\n\u001B[0;32m--> 273\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    274\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer2(x)\n\u001B[1;32m    275\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer3(x)\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/torchvision/models/resnet.py:102\u001B[0m, in \u001B[0;36mBasicBlock.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownsample \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    100\u001B[0m     identity \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownsample(x)\n\u001B[0;32m--> 102\u001B[0m out \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m identity\n\u001B[1;32m    103\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out)\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CNNVAE: Ekperyment "
   ],
   "id": "3b97200ae874d707"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T12:57:48.336343Z",
     "start_time": "2025-05-24T12:48:51.259682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "IMG_SIZE   = 128\n",
    "BATCH_SIZE = 16\n",
    "CHANNELS   = 3\n",
    "CLASSIFIER_EPOCHS = 25\n",
    "OVERSAMPLER_EPOCHS = 200\n",
    "\n",
    "dataset = CapsuleDataset(pos_dir=pos_folder, neg_dirs=neg_folder, transform=transform)\n",
    "print(dataset.__len__())\n",
    "\n",
    "labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(rskf.split(X=np.zeros(len(labels)), y=labels), start=1):\n",
    "    print(f\"===== Fold {fold_idx} =====\")\n",
    "\n",
    "    \n",
    "    CnnVae = CNNVAEWrapper(dataset,device,BATCH_SIZE,OVERSAMPLER_EPOCHS)\n",
    "    \n",
    "    CnnVae.fit(train_idx)\n",
    "\n",
    "\n",
    "    estimator = CNNVAEResNetEstimator(\n",
    "        dataset=dataset,\n",
    "        vae_model=CnnVae.vae_model,\n",
    "        device=device,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        classifier_epochs=CLASSIFIER_EPOCHS\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'mu_multiplier': [0.8, 1.2],\n",
    "        'logvar_multiplier': [0.5, 1.5],\n",
    "        'multiplier_generated_samples': [1/2,1, 2]\n",
    "    }\n",
    "\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=8, \n",
    "        cv=None,\n",
    "        verbose=2,\n",
    "        n_jobs=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    random_search.fit(train_idx)\n",
    "\n",
    "    best_estimator = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    test_ds = Subset(dataset, test_idx)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    f2, bal_acc, recall, specificity = best_estimator.trainer.validate(test_loader)\n",
    "    print(f\"Fold {fold_idx} Test Accuracy: {bal_acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'fold': fold_idx,\n",
    "        'f2_score': f2,\n",
    "        'balanced_accuracy': bal_acc,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        **best_params  \n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Zapis wyników z każdego folda\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('CNNVAE_cross_validation_results.csv', index=False)\n",
    "    "
   ],
   "id": "d20b162d6135eac6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n",
      "===== Fold 1 =====\n",
      "Train Epoch: 1 | Loss: 2304.4632\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/1 | Train Loss: 0.5439 Acc: 0.6841\n",
      "[CV] END logvar_multiplier=0.5, mu_multiplier=1.2, multiplier_generated_samples=2; total time=  54.1s\n",
      "Epoch 1/1 | Train Loss: 0.5428 Acc: 0.6736\n",
      "[CV] END logvar_multiplier=0.5, mu_multiplier=1.2, multiplier_generated_samples=2; total time=  54.5s\n",
      "Epoch 1/1 | Train Loss: 0.4985 Acc: 0.7526\n",
      "[CV] END logvar_multiplier=0.5, mu_multiplier=1.2, multiplier_generated_samples=2; total time=  56.1s\n",
      "Epoch 1/1 | Train Loss: 0.6003 Acc: 0.7580\n",
      "[CV] END logvar_multiplier=0.5, mu_multiplier=1.2, multiplier_generated_samples=2; total time=  48.9s\n",
      "Epoch 1/1 | Train Loss: 0.4814 Acc: 0.8107\n",
      "[CV] END logvar_multiplier=0.5, mu_multiplier=1.2, multiplier_generated_samples=2; total time=  43.4s\n",
      "Epoch 1/1 | Train Loss: 0.7441 Acc: 0.5652\n",
      "[CV] END logvar_multiplier=1.0, mu_multiplier=1.0, multiplier_generated_samples=0.5; total time=  40.4s\n",
      "Epoch 1/1 | Train Loss: 0.6404 Acc: 0.6047\n",
      "[CV] END logvar_multiplier=1.0, mu_multiplier=1.0, multiplier_generated_samples=0.5; total time=  40.1s\n",
      "Epoch 1/1 | Train Loss: 0.7743 Acc: 0.6024\n",
      "[CV] END logvar_multiplier=1.0, mu_multiplier=1.0, multiplier_generated_samples=0.5; total time=  41.2s\n",
      "Epoch 1/1 | Train Loss: 0.6172 Acc: 0.7119\n",
      "[CV] END logvar_multiplier=1.0, mu_multiplier=1.0, multiplier_generated_samples=0.5; total time=  40.1s\n",
      "Epoch 1/1 | Train Loss: 0.5543 Acc: 0.7982\n",
      "[CV] END logvar_multiplier=1.0, mu_multiplier=1.0, multiplier_generated_samples=0.5; total time=  38.2s\n",
      "Epoch 1/1 | Train Loss: 0.5298 Acc: 0.7133\n",
      "Fold 1 Test Accuracy: 0.5455\n",
      "===== Fold 2 =====\n",
      "Train Epoch: 1 | Loss: 17866.6649\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[124], line 52\u001B[0m\n\u001B[1;32m     35\u001B[0m param_grid \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmu_multiplier\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m0.8\u001B[39m, \u001B[38;5;241m1.0\u001B[39m, \u001B[38;5;241m1.2\u001B[39m],\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogvar_multiplier\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m1.0\u001B[39m, \u001B[38;5;241m1.5\u001B[39m],\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmultiplier_generated_samples\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m     39\u001B[0m }\n\u001B[1;32m     42\u001B[0m random_search \u001B[38;5;241m=\u001B[39m RandomizedSearchCV(\n\u001B[1;32m     43\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[1;32m     44\u001B[0m     param_distributions\u001B[38;5;241m=\u001B[39mparam_grid,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     49\u001B[0m     random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m\n\u001B[1;32m     50\u001B[0m )\n\u001B[0;32m---> 52\u001B[0m \u001B[43mrandom_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_idx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m best_estimator \u001B[38;5;241m=\u001B[39m random_search\u001B[38;5;241m.\u001B[39mbest_estimator_\n\u001B[1;32m     55\u001B[0m best_params \u001B[38;5;241m=\u001B[39m random_search\u001B[38;5;241m.\u001B[39mbest_params_\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/sklearn/base.py:1389\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1382\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1384\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1385\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1386\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1387\u001B[0m     )\n\u001B[1;32m   1388\u001B[0m ):\n\u001B[0;32m-> 1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1024\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m   1018\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m   1019\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m   1020\u001B[0m     )\n\u001B[1;32m   1022\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m-> 1024\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1026\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m   1027\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m   1028\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1951\u001B[0m, in \u001B[0;36mRandomizedSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1949\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1950\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1951\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1952\u001B[0m \u001B[43m        \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1953\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[1;32m   1954\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1955\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    962\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    963\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    964\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    965\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    966\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    967\u001B[0m         )\n\u001B[1;32m    968\u001B[0m     )\n\u001B[0;32m--> 970\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    971\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    973\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    974\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    975\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    976\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    977\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    978\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    979\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    980\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    981\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    982\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    983\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    984\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    985\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    986\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    988\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    989\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    990\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    991\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    992\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    993\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/sklearn/utils/parallel.py:77\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     72\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     73\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     74\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     76\u001B[0m )\n\u001B[0;32m---> 77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/joblib/parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[1;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[1;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[1;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[1;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[1;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[1;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/joblib/parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/sklearn/utils/parallel.py:139\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    137\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 139\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:864\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    862\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    863\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y_train \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 864\u001B[0m         \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    865\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    866\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/wrappers.py:65\u001B[0m, in \u001B[0;36mCNNVAEResNetEstimator.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m     61\u001B[0m num_neg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_neg_only_dataset)\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_neg_only_loader \u001B[38;5;241m=\u001B[39m DataLoader(train_neg_only_dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 65\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvae_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_similar_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_neg_only_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmu_multiplier\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmu_multiplier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlog_multiplier\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlogvar_multiplier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_neg\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmultiplier_generated_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgen_dir\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m transform \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[1;32m     74\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mResize((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_size)),\n\u001B[1;32m     75\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mToTensor(),\n\u001B[1;32m     76\u001B[0m ])\n\u001B[1;32m     78\u001B[0m \u001B[38;5;66;03m# 2. Łączymy dwa zbiory  w jeden duży treningowy\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/CNNVAE.py:209\u001B[0m, in \u001B[0;36mCNNVAE.generate_similar_data\u001B[0;34m(self, data, mu_multiplier, log_multiplier, num_samples, output_dir)\u001B[0m\n\u001B[1;32m    206\u001B[0m repeated_batches \u001B[38;5;241m=\u001B[39m itertools\u001B[38;5;241m.\u001B[39mcycle(data)  \u001B[38;5;66;03m# nieskończone batche\u001B[39;00m\n\u001B[1;32m    207\u001B[0m small_images \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 209\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m repeated_batches:\n\u001B[1;32m    210\u001B[0m     images \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(batch, (\u001B[38;5;28mtuple\u001B[39m, \u001B[38;5;28mlist\u001B[39m)) \u001B[38;5;28;01melse\u001B[39;00m batch  \u001B[38;5;66;03m# tylko obrazy\u001B[39;00m\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m img \u001B[38;5;129;01min\u001B[39;00m images:\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/DatasetClasses.py:60\u001B[0m, in \u001B[0;36mNegativeOnlySubset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m---> 60\u001B[0m     img, _\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msamples\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/DatasetClasses.py:44\u001B[0m, in \u001B[0;36mCapsuleDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[1;32m     43\u001B[0m     path, label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples[idx]\n\u001B[0;32m---> 44\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mRGB\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     46\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(img)\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/PIL/Image.py:922\u001B[0m, in \u001B[0;36mImage.convert\u001B[0;34m(self, mode, matrix, dither, palette, colors)\u001B[0m\n\u001B[1;32m    874\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mconvert\u001B[39m(\n\u001B[1;32m    875\u001B[0m     \u001B[38;5;28mself\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, matrix\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dither\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, palette\u001B[38;5;241m=\u001B[39mPalette\u001B[38;5;241m.\u001B[39mWEB, colors\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m\n\u001B[1;32m    876\u001B[0m ):\n\u001B[1;32m    877\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    878\u001B[0m \u001B[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001B[39;00m\n\u001B[1;32m    879\u001B[0m \u001B[38;5;124;03m    method translates pixels through the palette.  If mode is\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    919\u001B[0m \u001B[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001B[39;00m\n\u001B[1;32m    920\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 922\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    924\u001B[0m     has_transparency \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransparency\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\n\u001B[1;32m    925\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mode \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mP\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    926\u001B[0m         \u001B[38;5;66;03m# determine default mode\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ImbalancedDataProject/.venv/lib/python3.9/site-packages/PIL/ImageFile.py:291\u001B[0m, in \u001B[0;36mImageFile.load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    288\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(msg)\n\u001B[1;32m    290\u001B[0m b \u001B[38;5;241m=\u001B[39m b \u001B[38;5;241m+\u001B[39m s\n\u001B[0;32m--> 291\u001B[0m n, err_code \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    293\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CNNGAN: Eksperyment"
   ],
   "id": "7b8b541aeeed5a11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T10:49:56.346416Z",
     "start_time": "2025-05-26T17:49:33.845712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "IMG_SIZE   = 128\n",
    "BATCH_SIZE = 16\n",
    "CHANNELS   = 3\n",
    "CLASSIFIER_EPOCHS = 15\n",
    "OVERSAMPLER_EPOCHS = 250\n",
    "\n",
    "dataset = CapsuleDataset(pos_dir=pos_folder, neg_dirs=neg_folder, transform=transform)\n",
    "print(dataset.__len__())\n",
    "\n",
    "labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(rskf.split(X=np.zeros(len(labels)), y=labels), start=1):\n",
    "    print(f\"===== Fold {fold_idx} =====\")\n",
    "\n",
    "\n",
    "    CnnGan = CNNGANWrapper(dataset,device,BATCH_SIZE,OVERSAMPLER_EPOCHS)\n",
    "\n",
    "    CnnGan.fit(train_idx)\n",
    "\n",
    "\n",
    "    estimator = CNNGANResNetEstimator(\n",
    "        dataset=dataset,\n",
    "        gan_model=CnnGan.gan_model,\n",
    "        device=device,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        classifier_epochs=CLASSIFIER_EPOCHS\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'scale_factor': [0.5, 1, 1.5],  # Czynnik skalujący szum w GAN\n",
    "        'multiplier_generated_samples': [1/2,1, 2]\n",
    "    }\n",
    "\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=6,\n",
    "        cv=None,\n",
    "        verbose=2,\n",
    "        n_jobs=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    random_search.fit(train_idx)\n",
    "\n",
    "    best_estimator = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    test_ds = Subset(dataset, test_idx)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    f2, bal_acc, recall, specificity = best_estimator.trainer.validate(test_loader)\n",
    "    print(f\"Fold {fold_idx} Test Accuracy: {bal_acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'fold': fold_idx,\n",
    "        'f2_score': f2,\n",
    "        'balanced_accuracy': bal_acc,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        **best_params\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Zapis wyników z każdego folda\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('CNNGAN_cross_validation_results.csv', index=False)"
   ],
   "id": "88a95d341f05f041",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n",
      "===== Fold 1 =====\n",
      "Epoch 1: Generator Loss = 10.0291, Discriminator Loss = 8.6379\n",
      "Epoch 2: Generator Loss = 10.9063, Discriminator Loss = 8.2331\n",
      "Epoch 3: Generator Loss = 12.0662, Discriminator Loss = 6.6395\n",
      "Epoch 4: Generator Loss = 18.0754, Discriminator Loss = 5.1761\n",
      "Epoch 5: Generator Loss = 26.0159, Discriminator Loss = 4.0308\n",
      "Epoch 6: Generator Loss = 29.1323, Discriminator Loss = 5.6949\n",
      "Epoch 7: Generator Loss = 24.4812, Discriminator Loss = 4.9665\n",
      "Epoch 8: Generator Loss = 25.7317, Discriminator Loss = 5.7915\n",
      "Epoch 9: Generator Loss = 28.1827, Discriminator Loss = 6.6236\n",
      "Epoch 10: Generator Loss = 21.3980, Discriminator Loss = 7.9283\n",
      "Epoch 11: Generator Loss = 21.2976, Discriminator Loss = 7.0885\n",
      "Epoch 12: Generator Loss = 23.1601, Discriminator Loss = 8.2236\n",
      "Epoch 13: Generator Loss = 21.8036, Discriminator Loss = 8.0966\n",
      "Epoch 14: Generator Loss = 17.0830, Discriminator Loss = 8.8234\n",
      "Epoch 15: Generator Loss = 18.3067, Discriminator Loss = 7.6943\n",
      "Epoch 16: Generator Loss = 19.3916, Discriminator Loss = 9.0201\n",
      "Epoch 17: Generator Loss = 19.1948, Discriminator Loss = 7.7673\n",
      "Epoch 18: Generator Loss = 19.6304, Discriminator Loss = 7.6315\n",
      "Epoch 19: Generator Loss = 16.6848, Discriminator Loss = 8.2855\n",
      "Epoch 20: Generator Loss = 15.3524, Discriminator Loss = 10.4062\n",
      "Epoch 21: Generator Loss = 15.2399, Discriminator Loss = 8.7773\n",
      "Epoch 22: Generator Loss = 15.9068, Discriminator Loss = 9.2248\n",
      "Epoch 23: Generator Loss = 16.5853, Discriminator Loss = 7.4367\n",
      "Epoch 24: Generator Loss = 16.4656, Discriminator Loss = 9.1164\n",
      "Epoch 25: Generator Loss = 16.0853, Discriminator Loss = 7.9322\n",
      "Epoch 26: Generator Loss = 19.8512, Discriminator Loss = 8.3070\n",
      "Epoch 27: Generator Loss = 17.9042, Discriminator Loss = 8.3935\n",
      "Epoch 28: Generator Loss = 13.9610, Discriminator Loss = 7.5902\n",
      "Epoch 29: Generator Loss = 18.2591, Discriminator Loss = 8.7058\n",
      "Epoch 30: Generator Loss = 20.1528, Discriminator Loss = 8.1060\n",
      "Epoch 31: Generator Loss = 17.6074, Discriminator Loss = 7.4509\n",
      "Epoch 32: Generator Loss = 19.0472, Discriminator Loss = 9.4773\n",
      "Epoch 33: Generator Loss = 17.0378, Discriminator Loss = 8.7214\n",
      "Epoch 34: Generator Loss = 16.8691, Discriminator Loss = 8.9727\n",
      "Epoch 35: Generator Loss = 16.8889, Discriminator Loss = 8.1842\n",
      "Epoch 36: Generator Loss = 16.3469, Discriminator Loss = 8.3357\n",
      "Epoch 37: Generator Loss = 19.1201, Discriminator Loss = 7.2696\n",
      "Epoch 38: Generator Loss = 14.9506, Discriminator Loss = 6.3311\n",
      "Epoch 39: Generator Loss = 19.7297, Discriminator Loss = 10.8511\n",
      "Epoch 40: Generator Loss = 16.9679, Discriminator Loss = 7.0461\n",
      "Epoch 41: Generator Loss = 16.6209, Discriminator Loss = 9.1410\n",
      "Epoch 42: Generator Loss = 18.8333, Discriminator Loss = 7.1115\n",
      "Epoch 43: Generator Loss = 18.5253, Discriminator Loss = 8.1634\n",
      "Epoch 44: Generator Loss = 17.7648, Discriminator Loss = 7.1836\n",
      "Epoch 45: Generator Loss = 18.2112, Discriminator Loss = 7.2580\n",
      "Epoch 46: Generator Loss = 19.3766, Discriminator Loss = 12.2904\n",
      "Epoch 47: Generator Loss = 14.4784, Discriminator Loss = 8.1671\n",
      "Epoch 48: Generator Loss = 13.9406, Discriminator Loss = 7.4152\n",
      "Epoch 49: Generator Loss = 16.8369, Discriminator Loss = 7.9070\n",
      "Epoch 50: Generator Loss = 21.1283, Discriminator Loss = 8.0550\n",
      "Epoch 51: Generator Loss = 13.6527, Discriminator Loss = 7.3488\n",
      "Epoch 52: Generator Loss = 21.5009, Discriminator Loss = 7.5095\n",
      "Epoch 53: Generator Loss = 16.5334, Discriminator Loss = 8.2896\n",
      "Epoch 54: Generator Loss = 20.5549, Discriminator Loss = 6.4749\n",
      "Epoch 55: Generator Loss = 20.7750, Discriminator Loss = 5.7902\n",
      "Epoch 56: Generator Loss = 20.1530, Discriminator Loss = 9.1446\n",
      "Epoch 57: Generator Loss = 18.4661, Discriminator Loss = 7.9743\n",
      "Epoch 58: Generator Loss = 18.8500, Discriminator Loss = 6.2726\n",
      "Epoch 59: Generator Loss = 21.9329, Discriminator Loss = 8.1498\n",
      "Epoch 60: Generator Loss = 18.8770, Discriminator Loss = 7.7439\n",
      "Epoch 61: Generator Loss = 18.9866, Discriminator Loss = 6.7179\n",
      "Epoch 62: Generator Loss = 23.4924, Discriminator Loss = 6.1639\n",
      "Epoch 63: Generator Loss = 20.0505, Discriminator Loss = 5.3405\n",
      "Epoch 64: Generator Loss = 28.1419, Discriminator Loss = 4.7471\n",
      "Epoch 65: Generator Loss = 27.5872, Discriminator Loss = 4.3863\n",
      "Epoch 66: Generator Loss = 31.5909, Discriminator Loss = 4.1108\n",
      "Epoch 67: Generator Loss = 31.1339, Discriminator Loss = 11.3530\n",
      "Epoch 68: Generator Loss = 21.0987, Discriminator Loss = 7.0311\n",
      "Epoch 69: Generator Loss = 22.4194, Discriminator Loss = 6.0259\n",
      "Epoch 70: Generator Loss = 25.8576, Discriminator Loss = 6.8951\n",
      "Epoch 71: Generator Loss = 24.0843, Discriminator Loss = 5.1304\n",
      "Epoch 72: Generator Loss = 27.3905, Discriminator Loss = 4.9616\n",
      "Epoch 73: Generator Loss = 27.6652, Discriminator Loss = 4.6553\n",
      "Epoch 74: Generator Loss = 32.4322, Discriminator Loss = 3.6535\n",
      "Epoch 75: Generator Loss = 32.7488, Discriminator Loss = 5.1302\n",
      "Epoch 76: Generator Loss = 32.4674, Discriminator Loss = 5.6472\n",
      "Epoch 77: Generator Loss = 28.7521, Discriminator Loss = 5.1432\n",
      "Epoch 78: Generator Loss = 29.1873, Discriminator Loss = 3.8945\n",
      "Epoch 79: Generator Loss = 30.2595, Discriminator Loss = 4.9868\n",
      "Epoch 80: Generator Loss = 36.1372, Discriminator Loss = 3.8407\n",
      "Epoch 81: Generator Loss = 32.9218, Discriminator Loss = 4.4051\n",
      "Epoch 82: Generator Loss = 36.5432, Discriminator Loss = 5.9359\n",
      "Epoch 83: Generator Loss = 35.8872, Discriminator Loss = 4.2004\n",
      "Epoch 84: Generator Loss = 37.8095, Discriminator Loss = 3.3580\n",
      "Epoch 85: Generator Loss = 35.0965, Discriminator Loss = 4.1616\n",
      "Epoch 86: Generator Loss = 35.6297, Discriminator Loss = 6.0030\n",
      "Epoch 87: Generator Loss = 32.9931, Discriminator Loss = 5.0699\n",
      "Epoch 88: Generator Loss = 36.7699, Discriminator Loss = 4.8719\n",
      "Epoch 89: Generator Loss = 38.0583, Discriminator Loss = 4.2570\n",
      "Epoch 90: Generator Loss = 48.0069, Discriminator Loss = 3.3524\n",
      "Epoch 91: Generator Loss = 42.8238, Discriminator Loss = 3.0443\n",
      "Epoch 92: Generator Loss = 29.2024, Discriminator Loss = 7.1283\n",
      "Epoch 93: Generator Loss = 38.5334, Discriminator Loss = 4.3085\n",
      "Epoch 94: Generator Loss = 42.2749, Discriminator Loss = 3.5006\n",
      "Epoch 95: Generator Loss = 50.5624, Discriminator Loss = 3.2437\n",
      "Epoch 96: Generator Loss = 12.3780, Discriminator Loss = 11.7616\n",
      "Epoch 97: Generator Loss = 11.8583, Discriminator Loss = 10.0420\n",
      "Epoch 98: Generator Loss = 14.3234, Discriminator Loss = 8.0034\n",
      "Epoch 99: Generator Loss = 22.8891, Discriminator Loss = 6.6091\n",
      "Epoch 100: Generator Loss = 28.3331, Discriminator Loss = 5.1046\n",
      "Epoch 101: Generator Loss = 35.4729, Discriminator Loss = 6.4352\n",
      "Epoch 102: Generator Loss = 40.3243, Discriminator Loss = 3.5146\n",
      "Epoch 103: Generator Loss = 45.1866, Discriminator Loss = 3.6458\n",
      "Epoch 104: Generator Loss = 40.0654, Discriminator Loss = 2.5781\n",
      "Epoch 105: Generator Loss = 57.2883, Discriminator Loss = 2.3476\n",
      "Epoch 106: Generator Loss = 46.1058, Discriminator Loss = 4.4255\n",
      "Epoch 107: Generator Loss = 44.1551, Discriminator Loss = 3.2458\n",
      "Epoch 108: Generator Loss = 32.7664, Discriminator Loss = 3.6062\n",
      "Epoch 109: Generator Loss = 52.4113, Discriminator Loss = 4.3091\n",
      "Epoch 110: Generator Loss = 46.7222, Discriminator Loss = 2.2292\n",
      "Epoch 111: Generator Loss = 51.9352, Discriminator Loss = 2.5948\n",
      "Epoch 112: Generator Loss = 40.3609, Discriminator Loss = 4.3825\n",
      "Epoch 113: Generator Loss = 50.9004, Discriminator Loss = 3.1361\n",
      "Epoch 114: Generator Loss = 52.6861, Discriminator Loss = 2.4273\n",
      "Epoch 115: Generator Loss = 49.8529, Discriminator Loss = 1.9588\n",
      "Epoch 116: Generator Loss = 51.5143, Discriminator Loss = 1.4007\n",
      "Epoch 117: Generator Loss = 51.8693, Discriminator Loss = 1.5176\n",
      "Epoch 118: Generator Loss = 49.8596, Discriminator Loss = 2.1688\n",
      "Epoch 119: Generator Loss = 59.0004, Discriminator Loss = 1.4691\n",
      "Epoch 120: Generator Loss = 48.6906, Discriminator Loss = 3.9582\n",
      "Epoch 121: Generator Loss = 60.1579, Discriminator Loss = 1.3322\n",
      "Epoch 122: Generator Loss = 54.9905, Discriminator Loss = 1.6592\n",
      "Epoch 123: Generator Loss = 47.1226, Discriminator Loss = 3.3697\n",
      "Epoch 124: Generator Loss = 48.9613, Discriminator Loss = 4.9381\n",
      "Epoch 125: Generator Loss = 48.7819, Discriminator Loss = 3.6559\n",
      "Epoch 126: Generator Loss = 53.7714, Discriminator Loss = 2.7771\n",
      "Epoch 127: Generator Loss = 41.6835, Discriminator Loss = 2.3014\n",
      "Epoch 128: Generator Loss = 61.6533, Discriminator Loss = 2.8660\n",
      "Epoch 129: Generator Loss = 51.8698, Discriminator Loss = 1.9763\n",
      "Epoch 130: Generator Loss = 51.9292, Discriminator Loss = 1.6386\n",
      "Epoch 131: Generator Loss = 61.4722, Discriminator Loss = 1.8228\n",
      "Epoch 132: Generator Loss = 41.4877, Discriminator Loss = 6.9487\n",
      "Epoch 133: Generator Loss = 52.2326, Discriminator Loss = 3.0655\n",
      "Epoch 134: Generator Loss = 40.1168, Discriminator Loss = 1.9162\n",
      "Epoch 135: Generator Loss = 62.1432, Discriminator Loss = 1.1868\n",
      "Epoch 136: Generator Loss = 58.7771, Discriminator Loss = 1.6487\n",
      "Epoch 137: Generator Loss = 48.9236, Discriminator Loss = 1.4749\n",
      "Epoch 138: Generator Loss = 54.1173, Discriminator Loss = 1.2662\n",
      "Epoch 139: Generator Loss = 61.9448, Discriminator Loss = 1.8370\n",
      "Epoch 140: Generator Loss = 60.2009, Discriminator Loss = 1.0826\n",
      "Epoch 141: Generator Loss = 60.4966, Discriminator Loss = 1.2344\n",
      "Epoch 142: Generator Loss = 75.5053, Discriminator Loss = 0.8517\n",
      "Epoch 143: Generator Loss = 65.6845, Discriminator Loss = 1.5758\n",
      "Epoch 144: Generator Loss = 63.4822, Discriminator Loss = 1.6132\n",
      "Epoch 145: Generator Loss = 58.4563, Discriminator Loss = 2.1266\n",
      "Epoch 146: Generator Loss = 76.4977, Discriminator Loss = 1.6940\n",
      "Epoch 147: Generator Loss = 53.4557, Discriminator Loss = 2.4648\n",
      "Epoch 148: Generator Loss = 65.8842, Discriminator Loss = 2.0699\n",
      "Epoch 149: Generator Loss = 54.3973, Discriminator Loss = 2.2569\n",
      "Epoch 150: Generator Loss = 63.0147, Discriminator Loss = 7.9915\n",
      "Epoch 151: Generator Loss = 24.7438, Discriminator Loss = 8.6090\n",
      "Epoch 152: Generator Loss = 35.2005, Discriminator Loss = 5.2262\n",
      "Epoch 153: Generator Loss = 48.3543, Discriminator Loss = 3.1968\n",
      "Epoch 154: Generator Loss = 55.6339, Discriminator Loss = 2.8744\n",
      "Epoch 155: Generator Loss = 53.2493, Discriminator Loss = 4.3478\n",
      "Epoch 156: Generator Loss = 44.7230, Discriminator Loss = 3.6824\n",
      "Epoch 157: Generator Loss = 67.8067, Discriminator Loss = 1.4879\n",
      "Epoch 158: Generator Loss = 54.3502, Discriminator Loss = 1.6667\n",
      "Epoch 159: Generator Loss = 64.6365, Discriminator Loss = 1.6168\n",
      "Epoch 160: Generator Loss = 52.0302, Discriminator Loss = 4.1322\n",
      "Epoch 161: Generator Loss = 78.1704, Discriminator Loss = 1.8719\n",
      "Epoch 162: Generator Loss = 56.1404, Discriminator Loss = 0.7598\n",
      "Epoch 163: Generator Loss = 69.4329, Discriminator Loss = 1.4692\n",
      "Epoch 164: Generator Loss = 65.7096, Discriminator Loss = 1.2861\n",
      "Epoch 165: Generator Loss = 76.9651, Discriminator Loss = 0.5982\n",
      "Epoch 166: Generator Loss = 81.3091, Discriminator Loss = 0.7986\n",
      "Epoch 167: Generator Loss = 70.3623, Discriminator Loss = 0.8454\n",
      "Epoch 168: Generator Loss = 64.7378, Discriminator Loss = 0.7972\n",
      "Epoch 169: Generator Loss = 66.5526, Discriminator Loss = 0.8080\n",
      "Epoch 170: Generator Loss = 83.2098, Discriminator Loss = 0.8359\n",
      "Epoch 171: Generator Loss = 70.9247, Discriminator Loss = 0.8089\n",
      "Epoch 172: Generator Loss = 73.4227, Discriminator Loss = 0.5180\n",
      "Epoch 173: Generator Loss = 114.5216, Discriminator Loss = 0.2605\n",
      "Epoch 174: Generator Loss = 104.5914, Discriminator Loss = 0.3099\n",
      "Epoch 175: Generator Loss = 106.4037, Discriminator Loss = 0.5151\n",
      "Epoch 176: Generator Loss = 96.0649, Discriminator Loss = 0.4154\n",
      "Epoch 177: Generator Loss = 71.2942, Discriminator Loss = 1.5424\n",
      "Epoch 178: Generator Loss = 78.1360, Discriminator Loss = 3.4897\n",
      "Epoch 179: Generator Loss = 73.1644, Discriminator Loss = 1.0580\n",
      "Epoch 180: Generator Loss = 68.9123, Discriminator Loss = 1.3120\n",
      "Epoch 181: Generator Loss = 79.7170, Discriminator Loss = 1.8683\n",
      "Epoch 182: Generator Loss = 91.3320, Discriminator Loss = 1.6892\n",
      "Epoch 183: Generator Loss = 66.4409, Discriminator Loss = 2.4433\n",
      "Epoch 184: Generator Loss = 80.4201, Discriminator Loss = 0.7560\n",
      "Epoch 185: Generator Loss = 83.5219, Discriminator Loss = 0.9098\n",
      "Epoch 186: Generator Loss = 71.1780, Discriminator Loss = 1.0553\n",
      "Epoch 187: Generator Loss = 81.3404, Discriminator Loss = 0.7634\n",
      "Epoch 188: Generator Loss = 79.2754, Discriminator Loss = 0.7241\n",
      "Epoch 189: Generator Loss = 78.8427, Discriminator Loss = 0.4973\n",
      "Epoch 190: Generator Loss = 70.6753, Discriminator Loss = 0.6366\n",
      "Epoch 191: Generator Loss = 71.8071, Discriminator Loss = 0.9083\n",
      "Epoch 192: Generator Loss = 68.5795, Discriminator Loss = 0.5123\n",
      "Epoch 193: Generator Loss = 78.3105, Discriminator Loss = 0.5428\n",
      "Epoch 194: Generator Loss = 75.0759, Discriminator Loss = 1.1801\n",
      "Epoch 195: Generator Loss = 78.3794, Discriminator Loss = 0.9140\n",
      "Epoch 196: Generator Loss = 86.5919, Discriminator Loss = 0.5304\n",
      "Epoch 197: Generator Loss = 74.6024, Discriminator Loss = 0.5505\n",
      "Epoch 198: Generator Loss = 93.4105, Discriminator Loss = 1.3759\n",
      "Epoch 199: Generator Loss = 66.2688, Discriminator Loss = 0.9437\n",
      "Epoch 200: Generator Loss = 77.3356, Discriminator Loss = 3.6818\n",
      "Epoch 201: Generator Loss = 70.6971, Discriminator Loss = 1.3541\n",
      "Epoch 202: Generator Loss = 74.7146, Discriminator Loss = 0.7123\n",
      "Epoch 203: Generator Loss = 78.2113, Discriminator Loss = 1.5233\n",
      "Epoch 204: Generator Loss = 65.1930, Discriminator Loss = 1.2352\n",
      "Epoch 205: Generator Loss = 68.4175, Discriminator Loss = 1.4660\n",
      "Epoch 206: Generator Loss = 88.3568, Discriminator Loss = 1.4479\n",
      "Epoch 207: Generator Loss = 85.7978, Discriminator Loss = 1.6402\n",
      "Epoch 208: Generator Loss = 83.2316, Discriminator Loss = 0.6183\n",
      "Epoch 209: Generator Loss = 90.7727, Discriminator Loss = 0.8830\n",
      "Epoch 210: Generator Loss = 88.1043, Discriminator Loss = 1.1542\n",
      "Epoch 211: Generator Loss = 91.1302, Discriminator Loss = 1.0328\n",
      "Epoch 212: Generator Loss = 76.5977, Discriminator Loss = 0.7506\n",
      "Epoch 213: Generator Loss = 83.8899, Discriminator Loss = 0.6322\n",
      "Epoch 214: Generator Loss = 83.7273, Discriminator Loss = 1.2854\n",
      "Epoch 215: Generator Loss = 71.6670, Discriminator Loss = 1.3671\n",
      "Epoch 216: Generator Loss = 82.1451, Discriminator Loss = 1.7297\n",
      "Epoch 217: Generator Loss = 86.6646, Discriminator Loss = 2.1248\n",
      "Epoch 218: Generator Loss = 83.9280, Discriminator Loss = 2.5697\n",
      "Epoch 219: Generator Loss = 69.5305, Discriminator Loss = 2.6021\n",
      "Epoch 220: Generator Loss = 86.5464, Discriminator Loss = 1.3548\n",
      "Epoch 221: Generator Loss = 72.2822, Discriminator Loss = 1.1538\n",
      "Epoch 222: Generator Loss = 85.4985, Discriminator Loss = 1.5485\n",
      "Epoch 223: Generator Loss = 80.9024, Discriminator Loss = 2.0488\n",
      "Epoch 224: Generator Loss = 94.7851, Discriminator Loss = 1.8967\n",
      "Epoch 225: Generator Loss = 74.2951, Discriminator Loss = 8.2955\n",
      "Epoch 226: Generator Loss = 29.3526, Discriminator Loss = 11.7863\n",
      "Epoch 227: Generator Loss = 63.4707, Discriminator Loss = 5.8986\n",
      "Epoch 228: Generator Loss = 69.7708, Discriminator Loss = 3.2241\n",
      "Epoch 229: Generator Loss = 66.5578, Discriminator Loss = 1.6726\n",
      "Epoch 230: Generator Loss = 61.9708, Discriminator Loss = 1.0125\n",
      "Epoch 231: Generator Loss = 65.7118, Discriminator Loss = 1.9548\n",
      "Epoch 232: Generator Loss = 74.2610, Discriminator Loss = 1.2243\n",
      "Epoch 233: Generator Loss = 56.1195, Discriminator Loss = 1.1964\n",
      "Epoch 234: Generator Loss = 79.8309, Discriminator Loss = 1.4553\n",
      "Epoch 235: Generator Loss = 73.0790, Discriminator Loss = 1.7836\n",
      "Epoch 236: Generator Loss = 72.3398, Discriminator Loss = 1.0321\n",
      "Epoch 237: Generator Loss = 84.3829, Discriminator Loss = 1.5753\n",
      "Epoch 238: Generator Loss = 76.9978, Discriminator Loss = 2.5971\n",
      "Epoch 239: Generator Loss = 69.9053, Discriminator Loss = 2.9269\n",
      "Epoch 240: Generator Loss = 69.2443, Discriminator Loss = 1.7183\n",
      "Epoch 241: Generator Loss = 66.8700, Discriminator Loss = 1.7170\n",
      "Epoch 242: Generator Loss = 64.8145, Discriminator Loss = 1.5079\n",
      "Epoch 243: Generator Loss = 66.7059, Discriminator Loss = 1.8336\n",
      "Epoch 244: Generator Loss = 64.6585, Discriminator Loss = 1.4483\n",
      "Epoch 245: Generator Loss = 64.2867, Discriminator Loss = 1.9974\n",
      "Epoch 246: Generator Loss = 76.8031, Discriminator Loss = 1.1350\n",
      "Epoch 247: Generator Loss = 84.3942, Discriminator Loss = 1.0150\n",
      "Epoch 248: Generator Loss = 76.6873, Discriminator Loss = 0.5110\n",
      "Epoch 249: Generator Loss = 93.3489, Discriminator Loss = 0.7930\n",
      "Epoch 250: Generator Loss = 74.8434, Discriminator Loss = 1.2886\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Epoch 1/15 | Train Loss: 0.4851 Acc: 0.7650\n",
      "Epoch 2/15 | Train Loss: 0.4148 Acc: 0.7859\n",
      "Epoch 3/15 | Train Loss: 0.3763 Acc: 0.7859\n",
      "Epoch 4/15 | Train Loss: 0.3335 Acc: 0.8251\n",
      "Epoch 5/15 | Train Loss: 0.3206 Acc: 0.8329\n",
      "Epoch 6/15 | Train Loss: 0.2955 Acc: 0.8616\n",
      "Epoch 7/15 | Train Loss: 0.3812 Acc: 0.8329\n",
      "Epoch 8/15 | Train Loss: 0.2793 Acc: 0.8538\n",
      "Epoch 9/15 | Train Loss: 0.2930 Acc: 0.8486\n",
      "Epoch 10/15 | Train Loss: 0.2928 Acc: 0.8642\n",
      "Epoch 11/15 | Train Loss: 0.2657 Acc: 0.8616\n",
      "Epoch 12/15 | Train Loss: 0.2468 Acc: 0.8877\n",
      "Epoch 13/15 | Train Loss: 0.2640 Acc: 0.8877\n",
      "Epoch 14/15 | Train Loss: 0.2644 Acc: 0.8721\n",
      "Epoch 15/15 | Train Loss: 0.2656 Acc: 0.8642\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 3.0min\n",
      "Epoch 1/15 | Train Loss: 0.5919 Acc: 0.7598\n",
      "Epoch 2/15 | Train Loss: 0.4412 Acc: 0.7520\n",
      "Epoch 3/15 | Train Loss: 0.3866 Acc: 0.8172\n",
      "Epoch 4/15 | Train Loss: 0.3979 Acc: 0.7807\n",
      "Epoch 5/15 | Train Loss: 0.3915 Acc: 0.8042\n",
      "Epoch 6/15 | Train Loss: 0.3171 Acc: 0.8433\n",
      "Epoch 7/15 | Train Loss: 0.3354 Acc: 0.8225\n",
      "Epoch 8/15 | Train Loss: 0.3301 Acc: 0.8381\n",
      "Epoch 9/15 | Train Loss: 0.3104 Acc: 0.8433\n",
      "Epoch 10/15 | Train Loss: 0.3138 Acc: 0.8460\n",
      "Epoch 11/15 | Train Loss: 0.2960 Acc: 0.8329\n",
      "Epoch 12/15 | Train Loss: 0.3088 Acc: 0.8355\n",
      "Epoch 13/15 | Train Loss: 0.2934 Acc: 0.8590\n",
      "Epoch 14/15 | Train Loss: 0.2992 Acc: 0.8538\n",
      "Epoch 15/15 | Train Loss: 0.2646 Acc: 0.8747\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5347 Acc: 0.7292\n",
      "Epoch 2/15 | Train Loss: 0.3859 Acc: 0.7917\n",
      "Epoch 3/15 | Train Loss: 0.3994 Acc: 0.7630\n",
      "Epoch 4/15 | Train Loss: 0.3940 Acc: 0.7656\n",
      "Epoch 5/15 | Train Loss: 0.3349 Acc: 0.8229\n",
      "Epoch 6/15 | Train Loss: 0.3720 Acc: 0.7995\n",
      "Epoch 7/15 | Train Loss: 0.3274 Acc: 0.8073\n",
      "Epoch 8/15 | Train Loss: 0.3205 Acc: 0.8151\n",
      "Epoch 9/15 | Train Loss: 0.3296 Acc: 0.8411\n",
      "Epoch 10/15 | Train Loss: 0.2868 Acc: 0.8646\n",
      "Epoch 11/15 | Train Loss: 0.3109 Acc: 0.8411\n",
      "Epoch 12/15 | Train Loss: 0.3170 Acc: 0.8542\n",
      "Epoch 13/15 | Train Loss: 0.2915 Acc: 0.8646\n",
      "Epoch 14/15 | Train Loss: 0.2945 Acc: 0.8516\n",
      "Epoch 15/15 | Train Loss: 0.2824 Acc: 0.8620\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5520 Acc: 0.8089\n",
      "Epoch 2/15 | Train Loss: 0.4351 Acc: 0.7994\n",
      "Epoch 3/15 | Train Loss: 0.4757 Acc: 0.8089\n",
      "Epoch 4/15 | Train Loss: 0.4212 Acc: 0.8185\n",
      "Epoch 5/15 | Train Loss: 0.3869 Acc: 0.8217\n",
      "Epoch 6/15 | Train Loss: 0.3234 Acc: 0.8599\n",
      "Epoch 7/15 | Train Loss: 0.3316 Acc: 0.8599\n",
      "Epoch 8/15 | Train Loss: 0.3152 Acc: 0.8439\n",
      "Epoch 9/15 | Train Loss: 0.3015 Acc: 0.8662\n",
      "Epoch 10/15 | Train Loss: 0.3125 Acc: 0.8662\n",
      "Epoch 11/15 | Train Loss: 0.3342 Acc: 0.8535\n",
      "Epoch 12/15 | Train Loss: 0.2810 Acc: 0.8790\n",
      "Epoch 13/15 | Train Loss: 0.2788 Acc: 0.8949\n",
      "Epoch 14/15 | Train Loss: 0.2824 Acc: 0.8726\n",
      "Epoch 15/15 | Train Loss: 0.3101 Acc: 0.8790\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.4316 Acc: 0.8429\n",
      "Epoch 2/15 | Train Loss: 0.3907 Acc: 0.8393\n",
      "Epoch 3/15 | Train Loss: 0.3962 Acc: 0.8536\n",
      "Epoch 4/15 | Train Loss: 0.3306 Acc: 0.9000\n",
      "Epoch 5/15 | Train Loss: 0.3207 Acc: 0.8714\n",
      "Epoch 6/15 | Train Loss: 0.3150 Acc: 0.8786\n",
      "Epoch 7/15 | Train Loss: 0.3159 Acc: 0.8821\n",
      "Epoch 8/15 | Train Loss: 0.2695 Acc: 0.8964\n",
      "Epoch 9/15 | Train Loss: 0.2753 Acc: 0.8750\n",
      "Epoch 10/15 | Train Loss: 0.2573 Acc: 0.9071\n",
      "Epoch 11/15 | Train Loss: 0.2593 Acc: 0.9143\n",
      "Epoch 12/15 | Train Loss: 0.2311 Acc: 0.9071\n",
      "Epoch 13/15 | Train Loss: 0.2469 Acc: 0.8964\n",
      "Epoch 14/15 | Train Loss: 0.2215 Acc: 0.8821\n",
      "Epoch 15/15 | Train Loss: 0.1933 Acc: 0.9107\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6571 Acc: 0.6151\n",
      "Epoch 2/15 | Train Loss: 0.6205 Acc: 0.6667\n",
      "Epoch 3/15 | Train Loss: 0.5510 Acc: 0.7222\n",
      "Epoch 4/15 | Train Loss: 0.5119 Acc: 0.7579\n",
      "Epoch 5/15 | Train Loss: 0.5176 Acc: 0.7341\n",
      "Epoch 6/15 | Train Loss: 0.4511 Acc: 0.7738\n",
      "Epoch 7/15 | Train Loss: 0.4164 Acc: 0.8016\n",
      "Epoch 8/15 | Train Loss: 0.4093 Acc: 0.7857\n",
      "Epoch 9/15 | Train Loss: 0.3935 Acc: 0.8016\n",
      "Epoch 10/15 | Train Loss: 0.3899 Acc: 0.8056\n",
      "Epoch 11/15 | Train Loss: 0.3620 Acc: 0.8214\n",
      "Epoch 12/15 | Train Loss: 0.3701 Acc: 0.8373\n",
      "Epoch 13/15 | Train Loss: 0.3656 Acc: 0.8254\n",
      "Epoch 14/15 | Train Loss: 0.3612 Acc: 0.8413\n",
      "Epoch 15/15 | Train Loss: 0.3804 Acc: 0.8135\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6636 Acc: 0.6429\n",
      "Epoch 2/15 | Train Loss: 0.5983 Acc: 0.6825\n",
      "Epoch 3/15 | Train Loss: 0.5917 Acc: 0.6468\n",
      "Epoch 4/15 | Train Loss: 0.5779 Acc: 0.6587\n",
      "Epoch 5/15 | Train Loss: 0.5198 Acc: 0.7143\n",
      "Epoch 6/15 | Train Loss: 0.5283 Acc: 0.7262\n",
      "Epoch 7/15 | Train Loss: 0.5107 Acc: 0.7103\n",
      "Epoch 8/15 | Train Loss: 0.4590 Acc: 0.7659\n",
      "Epoch 9/15 | Train Loss: 0.4271 Acc: 0.7897\n",
      "Epoch 10/15 | Train Loss: 0.4437 Acc: 0.7817\n",
      "Epoch 11/15 | Train Loss: 0.4238 Acc: 0.7976\n",
      "Epoch 12/15 | Train Loss: 0.4261 Acc: 0.8056\n",
      "Epoch 13/15 | Train Loss: 0.4156 Acc: 0.8056\n",
      "Epoch 14/15 | Train Loss: 0.3854 Acc: 0.8333\n",
      "Epoch 15/15 | Train Loss: 0.4011 Acc: 0.7937\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7081 Acc: 0.6364\n",
      "Epoch 2/15 | Train Loss: 0.5930 Acc: 0.6957\n",
      "Epoch 3/15 | Train Loss: 0.5308 Acc: 0.7273\n",
      "Epoch 4/15 | Train Loss: 0.5646 Acc: 0.6917\n",
      "Epoch 5/15 | Train Loss: 0.5964 Acc: 0.6719\n",
      "Epoch 6/15 | Train Loss: 0.4820 Acc: 0.7747\n",
      "Epoch 7/15 | Train Loss: 0.4887 Acc: 0.7431\n",
      "Epoch 8/15 | Train Loss: 0.4261 Acc: 0.7787\n",
      "Epoch 9/15 | Train Loss: 0.5119 Acc: 0.7628\n",
      "Epoch 10/15 | Train Loss: 0.4026 Acc: 0.7905\n",
      "Epoch 11/15 | Train Loss: 0.4162 Acc: 0.7984\n",
      "Epoch 12/15 | Train Loss: 0.4184 Acc: 0.7826\n",
      "Epoch 13/15 | Train Loss: 0.4279 Acc: 0.7866\n",
      "Epoch 14/15 | Train Loss: 0.4370 Acc: 0.7866\n",
      "Epoch 15/15 | Train Loss: 0.4976 Acc: 0.7628\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6591 Acc: 0.6992\n",
      "Epoch 2/15 | Train Loss: 0.5670 Acc: 0.7754\n",
      "Epoch 3/15 | Train Loss: 0.4700 Acc: 0.8093\n",
      "Epoch 4/15 | Train Loss: 0.5137 Acc: 0.7754\n",
      "Epoch 5/15 | Train Loss: 0.5187 Acc: 0.7627\n",
      "Epoch 6/15 | Train Loss: 0.4493 Acc: 0.7881\n",
      "Epoch 7/15 | Train Loss: 0.4360 Acc: 0.7966\n",
      "Epoch 8/15 | Train Loss: 0.3952 Acc: 0.8475\n",
      "Epoch 9/15 | Train Loss: 0.4303 Acc: 0.8220\n",
      "Epoch 10/15 | Train Loss: 0.4279 Acc: 0.8008\n",
      "Epoch 11/15 | Train Loss: 0.4154 Acc: 0.8051\n",
      "Epoch 12/15 | Train Loss: 0.3927 Acc: 0.8475\n",
      "Epoch 13/15 | Train Loss: 0.4024 Acc: 0.8051\n",
      "Epoch 14/15 | Train Loss: 0.4069 Acc: 0.8220\n",
      "Epoch 15/15 | Train Loss: 0.4319 Acc: 0.8051\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.8588 Acc: 0.5595\n",
      "Epoch 2/15 | Train Loss: 0.5691 Acc: 0.7753\n",
      "Epoch 3/15 | Train Loss: 0.4434 Acc: 0.8150\n",
      "Epoch 4/15 | Train Loss: 0.3616 Acc: 0.8634\n",
      "Epoch 5/15 | Train Loss: 0.3595 Acc: 0.8458\n",
      "Epoch 6/15 | Train Loss: 0.3934 Acc: 0.8458\n",
      "Epoch 7/15 | Train Loss: 0.3633 Acc: 0.8590\n",
      "Epoch 8/15 | Train Loss: 0.3343 Acc: 0.8722\n",
      "Epoch 9/15 | Train Loss: 0.3213 Acc: 0.8722\n",
      "Epoch 10/15 | Train Loss: 0.3100 Acc: 0.8767\n",
      "Epoch 11/15 | Train Loss: 0.2973 Acc: 0.8811\n",
      "Epoch 12/15 | Train Loss: 0.3093 Acc: 0.8855\n",
      "Epoch 13/15 | Train Loss: 0.2898 Acc: 0.8899\n",
      "Epoch 14/15 | Train Loss: 0.2915 Acc: 0.8811\n",
      "Epoch 15/15 | Train Loss: 0.2856 Acc: 0.8943\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6251 Acc: 0.6723\n",
      "Epoch 2/15 | Train Loss: 0.4784 Acc: 0.7297\n",
      "Epoch 3/15 | Train Loss: 0.4646 Acc: 0.7635\n",
      "Epoch 4/15 | Train Loss: 0.4204 Acc: 0.7973\n",
      "Epoch 5/15 | Train Loss: 0.4336 Acc: 0.7905\n",
      "Epoch 6/15 | Train Loss: 0.4176 Acc: 0.7905\n",
      "Epoch 7/15 | Train Loss: 0.3669 Acc: 0.8311\n",
      "Epoch 8/15 | Train Loss: 0.3480 Acc: 0.8209\n",
      "Epoch 9/15 | Train Loss: 0.2908 Acc: 0.8919\n",
      "Epoch 10/15 | Train Loss: 0.3310 Acc: 0.8480\n",
      "Epoch 11/15 | Train Loss: 0.3221 Acc: 0.8446\n",
      "Epoch 12/15 | Train Loss: 0.3607 Acc: 0.8345\n",
      "Epoch 13/15 | Train Loss: 0.3013 Acc: 0.8547\n",
      "Epoch 14/15 | Train Loss: 0.2774 Acc: 0.8682\n",
      "Epoch 15/15 | Train Loss: 0.3084 Acc: 0.8615\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6142 Acc: 0.6824\n",
      "Epoch 2/15 | Train Loss: 0.5735 Acc: 0.7162\n",
      "Epoch 3/15 | Train Loss: 0.5237 Acc: 0.7365\n",
      "Epoch 4/15 | Train Loss: 0.4395 Acc: 0.7703\n",
      "Epoch 5/15 | Train Loss: 0.4147 Acc: 0.7905\n",
      "Epoch 6/15 | Train Loss: 0.4785 Acc: 0.7399\n",
      "Epoch 7/15 | Train Loss: 0.4261 Acc: 0.7703\n",
      "Epoch 8/15 | Train Loss: 0.3897 Acc: 0.7872\n",
      "Epoch 9/15 | Train Loss: 0.3814 Acc: 0.8007\n",
      "Epoch 10/15 | Train Loss: 0.3844 Acc: 0.7973\n",
      "Epoch 11/15 | Train Loss: 0.4127 Acc: 0.7838\n",
      "Epoch 12/15 | Train Loss: 0.3223 Acc: 0.8750\n",
      "Epoch 13/15 | Train Loss: 0.3748 Acc: 0.8108\n",
      "Epoch 14/15 | Train Loss: 0.3400 Acc: 0.8345\n",
      "Epoch 15/15 | Train Loss: 0.3672 Acc: 0.8311\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6431 Acc: 0.6633\n",
      "Epoch 2/15 | Train Loss: 0.5243 Acc: 0.7104\n",
      "Epoch 3/15 | Train Loss: 0.4615 Acc: 0.7778\n",
      "Epoch 4/15 | Train Loss: 0.4619 Acc: 0.7576\n",
      "Epoch 5/15 | Train Loss: 0.4571 Acc: 0.7609\n",
      "Epoch 6/15 | Train Loss: 0.4155 Acc: 0.8047\n",
      "Epoch 7/15 | Train Loss: 0.4769 Acc: 0.7542\n",
      "Epoch 8/15 | Train Loss: 0.3866 Acc: 0.7946\n",
      "Epoch 9/15 | Train Loss: 0.3757 Acc: 0.7845\n",
      "Epoch 10/15 | Train Loss: 0.3424 Acc: 0.8485\n",
      "Epoch 11/15 | Train Loss: 0.3775 Acc: 0.8081\n",
      "Epoch 12/15 | Train Loss: 0.3444 Acc: 0.8249\n",
      "Epoch 13/15 | Train Loss: 0.3376 Acc: 0.8451\n",
      "Epoch 14/15 | Train Loss: 0.3857 Acc: 0.8182\n",
      "Epoch 15/15 | Train Loss: 0.3745 Acc: 0.8081\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5769 Acc: 0.7328\n",
      "Epoch 2/15 | Train Loss: 0.4602 Acc: 0.7977\n",
      "Epoch 3/15 | Train Loss: 0.4846 Acc: 0.7366\n",
      "Epoch 4/15 | Train Loss: 0.4861 Acc: 0.7939\n",
      "Epoch 5/15 | Train Loss: 0.4859 Acc: 0.7977\n",
      "Epoch 6/15 | Train Loss: 0.4462 Acc: 0.7824\n",
      "Epoch 7/15 | Train Loss: 0.4554 Acc: 0.7977\n",
      "Epoch 8/15 | Train Loss: 0.4162 Acc: 0.8015\n",
      "Epoch 9/15 | Train Loss: 0.3238 Acc: 0.8550\n",
      "Epoch 10/15 | Train Loss: 0.3520 Acc: 0.8397\n",
      "Epoch 11/15 | Train Loss: 0.3788 Acc: 0.8282\n",
      "Epoch 12/15 | Train Loss: 0.3519 Acc: 0.8740\n",
      "Epoch 13/15 | Train Loss: 0.3174 Acc: 0.8664\n",
      "Epoch 14/15 | Train Loss: 0.3404 Acc: 0.8435\n",
      "Epoch 15/15 | Train Loss: 0.3186 Acc: 0.8626\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5391 Acc: 0.7224\n",
      "Epoch 2/15 | Train Loss: 0.4771 Acc: 0.8163\n",
      "Epoch 3/15 | Train Loss: 0.3831 Acc: 0.8367\n",
      "Epoch 4/15 | Train Loss: 0.3175 Acc: 0.8571\n",
      "Epoch 5/15 | Train Loss: 0.3602 Acc: 0.8612\n",
      "Epoch 6/15 | Train Loss: 0.3311 Acc: 0.8490\n",
      "Epoch 7/15 | Train Loss: 0.3326 Acc: 0.8694\n",
      "Epoch 8/15 | Train Loss: 0.3282 Acc: 0.8653\n",
      "Epoch 9/15 | Train Loss: 0.2863 Acc: 0.8857\n",
      "Epoch 10/15 | Train Loss: 0.2644 Acc: 0.8857\n",
      "Epoch 11/15 | Train Loss: 0.2899 Acc: 0.8898\n",
      "Epoch 12/15 | Train Loss: 0.2657 Acc: 0.8898\n",
      "Epoch 13/15 | Train Loss: 0.3079 Acc: 0.8857\n",
      "Epoch 14/15 | Train Loss: 0.2389 Acc: 0.9184\n",
      "Epoch 15/15 | Train Loss: 0.2711 Acc: 0.8980\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6902 Acc: 0.6548\n",
      "Epoch 2/15 | Train Loss: 0.5828 Acc: 0.6786\n",
      "Epoch 3/15 | Train Loss: 0.4813 Acc: 0.7421\n",
      "Epoch 4/15 | Train Loss: 0.5259 Acc: 0.7302\n",
      "Epoch 5/15 | Train Loss: 0.4581 Acc: 0.7421\n",
      "Epoch 6/15 | Train Loss: 0.5064 Acc: 0.7817\n",
      "Epoch 7/15 | Train Loss: 0.4634 Acc: 0.7659\n",
      "Epoch 8/15 | Train Loss: 0.3985 Acc: 0.8056\n",
      "Epoch 9/15 | Train Loss: 0.4304 Acc: 0.7897\n",
      "Epoch 10/15 | Train Loss: 0.4111 Acc: 0.8135\n",
      "Epoch 11/15 | Train Loss: 0.3483 Acc: 0.8333\n",
      "Epoch 12/15 | Train Loss: 0.3630 Acc: 0.8492\n",
      "Epoch 13/15 | Train Loss: 0.3401 Acc: 0.8333\n",
      "Epoch 14/15 | Train Loss: 0.3618 Acc: 0.8452\n",
      "Epoch 15/15 | Train Loss: 0.3373 Acc: 0.8294\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7099 Acc: 0.6389\n",
      "Epoch 2/15 | Train Loss: 0.6311 Acc: 0.6865\n",
      "Epoch 3/15 | Train Loss: 0.5690 Acc: 0.7063\n",
      "Epoch 4/15 | Train Loss: 0.5626 Acc: 0.7222\n",
      "Epoch 5/15 | Train Loss: 0.5616 Acc: 0.7222\n",
      "Epoch 6/15 | Train Loss: 0.4796 Acc: 0.7381\n",
      "Epoch 7/15 | Train Loss: 0.4580 Acc: 0.7659\n",
      "Epoch 8/15 | Train Loss: 0.4104 Acc: 0.7976\n",
      "Epoch 9/15 | Train Loss: 0.4365 Acc: 0.7698\n",
      "Epoch 10/15 | Train Loss: 0.4261 Acc: 0.7976\n",
      "Epoch 11/15 | Train Loss: 0.4556 Acc: 0.7698\n",
      "Epoch 12/15 | Train Loss: 0.3930 Acc: 0.8135\n",
      "Epoch 13/15 | Train Loss: 0.4029 Acc: 0.8135\n",
      "Epoch 14/15 | Train Loss: 0.4209 Acc: 0.7698\n",
      "Epoch 15/15 | Train Loss: 0.3863 Acc: 0.8214\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7209 Acc: 0.6047\n",
      "Epoch 2/15 | Train Loss: 0.6351 Acc: 0.6403\n",
      "Epoch 3/15 | Train Loss: 0.5445 Acc: 0.6798\n",
      "Epoch 4/15 | Train Loss: 0.4822 Acc: 0.7589\n",
      "Epoch 5/15 | Train Loss: 0.5238 Acc: 0.7312\n",
      "Epoch 6/15 | Train Loss: 0.5118 Acc: 0.7352\n",
      "Epoch 7/15 | Train Loss: 0.4985 Acc: 0.7708\n",
      "Epoch 8/15 | Train Loss: 0.4479 Acc: 0.8142\n",
      "Epoch 9/15 | Train Loss: 0.4668 Acc: 0.7668\n",
      "Epoch 10/15 | Train Loss: 0.4814 Acc: 0.7391\n",
      "Epoch 11/15 | Train Loss: 0.3810 Acc: 0.8182\n",
      "Epoch 12/15 | Train Loss: 0.3789 Acc: 0.8103\n",
      "Epoch 13/15 | Train Loss: 0.4007 Acc: 0.8024\n",
      "Epoch 14/15 | Train Loss: 0.4826 Acc: 0.7826\n",
      "Epoch 15/15 | Train Loss: 0.4923 Acc: 0.7589\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7285 Acc: 0.6017\n",
      "Epoch 2/15 | Train Loss: 0.5721 Acc: 0.7585\n",
      "Epoch 3/15 | Train Loss: 0.5020 Acc: 0.7585\n",
      "Epoch 4/15 | Train Loss: 0.5001 Acc: 0.7924\n",
      "Epoch 5/15 | Train Loss: 0.4979 Acc: 0.7669\n",
      "Epoch 6/15 | Train Loss: 0.4331 Acc: 0.8093\n",
      "Epoch 7/15 | Train Loss: 0.4711 Acc: 0.7881\n",
      "Epoch 8/15 | Train Loss: 0.4632 Acc: 0.7712\n",
      "Epoch 9/15 | Train Loss: 0.4192 Acc: 0.8136\n",
      "Epoch 10/15 | Train Loss: 0.4325 Acc: 0.7924\n",
      "Epoch 11/15 | Train Loss: 0.4013 Acc: 0.8305\n",
      "Epoch 12/15 | Train Loss: 0.4248 Acc: 0.8093\n",
      "Epoch 13/15 | Train Loss: 0.4373 Acc: 0.8136\n",
      "Epoch 14/15 | Train Loss: 0.4276 Acc: 0.8093\n",
      "Epoch 15/15 | Train Loss: 0.3873 Acc: 0.8093\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5878 Acc: 0.6344\n",
      "Epoch 2/15 | Train Loss: 0.4901 Acc: 0.8238\n",
      "Epoch 3/15 | Train Loss: 0.3623 Acc: 0.8502\n",
      "Epoch 4/15 | Train Loss: 0.4418 Acc: 0.8370\n",
      "Epoch 5/15 | Train Loss: 0.4110 Acc: 0.8546\n",
      "Epoch 6/15 | Train Loss: 0.3370 Acc: 0.8502\n",
      "Epoch 7/15 | Train Loss: 0.3506 Acc: 0.8899\n",
      "Epoch 8/15 | Train Loss: 0.3305 Acc: 0.8767\n",
      "Epoch 9/15 | Train Loss: 0.2903 Acc: 0.8767\n",
      "Epoch 10/15 | Train Loss: 0.3275 Acc: 0.8678\n",
      "Epoch 11/15 | Train Loss: 0.2947 Acc: 0.8987\n",
      "Epoch 12/15 | Train Loss: 0.3050 Acc: 0.8943\n",
      "Epoch 13/15 | Train Loss: 0.3396 Acc: 0.8634\n",
      "Epoch 14/15 | Train Loss: 0.3080 Acc: 0.8987\n",
      "Epoch 15/15 | Train Loss: 0.2676 Acc: 0.8943\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5306 Acc: 0.7546\n",
      "Epoch 2/15 | Train Loss: 0.4153 Acc: 0.7702\n",
      "Epoch 3/15 | Train Loss: 0.3562 Acc: 0.8094\n",
      "Epoch 4/15 | Train Loss: 0.3402 Acc: 0.8407\n",
      "Epoch 5/15 | Train Loss: 0.3398 Acc: 0.8225\n",
      "Epoch 6/15 | Train Loss: 0.3342 Acc: 0.8381\n",
      "Epoch 7/15 | Train Loss: 0.3131 Acc: 0.8460\n",
      "Epoch 8/15 | Train Loss: 0.2954 Acc: 0.8668\n",
      "Epoch 9/15 | Train Loss: 0.2486 Acc: 0.8903\n",
      "Epoch 10/15 | Train Loss: 0.2541 Acc: 0.8930\n",
      "Epoch 11/15 | Train Loss: 0.2611 Acc: 0.8668\n",
      "Epoch 12/15 | Train Loss: 0.2496 Acc: 0.8721\n",
      "Epoch 13/15 | Train Loss: 0.2596 Acc: 0.8877\n",
      "Epoch 14/15 | Train Loss: 0.2341 Acc: 0.8956\n",
      "Epoch 15/15 | Train Loss: 0.2524 Acc: 0.8956\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.4610 Acc: 0.7520\n",
      "Epoch 2/15 | Train Loss: 0.4271 Acc: 0.7702\n",
      "Epoch 3/15 | Train Loss: 0.4465 Acc: 0.7598\n",
      "Epoch 4/15 | Train Loss: 0.3812 Acc: 0.7728\n",
      "Epoch 5/15 | Train Loss: 0.3776 Acc: 0.7859\n",
      "Epoch 6/15 | Train Loss: 0.3200 Acc: 0.8433\n",
      "Epoch 7/15 | Train Loss: 0.3285 Acc: 0.8251\n",
      "Epoch 8/15 | Train Loss: 0.2884 Acc: 0.8642\n",
      "Epoch 9/15 | Train Loss: 0.2993 Acc: 0.8381\n",
      "Epoch 10/15 | Train Loss: 0.3049 Acc: 0.8512\n",
      "Epoch 11/15 | Train Loss: 0.3100 Acc: 0.8460\n",
      "Epoch 12/15 | Train Loss: 0.3141 Acc: 0.8303\n",
      "Epoch 13/15 | Train Loss: 0.2840 Acc: 0.8721\n",
      "Epoch 14/15 | Train Loss: 0.2831 Acc: 0.8721\n",
      "Epoch 15/15 | Train Loss: 0.2847 Acc: 0.8355\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.6195 Acc: 0.7292\n",
      "Epoch 2/15 | Train Loss: 0.4650 Acc: 0.7682\n",
      "Epoch 3/15 | Train Loss: 0.4362 Acc: 0.7604\n",
      "Epoch 4/15 | Train Loss: 0.3874 Acc: 0.7995\n",
      "Epoch 5/15 | Train Loss: 0.3773 Acc: 0.8125\n",
      "Epoch 6/15 | Train Loss: 0.3459 Acc: 0.8203\n",
      "Epoch 7/15 | Train Loss: 0.3353 Acc: 0.8307\n",
      "Epoch 8/15 | Train Loss: 0.3020 Acc: 0.8568\n",
      "Epoch 9/15 | Train Loss: 0.2760 Acc: 0.8802\n",
      "Epoch 10/15 | Train Loss: 0.2978 Acc: 0.8438\n",
      "Epoch 11/15 | Train Loss: 0.3064 Acc: 0.8594\n",
      "Epoch 12/15 | Train Loss: 0.3014 Acc: 0.8672\n",
      "Epoch 13/15 | Train Loss: 0.2958 Acc: 0.8490\n",
      "Epoch 14/15 | Train Loss: 0.2755 Acc: 0.8672\n",
      "Epoch 15/15 | Train Loss: 0.2881 Acc: 0.8568\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5077 Acc: 0.7866\n",
      "Epoch 2/15 | Train Loss: 0.3650 Acc: 0.8344\n",
      "Epoch 3/15 | Train Loss: 0.3567 Acc: 0.8280\n",
      "Epoch 4/15 | Train Loss: 0.3818 Acc: 0.8280\n",
      "Epoch 5/15 | Train Loss: 0.3264 Acc: 0.8662\n",
      "Epoch 6/15 | Train Loss: 0.3742 Acc: 0.8153\n",
      "Epoch 7/15 | Train Loss: 0.3338 Acc: 0.8535\n",
      "Epoch 8/15 | Train Loss: 0.3521 Acc: 0.8344\n",
      "Epoch 9/15 | Train Loss: 0.3156 Acc: 0.8503\n",
      "Epoch 10/15 | Train Loss: 0.3179 Acc: 0.8758\n",
      "Epoch 11/15 | Train Loss: 0.2814 Acc: 0.8726\n",
      "Epoch 12/15 | Train Loss: 0.3586 Acc: 0.8408\n",
      "Epoch 13/15 | Train Loss: 0.2879 Acc: 0.8790\n",
      "Epoch 14/15 | Train Loss: 0.3116 Acc: 0.8726\n",
      "Epoch 15/15 | Train Loss: 0.3098 Acc: 0.8439\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5032 Acc: 0.7929\n",
      "Epoch 2/15 | Train Loss: 0.3572 Acc: 0.8607\n",
      "Epoch 3/15 | Train Loss: 0.3668 Acc: 0.8571\n",
      "Epoch 4/15 | Train Loss: 0.2955 Acc: 0.8821\n",
      "Epoch 5/15 | Train Loss: 0.3392 Acc: 0.8750\n",
      "Epoch 6/15 | Train Loss: 0.2859 Acc: 0.8893\n",
      "Epoch 7/15 | Train Loss: 0.3123 Acc: 0.8821\n",
      "Epoch 8/15 | Train Loss: 0.2812 Acc: 0.8714\n",
      "Epoch 9/15 | Train Loss: 0.2489 Acc: 0.8750\n",
      "Epoch 10/15 | Train Loss: 0.2379 Acc: 0.9036\n",
      "Epoch 11/15 | Train Loss: 0.2613 Acc: 0.9107\n",
      "Epoch 12/15 | Train Loss: 0.2430 Acc: 0.9036\n",
      "Epoch 13/15 | Train Loss: 0.2287 Acc: 0.8929\n",
      "Epoch 14/15 | Train Loss: 0.1999 Acc: 0.9286\n",
      "Epoch 15/15 | Train Loss: 0.2075 Acc: 0.9214\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6643 Acc: 0.6667\n",
      "Epoch 2/15 | Train Loss: 0.5556 Acc: 0.7143\n",
      "Epoch 3/15 | Train Loss: 0.5298 Acc: 0.6508\n",
      "Epoch 4/15 | Train Loss: 0.4787 Acc: 0.7579\n",
      "Epoch 5/15 | Train Loss: 0.4877 Acc: 0.7579\n",
      "Epoch 6/15 | Train Loss: 0.5150 Acc: 0.7500\n",
      "Epoch 7/15 | Train Loss: 0.3779 Acc: 0.8175\n",
      "Epoch 8/15 | Train Loss: 0.4388 Acc: 0.7778\n",
      "Epoch 9/15 | Train Loss: 0.4340 Acc: 0.8095\n",
      "Epoch 10/15 | Train Loss: 0.3803 Acc: 0.8214\n",
      "Epoch 11/15 | Train Loss: 0.3573 Acc: 0.8333\n",
      "Epoch 12/15 | Train Loss: 0.3358 Acc: 0.8452\n",
      "Epoch 13/15 | Train Loss: 0.3719 Acc: 0.8452\n",
      "Epoch 14/15 | Train Loss: 0.3970 Acc: 0.8016\n",
      "Epoch 15/15 | Train Loss: 0.3987 Acc: 0.8175\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7279 Acc: 0.6230\n",
      "Epoch 2/15 | Train Loss: 0.6598 Acc: 0.6627\n",
      "Epoch 3/15 | Train Loss: 0.5754 Acc: 0.6548\n",
      "Epoch 4/15 | Train Loss: 0.4917 Acc: 0.7579\n",
      "Epoch 5/15 | Train Loss: 0.4907 Acc: 0.7341\n",
      "Epoch 6/15 | Train Loss: 0.5091 Acc: 0.7183\n",
      "Epoch 7/15 | Train Loss: 0.4704 Acc: 0.7619\n",
      "Epoch 8/15 | Train Loss: 0.4277 Acc: 0.7817\n",
      "Epoch 9/15 | Train Loss: 0.4643 Acc: 0.7579\n",
      "Epoch 10/15 | Train Loss: 0.4408 Acc: 0.7421\n",
      "Epoch 11/15 | Train Loss: 0.4156 Acc: 0.7778\n",
      "Epoch 12/15 | Train Loss: 0.3926 Acc: 0.8016\n",
      "Epoch 13/15 | Train Loss: 0.4353 Acc: 0.8095\n",
      "Epoch 14/15 | Train Loss: 0.4130 Acc: 0.7937\n",
      "Epoch 15/15 | Train Loss: 0.4322 Acc: 0.8095\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.8115 Acc: 0.5810\n",
      "Epoch 2/15 | Train Loss: 0.6149 Acc: 0.6561\n",
      "Epoch 3/15 | Train Loss: 0.5650 Acc: 0.6877\n",
      "Epoch 4/15 | Train Loss: 0.5062 Acc: 0.6996\n",
      "Epoch 5/15 | Train Loss: 0.4884 Acc: 0.7549\n",
      "Epoch 6/15 | Train Loss: 0.4948 Acc: 0.7470\n",
      "Epoch 7/15 | Train Loss: 0.5042 Acc: 0.7470\n",
      "Epoch 8/15 | Train Loss: 0.4379 Acc: 0.7826\n",
      "Epoch 9/15 | Train Loss: 0.5236 Acc: 0.7312\n",
      "Epoch 10/15 | Train Loss: 0.5106 Acc: 0.7470\n",
      "Epoch 11/15 | Train Loss: 0.4554 Acc: 0.7391\n",
      "Epoch 12/15 | Train Loss: 0.4475 Acc: 0.8063\n",
      "Epoch 13/15 | Train Loss: 0.4300 Acc: 0.7708\n",
      "Epoch 14/15 | Train Loss: 0.4418 Acc: 0.7787\n",
      "Epoch 15/15 | Train Loss: 0.4210 Acc: 0.8261\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6990 Acc: 0.6483\n",
      "Epoch 2/15 | Train Loss: 0.5677 Acc: 0.7585\n",
      "Epoch 3/15 | Train Loss: 0.5265 Acc: 0.7669\n",
      "Epoch 4/15 | Train Loss: 0.4963 Acc: 0.7966\n",
      "Epoch 5/15 | Train Loss: 0.4484 Acc: 0.7966\n",
      "Epoch 6/15 | Train Loss: 0.4815 Acc: 0.7924\n",
      "Epoch 7/15 | Train Loss: 0.4233 Acc: 0.8051\n",
      "Epoch 8/15 | Train Loss: 0.4557 Acc: 0.8008\n",
      "Epoch 9/15 | Train Loss: 0.4317 Acc: 0.7839\n",
      "Epoch 10/15 | Train Loss: 0.3974 Acc: 0.8644\n",
      "Epoch 11/15 | Train Loss: 0.4232 Acc: 0.8136\n",
      "Epoch 12/15 | Train Loss: 0.3741 Acc: 0.8263\n",
      "Epoch 13/15 | Train Loss: 0.4197 Acc: 0.8263\n",
      "Epoch 14/15 | Train Loss: 0.3908 Acc: 0.8305\n",
      "Epoch 15/15 | Train Loss: 0.3597 Acc: 0.8305\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.4760 Acc: 0.7665\n",
      "Epoch 2/15 | Train Loss: 0.4449 Acc: 0.8150\n",
      "Epoch 3/15 | Train Loss: 0.4302 Acc: 0.8018\n",
      "Epoch 4/15 | Train Loss: 0.3770 Acc: 0.8414\n",
      "Epoch 5/15 | Train Loss: 0.4552 Acc: 0.8282\n",
      "Epoch 6/15 | Train Loss: 0.3455 Acc: 0.8546\n",
      "Epoch 7/15 | Train Loss: 0.3440 Acc: 0.8678\n",
      "Epoch 8/15 | Train Loss: 0.4283 Acc: 0.8062\n",
      "Epoch 9/15 | Train Loss: 0.3043 Acc: 0.8811\n",
      "Epoch 10/15 | Train Loss: 0.2873 Acc: 0.8767\n",
      "Epoch 11/15 | Train Loss: 0.3614 Acc: 0.8502\n",
      "Epoch 12/15 | Train Loss: 0.3026 Acc: 0.8855\n",
      "Epoch 13/15 | Train Loss: 0.3104 Acc: 0.8678\n",
      "Epoch 14/15 | Train Loss: 0.2681 Acc: 0.8899\n",
      "Epoch 15/15 | Train Loss: 0.3204 Acc: 0.8899\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6133 Acc: 0.7615\n",
      "Epoch 2/15 | Train Loss: 0.4704 Acc: 0.7959\n",
      "Epoch 3/15 | Train Loss: 0.4243 Acc: 0.7959\n",
      "Epoch 4/15 | Train Loss: 0.3599 Acc: 0.8188\n",
      "Epoch 5/15 | Train Loss: 0.3640 Acc: 0.8372\n",
      "Epoch 6/15 | Train Loss: 0.3441 Acc: 0.8463\n",
      "Epoch 7/15 | Train Loss: 0.3155 Acc: 0.8532\n",
      "Epoch 8/15 | Train Loss: 0.3092 Acc: 0.8555\n",
      "Epoch 9/15 | Train Loss: 0.2666 Acc: 0.8853\n",
      "Epoch 10/15 | Train Loss: 0.2695 Acc: 0.8899\n",
      "Epoch 11/15 | Train Loss: 0.2829 Acc: 0.8601\n",
      "Epoch 12/15 | Train Loss: 0.2942 Acc: 0.8532\n",
      "Epoch 13/15 | Train Loss: 0.2625 Acc: 0.8853\n",
      "Epoch 14/15 | Train Loss: 0.2687 Acc: 0.8922\n",
      "Epoch 15/15 | Train Loss: 0.3009 Acc: 0.8440\n",
      "Fold 1 Test Accuracy: 0.6818\n",
      "===== Fold 2 =====\n",
      "Epoch 1: Generator Loss = 9.8105, Discriminator Loss = 8.4732\n",
      "Epoch 2: Generator Loss = 9.6912, Discriminator Loss = 9.0555\n",
      "Epoch 3: Generator Loss = 10.9229, Discriminator Loss = 8.3284\n",
      "Epoch 4: Generator Loss = 17.1684, Discriminator Loss = 6.2105\n",
      "Epoch 5: Generator Loss = 25.3723, Discriminator Loss = 4.0716\n",
      "Epoch 6: Generator Loss = 29.3015, Discriminator Loss = 5.3107\n",
      "Epoch 7: Generator Loss = 27.7601, Discriminator Loss = 5.2750\n",
      "Epoch 8: Generator Loss = 31.9351, Discriminator Loss = 5.0160\n",
      "Epoch 9: Generator Loss = 26.6615, Discriminator Loss = 4.1994\n",
      "Epoch 10: Generator Loss = 26.7629, Discriminator Loss = 4.9672\n",
      "Epoch 11: Generator Loss = 27.2182, Discriminator Loss = 7.1660\n",
      "Epoch 12: Generator Loss = 23.9134, Discriminator Loss = 8.7410\n",
      "Epoch 13: Generator Loss = 22.6089, Discriminator Loss = 8.0364\n",
      "Epoch 14: Generator Loss = 19.0480, Discriminator Loss = 7.8345\n",
      "Epoch 15: Generator Loss = 20.9120, Discriminator Loss = 6.8547\n",
      "Epoch 16: Generator Loss = 18.3556, Discriminator Loss = 6.8300\n",
      "Epoch 17: Generator Loss = 23.6068, Discriminator Loss = 6.7289\n",
      "Epoch 18: Generator Loss = 15.8216, Discriminator Loss = 9.1742\n",
      "Epoch 19: Generator Loss = 23.7470, Discriminator Loss = 9.6529\n",
      "Epoch 20: Generator Loss = 20.1906, Discriminator Loss = 7.5683\n",
      "Epoch 21: Generator Loss = 21.0114, Discriminator Loss = 7.4788\n",
      "Epoch 22: Generator Loss = 18.1949, Discriminator Loss = 7.2499\n",
      "Epoch 23: Generator Loss = 17.9490, Discriminator Loss = 7.8338\n",
      "Epoch 24: Generator Loss = 22.9891, Discriminator Loss = 7.6119\n",
      "Epoch 25: Generator Loss = 21.2771, Discriminator Loss = 7.1750\n",
      "Epoch 26: Generator Loss = 20.8129, Discriminator Loss = 7.1766\n",
      "Epoch 27: Generator Loss = 19.9622, Discriminator Loss = 7.7123\n",
      "Epoch 28: Generator Loss = 19.9248, Discriminator Loss = 6.7222\n",
      "Epoch 29: Generator Loss = 22.4197, Discriminator Loss = 6.3165\n",
      "Epoch 30: Generator Loss = 21.3418, Discriminator Loss = 7.8581\n",
      "Epoch 31: Generator Loss = 21.9782, Discriminator Loss = 9.1651\n",
      "Epoch 32: Generator Loss = 22.7599, Discriminator Loss = 7.1641\n",
      "Epoch 33: Generator Loss = 18.6386, Discriminator Loss = 7.9598\n",
      "Epoch 34: Generator Loss = 21.6717, Discriminator Loss = 7.5718\n",
      "Epoch 35: Generator Loss = 22.4485, Discriminator Loss = 8.0733\n",
      "Epoch 36: Generator Loss = 23.1816, Discriminator Loss = 7.4819\n",
      "Epoch 37: Generator Loss = 18.4047, Discriminator Loss = 8.3132\n",
      "Epoch 38: Generator Loss = 19.3180, Discriminator Loss = 6.8735\n",
      "Epoch 39: Generator Loss = 21.0440, Discriminator Loss = 7.6227\n",
      "Epoch 40: Generator Loss = 18.4083, Discriminator Loss = 6.5658\n",
      "Epoch 41: Generator Loss = 23.4855, Discriminator Loss = 7.3174\n",
      "Epoch 42: Generator Loss = 18.9811, Discriminator Loss = 6.2876\n",
      "Epoch 43: Generator Loss = 29.3223, Discriminator Loss = 5.7714\n",
      "Epoch 44: Generator Loss = 17.1686, Discriminator Loss = 6.7573\n",
      "Epoch 45: Generator Loss = 23.4464, Discriminator Loss = 6.1763\n",
      "Epoch 46: Generator Loss = 22.5630, Discriminator Loss = 10.1140\n",
      "Epoch 47: Generator Loss = 17.5614, Discriminator Loss = 7.9075\n",
      "Epoch 48: Generator Loss = 21.1766, Discriminator Loss = 6.8143\n",
      "Epoch 49: Generator Loss = 19.2541, Discriminator Loss = 7.3255\n",
      "Epoch 50: Generator Loss = 21.3255, Discriminator Loss = 8.2024\n",
      "Epoch 51: Generator Loss = 21.1562, Discriminator Loss = 6.5252\n",
      "Epoch 52: Generator Loss = 26.4582, Discriminator Loss = 5.1201\n",
      "Epoch 53: Generator Loss = 28.9264, Discriminator Loss = 5.7548\n",
      "Epoch 54: Generator Loss = 28.1335, Discriminator Loss = 5.0921\n",
      "Epoch 55: Generator Loss = 31.3168, Discriminator Loss = 4.2999\n",
      "Epoch 56: Generator Loss = 34.0489, Discriminator Loss = 4.6280\n",
      "Epoch 57: Generator Loss = 29.0226, Discriminator Loss = 5.0169\n",
      "Epoch 58: Generator Loss = 39.0013, Discriminator Loss = 3.2155\n",
      "Epoch 59: Generator Loss = 31.9892, Discriminator Loss = 2.8598\n",
      "Epoch 60: Generator Loss = 32.4623, Discriminator Loss = 5.0190\n",
      "Epoch 61: Generator Loss = 43.5113, Discriminator Loss = 3.3369\n",
      "Epoch 62: Generator Loss = 28.3055, Discriminator Loss = 7.7047\n",
      "Epoch 63: Generator Loss = 38.7193, Discriminator Loss = 3.3408\n",
      "Epoch 64: Generator Loss = 41.1165, Discriminator Loss = 2.1470\n",
      "Epoch 65: Generator Loss = 50.4190, Discriminator Loss = 1.9357\n",
      "Epoch 66: Generator Loss = 38.2889, Discriminator Loss = 4.1853\n",
      "Epoch 67: Generator Loss = 42.8010, Discriminator Loss = 1.6643\n",
      "Epoch 68: Generator Loss = 55.0414, Discriminator Loss = 2.5697\n",
      "Epoch 69: Generator Loss = 58.1303, Discriminator Loss = 1.8017\n",
      "Epoch 70: Generator Loss = 51.0943, Discriminator Loss = 1.6414\n",
      "Epoch 71: Generator Loss = 50.8764, Discriminator Loss = 1.6304\n",
      "Epoch 72: Generator Loss = 53.4787, Discriminator Loss = 1.6339\n",
      "Epoch 73: Generator Loss = 59.9888, Discriminator Loss = 1.2066\n",
      "Epoch 74: Generator Loss = 59.1602, Discriminator Loss = 1.4366\n",
      "Epoch 75: Generator Loss = 64.5698, Discriminator Loss = 1.3996\n",
      "Epoch 76: Generator Loss = 64.6976, Discriminator Loss = 2.2138\n",
      "Epoch 77: Generator Loss = 60.8292, Discriminator Loss = 1.0215\n",
      "Epoch 78: Generator Loss = 56.1149, Discriminator Loss = 0.8878\n",
      "Epoch 79: Generator Loss = 60.5609, Discriminator Loss = 1.3156\n",
      "Epoch 80: Generator Loss = 60.8436, Discriminator Loss = 0.9959\n",
      "Epoch 81: Generator Loss = 63.3251, Discriminator Loss = 1.2403\n",
      "Epoch 82: Generator Loss = 60.8576, Discriminator Loss = 1.1464\n",
      "Epoch 83: Generator Loss = 62.3069, Discriminator Loss = 0.5354\n",
      "Epoch 84: Generator Loss = 61.9011, Discriminator Loss = 1.0670\n",
      "Epoch 85: Generator Loss = 66.4728, Discriminator Loss = 0.5506\n",
      "Epoch 86: Generator Loss = 65.5595, Discriminator Loss = 1.3642\n",
      "Epoch 87: Generator Loss = 57.2501, Discriminator Loss = 4.3373\n",
      "Epoch 88: Generator Loss = 56.5158, Discriminator Loss = 0.9695\n",
      "Epoch 89: Generator Loss = 65.7615, Discriminator Loss = 1.6123\n",
      "Epoch 90: Generator Loss = 68.9529, Discriminator Loss = 0.7240\n",
      "Epoch 91: Generator Loss = 67.4100, Discriminator Loss = 0.5860\n",
      "Epoch 92: Generator Loss = 78.0783, Discriminator Loss = 0.9128\n",
      "Epoch 93: Generator Loss = 58.9160, Discriminator Loss = 0.7015\n",
      "Epoch 94: Generator Loss = 67.0849, Discriminator Loss = 1.0568\n",
      "Epoch 95: Generator Loss = 66.2449, Discriminator Loss = 2.1201\n",
      "Epoch 96: Generator Loss = 71.8882, Discriminator Loss = 0.9033\n",
      "Epoch 97: Generator Loss = 71.7210, Discriminator Loss = 1.9324\n",
      "Epoch 98: Generator Loss = 55.9999, Discriminator Loss = 0.8389\n",
      "Epoch 99: Generator Loss = 66.7376, Discriminator Loss = 1.2355\n",
      "Epoch 100: Generator Loss = 67.5477, Discriminator Loss = 0.6474\n",
      "Epoch 101: Generator Loss = 68.9080, Discriminator Loss = 0.7012\n",
      "Epoch 102: Generator Loss = 78.0627, Discriminator Loss = 0.7798\n",
      "Epoch 103: Generator Loss = 67.0787, Discriminator Loss = 0.5442\n",
      "Epoch 104: Generator Loss = 79.3442, Discriminator Loss = 0.5527\n",
      "Epoch 105: Generator Loss = 87.7069, Discriminator Loss = 0.4499\n",
      "Epoch 106: Generator Loss = 86.0198, Discriminator Loss = 0.2727\n",
      "Epoch 107: Generator Loss = 84.0439, Discriminator Loss = 0.7475\n",
      "Epoch 108: Generator Loss = 82.0418, Discriminator Loss = 0.9368\n",
      "Epoch 109: Generator Loss = 72.7638, Discriminator Loss = 0.7741\n",
      "Epoch 110: Generator Loss = 77.2745, Discriminator Loss = 0.7314\n",
      "Epoch 111: Generator Loss = 80.8309, Discriminator Loss = 1.4945\n",
      "Epoch 112: Generator Loss = 85.4842, Discriminator Loss = 1.6016\n",
      "Epoch 113: Generator Loss = 73.7666, Discriminator Loss = 0.6152\n",
      "Epoch 114: Generator Loss = 68.7014, Discriminator Loss = 0.7855\n",
      "Epoch 115: Generator Loss = 78.1717, Discriminator Loss = 1.4888\n",
      "Epoch 116: Generator Loss = 67.1743, Discriminator Loss = 0.6837\n",
      "Epoch 117: Generator Loss = 78.8429, Discriminator Loss = 0.4538\n",
      "Epoch 118: Generator Loss = 88.3927, Discriminator Loss = 6.1778\n",
      "Epoch 119: Generator Loss = 51.1829, Discriminator Loss = 7.4044\n",
      "Epoch 120: Generator Loss = 66.6366, Discriminator Loss = 2.2025\n",
      "Epoch 121: Generator Loss = 56.0055, Discriminator Loss = 1.4542\n",
      "Epoch 122: Generator Loss = 64.1339, Discriminator Loss = 3.0654\n",
      "Epoch 123: Generator Loss = 52.5331, Discriminator Loss = 1.3012\n",
      "Epoch 124: Generator Loss = 64.9747, Discriminator Loss = 1.4453\n",
      "Epoch 125: Generator Loss = 67.2204, Discriminator Loss = 0.9397\n",
      "Epoch 126: Generator Loss = 66.8052, Discriminator Loss = 0.5721\n",
      "Epoch 127: Generator Loss = 78.3189, Discriminator Loss = 0.9489\n",
      "Epoch 128: Generator Loss = 82.0074, Discriminator Loss = 0.5858\n",
      "Epoch 129: Generator Loss = 68.0473, Discriminator Loss = 0.6944\n",
      "Epoch 130: Generator Loss = 72.1568, Discriminator Loss = 0.9964\n",
      "Epoch 131: Generator Loss = 78.3840, Discriminator Loss = 1.9026\n",
      "Epoch 132: Generator Loss = 61.5116, Discriminator Loss = 2.6807\n",
      "Epoch 133: Generator Loss = 62.4616, Discriminator Loss = 1.8242\n",
      "Epoch 134: Generator Loss = 84.2608, Discriminator Loss = 0.8694\n",
      "Epoch 135: Generator Loss = 73.7815, Discriminator Loss = 0.9069\n",
      "Epoch 136: Generator Loss = 62.1439, Discriminator Loss = 0.6623\n",
      "Epoch 137: Generator Loss = 80.8169, Discriminator Loss = 1.4542\n",
      "Epoch 138: Generator Loss = 75.7926, Discriminator Loss = 1.2165\n",
      "Epoch 139: Generator Loss = 80.3861, Discriminator Loss = 3.5116\n",
      "Epoch 140: Generator Loss = 67.7136, Discriminator Loss = 3.0432\n",
      "Epoch 141: Generator Loss = 71.6377, Discriminator Loss = 1.5584\n",
      "Epoch 142: Generator Loss = 76.4056, Discriminator Loss = 0.8549\n",
      "Epoch 143: Generator Loss = 73.6205, Discriminator Loss = 0.7114\n",
      "Epoch 144: Generator Loss = 78.9930, Discriminator Loss = 0.9773\n",
      "Epoch 145: Generator Loss = 75.5615, Discriminator Loss = 0.7487\n",
      "Epoch 146: Generator Loss = 83.4200, Discriminator Loss = 0.6173\n",
      "Epoch 147: Generator Loss = 84.7271, Discriminator Loss = 0.7931\n",
      "Epoch 148: Generator Loss = 90.5392, Discriminator Loss = 0.6592\n",
      "Epoch 149: Generator Loss = 79.2249, Discriminator Loss = 1.3453\n",
      "Epoch 150: Generator Loss = 66.1935, Discriminator Loss = 0.4862\n",
      "Epoch 151: Generator Loss = 81.8194, Discriminator Loss = 0.7454\n",
      "Epoch 152: Generator Loss = 84.7440, Discriminator Loss = 0.5482\n",
      "Epoch 153: Generator Loss = 73.2692, Discriminator Loss = 1.0076\n",
      "Epoch 154: Generator Loss = 78.7597, Discriminator Loss = 0.6743\n",
      "Epoch 155: Generator Loss = 72.7253, Discriminator Loss = 0.6579\n",
      "Epoch 156: Generator Loss = 67.6597, Discriminator Loss = 1.0643\n",
      "Epoch 157: Generator Loss = 88.6165, Discriminator Loss = 1.6322\n",
      "Epoch 158: Generator Loss = 89.8947, Discriminator Loss = 2.8627\n",
      "Epoch 159: Generator Loss = 40.8833, Discriminator Loss = 16.1287\n",
      "Epoch 160: Generator Loss = 29.6041, Discriminator Loss = 4.7234\n",
      "Epoch 161: Generator Loss = 42.4300, Discriminator Loss = 7.3973\n",
      "Epoch 162: Generator Loss = 46.3254, Discriminator Loss = 2.6051\n",
      "Epoch 163: Generator Loss = 52.2277, Discriminator Loss = 3.3494\n",
      "Epoch 164: Generator Loss = 46.9576, Discriminator Loss = 3.3582\n",
      "Epoch 165: Generator Loss = 56.5459, Discriminator Loss = 3.0937\n",
      "Epoch 166: Generator Loss = 56.6669, Discriminator Loss = 2.7437\n",
      "Epoch 167: Generator Loss = 56.3558, Discriminator Loss = 3.6521\n",
      "Epoch 168: Generator Loss = 57.6810, Discriminator Loss = 4.5902\n",
      "Epoch 169: Generator Loss = 68.6735, Discriminator Loss = 2.3864\n",
      "Epoch 170: Generator Loss = 56.8790, Discriminator Loss = 0.7080\n",
      "Epoch 171: Generator Loss = 69.5625, Discriminator Loss = 0.8604\n",
      "Epoch 172: Generator Loss = 64.6002, Discriminator Loss = 0.9706\n",
      "Epoch 173: Generator Loss = 67.6438, Discriminator Loss = 0.8356\n",
      "Epoch 174: Generator Loss = 86.8193, Discriminator Loss = 0.4550\n",
      "Epoch 175: Generator Loss = 72.8337, Discriminator Loss = 1.6177\n",
      "Epoch 176: Generator Loss = 49.3274, Discriminator Loss = 3.4310\n",
      "Epoch 177: Generator Loss = 52.8264, Discriminator Loss = 2.0211\n",
      "Epoch 178: Generator Loss = 74.8549, Discriminator Loss = 1.6840\n",
      "Epoch 179: Generator Loss = 59.9036, Discriminator Loss = 2.0885\n",
      "Epoch 180: Generator Loss = 72.5064, Discriminator Loss = 0.9871\n",
      "Epoch 181: Generator Loss = 80.8657, Discriminator Loss = 1.0521\n",
      "Epoch 182: Generator Loss = 79.8229, Discriminator Loss = 1.0042\n",
      "Epoch 183: Generator Loss = 71.2243, Discriminator Loss = 1.0501\n",
      "Epoch 184: Generator Loss = 69.2492, Discriminator Loss = 1.0543\n",
      "Epoch 185: Generator Loss = 78.1794, Discriminator Loss = 0.6414\n",
      "Epoch 186: Generator Loss = 78.1512, Discriminator Loss = 0.6960\n",
      "Epoch 187: Generator Loss = 67.0354, Discriminator Loss = 1.6635\n",
      "Epoch 188: Generator Loss = 74.2623, Discriminator Loss = 0.6443\n",
      "Epoch 189: Generator Loss = 84.2383, Discriminator Loss = 0.9901\n",
      "Epoch 190: Generator Loss = 93.1844, Discriminator Loss = 1.0987\n",
      "Epoch 191: Generator Loss = 80.6709, Discriminator Loss = 0.8011\n",
      "Epoch 192: Generator Loss = 84.2236, Discriminator Loss = 1.0636\n",
      "Epoch 193: Generator Loss = 96.5012, Discriminator Loss = 1.6544\n",
      "Epoch 194: Generator Loss = 74.5938, Discriminator Loss = 0.7066\n",
      "Epoch 195: Generator Loss = 254.3617, Discriminator Loss = 45.0753\n",
      "Epoch 196: Generator Loss = 169.2209, Discriminator Loss = 8.0503\n",
      "Epoch 197: Generator Loss = 83.6930, Discriminator Loss = 1.9933\n",
      "Epoch 198: Generator Loss = 84.7736, Discriminator Loss = 4.2834\n",
      "Epoch 199: Generator Loss = 69.4291, Discriminator Loss = 2.9519\n",
      "Epoch 200: Generator Loss = 70.0063, Discriminator Loss = 2.1829\n",
      "Epoch 201: Generator Loss = 66.2773, Discriminator Loss = 1.4689\n",
      "Epoch 202: Generator Loss = 74.5968, Discriminator Loss = 6.7824\n",
      "Epoch 203: Generator Loss = 65.6351, Discriminator Loss = 5.8438\n",
      "Epoch 204: Generator Loss = 61.5874, Discriminator Loss = 2.3866\n",
      "Epoch 205: Generator Loss = 60.6313, Discriminator Loss = 1.0570\n",
      "Epoch 206: Generator Loss = 82.4213, Discriminator Loss = 1.9782\n",
      "Epoch 207: Generator Loss = 65.7421, Discriminator Loss = 1.6584\n",
      "Epoch 208: Generator Loss = 63.8515, Discriminator Loss = 1.1925\n",
      "Epoch 209: Generator Loss = 66.8820, Discriminator Loss = 2.4587\n",
      "Epoch 210: Generator Loss = 70.8103, Discriminator Loss = 1.5794\n",
      "Epoch 211: Generator Loss = 68.4365, Discriminator Loss = 1.1184\n",
      "Epoch 212: Generator Loss = 76.2351, Discriminator Loss = 1.2513\n",
      "Epoch 213: Generator Loss = 58.8566, Discriminator Loss = 0.9906\n",
      "Epoch 214: Generator Loss = 77.0290, Discriminator Loss = 0.6918\n",
      "Epoch 215: Generator Loss = 67.1990, Discriminator Loss = 0.5392\n",
      "Epoch 216: Generator Loss = 55.8568, Discriminator Loss = 1.3763\n",
      "Epoch 217: Generator Loss = 73.2528, Discriminator Loss = 1.0852\n",
      "Epoch 218: Generator Loss = 76.6688, Discriminator Loss = 1.0265\n",
      "Epoch 219: Generator Loss = 75.9890, Discriminator Loss = 2.9219\n",
      "Epoch 220: Generator Loss = 67.3856, Discriminator Loss = 1.2644\n",
      "Epoch 221: Generator Loss = 64.7783, Discriminator Loss = 0.8273\n",
      "Epoch 222: Generator Loss = 69.5330, Discriminator Loss = 0.6236\n",
      "Epoch 223: Generator Loss = 87.8085, Discriminator Loss = 1.0080\n",
      "Epoch 224: Generator Loss = 78.4398, Discriminator Loss = 0.8279\n",
      "Epoch 225: Generator Loss = 74.0463, Discriminator Loss = 1.3833\n",
      "Epoch 226: Generator Loss = 89.2217, Discriminator Loss = 1.2724\n",
      "Epoch 227: Generator Loss = 68.7251, Discriminator Loss = 1.3612\n",
      "Epoch 228: Generator Loss = 82.6396, Discriminator Loss = 1.6988\n",
      "Epoch 229: Generator Loss = 63.7610, Discriminator Loss = 1.6754\n",
      "Epoch 230: Generator Loss = 82.3189, Discriminator Loss = 1.0336\n",
      "Epoch 231: Generator Loss = 89.4825, Discriminator Loss = 0.6861\n",
      "Epoch 232: Generator Loss = 65.0388, Discriminator Loss = 3.5648\n",
      "Epoch 233: Generator Loss = 69.3255, Discriminator Loss = 7.1025\n",
      "Epoch 234: Generator Loss = 65.0194, Discriminator Loss = 1.8007\n",
      "Epoch 235: Generator Loss = 56.4693, Discriminator Loss = 1.3148\n",
      "Epoch 236: Generator Loss = 66.6258, Discriminator Loss = 0.7698\n",
      "Epoch 237: Generator Loss = 72.9032, Discriminator Loss = 1.1642\n",
      "Epoch 238: Generator Loss = 74.7129, Discriminator Loss = 0.9491\n",
      "Epoch 239: Generator Loss = 83.4608, Discriminator Loss = 0.4174\n",
      "Epoch 240: Generator Loss = 71.6330, Discriminator Loss = 0.9331\n",
      "Epoch 241: Generator Loss = 74.6635, Discriminator Loss = 0.5075\n",
      "Epoch 242: Generator Loss = 87.1461, Discriminator Loss = 0.7929\n",
      "Epoch 243: Generator Loss = 78.8326, Discriminator Loss = 2.1521\n",
      "Epoch 244: Generator Loss = 71.3619, Discriminator Loss = 0.9437\n",
      "Epoch 245: Generator Loss = 64.3724, Discriminator Loss = 1.4973\n",
      "Epoch 246: Generator Loss = 82.7372, Discriminator Loss = 1.4416\n",
      "Epoch 247: Generator Loss = 62.7270, Discriminator Loss = 1.5803\n",
      "Epoch 248: Generator Loss = 106.1518, Discriminator Loss = 0.7130\n",
      "Epoch 249: Generator Loss = 82.3367, Discriminator Loss = 2.7804\n",
      "Epoch 250: Generator Loss = 98.7480, Discriminator Loss = 0.7332\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Epoch 1/15 | Train Loss: 0.5060 Acc: 0.7650\n",
      "Epoch 2/15 | Train Loss: 0.4034 Acc: 0.7781\n",
      "Epoch 3/15 | Train Loss: 0.3450 Acc: 0.8251\n",
      "Epoch 4/15 | Train Loss: 0.3997 Acc: 0.8120\n",
      "Epoch 5/15 | Train Loss: 0.3325 Acc: 0.8355\n",
      "Epoch 6/15 | Train Loss: 0.3193 Acc: 0.8538\n",
      "Epoch 7/15 | Train Loss: 0.2893 Acc: 0.8668\n",
      "Epoch 8/15 | Train Loss: 0.2946 Acc: 0.8538\n",
      "Epoch 9/15 | Train Loss: 0.2704 Acc: 0.8695\n",
      "Epoch 10/15 | Train Loss: 0.2512 Acc: 0.8903\n",
      "Epoch 11/15 | Train Loss: 0.2354 Acc: 0.8903\n",
      "Epoch 12/15 | Train Loss: 0.2415 Acc: 0.8799\n",
      "Epoch 13/15 | Train Loss: 0.2484 Acc: 0.8877\n",
      "Epoch 14/15 | Train Loss: 0.2253 Acc: 0.9008\n",
      "Epoch 15/15 | Train Loss: 0.2342 Acc: 0.9034\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.5017 Acc: 0.7598\n",
      "Epoch 2/15 | Train Loss: 0.3844 Acc: 0.7937\n",
      "Epoch 3/15 | Train Loss: 0.3633 Acc: 0.7833\n",
      "Epoch 4/15 | Train Loss: 0.3771 Acc: 0.7911\n",
      "Epoch 5/15 | Train Loss: 0.3443 Acc: 0.8277\n",
      "Epoch 6/15 | Train Loss: 0.3156 Acc: 0.8251\n",
      "Epoch 7/15 | Train Loss: 0.3021 Acc: 0.8512\n",
      "Epoch 8/15 | Train Loss: 0.2941 Acc: 0.8538\n",
      "Epoch 9/15 | Train Loss: 0.2959 Acc: 0.8486\n",
      "Epoch 10/15 | Train Loss: 0.2688 Acc: 0.8642\n",
      "Epoch 11/15 | Train Loss: 0.2714 Acc: 0.8642\n",
      "Epoch 12/15 | Train Loss: 0.2615 Acc: 0.8695\n",
      "Epoch 13/15 | Train Loss: 0.2593 Acc: 0.8695\n",
      "Epoch 14/15 | Train Loss: 0.2667 Acc: 0.8668\n",
      "Epoch 15/15 | Train Loss: 0.2512 Acc: 0.8721\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.4928 Acc: 0.7786\n",
      "Epoch 2/15 | Train Loss: 0.4029 Acc: 0.7969\n",
      "Epoch 3/15 | Train Loss: 0.3776 Acc: 0.7943\n",
      "Epoch 4/15 | Train Loss: 0.3657 Acc: 0.8177\n",
      "Epoch 5/15 | Train Loss: 0.3156 Acc: 0.8490\n",
      "Epoch 6/15 | Train Loss: 0.3614 Acc: 0.8047\n",
      "Epoch 7/15 | Train Loss: 0.3034 Acc: 0.8333\n",
      "Epoch 8/15 | Train Loss: 0.3294 Acc: 0.8594\n",
      "Epoch 9/15 | Train Loss: 0.2685 Acc: 0.8906\n",
      "Epoch 10/15 | Train Loss: 0.2541 Acc: 0.8828\n",
      "Epoch 11/15 | Train Loss: 0.2509 Acc: 0.8672\n",
      "Epoch 12/15 | Train Loss: 0.2686 Acc: 0.8568\n",
      "Epoch 13/15 | Train Loss: 0.2895 Acc: 0.8516\n",
      "Epoch 14/15 | Train Loss: 0.2455 Acc: 0.8854\n",
      "Epoch 15/15 | Train Loss: 0.2706 Acc: 0.8516\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.5123 Acc: 0.7866\n",
      "Epoch 2/15 | Train Loss: 0.4148 Acc: 0.8121\n",
      "Epoch 3/15 | Train Loss: 0.4045 Acc: 0.8248\n",
      "Epoch 4/15 | Train Loss: 0.3928 Acc: 0.8439\n",
      "Epoch 5/15 | Train Loss: 0.3490 Acc: 0.8503\n",
      "Epoch 6/15 | Train Loss: 0.3497 Acc: 0.8535\n",
      "Epoch 7/15 | Train Loss: 0.3159 Acc: 0.8758\n",
      "Epoch 8/15 | Train Loss: 0.3158 Acc: 0.8662\n",
      "Epoch 9/15 | Train Loss: 0.3023 Acc: 0.8567\n",
      "Epoch 10/15 | Train Loss: 0.3077 Acc: 0.8790\n",
      "Epoch 11/15 | Train Loss: 0.2909 Acc: 0.8822\n",
      "Epoch 12/15 | Train Loss: 0.2565 Acc: 0.8981\n",
      "Epoch 13/15 | Train Loss: 0.2857 Acc: 0.8726\n",
      "Epoch 14/15 | Train Loss: 0.2805 Acc: 0.8917\n",
      "Epoch 15/15 | Train Loss: 0.2549 Acc: 0.8917\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5212 Acc: 0.8214\n",
      "Epoch 2/15 | Train Loss: 0.4131 Acc: 0.8429\n",
      "Epoch 3/15 | Train Loss: 0.3288 Acc: 0.8821\n",
      "Epoch 4/15 | Train Loss: 0.3038 Acc: 0.8857\n",
      "Epoch 5/15 | Train Loss: 0.3258 Acc: 0.8786\n",
      "Epoch 6/15 | Train Loss: 0.2934 Acc: 0.8964\n",
      "Epoch 7/15 | Train Loss: 0.2540 Acc: 0.8536\n",
      "Epoch 8/15 | Train Loss: 0.3195 Acc: 0.8964\n",
      "Epoch 9/15 | Train Loss: 0.2715 Acc: 0.9036\n",
      "Epoch 10/15 | Train Loss: 0.2221 Acc: 0.9107\n",
      "Epoch 11/15 | Train Loss: 0.2653 Acc: 0.9036\n",
      "Epoch 12/15 | Train Loss: 0.2370 Acc: 0.9036\n",
      "Epoch 13/15 | Train Loss: 0.2158 Acc: 0.9179\n",
      "Epoch 14/15 | Train Loss: 0.2077 Acc: 0.9321\n",
      "Epoch 15/15 | Train Loss: 0.2342 Acc: 0.9143\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7001 Acc: 0.6468\n",
      "Epoch 2/15 | Train Loss: 0.5520 Acc: 0.6865\n",
      "Epoch 3/15 | Train Loss: 0.5333 Acc: 0.7183\n",
      "Epoch 4/15 | Train Loss: 0.4990 Acc: 0.7460\n",
      "Epoch 5/15 | Train Loss: 0.4836 Acc: 0.7579\n",
      "Epoch 6/15 | Train Loss: 0.4382 Acc: 0.7857\n",
      "Epoch 7/15 | Train Loss: 0.4320 Acc: 0.7579\n",
      "Epoch 8/15 | Train Loss: 0.4668 Acc: 0.8095\n",
      "Epoch 9/15 | Train Loss: 0.4033 Acc: 0.8095\n",
      "Epoch 10/15 | Train Loss: 0.3779 Acc: 0.8175\n",
      "Epoch 11/15 | Train Loss: 0.3789 Acc: 0.8175\n",
      "Epoch 12/15 | Train Loss: 0.3856 Acc: 0.8373\n",
      "Epoch 13/15 | Train Loss: 0.4267 Acc: 0.7857\n",
      "Epoch 14/15 | Train Loss: 0.4088 Acc: 0.7937\n",
      "Epoch 15/15 | Train Loss: 0.3340 Acc: 0.8413\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.8083 Acc: 0.6151\n",
      "Epoch 2/15 | Train Loss: 0.6174 Acc: 0.6865\n",
      "Epoch 3/15 | Train Loss: 0.5879 Acc: 0.6746\n",
      "Epoch 4/15 | Train Loss: 0.5589 Acc: 0.7024\n",
      "Epoch 5/15 | Train Loss: 0.4849 Acc: 0.7500\n",
      "Epoch 6/15 | Train Loss: 0.5067 Acc: 0.7381\n",
      "Epoch 7/15 | Train Loss: 0.4539 Acc: 0.7817\n",
      "Epoch 8/15 | Train Loss: 0.4628 Acc: 0.7659\n",
      "Epoch 9/15 | Train Loss: 0.4696 Acc: 0.7619\n",
      "Epoch 10/15 | Train Loss: 0.4309 Acc: 0.8056\n",
      "Epoch 11/15 | Train Loss: 0.4022 Acc: 0.7778\n",
      "Epoch 12/15 | Train Loss: 0.4907 Acc: 0.7579\n",
      "Epoch 13/15 | Train Loss: 0.4048 Acc: 0.8135\n",
      "Epoch 14/15 | Train Loss: 0.4109 Acc: 0.8095\n",
      "Epoch 15/15 | Train Loss: 0.4479 Acc: 0.7738\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6906 Acc: 0.6126\n",
      "Epoch 2/15 | Train Loss: 0.6226 Acc: 0.6482\n",
      "Epoch 3/15 | Train Loss: 0.6013 Acc: 0.6601\n",
      "Epoch 4/15 | Train Loss: 0.4931 Acc: 0.7194\n",
      "Epoch 5/15 | Train Loss: 0.5382 Acc: 0.7391\n",
      "Epoch 6/15 | Train Loss: 0.5180 Acc: 0.7273\n",
      "Epoch 7/15 | Train Loss: 0.4362 Acc: 0.7747\n",
      "Epoch 8/15 | Train Loss: 0.5022 Acc: 0.7589\n",
      "Epoch 9/15 | Train Loss: 0.4183 Acc: 0.8024\n",
      "Epoch 10/15 | Train Loss: 0.3942 Acc: 0.8340\n",
      "Epoch 11/15 | Train Loss: 0.4505 Acc: 0.7747\n",
      "Epoch 12/15 | Train Loss: 0.4022 Acc: 0.8261\n",
      "Epoch 13/15 | Train Loss: 0.3995 Acc: 0.8142\n",
      "Epoch 14/15 | Train Loss: 0.3748 Acc: 0.8182\n",
      "Epoch 15/15 | Train Loss: 0.4112 Acc: 0.8024\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6738 Acc: 0.6568\n",
      "Epoch 2/15 | Train Loss: 0.4927 Acc: 0.7924\n",
      "Epoch 3/15 | Train Loss: 0.4920 Acc: 0.7797\n",
      "Epoch 4/15 | Train Loss: 0.4682 Acc: 0.7839\n",
      "Epoch 5/15 | Train Loss: 0.5033 Acc: 0.7712\n",
      "Epoch 6/15 | Train Loss: 0.4304 Acc: 0.7966\n",
      "Epoch 7/15 | Train Loss: 0.4830 Acc: 0.8051\n",
      "Epoch 8/15 | Train Loss: 0.3895 Acc: 0.8220\n",
      "Epoch 9/15 | Train Loss: 0.3377 Acc: 0.8602\n",
      "Epoch 10/15 | Train Loss: 0.3802 Acc: 0.8220\n",
      "Epoch 11/15 | Train Loss: 0.3666 Acc: 0.8517\n",
      "Epoch 12/15 | Train Loss: 0.4135 Acc: 0.8178\n",
      "Epoch 13/15 | Train Loss: 0.3594 Acc: 0.8517\n",
      "Epoch 14/15 | Train Loss: 0.3681 Acc: 0.8347\n",
      "Epoch 15/15 | Train Loss: 0.3362 Acc: 0.8559\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5624 Acc: 0.7445\n",
      "Epoch 2/15 | Train Loss: 0.5242 Acc: 0.7930\n",
      "Epoch 3/15 | Train Loss: 0.4563 Acc: 0.8194\n",
      "Epoch 4/15 | Train Loss: 0.3666 Acc: 0.8546\n",
      "Epoch 5/15 | Train Loss: 0.3533 Acc: 0.8502\n",
      "Epoch 6/15 | Train Loss: 0.3132 Acc: 0.8590\n",
      "Epoch 7/15 | Train Loss: 0.3121 Acc: 0.8502\n",
      "Epoch 8/15 | Train Loss: 0.3175 Acc: 0.8722\n",
      "Epoch 9/15 | Train Loss: 0.3140 Acc: 0.8767\n",
      "Epoch 10/15 | Train Loss: 0.2485 Acc: 0.8943\n",
      "Epoch 11/15 | Train Loss: 0.2913 Acc: 0.8811\n",
      "Epoch 12/15 | Train Loss: 0.2776 Acc: 0.8855\n",
      "Epoch 13/15 | Train Loss: 0.2593 Acc: 0.8943\n",
      "Epoch 14/15 | Train Loss: 0.2617 Acc: 0.8899\n",
      "Epoch 15/15 | Train Loss: 0.2400 Acc: 0.8987\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5962 Acc: 0.7162\n",
      "Epoch 2/15 | Train Loss: 0.5073 Acc: 0.7128\n",
      "Epoch 3/15 | Train Loss: 0.4681 Acc: 0.7466\n",
      "Epoch 4/15 | Train Loss: 0.5177 Acc: 0.7568\n",
      "Epoch 5/15 | Train Loss: 0.4277 Acc: 0.7770\n",
      "Epoch 6/15 | Train Loss: 0.3895 Acc: 0.8176\n",
      "Epoch 7/15 | Train Loss: 0.4369 Acc: 0.7804\n",
      "Epoch 8/15 | Train Loss: 0.3646 Acc: 0.8277\n",
      "Epoch 9/15 | Train Loss: 0.3326 Acc: 0.8446\n",
      "Epoch 10/15 | Train Loss: 0.3113 Acc: 0.8581\n",
      "Epoch 11/15 | Train Loss: 0.3188 Acc: 0.8514\n",
      "Epoch 12/15 | Train Loss: 0.3353 Acc: 0.8176\n",
      "Epoch 13/15 | Train Loss: 0.3315 Acc: 0.8480\n",
      "Epoch 14/15 | Train Loss: 0.3384 Acc: 0.8514\n",
      "Epoch 15/15 | Train Loss: 0.2966 Acc: 0.8682\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6611 Acc: 0.7061\n",
      "Epoch 2/15 | Train Loss: 0.5256 Acc: 0.7331\n",
      "Epoch 3/15 | Train Loss: 0.4439 Acc: 0.7534\n",
      "Epoch 4/15 | Train Loss: 0.4712 Acc: 0.7568\n",
      "Epoch 5/15 | Train Loss: 0.4586 Acc: 0.7365\n",
      "Epoch 6/15 | Train Loss: 0.4462 Acc: 0.7736\n",
      "Epoch 7/15 | Train Loss: 0.4456 Acc: 0.7872\n",
      "Epoch 8/15 | Train Loss: 0.3816 Acc: 0.8007\n",
      "Epoch 9/15 | Train Loss: 0.4241 Acc: 0.7804\n",
      "Epoch 10/15 | Train Loss: 0.3564 Acc: 0.8480\n",
      "Epoch 11/15 | Train Loss: 0.3535 Acc: 0.8311\n",
      "Epoch 12/15 | Train Loss: 0.3424 Acc: 0.8209\n",
      "Epoch 13/15 | Train Loss: 0.3677 Acc: 0.8176\n",
      "Epoch 14/15 | Train Loss: 0.3593 Acc: 0.8311\n",
      "Epoch 15/15 | Train Loss: 0.3539 Acc: 0.8378\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6368 Acc: 0.6465\n",
      "Epoch 2/15 | Train Loss: 0.5132 Acc: 0.7306\n",
      "Epoch 3/15 | Train Loss: 0.5191 Acc: 0.7037\n",
      "Epoch 4/15 | Train Loss: 0.4302 Acc: 0.8081\n",
      "Epoch 5/15 | Train Loss: 0.4585 Acc: 0.7205\n",
      "Epoch 6/15 | Train Loss: 0.3539 Acc: 0.8451\n",
      "Epoch 7/15 | Train Loss: 0.4027 Acc: 0.7980\n",
      "Epoch 8/15 | Train Loss: 0.3795 Acc: 0.8047\n",
      "Epoch 9/15 | Train Loss: 0.3393 Acc: 0.8384\n",
      "Epoch 10/15 | Train Loss: 0.3785 Acc: 0.7946\n",
      "Epoch 11/15 | Train Loss: 0.3124 Acc: 0.8552\n",
      "Epoch 12/15 | Train Loss: 0.3191 Acc: 0.8687\n",
      "Epoch 13/15 | Train Loss: 0.3280 Acc: 0.8418\n",
      "Epoch 14/15 | Train Loss: 0.3619 Acc: 0.7946\n",
      "Epoch 15/15 | Train Loss: 0.2960 Acc: 0.8687\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6183 Acc: 0.7252\n",
      "Epoch 2/15 | Train Loss: 0.5100 Acc: 0.7939\n",
      "Epoch 3/15 | Train Loss: 0.4846 Acc: 0.7748\n",
      "Epoch 4/15 | Train Loss: 0.4250 Acc: 0.8321\n",
      "Epoch 5/15 | Train Loss: 0.4159 Acc: 0.7901\n",
      "Epoch 6/15 | Train Loss: 0.4006 Acc: 0.8206\n",
      "Epoch 7/15 | Train Loss: 0.4052 Acc: 0.8168\n",
      "Epoch 8/15 | Train Loss: 0.4183 Acc: 0.8321\n",
      "Epoch 9/15 | Train Loss: 0.3880 Acc: 0.8244\n",
      "Epoch 10/15 | Train Loss: 0.3572 Acc: 0.8588\n",
      "Epoch 11/15 | Train Loss: 0.3318 Acc: 0.8626\n",
      "Epoch 12/15 | Train Loss: 0.3559 Acc: 0.8435\n",
      "Epoch 13/15 | Train Loss: 0.3457 Acc: 0.8397\n",
      "Epoch 14/15 | Train Loss: 0.3329 Acc: 0.8473\n",
      "Epoch 15/15 | Train Loss: 0.3452 Acc: 0.8664\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5212 Acc: 0.7878\n",
      "Epoch 2/15 | Train Loss: 0.4734 Acc: 0.8163\n",
      "Epoch 3/15 | Train Loss: 0.3662 Acc: 0.8571\n",
      "Epoch 4/15 | Train Loss: 0.3481 Acc: 0.8571\n",
      "Epoch 5/15 | Train Loss: 0.3249 Acc: 0.8653\n",
      "Epoch 6/15 | Train Loss: 0.3367 Acc: 0.8735\n",
      "Epoch 7/15 | Train Loss: 0.2773 Acc: 0.8735\n",
      "Epoch 8/15 | Train Loss: 0.3138 Acc: 0.8776\n",
      "Epoch 9/15 | Train Loss: 0.3056 Acc: 0.8694\n",
      "Epoch 10/15 | Train Loss: 0.2501 Acc: 0.9265\n",
      "Epoch 11/15 | Train Loss: 0.2921 Acc: 0.8816\n",
      "Epoch 12/15 | Train Loss: 0.2444 Acc: 0.9102\n",
      "Epoch 13/15 | Train Loss: 0.3028 Acc: 0.8776\n",
      "Epoch 14/15 | Train Loss: 0.2294 Acc: 0.9102\n",
      "Epoch 15/15 | Train Loss: 0.2465 Acc: 0.9061\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6741 Acc: 0.6587\n",
      "Epoch 2/15 | Train Loss: 0.5596 Acc: 0.6944\n",
      "Epoch 3/15 | Train Loss: 0.5316 Acc: 0.7302\n",
      "Epoch 4/15 | Train Loss: 0.5104 Acc: 0.7421\n",
      "Epoch 5/15 | Train Loss: 0.4923 Acc: 0.7381\n",
      "Epoch 6/15 | Train Loss: 0.4970 Acc: 0.7698\n",
      "Epoch 7/15 | Train Loss: 0.4534 Acc: 0.8095\n",
      "Epoch 8/15 | Train Loss: 0.3938 Acc: 0.8294\n",
      "Epoch 9/15 | Train Loss: 0.3948 Acc: 0.8294\n",
      "Epoch 10/15 | Train Loss: 0.3981 Acc: 0.8175\n",
      "Epoch 11/15 | Train Loss: 0.3193 Acc: 0.8571\n",
      "Epoch 12/15 | Train Loss: 0.3675 Acc: 0.8373\n",
      "Epoch 13/15 | Train Loss: 0.3134 Acc: 0.8571\n",
      "Epoch 14/15 | Train Loss: 0.3083 Acc: 0.8690\n",
      "Epoch 15/15 | Train Loss: 0.3231 Acc: 0.8611\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6959 Acc: 0.6587\n",
      "Epoch 2/15 | Train Loss: 0.6082 Acc: 0.6508\n",
      "Epoch 3/15 | Train Loss: 0.5154 Acc: 0.7222\n",
      "Epoch 4/15 | Train Loss: 0.5016 Acc: 0.7183\n",
      "Epoch 5/15 | Train Loss: 0.5455 Acc: 0.7540\n",
      "Epoch 6/15 | Train Loss: 0.5431 Acc: 0.7262\n",
      "Epoch 7/15 | Train Loss: 0.5375 Acc: 0.7302\n",
      "Epoch 8/15 | Train Loss: 0.4420 Acc: 0.7579\n",
      "Epoch 9/15 | Train Loss: 0.4994 Acc: 0.7460\n",
      "Epoch 10/15 | Train Loss: 0.4327 Acc: 0.7976\n",
      "Epoch 11/15 | Train Loss: 0.4314 Acc: 0.7937\n",
      "Epoch 12/15 | Train Loss: 0.4220 Acc: 0.7976\n",
      "Epoch 13/15 | Train Loss: 0.4416 Acc: 0.7659\n",
      "Epoch 14/15 | Train Loss: 0.4220 Acc: 0.7897\n",
      "Epoch 15/15 | Train Loss: 0.4436 Acc: 0.7857\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7742 Acc: 0.6245\n",
      "Epoch 2/15 | Train Loss: 0.6134 Acc: 0.6482\n",
      "Epoch 3/15 | Train Loss: 0.5696 Acc: 0.7470\n",
      "Epoch 4/15 | Train Loss: 0.5473 Acc: 0.6957\n",
      "Epoch 5/15 | Train Loss: 0.4921 Acc: 0.7589\n",
      "Epoch 6/15 | Train Loss: 0.4878 Acc: 0.7233\n",
      "Epoch 7/15 | Train Loss: 0.4978 Acc: 0.7115\n",
      "Epoch 8/15 | Train Loss: 0.4298 Acc: 0.8182\n",
      "Epoch 9/15 | Train Loss: 0.4175 Acc: 0.7826\n",
      "Epoch 10/15 | Train Loss: 0.4450 Acc: 0.7747\n",
      "Epoch 11/15 | Train Loss: 0.4621 Acc: 0.7470\n",
      "Epoch 12/15 | Train Loss: 0.4197 Acc: 0.8103\n",
      "Epoch 13/15 | Train Loss: 0.3893 Acc: 0.8182\n",
      "Epoch 14/15 | Train Loss: 0.3787 Acc: 0.8419\n",
      "Epoch 15/15 | Train Loss: 0.3730 Acc: 0.8221\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7673 Acc: 0.5847\n",
      "Epoch 2/15 | Train Loss: 0.5222 Acc: 0.7669\n",
      "Epoch 3/15 | Train Loss: 0.5572 Acc: 0.7839\n",
      "Epoch 4/15 | Train Loss: 0.4804 Acc: 0.7839\n",
      "Epoch 5/15 | Train Loss: 0.4235 Acc: 0.8263\n",
      "Epoch 6/15 | Train Loss: 0.5137 Acc: 0.7712\n",
      "Epoch 7/15 | Train Loss: 0.4589 Acc: 0.8008\n",
      "Epoch 8/15 | Train Loss: 0.5021 Acc: 0.7797\n",
      "Epoch 9/15 | Train Loss: 0.3834 Acc: 0.8390\n",
      "Epoch 10/15 | Train Loss: 0.3804 Acc: 0.8305\n",
      "Epoch 11/15 | Train Loss: 0.4219 Acc: 0.8178\n",
      "Epoch 12/15 | Train Loss: 0.3697 Acc: 0.8475\n",
      "Epoch 13/15 | Train Loss: 0.3729 Acc: 0.8263\n",
      "Epoch 14/15 | Train Loss: 0.3534 Acc: 0.8305\n",
      "Epoch 15/15 | Train Loss: 0.4381 Acc: 0.8051\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7240 Acc: 0.6035\n",
      "Epoch 2/15 | Train Loss: 0.5281 Acc: 0.7930\n",
      "Epoch 3/15 | Train Loss: 0.3945 Acc: 0.8502\n",
      "Epoch 4/15 | Train Loss: 0.3648 Acc: 0.8370\n",
      "Epoch 5/15 | Train Loss: 0.3554 Acc: 0.8634\n",
      "Epoch 6/15 | Train Loss: 0.3576 Acc: 0.8678\n",
      "Epoch 7/15 | Train Loss: 0.3472 Acc: 0.8590\n",
      "Epoch 8/15 | Train Loss: 0.2779 Acc: 0.8943\n",
      "Epoch 9/15 | Train Loss: 0.2988 Acc: 0.8811\n",
      "Epoch 10/15 | Train Loss: 0.2557 Acc: 0.9031\n",
      "Epoch 11/15 | Train Loss: 0.2546 Acc: 0.9031\n",
      "Epoch 12/15 | Train Loss: 0.3142 Acc: 0.8811\n",
      "Epoch 13/15 | Train Loss: 0.2688 Acc: 0.8899\n",
      "Epoch 14/15 | Train Loss: 0.2837 Acc: 0.9031\n",
      "Epoch 15/15 | Train Loss: 0.2414 Acc: 0.9031\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5450 Acc: 0.7232\n",
      "Epoch 2/15 | Train Loss: 0.3893 Acc: 0.8042\n",
      "Epoch 3/15 | Train Loss: 0.3643 Acc: 0.7990\n",
      "Epoch 4/15 | Train Loss: 0.3330 Acc: 0.8564\n",
      "Epoch 5/15 | Train Loss: 0.3609 Acc: 0.8251\n",
      "Epoch 6/15 | Train Loss: 0.3244 Acc: 0.8381\n",
      "Epoch 7/15 | Train Loss: 0.3136 Acc: 0.8538\n",
      "Epoch 8/15 | Train Loss: 0.2796 Acc: 0.8564\n",
      "Epoch 9/15 | Train Loss: 0.2541 Acc: 0.8825\n",
      "Epoch 10/15 | Train Loss: 0.2679 Acc: 0.8721\n",
      "Epoch 11/15 | Train Loss: 0.2649 Acc: 0.8747\n",
      "Epoch 12/15 | Train Loss: 0.2434 Acc: 0.8799\n",
      "Epoch 13/15 | Train Loss: 0.2307 Acc: 0.8930\n",
      "Epoch 14/15 | Train Loss: 0.2017 Acc: 0.9269\n",
      "Epoch 15/15 | Train Loss: 0.2465 Acc: 0.8799\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5421 Acc: 0.7572\n",
      "Epoch 2/15 | Train Loss: 0.3753 Acc: 0.7807\n",
      "Epoch 3/15 | Train Loss: 0.3855 Acc: 0.7885\n",
      "Epoch 4/15 | Train Loss: 0.3307 Acc: 0.8094\n",
      "Epoch 5/15 | Train Loss: 0.3520 Acc: 0.8198\n",
      "Epoch 6/15 | Train Loss: 0.3546 Acc: 0.7833\n",
      "Epoch 7/15 | Train Loss: 0.3230 Acc: 0.8381\n",
      "Epoch 8/15 | Train Loss: 0.2791 Acc: 0.8564\n",
      "Epoch 9/15 | Train Loss: 0.2871 Acc: 0.8590\n",
      "Epoch 10/15 | Train Loss: 0.2544 Acc: 0.8747\n",
      "Epoch 11/15 | Train Loss: 0.2753 Acc: 0.8590\n",
      "Epoch 12/15 | Train Loss: 0.2639 Acc: 0.8668\n",
      "Epoch 13/15 | Train Loss: 0.2549 Acc: 0.8721\n",
      "Epoch 14/15 | Train Loss: 0.2721 Acc: 0.8590\n",
      "Epoch 15/15 | Train Loss: 0.2494 Acc: 0.8825\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5505 Acc: 0.7109\n",
      "Epoch 2/15 | Train Loss: 0.4163 Acc: 0.7839\n",
      "Epoch 3/15 | Train Loss: 0.3559 Acc: 0.8177\n",
      "Epoch 4/15 | Train Loss: 0.3549 Acc: 0.7943\n",
      "Epoch 5/15 | Train Loss: 0.3343 Acc: 0.8333\n",
      "Epoch 6/15 | Train Loss: 0.3206 Acc: 0.8490\n",
      "Epoch 7/15 | Train Loss: 0.2912 Acc: 0.8542\n",
      "Epoch 8/15 | Train Loss: 0.2757 Acc: 0.8646\n",
      "Epoch 9/15 | Train Loss: 0.2896 Acc: 0.8438\n",
      "Epoch 10/15 | Train Loss: 0.2491 Acc: 0.8750\n",
      "Epoch 11/15 | Train Loss: 0.2692 Acc: 0.8646\n",
      "Epoch 12/15 | Train Loss: 0.2649 Acc: 0.8698\n",
      "Epoch 13/15 | Train Loss: 0.2507 Acc: 0.8776\n",
      "Epoch 14/15 | Train Loss: 0.2794 Acc: 0.8698\n",
      "Epoch 15/15 | Train Loss: 0.2711 Acc: 0.8594\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.4948 Acc: 0.7548\n",
      "Epoch 2/15 | Train Loss: 0.4692 Acc: 0.8025\n",
      "Epoch 3/15 | Train Loss: 0.3957 Acc: 0.8057\n",
      "Epoch 4/15 | Train Loss: 0.3769 Acc: 0.8503\n",
      "Epoch 5/15 | Train Loss: 0.3670 Acc: 0.8248\n",
      "Epoch 6/15 | Train Loss: 0.3560 Acc: 0.8535\n",
      "Epoch 7/15 | Train Loss: 0.3385 Acc: 0.8535\n",
      "Epoch 8/15 | Train Loss: 0.2906 Acc: 0.8822\n",
      "Epoch 9/15 | Train Loss: 0.3286 Acc: 0.8599\n",
      "Epoch 10/15 | Train Loss: 0.3078 Acc: 0.8694\n",
      "Epoch 11/15 | Train Loss: 0.2951 Acc: 0.8854\n",
      "Epoch 12/15 | Train Loss: 0.2586 Acc: 0.8758\n",
      "Epoch 13/15 | Train Loss: 0.2970 Acc: 0.8758\n",
      "Epoch 14/15 | Train Loss: 0.2854 Acc: 0.8885\n",
      "Epoch 15/15 | Train Loss: 0.2675 Acc: 0.8885\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.4642 Acc: 0.8071\n",
      "Epoch 2/15 | Train Loss: 0.4203 Acc: 0.8679\n",
      "Epoch 3/15 | Train Loss: 0.3687 Acc: 0.8536\n",
      "Epoch 4/15 | Train Loss: 0.3550 Acc: 0.8607\n",
      "Epoch 5/15 | Train Loss: 0.2991 Acc: 0.8929\n",
      "Epoch 6/15 | Train Loss: 0.2735 Acc: 0.9000\n",
      "Epoch 7/15 | Train Loss: 0.2743 Acc: 0.8857\n",
      "Epoch 8/15 | Train Loss: 0.2549 Acc: 0.8964\n",
      "Epoch 9/15 | Train Loss: 0.2650 Acc: 0.8750\n",
      "Epoch 10/15 | Train Loss: 0.2233 Acc: 0.9000\n",
      "Epoch 11/15 | Train Loss: 0.2413 Acc: 0.9179\n",
      "Epoch 12/15 | Train Loss: 0.2290 Acc: 0.8964\n",
      "Epoch 13/15 | Train Loss: 0.1956 Acc: 0.9321\n",
      "Epoch 14/15 | Train Loss: 0.2094 Acc: 0.9143\n",
      "Epoch 15/15 | Train Loss: 0.1968 Acc: 0.9286\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6942 Acc: 0.6111\n",
      "Epoch 2/15 | Train Loss: 0.5613 Acc: 0.6825\n",
      "Epoch 3/15 | Train Loss: 0.5223 Acc: 0.7183\n",
      "Epoch 4/15 | Train Loss: 0.4814 Acc: 0.7579\n",
      "Epoch 5/15 | Train Loss: 0.5476 Acc: 0.7341\n",
      "Epoch 6/15 | Train Loss: 0.4920 Acc: 0.7698\n",
      "Epoch 7/15 | Train Loss: 0.4138 Acc: 0.7778\n",
      "Epoch 8/15 | Train Loss: 0.4050 Acc: 0.8016\n",
      "Epoch 9/15 | Train Loss: 0.3383 Acc: 0.8452\n",
      "Epoch 10/15 | Train Loss: 0.3898 Acc: 0.8214\n",
      "Epoch 11/15 | Train Loss: 0.3327 Acc: 0.8373\n",
      "Epoch 12/15 | Train Loss: 0.3529 Acc: 0.8532\n",
      "Epoch 13/15 | Train Loss: 0.3514 Acc: 0.8294\n",
      "Epoch 14/15 | Train Loss: 0.3619 Acc: 0.8135\n",
      "Epoch 15/15 | Train Loss: 0.3453 Acc: 0.8532\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7764 Acc: 0.6190\n",
      "Epoch 2/15 | Train Loss: 0.5974 Acc: 0.6190\n",
      "Epoch 3/15 | Train Loss: 0.5952 Acc: 0.6667\n",
      "Epoch 4/15 | Train Loss: 0.5667 Acc: 0.7302\n",
      "Epoch 5/15 | Train Loss: 0.5174 Acc: 0.7262\n",
      "Epoch 6/15 | Train Loss: 0.5164 Acc: 0.7262\n",
      "Epoch 7/15 | Train Loss: 0.4764 Acc: 0.7341\n",
      "Epoch 8/15 | Train Loss: 0.4318 Acc: 0.7817\n",
      "Epoch 9/15 | Train Loss: 0.4515 Acc: 0.7817\n",
      "Epoch 10/15 | Train Loss: 0.4305 Acc: 0.7778\n",
      "Epoch 11/15 | Train Loss: 0.4193 Acc: 0.8373\n",
      "Epoch 12/15 | Train Loss: 0.4097 Acc: 0.8254\n",
      "Epoch 13/15 | Train Loss: 0.4922 Acc: 0.7659\n",
      "Epoch 14/15 | Train Loss: 0.4323 Acc: 0.7698\n",
      "Epoch 15/15 | Train Loss: 0.3754 Acc: 0.8294\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6730 Acc: 0.6482\n",
      "Epoch 2/15 | Train Loss: 0.5421 Acc: 0.7115\n",
      "Epoch 3/15 | Train Loss: 0.5024 Acc: 0.7273\n",
      "Epoch 4/15 | Train Loss: 0.5413 Acc: 0.7352\n",
      "Epoch 5/15 | Train Loss: 0.4681 Acc: 0.7747\n",
      "Epoch 6/15 | Train Loss: 0.4600 Acc: 0.7510\n",
      "Epoch 7/15 | Train Loss: 0.4467 Acc: 0.7668\n",
      "Epoch 8/15 | Train Loss: 0.4189 Acc: 0.8024\n",
      "Epoch 9/15 | Train Loss: 0.3905 Acc: 0.8261\n",
      "Epoch 10/15 | Train Loss: 0.4174 Acc: 0.7708\n",
      "Epoch 11/15 | Train Loss: 0.4920 Acc: 0.7787\n",
      "Epoch 12/15 | Train Loss: 0.3790 Acc: 0.8182\n",
      "Epoch 13/15 | Train Loss: 0.3978 Acc: 0.8221\n",
      "Epoch 14/15 | Train Loss: 0.3724 Acc: 0.8498\n",
      "Epoch 15/15 | Train Loss: 0.3650 Acc: 0.8261\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6704 Acc: 0.6610\n",
      "Epoch 2/15 | Train Loss: 0.5898 Acc: 0.7203\n",
      "Epoch 3/15 | Train Loss: 0.5123 Acc: 0.7966\n",
      "Epoch 4/15 | Train Loss: 0.4613 Acc: 0.7797\n",
      "Epoch 5/15 | Train Loss: 0.4827 Acc: 0.7839\n",
      "Epoch 6/15 | Train Loss: 0.4204 Acc: 0.8390\n",
      "Epoch 7/15 | Train Loss: 0.3883 Acc: 0.8305\n",
      "Epoch 8/15 | Train Loss: 0.5116 Acc: 0.7754\n",
      "Epoch 9/15 | Train Loss: 0.4386 Acc: 0.8051\n",
      "Epoch 10/15 | Train Loss: 0.4202 Acc: 0.8390\n",
      "Epoch 11/15 | Train Loss: 0.4160 Acc: 0.8263\n",
      "Epoch 12/15 | Train Loss: 0.3743 Acc: 0.8136\n",
      "Epoch 13/15 | Train Loss: 0.4091 Acc: 0.8178\n",
      "Epoch 14/15 | Train Loss: 0.3762 Acc: 0.8432\n",
      "Epoch 15/15 | Train Loss: 0.3611 Acc: 0.8390\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5131 Acc: 0.7709\n",
      "Epoch 2/15 | Train Loss: 0.4623 Acc: 0.8238\n",
      "Epoch 3/15 | Train Loss: 0.3986 Acc: 0.8502\n",
      "Epoch 4/15 | Train Loss: 0.3993 Acc: 0.8458\n",
      "Epoch 5/15 | Train Loss: 0.3805 Acc: 0.8150\n",
      "Epoch 6/15 | Train Loss: 0.4741 Acc: 0.8282\n",
      "Epoch 7/15 | Train Loss: 0.3494 Acc: 0.8634\n",
      "Epoch 8/15 | Train Loss: 0.3804 Acc: 0.8502\n",
      "Epoch 9/15 | Train Loss: 0.3196 Acc: 0.8502\n",
      "Epoch 10/15 | Train Loss: 0.3149 Acc: 0.8767\n",
      "Epoch 11/15 | Train Loss: 0.2887 Acc: 0.9075\n",
      "Epoch 12/15 | Train Loss: 0.2470 Acc: 0.9207\n",
      "Epoch 13/15 | Train Loss: 0.2738 Acc: 0.8943\n",
      "Epoch 14/15 | Train Loss: 0.2528 Acc: 0.9075\n",
      "Epoch 15/15 | Train Loss: 0.2641 Acc: 0.8987\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.4892 Acc: 0.7683\n",
      "Epoch 2/15 | Train Loss: 0.4378 Acc: 0.7936\n",
      "Epoch 3/15 | Train Loss: 0.3903 Acc: 0.8073\n",
      "Epoch 4/15 | Train Loss: 0.3482 Acc: 0.8326\n",
      "Epoch 5/15 | Train Loss: 0.3529 Acc: 0.8096\n",
      "Epoch 6/15 | Train Loss: 0.3239 Acc: 0.8417\n",
      "Epoch 7/15 | Train Loss: 0.3434 Acc: 0.8417\n",
      "Epoch 8/15 | Train Loss: 0.3036 Acc: 0.8463\n",
      "Epoch 9/15 | Train Loss: 0.2930 Acc: 0.8670\n",
      "Epoch 10/15 | Train Loss: 0.2755 Acc: 0.8899\n",
      "Epoch 11/15 | Train Loss: 0.2665 Acc: 0.8830\n",
      "Epoch 12/15 | Train Loss: 0.2693 Acc: 0.8945\n",
      "Epoch 13/15 | Train Loss: 0.2708 Acc: 0.8784\n",
      "Epoch 14/15 | Train Loss: 0.2908 Acc: 0.8670\n",
      "Epoch 15/15 | Train Loss: 0.2725 Acc: 0.8761\n",
      "Fold 2 Test Accuracy: 0.6364\n",
      "===== Fold 3 =====\n",
      "Epoch 1: Generator Loss = 9.5919, Discriminator Loss = 9.0786\n",
      "Epoch 2: Generator Loss = 10.4514, Discriminator Loss = 9.4216\n",
      "Epoch 3: Generator Loss = 11.5757, Discriminator Loss = 8.3664\n",
      "Epoch 4: Generator Loss = 16.0023, Discriminator Loss = 6.8176\n",
      "Epoch 5: Generator Loss = 23.0950, Discriminator Loss = 4.5143\n",
      "Epoch 6: Generator Loss = 30.1140, Discriminator Loss = 3.5131\n",
      "Epoch 7: Generator Loss = 39.3201, Discriminator Loss = 3.0782\n",
      "Epoch 8: Generator Loss = 37.9350, Discriminator Loss = 3.0398\n",
      "Epoch 9: Generator Loss = 39.8761, Discriminator Loss = 4.2941\n",
      "Epoch 10: Generator Loss = 33.2986, Discriminator Loss = 5.0198\n",
      "Epoch 11: Generator Loss = 38.3143, Discriminator Loss = 4.9038\n",
      "Epoch 12: Generator Loss = 31.0985, Discriminator Loss = 6.2334\n",
      "Epoch 13: Generator Loss = 32.0069, Discriminator Loss = 9.5975\n",
      "Epoch 14: Generator Loss = 24.0276, Discriminator Loss = 9.2594\n",
      "Epoch 15: Generator Loss = 32.1760, Discriminator Loss = 6.3697\n",
      "Epoch 16: Generator Loss = 27.4603, Discriminator Loss = 6.1280\n",
      "Epoch 17: Generator Loss = 21.5853, Discriminator Loss = 8.8972\n",
      "Epoch 18: Generator Loss = 25.1433, Discriminator Loss = 7.6800\n",
      "Epoch 19: Generator Loss = 19.1995, Discriminator Loss = 8.5404\n",
      "Epoch 20: Generator Loss = 17.4831, Discriminator Loss = 8.7318\n",
      "Epoch 21: Generator Loss = 13.3378, Discriminator Loss = 8.7120\n",
      "Epoch 22: Generator Loss = 13.9403, Discriminator Loss = 8.4586\n",
      "Epoch 23: Generator Loss = 19.4676, Discriminator Loss = 7.2215\n",
      "Epoch 24: Generator Loss = 18.6564, Discriminator Loss = 9.7013\n",
      "Epoch 25: Generator Loss = 21.5724, Discriminator Loss = 7.3735\n",
      "Epoch 26: Generator Loss = 19.4945, Discriminator Loss = 7.7521\n",
      "Epoch 27: Generator Loss = 20.6364, Discriminator Loss = 6.6382\n",
      "Epoch 28: Generator Loss = 20.6965, Discriminator Loss = 6.3553\n",
      "Epoch 29: Generator Loss = 24.6732, Discriminator Loss = 7.0119\n",
      "Epoch 30: Generator Loss = 21.5337, Discriminator Loss = 8.5073\n",
      "Epoch 31: Generator Loss = 27.4009, Discriminator Loss = 7.5253\n",
      "Epoch 32: Generator Loss = 20.6810, Discriminator Loss = 8.3203\n",
      "Epoch 33: Generator Loss = 26.4000, Discriminator Loss = 9.2221\n",
      "Epoch 34: Generator Loss = 23.9047, Discriminator Loss = 7.8162\n",
      "Epoch 35: Generator Loss = 17.3209, Discriminator Loss = 8.3866\n",
      "Epoch 36: Generator Loss = 17.4576, Discriminator Loss = 7.1437\n",
      "Epoch 37: Generator Loss = 20.8909, Discriminator Loss = 8.9285\n",
      "Epoch 38: Generator Loss = 23.2249, Discriminator Loss = 8.9374\n",
      "Epoch 39: Generator Loss = 16.6584, Discriminator Loss = 7.7963\n",
      "Epoch 40: Generator Loss = 18.4988, Discriminator Loss = 8.0422\n",
      "Epoch 41: Generator Loss = 18.7519, Discriminator Loss = 10.8433\n",
      "Epoch 42: Generator Loss = 16.4599, Discriminator Loss = 8.5137\n",
      "Epoch 43: Generator Loss = 14.9249, Discriminator Loss = 7.0642\n",
      "Epoch 44: Generator Loss = 19.2289, Discriminator Loss = 6.8480\n",
      "Epoch 45: Generator Loss = 17.4868, Discriminator Loss = 8.7093\n",
      "Epoch 46: Generator Loss = 15.9574, Discriminator Loss = 7.9089\n",
      "Epoch 47: Generator Loss = 19.7865, Discriminator Loss = 6.9007\n",
      "Epoch 48: Generator Loss = 20.7191, Discriminator Loss = 5.7145\n",
      "Epoch 49: Generator Loss = 27.0722, Discriminator Loss = 6.4737\n",
      "Epoch 50: Generator Loss = 19.1077, Discriminator Loss = 7.2906\n",
      "Epoch 51: Generator Loss = 17.6480, Discriminator Loss = 8.7319\n",
      "Epoch 52: Generator Loss = 14.5550, Discriminator Loss = 7.6644\n",
      "Epoch 53: Generator Loss = 15.4982, Discriminator Loss = 7.7657\n",
      "Epoch 54: Generator Loss = 27.3102, Discriminator Loss = 9.5827\n",
      "Epoch 55: Generator Loss = 16.6774, Discriminator Loss = 9.6493\n",
      "Epoch 56: Generator Loss = 15.1422, Discriminator Loss = 6.9926\n",
      "Epoch 57: Generator Loss = 20.1479, Discriminator Loss = 7.4134\n",
      "Epoch 58: Generator Loss = 23.8256, Discriminator Loss = 7.2162\n",
      "Epoch 59: Generator Loss = 20.5858, Discriminator Loss = 7.4476\n",
      "Epoch 60: Generator Loss = 15.1193, Discriminator Loss = 7.9386\n",
      "Epoch 61: Generator Loss = 18.1537, Discriminator Loss = 6.3079\n",
      "Epoch 62: Generator Loss = 23.4841, Discriminator Loss = 5.8418\n",
      "Epoch 63: Generator Loss = 24.5447, Discriminator Loss = 4.9568\n",
      "Epoch 64: Generator Loss = 23.8910, Discriminator Loss = 5.8568\n",
      "Epoch 65: Generator Loss = 27.5545, Discriminator Loss = 5.0880\n",
      "Epoch 66: Generator Loss = 26.0890, Discriminator Loss = 4.8397\n",
      "Epoch 67: Generator Loss = 29.1094, Discriminator Loss = 5.3768\n",
      "Epoch 68: Generator Loss = 26.0588, Discriminator Loss = 4.6629\n",
      "Epoch 69: Generator Loss = 34.1852, Discriminator Loss = 3.4779\n",
      "Epoch 70: Generator Loss = 23.1363, Discriminator Loss = 6.4855\n",
      "Epoch 71: Generator Loss = 30.6407, Discriminator Loss = 4.1370\n",
      "Epoch 72: Generator Loss = 33.4034, Discriminator Loss = 4.5983\n",
      "Epoch 73: Generator Loss = 35.4557, Discriminator Loss = 4.2582\n",
      "Epoch 74: Generator Loss = 40.1573, Discriminator Loss = 3.9229\n",
      "Epoch 75: Generator Loss = 34.5036, Discriminator Loss = 3.5619\n",
      "Epoch 76: Generator Loss = 34.7794, Discriminator Loss = 5.3444\n",
      "Epoch 77: Generator Loss = 41.3701, Discriminator Loss = 4.0906\n",
      "Epoch 78: Generator Loss = 33.2020, Discriminator Loss = 3.0794\n",
      "Epoch 79: Generator Loss = 47.9039, Discriminator Loss = 3.6623\n",
      "Epoch 80: Generator Loss = 37.1232, Discriminator Loss = 2.4937\n",
      "Epoch 81: Generator Loss = 50.7471, Discriminator Loss = 2.5598\n",
      "Epoch 82: Generator Loss = 51.6646, Discriminator Loss = 4.8376\n",
      "Epoch 83: Generator Loss = 47.1836, Discriminator Loss = 1.4843\n",
      "Epoch 84: Generator Loss = 51.4324, Discriminator Loss = 1.7769\n",
      "Epoch 85: Generator Loss = 44.0153, Discriminator Loss = 2.0089\n",
      "Epoch 86: Generator Loss = 58.7915, Discriminator Loss = 2.4896\n",
      "Epoch 87: Generator Loss = 48.0745, Discriminator Loss = 1.6362\n",
      "Epoch 88: Generator Loss = 58.2100, Discriminator Loss = 1.8140\n",
      "Epoch 89: Generator Loss = 51.0602, Discriminator Loss = 1.4057\n",
      "Epoch 90: Generator Loss = 53.0960, Discriminator Loss = 1.3113\n",
      "Epoch 91: Generator Loss = 53.4387, Discriminator Loss = 6.0274\n",
      "Epoch 92: Generator Loss = 54.7227, Discriminator Loss = 3.0171\n",
      "Epoch 93: Generator Loss = 48.8814, Discriminator Loss = 1.2294\n",
      "Epoch 94: Generator Loss = 47.7249, Discriminator Loss = 1.4759\n",
      "Epoch 95: Generator Loss = 54.5398, Discriminator Loss = 0.9679\n",
      "Epoch 96: Generator Loss = 49.6005, Discriminator Loss = 1.6992\n",
      "Epoch 97: Generator Loss = 58.3066, Discriminator Loss = 1.2261\n",
      "Epoch 98: Generator Loss = 64.7632, Discriminator Loss = 2.3663\n",
      "Epoch 99: Generator Loss = 59.6013, Discriminator Loss = 1.1188\n",
      "Epoch 100: Generator Loss = 60.9046, Discriminator Loss = 4.4183\n",
      "Epoch 101: Generator Loss = 37.8066, Discriminator Loss = 4.4807\n",
      "Epoch 102: Generator Loss = 55.8758, Discriminator Loss = 1.5491\n",
      "Epoch 103: Generator Loss = 62.1301, Discriminator Loss = 1.4804\n",
      "Epoch 104: Generator Loss = 63.2792, Discriminator Loss = 0.8959\n",
      "Epoch 105: Generator Loss = 61.4807, Discriminator Loss = 0.5362\n",
      "Epoch 106: Generator Loss = 61.1007, Discriminator Loss = 1.5476\n",
      "Epoch 107: Generator Loss = 52.9245, Discriminator Loss = 0.9823\n",
      "Epoch 108: Generator Loss = 63.6566, Discriminator Loss = 1.4961\n",
      "Epoch 109: Generator Loss = 84.0130, Discriminator Loss = 1.9241\n",
      "Epoch 110: Generator Loss = 63.6066, Discriminator Loss = 1.2276\n",
      "Epoch 111: Generator Loss = 68.2059, Discriminator Loss = 1.0438\n",
      "Epoch 112: Generator Loss = 72.4547, Discriminator Loss = 0.9407\n",
      "Epoch 113: Generator Loss = 63.2429, Discriminator Loss = 0.9522\n",
      "Epoch 114: Generator Loss = 76.4608, Discriminator Loss = 1.0053\n",
      "Epoch 115: Generator Loss = 75.3315, Discriminator Loss = 1.2123\n",
      "Epoch 116: Generator Loss = 68.5702, Discriminator Loss = 0.6545\n",
      "Epoch 117: Generator Loss = 68.4098, Discriminator Loss = 0.5918\n",
      "Epoch 118: Generator Loss = 68.2821, Discriminator Loss = 1.0397\n",
      "Epoch 119: Generator Loss = 49.8951, Discriminator Loss = 4.8432\n",
      "Epoch 120: Generator Loss = 53.8035, Discriminator Loss = 9.3024\n",
      "Epoch 121: Generator Loss = 48.8073, Discriminator Loss = 3.0769\n",
      "Epoch 122: Generator Loss = 64.1805, Discriminator Loss = 1.3502\n",
      "Epoch 123: Generator Loss = 60.9916, Discriminator Loss = 1.4492\n",
      "Epoch 124: Generator Loss = 58.5388, Discriminator Loss = 1.9056\n",
      "Epoch 125: Generator Loss = 75.1037, Discriminator Loss = 1.0945\n",
      "Epoch 126: Generator Loss = 78.6962, Discriminator Loss = 0.7229\n",
      "Epoch 127: Generator Loss = 76.2053, Discriminator Loss = 0.4939\n",
      "Epoch 128: Generator Loss = 79.0400, Discriminator Loss = 0.8369\n",
      "Epoch 129: Generator Loss = 65.6537, Discriminator Loss = 0.8347\n",
      "Epoch 130: Generator Loss = 65.1109, Discriminator Loss = 1.2048\n",
      "Epoch 131: Generator Loss = 73.3471, Discriminator Loss = 1.3763\n",
      "Epoch 132: Generator Loss = 57.5046, Discriminator Loss = 0.6754\n",
      "Epoch 133: Generator Loss = 67.4379, Discriminator Loss = 1.1308\n",
      "Epoch 134: Generator Loss = 69.2941, Discriminator Loss = 0.5328\n",
      "Epoch 135: Generator Loss = 81.6894, Discriminator Loss = 1.0108\n",
      "Epoch 136: Generator Loss = 60.7396, Discriminator Loss = 0.8069\n",
      "Epoch 137: Generator Loss = 65.4990, Discriminator Loss = 2.6988\n",
      "Epoch 138: Generator Loss = 63.5756, Discriminator Loss = 1.7764\n",
      "Epoch 139: Generator Loss = 79.4645, Discriminator Loss = 1.1126\n",
      "Epoch 140: Generator Loss = 68.3803, Discriminator Loss = 0.4218\n",
      "Epoch 141: Generator Loss = 72.7216, Discriminator Loss = 2.6093\n",
      "Epoch 142: Generator Loss = 72.1768, Discriminator Loss = 1.7252\n",
      "Epoch 143: Generator Loss = 59.8791, Discriminator Loss = 0.6045\n",
      "Epoch 144: Generator Loss = 62.0365, Discriminator Loss = 1.3823\n",
      "Epoch 145: Generator Loss = 70.9453, Discriminator Loss = 1.1363\n",
      "Epoch 146: Generator Loss = 53.7819, Discriminator Loss = 0.6822\n",
      "Epoch 147: Generator Loss = 66.8258, Discriminator Loss = 0.8686\n",
      "Epoch 148: Generator Loss = 66.2881, Discriminator Loss = 1.1156\n",
      "Epoch 149: Generator Loss = 50.3793, Discriminator Loss = 1.1681\n",
      "Epoch 150: Generator Loss = 59.1104, Discriminator Loss = 0.7831\n",
      "Epoch 151: Generator Loss = 69.6550, Discriminator Loss = 0.5679\n",
      "Epoch 152: Generator Loss = 83.4919, Discriminator Loss = 1.8235\n",
      "Epoch 153: Generator Loss = 60.1917, Discriminator Loss = 12.7939\n",
      "Epoch 154: Generator Loss = 43.0842, Discriminator Loss = 8.9845\n",
      "Epoch 155: Generator Loss = 33.7809, Discriminator Loss = 3.6844\n",
      "Epoch 156: Generator Loss = 56.2786, Discriminator Loss = 3.5042\n",
      "Epoch 157: Generator Loss = 58.2352, Discriminator Loss = 2.5736\n",
      "Epoch 158: Generator Loss = 46.9987, Discriminator Loss = 3.4160\n",
      "Epoch 159: Generator Loss = 65.9958, Discriminator Loss = 1.8210\n",
      "Epoch 160: Generator Loss = 53.2399, Discriminator Loss = 2.0530\n",
      "Epoch 161: Generator Loss = 72.5438, Discriminator Loss = 1.3757\n",
      "Epoch 162: Generator Loss = 78.8249, Discriminator Loss = 1.3537\n",
      "Epoch 163: Generator Loss = 61.7786, Discriminator Loss = 1.5111\n",
      "Epoch 164: Generator Loss = 76.1335, Discriminator Loss = 2.6088\n",
      "Epoch 165: Generator Loss = 69.7474, Discriminator Loss = 1.0089\n",
      "Epoch 166: Generator Loss = 77.1347, Discriminator Loss = 1.5269\n",
      "Epoch 167: Generator Loss = 50.7135, Discriminator Loss = 2.6889\n",
      "Epoch 168: Generator Loss = 84.8812, Discriminator Loss = 1.7986\n",
      "Epoch 169: Generator Loss = 56.8829, Discriminator Loss = 1.6468\n",
      "Epoch 170: Generator Loss = 67.8155, Discriminator Loss = 2.5766\n",
      "Epoch 171: Generator Loss = 49.8154, Discriminator Loss = 12.3828\n",
      "Epoch 172: Generator Loss = 47.3937, Discriminator Loss = 3.9573\n",
      "Epoch 173: Generator Loss = 54.1700, Discriminator Loss = 2.1442\n",
      "Epoch 174: Generator Loss = 60.9159, Discriminator Loss = 1.5327\n",
      "Epoch 175: Generator Loss = 82.5497, Discriminator Loss = 1.3562\n",
      "Epoch 176: Generator Loss = 68.5242, Discriminator Loss = 1.2739\n",
      "Epoch 177: Generator Loss = 82.3890, Discriminator Loss = 1.7705\n",
      "Epoch 178: Generator Loss = 79.8533, Discriminator Loss = 1.4433\n",
      "Epoch 179: Generator Loss = 74.9536, Discriminator Loss = 1.5204\n",
      "Epoch 180: Generator Loss = 73.0562, Discriminator Loss = 0.7469\n",
      "Epoch 181: Generator Loss = 71.2691, Discriminator Loss = 0.8612\n",
      "Epoch 182: Generator Loss = 59.3229, Discriminator Loss = 0.6813\n",
      "Epoch 183: Generator Loss = 60.6525, Discriminator Loss = 1.9747\n",
      "Epoch 184: Generator Loss = 69.8548, Discriminator Loss = 1.5770\n",
      "Epoch 185: Generator Loss = 65.2560, Discriminator Loss = 0.5422\n",
      "Epoch 186: Generator Loss = 74.9159, Discriminator Loss = 1.0374\n",
      "Epoch 187: Generator Loss = 67.3923, Discriminator Loss = 2.9913\n",
      "Epoch 188: Generator Loss = 77.1381, Discriminator Loss = 1.0432\n",
      "Epoch 189: Generator Loss = 74.3499, Discriminator Loss = 1.6480\n",
      "Epoch 190: Generator Loss = 63.8783, Discriminator Loss = 0.5988\n",
      "Epoch 191: Generator Loss = 74.7729, Discriminator Loss = 0.9857\n",
      "Epoch 192: Generator Loss = 72.3163, Discriminator Loss = 1.1225\n",
      "Epoch 193: Generator Loss = 81.9595, Discriminator Loss = 1.0275\n",
      "Epoch 194: Generator Loss = 86.7144, Discriminator Loss = 0.5098\n",
      "Epoch 195: Generator Loss = 59.0346, Discriminator Loss = 1.0347\n",
      "Epoch 196: Generator Loss = 65.2364, Discriminator Loss = 1.9997\n",
      "Epoch 197: Generator Loss = 80.1752, Discriminator Loss = 1.3423\n",
      "Epoch 198: Generator Loss = 67.8941, Discriminator Loss = 1.1757\n",
      "Epoch 199: Generator Loss = 74.3308, Discriminator Loss = 1.1365\n",
      "Epoch 200: Generator Loss = 64.0860, Discriminator Loss = 1.1764\n",
      "Epoch 201: Generator Loss = 89.9256, Discriminator Loss = 0.7571\n",
      "Epoch 202: Generator Loss = 89.4096, Discriminator Loss = 1.4660\n",
      "Epoch 203: Generator Loss = 64.7376, Discriminator Loss = 1.6571\n",
      "Epoch 204: Generator Loss = 82.6102, Discriminator Loss = 0.7115\n",
      "Epoch 205: Generator Loss = 87.0201, Discriminator Loss = 2.2263\n",
      "Epoch 206: Generator Loss = 78.0769, Discriminator Loss = 7.1370\n",
      "Epoch 207: Generator Loss = 47.4412, Discriminator Loss = 3.2535\n",
      "Epoch 208: Generator Loss = 58.0556, Discriminator Loss = 1.6652\n",
      "Epoch 209: Generator Loss = 65.3888, Discriminator Loss = 1.2744\n",
      "Epoch 210: Generator Loss = 70.7559, Discriminator Loss = 2.2297\n",
      "Epoch 211: Generator Loss = 78.0792, Discriminator Loss = 4.5569\n",
      "Epoch 212: Generator Loss = 65.3727, Discriminator Loss = 1.0250\n",
      "Epoch 213: Generator Loss = 80.5379, Discriminator Loss = 1.5874\n",
      "Epoch 214: Generator Loss = 69.4013, Discriminator Loss = 2.3921\n",
      "Epoch 215: Generator Loss = 92.8220, Discriminator Loss = 1.9509\n",
      "Epoch 216: Generator Loss = 78.2338, Discriminator Loss = 2.0048\n",
      "Epoch 217: Generator Loss = 75.1462, Discriminator Loss = 1.5758\n",
      "Epoch 218: Generator Loss = 82.5741, Discriminator Loss = 0.9107\n",
      "Epoch 219: Generator Loss = 79.3404, Discriminator Loss = 0.7315\n",
      "Epoch 220: Generator Loss = 92.9751, Discriminator Loss = 0.9071\n",
      "Epoch 221: Generator Loss = 81.9565, Discriminator Loss = 0.7478\n",
      "Epoch 222: Generator Loss = 87.5515, Discriminator Loss = 0.7328\n",
      "Epoch 223: Generator Loss = 89.4275, Discriminator Loss = 1.2150\n",
      "Epoch 224: Generator Loss = 96.5707, Discriminator Loss = 3.6276\n",
      "Epoch 225: Generator Loss = 60.2622, Discriminator Loss = 1.2275\n",
      "Epoch 226: Generator Loss = 60.7016, Discriminator Loss = 1.9068\n",
      "Epoch 227: Generator Loss = 79.4430, Discriminator Loss = 1.5812\n",
      "Epoch 228: Generator Loss = 76.0459, Discriminator Loss = 1.3767\n",
      "Epoch 229: Generator Loss = 79.1796, Discriminator Loss = 1.1352\n",
      "Epoch 230: Generator Loss = 73.1508, Discriminator Loss = 1.9747\n",
      "Epoch 231: Generator Loss = 81.0089, Discriminator Loss = 0.5512\n",
      "Epoch 232: Generator Loss = 61.8397, Discriminator Loss = 1.0353\n",
      "Epoch 233: Generator Loss = 70.6173, Discriminator Loss = 1.6262\n",
      "Epoch 234: Generator Loss = 84.0031, Discriminator Loss = 1.3847\n",
      "Epoch 235: Generator Loss = 61.6397, Discriminator Loss = 4.8486\n",
      "Epoch 236: Generator Loss = 70.4031, Discriminator Loss = 2.9207\n",
      "Epoch 237: Generator Loss = 68.5774, Discriminator Loss = 1.5133\n",
      "Epoch 238: Generator Loss = 78.1486, Discriminator Loss = 0.9592\n",
      "Epoch 239: Generator Loss = 62.4498, Discriminator Loss = 0.6331\n",
      "Epoch 240: Generator Loss = 93.4758, Discriminator Loss = 0.9234\n",
      "Epoch 241: Generator Loss = 78.6345, Discriminator Loss = 0.9730\n",
      "Epoch 242: Generator Loss = 101.9948, Discriminator Loss = 0.7119\n",
      "Epoch 243: Generator Loss = 88.9774, Discriminator Loss = 0.6180\n",
      "Epoch 244: Generator Loss = 79.7655, Discriminator Loss = 0.7755\n",
      "Epoch 245: Generator Loss = 79.5689, Discriminator Loss = 1.0751\n",
      "Epoch 246: Generator Loss = 62.3615, Discriminator Loss = 3.7722\n",
      "Epoch 247: Generator Loss = 59.0739, Discriminator Loss = 2.0321\n",
      "Epoch 248: Generator Loss = 81.2334, Discriminator Loss = 3.8387\n",
      "Epoch 249: Generator Loss = 70.6332, Discriminator Loss = 8.8850\n",
      "Epoch 250: Generator Loss = 43.5981, Discriminator Loss = 3.9290\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Epoch 1/15 | Train Loss: 0.5313 Acc: 0.7258\n",
      "Epoch 2/15 | Train Loss: 0.4012 Acc: 0.7911\n",
      "Epoch 3/15 | Train Loss: 0.3977 Acc: 0.8198\n",
      "Epoch 4/15 | Train Loss: 0.3396 Acc: 0.8407\n",
      "Epoch 5/15 | Train Loss: 0.3206 Acc: 0.8355\n",
      "Epoch 6/15 | Train Loss: 0.3490 Acc: 0.8172\n",
      "Epoch 7/15 | Train Loss: 0.3161 Acc: 0.8512\n",
      "Epoch 8/15 | Train Loss: 0.2722 Acc: 0.8799\n",
      "Epoch 9/15 | Train Loss: 0.2768 Acc: 0.8721\n",
      "Epoch 10/15 | Train Loss: 0.2626 Acc: 0.8773\n",
      "Epoch 11/15 | Train Loss: 0.2635 Acc: 0.8799\n",
      "Epoch 12/15 | Train Loss: 0.2282 Acc: 0.8851\n",
      "Epoch 13/15 | Train Loss: 0.2424 Acc: 0.8799\n",
      "Epoch 14/15 | Train Loss: 0.2576 Acc: 0.8825\n",
      "Epoch 15/15 | Train Loss: 0.2407 Acc: 0.8747\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.5720 Acc: 0.7363\n",
      "Epoch 2/15 | Train Loss: 0.4119 Acc: 0.7781\n",
      "Epoch 3/15 | Train Loss: 0.3953 Acc: 0.7833\n",
      "Epoch 4/15 | Train Loss: 0.3801 Acc: 0.7990\n",
      "Epoch 5/15 | Train Loss: 0.3589 Acc: 0.8146\n",
      "Epoch 6/15 | Train Loss: 0.3509 Acc: 0.8094\n",
      "Epoch 7/15 | Train Loss: 0.2969 Acc: 0.8564\n",
      "Epoch 8/15 | Train Loss: 0.2596 Acc: 0.8616\n",
      "Epoch 9/15 | Train Loss: 0.2864 Acc: 0.8825\n",
      "Epoch 10/15 | Train Loss: 0.2796 Acc: 0.8616\n",
      "Epoch 11/15 | Train Loss: 0.2873 Acc: 0.8564\n",
      "Epoch 12/15 | Train Loss: 0.2993 Acc: 0.8590\n",
      "Epoch 13/15 | Train Loss: 0.2890 Acc: 0.8538\n",
      "Epoch 14/15 | Train Loss: 0.2804 Acc: 0.8773\n",
      "Epoch 15/15 | Train Loss: 0.2912 Acc: 0.8433\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.5001 Acc: 0.7760\n",
      "Epoch 2/15 | Train Loss: 0.4350 Acc: 0.7474\n",
      "Epoch 3/15 | Train Loss: 0.3773 Acc: 0.8021\n",
      "Epoch 4/15 | Train Loss: 0.3592 Acc: 0.8073\n",
      "Epoch 5/15 | Train Loss: 0.3434 Acc: 0.8229\n",
      "Epoch 6/15 | Train Loss: 0.3522 Acc: 0.8359\n",
      "Epoch 7/15 | Train Loss: 0.3207 Acc: 0.8255\n",
      "Epoch 8/15 | Train Loss: 0.3312 Acc: 0.8411\n",
      "Epoch 9/15 | Train Loss: 0.2831 Acc: 0.8568\n",
      "Epoch 10/15 | Train Loss: 0.3077 Acc: 0.8359\n",
      "Epoch 11/15 | Train Loss: 0.3127 Acc: 0.8411\n",
      "Epoch 12/15 | Train Loss: 0.2471 Acc: 0.8906\n",
      "Epoch 13/15 | Train Loss: 0.3105 Acc: 0.8411\n",
      "Epoch 14/15 | Train Loss: 0.2576 Acc: 0.8776\n",
      "Epoch 15/15 | Train Loss: 0.2697 Acc: 0.8620\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.4934 Acc: 0.7866\n",
      "Epoch 2/15 | Train Loss: 0.4027 Acc: 0.8344\n",
      "Epoch 3/15 | Train Loss: 0.3580 Acc: 0.8248\n",
      "Epoch 4/15 | Train Loss: 0.3825 Acc: 0.8344\n",
      "Epoch 5/15 | Train Loss: 0.4018 Acc: 0.8312\n",
      "Epoch 6/15 | Train Loss: 0.3757 Acc: 0.8471\n",
      "Epoch 7/15 | Train Loss: 0.3871 Acc: 0.8408\n",
      "Epoch 8/15 | Train Loss: 0.3007 Acc: 0.8631\n",
      "Epoch 9/15 | Train Loss: 0.2813 Acc: 0.8790\n",
      "Epoch 10/15 | Train Loss: 0.2704 Acc: 0.8885\n",
      "Epoch 11/15 | Train Loss: 0.2939 Acc: 0.8726\n",
      "Epoch 12/15 | Train Loss: 0.3062 Acc: 0.8694\n",
      "Epoch 13/15 | Train Loss: 0.2786 Acc: 0.8790\n",
      "Epoch 14/15 | Train Loss: 0.3136 Acc: 0.8631\n",
      "Epoch 15/15 | Train Loss: 0.2814 Acc: 0.8822\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5514 Acc: 0.7929\n",
      "Epoch 2/15 | Train Loss: 0.3679 Acc: 0.8536\n",
      "Epoch 3/15 | Train Loss: 0.3279 Acc: 0.8750\n",
      "Epoch 4/15 | Train Loss: 0.3387 Acc: 0.8607\n",
      "Epoch 5/15 | Train Loss: 0.2875 Acc: 0.8857\n",
      "Epoch 6/15 | Train Loss: 0.3160 Acc: 0.8857\n",
      "Epoch 7/15 | Train Loss: 0.2555 Acc: 0.9036\n",
      "Epoch 8/15 | Train Loss: 0.2470 Acc: 0.9036\n",
      "Epoch 9/15 | Train Loss: 0.2393 Acc: 0.9036\n",
      "Epoch 10/15 | Train Loss: 0.2465 Acc: 0.9179\n",
      "Epoch 11/15 | Train Loss: 0.2286 Acc: 0.9071\n",
      "Epoch 12/15 | Train Loss: 0.2323 Acc: 0.9036\n",
      "Epoch 13/15 | Train Loss: 0.2286 Acc: 0.9071\n",
      "Epoch 14/15 | Train Loss: 0.1832 Acc: 0.9286\n",
      "Epoch 15/15 | Train Loss: 0.2375 Acc: 0.9036\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7252 Acc: 0.5992\n",
      "Epoch 2/15 | Train Loss: 0.6319 Acc: 0.6587\n",
      "Epoch 3/15 | Train Loss: 0.5800 Acc: 0.6865\n",
      "Epoch 4/15 | Train Loss: 0.5015 Acc: 0.7341\n",
      "Epoch 5/15 | Train Loss: 0.5085 Acc: 0.7381\n",
      "Epoch 6/15 | Train Loss: 0.4660 Acc: 0.7857\n",
      "Epoch 7/15 | Train Loss: 0.4135 Acc: 0.7937\n",
      "Epoch 8/15 | Train Loss: 0.4124 Acc: 0.7897\n",
      "Epoch 9/15 | Train Loss: 0.4141 Acc: 0.7897\n",
      "Epoch 10/15 | Train Loss: 0.4267 Acc: 0.7698\n",
      "Epoch 11/15 | Train Loss: 0.3885 Acc: 0.7857\n",
      "Epoch 12/15 | Train Loss: 0.3810 Acc: 0.8333\n",
      "Epoch 13/15 | Train Loss: 0.3679 Acc: 0.8214\n",
      "Epoch 14/15 | Train Loss: 0.4285 Acc: 0.8016\n",
      "Epoch 15/15 | Train Loss: 0.3821 Acc: 0.8095\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7381 Acc: 0.6508\n",
      "Epoch 2/15 | Train Loss: 0.5970 Acc: 0.6746\n",
      "Epoch 3/15 | Train Loss: 0.5695 Acc: 0.6905\n",
      "Epoch 4/15 | Train Loss: 0.5373 Acc: 0.7262\n",
      "Epoch 5/15 | Train Loss: 0.5228 Acc: 0.7381\n",
      "Epoch 6/15 | Train Loss: 0.4691 Acc: 0.7540\n",
      "Epoch 7/15 | Train Loss: 0.4444 Acc: 0.8095\n",
      "Epoch 8/15 | Train Loss: 0.4471 Acc: 0.8056\n",
      "Epoch 9/15 | Train Loss: 0.4867 Acc: 0.7778\n",
      "Epoch 10/15 | Train Loss: 0.4393 Acc: 0.7738\n",
      "Epoch 11/15 | Train Loss: 0.4281 Acc: 0.8135\n",
      "Epoch 12/15 | Train Loss: 0.3959 Acc: 0.8175\n",
      "Epoch 13/15 | Train Loss: 0.3736 Acc: 0.8214\n",
      "Epoch 14/15 | Train Loss: 0.3957 Acc: 0.8373\n",
      "Epoch 15/15 | Train Loss: 0.4053 Acc: 0.8175\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7056 Acc: 0.6008\n",
      "Epoch 2/15 | Train Loss: 0.5542 Acc: 0.7233\n",
      "Epoch 3/15 | Train Loss: 0.5732 Acc: 0.6996\n",
      "Epoch 4/15 | Train Loss: 0.5373 Acc: 0.7668\n",
      "Epoch 5/15 | Train Loss: 0.4894 Acc: 0.7787\n",
      "Epoch 6/15 | Train Loss: 0.5034 Acc: 0.7470\n",
      "Epoch 7/15 | Train Loss: 0.4818 Acc: 0.7747\n",
      "Epoch 8/15 | Train Loss: 0.4794 Acc: 0.7668\n",
      "Epoch 9/15 | Train Loss: 0.4109 Acc: 0.8300\n",
      "Epoch 10/15 | Train Loss: 0.4402 Acc: 0.7668\n",
      "Epoch 11/15 | Train Loss: 0.4173 Acc: 0.7826\n",
      "Epoch 12/15 | Train Loss: 0.4133 Acc: 0.8103\n",
      "Epoch 13/15 | Train Loss: 0.4121 Acc: 0.7984\n",
      "Epoch 14/15 | Train Loss: 0.4124 Acc: 0.8063\n",
      "Epoch 15/15 | Train Loss: 0.4060 Acc: 0.8182\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6171 Acc: 0.7161\n",
      "Epoch 2/15 | Train Loss: 0.6128 Acc: 0.7331\n",
      "Epoch 3/15 | Train Loss: 0.5226 Acc: 0.7669\n",
      "Epoch 4/15 | Train Loss: 0.4525 Acc: 0.7712\n",
      "Epoch 5/15 | Train Loss: 0.4646 Acc: 0.7966\n",
      "Epoch 6/15 | Train Loss: 0.4941 Acc: 0.7839\n",
      "Epoch 7/15 | Train Loss: 0.4352 Acc: 0.8051\n",
      "Epoch 8/15 | Train Loss: 0.4030 Acc: 0.8263\n",
      "Epoch 9/15 | Train Loss: 0.4083 Acc: 0.7966\n",
      "Epoch 10/15 | Train Loss: 0.3565 Acc: 0.8347\n",
      "Epoch 11/15 | Train Loss: 0.3763 Acc: 0.8178\n",
      "Epoch 12/15 | Train Loss: 0.3933 Acc: 0.8051\n",
      "Epoch 13/15 | Train Loss: 0.4130 Acc: 0.8136\n",
      "Epoch 14/15 | Train Loss: 0.3747 Acc: 0.8347\n",
      "Epoch 15/15 | Train Loss: 0.3909 Acc: 0.8517\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7193 Acc: 0.6079\n",
      "Epoch 2/15 | Train Loss: 0.4687 Acc: 0.8238\n",
      "Epoch 3/15 | Train Loss: 0.4317 Acc: 0.8282\n",
      "Epoch 4/15 | Train Loss: 0.4040 Acc: 0.8414\n",
      "Epoch 5/15 | Train Loss: 0.3638 Acc: 0.8502\n",
      "Epoch 6/15 | Train Loss: 0.3922 Acc: 0.8546\n",
      "Epoch 7/15 | Train Loss: 0.3307 Acc: 0.8678\n",
      "Epoch 8/15 | Train Loss: 0.3084 Acc: 0.8855\n",
      "Epoch 9/15 | Train Loss: 0.3141 Acc: 0.8590\n",
      "Epoch 10/15 | Train Loss: 0.3285 Acc: 0.8943\n",
      "Epoch 11/15 | Train Loss: 0.3180 Acc: 0.8634\n",
      "Epoch 12/15 | Train Loss: 0.2907 Acc: 0.8943\n",
      "Epoch 13/15 | Train Loss: 0.3202 Acc: 0.8899\n",
      "Epoch 14/15 | Train Loss: 0.2866 Acc: 0.8899\n",
      "Epoch 15/15 | Train Loss: 0.2693 Acc: 0.8943\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6343 Acc: 0.6655\n",
      "Epoch 2/15 | Train Loss: 0.5173 Acc: 0.7669\n",
      "Epoch 3/15 | Train Loss: 0.4768 Acc: 0.7568\n",
      "Epoch 4/15 | Train Loss: 0.4881 Acc: 0.7196\n",
      "Epoch 5/15 | Train Loss: 0.4160 Acc: 0.7872\n",
      "Epoch 6/15 | Train Loss: 0.4453 Acc: 0.7838\n",
      "Epoch 7/15 | Train Loss: 0.3761 Acc: 0.8176\n",
      "Epoch 8/15 | Train Loss: 0.3638 Acc: 0.8142\n",
      "Epoch 9/15 | Train Loss: 0.3486 Acc: 0.8412\n",
      "Epoch 10/15 | Train Loss: 0.3338 Acc: 0.8311\n",
      "Epoch 11/15 | Train Loss: 0.3432 Acc: 0.8041\n",
      "Epoch 12/15 | Train Loss: 0.3449 Acc: 0.8345\n",
      "Epoch 13/15 | Train Loss: 0.3226 Acc: 0.8514\n",
      "Epoch 14/15 | Train Loss: 0.3165 Acc: 0.8750\n",
      "Epoch 15/15 | Train Loss: 0.3237 Acc: 0.8277\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7267 Acc: 0.6824\n",
      "Epoch 2/15 | Train Loss: 0.5628 Acc: 0.7264\n",
      "Epoch 3/15 | Train Loss: 0.4906 Acc: 0.7331\n",
      "Epoch 4/15 | Train Loss: 0.5112 Acc: 0.7230\n",
      "Epoch 5/15 | Train Loss: 0.4165 Acc: 0.8007\n",
      "Epoch 6/15 | Train Loss: 0.4472 Acc: 0.7736\n",
      "Epoch 7/15 | Train Loss: 0.4660 Acc: 0.7264\n",
      "Epoch 8/15 | Train Loss: 0.3950 Acc: 0.8108\n",
      "Epoch 9/15 | Train Loss: 0.3923 Acc: 0.8108\n",
      "Epoch 10/15 | Train Loss: 0.4254 Acc: 0.7973\n",
      "Epoch 11/15 | Train Loss: 0.3891 Acc: 0.8074\n",
      "Epoch 12/15 | Train Loss: 0.3206 Acc: 0.8716\n",
      "Epoch 13/15 | Train Loss: 0.3250 Acc: 0.8649\n",
      "Epoch 14/15 | Train Loss: 0.3609 Acc: 0.8074\n",
      "Epoch 15/15 | Train Loss: 0.3594 Acc: 0.8243\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6300 Acc: 0.6667\n",
      "Epoch 2/15 | Train Loss: 0.5196 Acc: 0.7340\n",
      "Epoch 3/15 | Train Loss: 0.4650 Acc: 0.7475\n",
      "Epoch 4/15 | Train Loss: 0.4454 Acc: 0.7778\n",
      "Epoch 5/15 | Train Loss: 0.4190 Acc: 0.7778\n",
      "Epoch 6/15 | Train Loss: 0.4111 Acc: 0.7946\n",
      "Epoch 7/15 | Train Loss: 0.3804 Acc: 0.8114\n",
      "Epoch 8/15 | Train Loss: 0.3936 Acc: 0.8283\n",
      "Epoch 9/15 | Train Loss: 0.3854 Acc: 0.8182\n",
      "Epoch 10/15 | Train Loss: 0.3858 Acc: 0.8148\n",
      "Epoch 11/15 | Train Loss: 0.3563 Acc: 0.8148\n",
      "Epoch 12/15 | Train Loss: 0.3350 Acc: 0.8316\n",
      "Epoch 13/15 | Train Loss: 0.3521 Acc: 0.8249\n",
      "Epoch 14/15 | Train Loss: 0.3319 Acc: 0.8519\n",
      "Epoch 15/15 | Train Loss: 0.3221 Acc: 0.8384\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 3.0min\n",
      "Epoch 1/15 | Train Loss: 0.6149 Acc: 0.7061\n",
      "Epoch 2/15 | Train Loss: 0.5179 Acc: 0.7748\n",
      "Epoch 3/15 | Train Loss: 0.5045 Acc: 0.8092\n",
      "Epoch 4/15 | Train Loss: 0.4469 Acc: 0.7863\n",
      "Epoch 5/15 | Train Loss: 0.4707 Acc: 0.7824\n",
      "Epoch 6/15 | Train Loss: 0.3753 Acc: 0.8282\n",
      "Epoch 7/15 | Train Loss: 0.3917 Acc: 0.8130\n",
      "Epoch 8/15 | Train Loss: 0.3768 Acc: 0.8511\n",
      "Epoch 9/15 | Train Loss: 0.4236 Acc: 0.8359\n",
      "Epoch 10/15 | Train Loss: 0.3546 Acc: 0.8435\n",
      "Epoch 11/15 | Train Loss: 0.3214 Acc: 0.8588\n",
      "Epoch 12/15 | Train Loss: 0.3246 Acc: 0.8588\n",
      "Epoch 13/15 | Train Loss: 0.3626 Acc: 0.8473\n",
      "Epoch 14/15 | Train Loss: 0.3476 Acc: 0.8664\n",
      "Epoch 15/15 | Train Loss: 0.3859 Acc: 0.8397\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6312 Acc: 0.6857\n",
      "Epoch 2/15 | Train Loss: 0.4321 Acc: 0.8367\n",
      "Epoch 3/15 | Train Loss: 0.4058 Acc: 0.8531\n",
      "Epoch 4/15 | Train Loss: 0.4037 Acc: 0.8286\n",
      "Epoch 5/15 | Train Loss: 0.3869 Acc: 0.8531\n",
      "Epoch 6/15 | Train Loss: 0.3874 Acc: 0.8776\n",
      "Epoch 7/15 | Train Loss: 0.3035 Acc: 0.8776\n",
      "Epoch 8/15 | Train Loss: 0.3252 Acc: 0.8449\n",
      "Epoch 9/15 | Train Loss: 0.2990 Acc: 0.8735\n",
      "Epoch 10/15 | Train Loss: 0.3205 Acc: 0.8694\n",
      "Epoch 11/15 | Train Loss: 0.3276 Acc: 0.8735\n",
      "Epoch 12/15 | Train Loss: 0.3226 Acc: 0.8571\n",
      "Epoch 13/15 | Train Loss: 0.2592 Acc: 0.8980\n",
      "Epoch 14/15 | Train Loss: 0.2548 Acc: 0.8980\n",
      "Epoch 15/15 | Train Loss: 0.2945 Acc: 0.8898\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7523 Acc: 0.6032\n",
      "Epoch 2/15 | Train Loss: 0.6366 Acc: 0.7024\n",
      "Epoch 3/15 | Train Loss: 0.5151 Acc: 0.7381\n",
      "Epoch 4/15 | Train Loss: 0.4703 Acc: 0.7698\n",
      "Epoch 5/15 | Train Loss: 0.4847 Acc: 0.7500\n",
      "Epoch 6/15 | Train Loss: 0.4621 Acc: 0.7897\n",
      "Epoch 7/15 | Train Loss: 0.5039 Acc: 0.7460\n",
      "Epoch 8/15 | Train Loss: 0.4314 Acc: 0.8095\n",
      "Epoch 9/15 | Train Loss: 0.3746 Acc: 0.8333\n",
      "Epoch 10/15 | Train Loss: 0.3639 Acc: 0.8413\n",
      "Epoch 11/15 | Train Loss: 0.3934 Acc: 0.8294\n",
      "Epoch 12/15 | Train Loss: 0.4188 Acc: 0.8254\n",
      "Epoch 13/15 | Train Loss: 0.3613 Acc: 0.8532\n",
      "Epoch 14/15 | Train Loss: 0.3783 Acc: 0.8294\n",
      "Epoch 15/15 | Train Loss: 0.3757 Acc: 0.8254\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6889 Acc: 0.6746\n",
      "Epoch 2/15 | Train Loss: 0.6420 Acc: 0.6706\n",
      "Epoch 3/15 | Train Loss: 0.5203 Acc: 0.7183\n",
      "Epoch 4/15 | Train Loss: 0.5251 Acc: 0.7262\n",
      "Epoch 5/15 | Train Loss: 0.5283 Acc: 0.7143\n",
      "Epoch 6/15 | Train Loss: 0.4733 Acc: 0.7698\n",
      "Epoch 7/15 | Train Loss: 0.4620 Acc: 0.7897\n",
      "Epoch 8/15 | Train Loss: 0.4545 Acc: 0.7857\n",
      "Epoch 9/15 | Train Loss: 0.4525 Acc: 0.7897\n",
      "Epoch 10/15 | Train Loss: 0.4299 Acc: 0.7897\n",
      "Epoch 11/15 | Train Loss: 0.4226 Acc: 0.7857\n",
      "Epoch 12/15 | Train Loss: 0.4058 Acc: 0.8016\n",
      "Epoch 13/15 | Train Loss: 0.3978 Acc: 0.8254\n",
      "Epoch 14/15 | Train Loss: 0.4014 Acc: 0.7976\n",
      "Epoch 15/15 | Train Loss: 0.4195 Acc: 0.7857\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7232 Acc: 0.6245\n",
      "Epoch 2/15 | Train Loss: 0.6080 Acc: 0.6996\n",
      "Epoch 3/15 | Train Loss: 0.5966 Acc: 0.7075\n",
      "Epoch 4/15 | Train Loss: 0.5544 Acc: 0.7075\n",
      "Epoch 5/15 | Train Loss: 0.4735 Acc: 0.7589\n",
      "Epoch 6/15 | Train Loss: 0.5980 Acc: 0.6877\n",
      "Epoch 7/15 | Train Loss: 0.4779 Acc: 0.7708\n",
      "Epoch 8/15 | Train Loss: 0.4404 Acc: 0.7787\n",
      "Epoch 9/15 | Train Loss: 0.4340 Acc: 0.7945\n",
      "Epoch 10/15 | Train Loss: 0.4294 Acc: 0.7668\n",
      "Epoch 11/15 | Train Loss: 0.4262 Acc: 0.8063\n",
      "Epoch 12/15 | Train Loss: 0.3945 Acc: 0.7826\n",
      "Epoch 13/15 | Train Loss: 0.3939 Acc: 0.7984\n",
      "Epoch 14/15 | Train Loss: 0.4018 Acc: 0.8024\n",
      "Epoch 15/15 | Train Loss: 0.4333 Acc: 0.7826\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6167 Acc: 0.6864\n",
      "Epoch 2/15 | Train Loss: 0.5518 Acc: 0.7712\n",
      "Epoch 3/15 | Train Loss: 0.5471 Acc: 0.7712\n",
      "Epoch 4/15 | Train Loss: 0.5156 Acc: 0.7458\n",
      "Epoch 5/15 | Train Loss: 0.4208 Acc: 0.8178\n",
      "Epoch 6/15 | Train Loss: 0.4457 Acc: 0.8008\n",
      "Epoch 7/15 | Train Loss: 0.4328 Acc: 0.8305\n",
      "Epoch 8/15 | Train Loss: 0.4488 Acc: 0.8093\n",
      "Epoch 9/15 | Train Loss: 0.4378 Acc: 0.8220\n",
      "Epoch 10/15 | Train Loss: 0.4166 Acc: 0.8178\n",
      "Epoch 11/15 | Train Loss: 0.3788 Acc: 0.8347\n",
      "Epoch 12/15 | Train Loss: 0.4121 Acc: 0.8263\n",
      "Epoch 13/15 | Train Loss: 0.3870 Acc: 0.8136\n",
      "Epoch 14/15 | Train Loss: 0.3833 Acc: 0.8136\n",
      "Epoch 15/15 | Train Loss: 0.3354 Acc: 0.8559\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5320 Acc: 0.7489\n",
      "Epoch 2/15 | Train Loss: 0.4307 Acc: 0.8238\n",
      "Epoch 3/15 | Train Loss: 0.4171 Acc: 0.8370\n",
      "Epoch 4/15 | Train Loss: 0.4341 Acc: 0.8282\n",
      "Epoch 5/15 | Train Loss: 0.3335 Acc: 0.8634\n",
      "Epoch 6/15 | Train Loss: 0.3552 Acc: 0.8326\n",
      "Epoch 7/15 | Train Loss: 0.3266 Acc: 0.8943\n",
      "Epoch 8/15 | Train Loss: 0.3630 Acc: 0.8722\n",
      "Epoch 9/15 | Train Loss: 0.3505 Acc: 0.8546\n",
      "Epoch 10/15 | Train Loss: 0.3500 Acc: 0.8634\n",
      "Epoch 11/15 | Train Loss: 0.2545 Acc: 0.9031\n",
      "Epoch 12/15 | Train Loss: 0.3092 Acc: 0.8767\n",
      "Epoch 13/15 | Train Loss: 0.2384 Acc: 0.9031\n",
      "Epoch 14/15 | Train Loss: 0.2699 Acc: 0.8943\n",
      "Epoch 15/15 | Train Loss: 0.2796 Acc: 0.8767\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.4719 Acc: 0.7546\n",
      "Epoch 2/15 | Train Loss: 0.3866 Acc: 0.7963\n",
      "Epoch 3/15 | Train Loss: 0.3886 Acc: 0.7885\n",
      "Epoch 4/15 | Train Loss: 0.3436 Acc: 0.8303\n",
      "Epoch 5/15 | Train Loss: 0.3215 Acc: 0.8564\n",
      "Epoch 6/15 | Train Loss: 0.3148 Acc: 0.8407\n",
      "Epoch 7/15 | Train Loss: 0.2752 Acc: 0.8486\n",
      "Epoch 8/15 | Train Loss: 0.2933 Acc: 0.8773\n",
      "Epoch 9/15 | Train Loss: 0.2658 Acc: 0.8668\n",
      "Epoch 10/15 | Train Loss: 0.2861 Acc: 0.8616\n",
      "Epoch 11/15 | Train Loss: 0.2347 Acc: 0.8825\n",
      "Epoch 12/15 | Train Loss: 0.2446 Acc: 0.9008\n",
      "Epoch 13/15 | Train Loss: 0.2447 Acc: 0.8825\n",
      "Epoch 14/15 | Train Loss: 0.2563 Acc: 0.8773\n",
      "Epoch 15/15 | Train Loss: 0.2160 Acc: 0.9008\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.4877 Acc: 0.7520\n",
      "Epoch 2/15 | Train Loss: 0.3692 Acc: 0.8146\n",
      "Epoch 3/15 | Train Loss: 0.3724 Acc: 0.8016\n",
      "Epoch 4/15 | Train Loss: 0.3459 Acc: 0.8172\n",
      "Epoch 5/15 | Train Loss: 0.3246 Acc: 0.8303\n",
      "Epoch 6/15 | Train Loss: 0.3380 Acc: 0.8460\n",
      "Epoch 7/15 | Train Loss: 0.3251 Acc: 0.8198\n",
      "Epoch 8/15 | Train Loss: 0.2669 Acc: 0.8642\n",
      "Epoch 9/15 | Train Loss: 0.2806 Acc: 0.8695\n",
      "Epoch 10/15 | Train Loss: 0.2877 Acc: 0.8616\n",
      "Epoch 11/15 | Train Loss: 0.2767 Acc: 0.8773\n",
      "Epoch 12/15 | Train Loss: 0.2911 Acc: 0.8695\n",
      "Epoch 13/15 | Train Loss: 0.3096 Acc: 0.8407\n",
      "Epoch 14/15 | Train Loss: 0.2633 Acc: 0.8721\n",
      "Epoch 15/15 | Train Loss: 0.2727 Acc: 0.8747\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5754 Acc: 0.7578\n",
      "Epoch 2/15 | Train Loss: 0.4016 Acc: 0.8203\n",
      "Epoch 3/15 | Train Loss: 0.3755 Acc: 0.8151\n",
      "Epoch 4/15 | Train Loss: 0.3862 Acc: 0.8021\n",
      "Epoch 5/15 | Train Loss: 0.3871 Acc: 0.7917\n",
      "Epoch 6/15 | Train Loss: 0.3587 Acc: 0.8177\n",
      "Epoch 7/15 | Train Loss: 0.3395 Acc: 0.8307\n",
      "Epoch 8/15 | Train Loss: 0.2832 Acc: 0.8646\n",
      "Epoch 9/15 | Train Loss: 0.2680 Acc: 0.8776\n",
      "Epoch 10/15 | Train Loss: 0.2806 Acc: 0.8698\n",
      "Epoch 11/15 | Train Loss: 0.2657 Acc: 0.8698\n",
      "Epoch 12/15 | Train Loss: 0.2744 Acc: 0.8594\n",
      "Epoch 13/15 | Train Loss: 0.2697 Acc: 0.8646\n",
      "Epoch 14/15 | Train Loss: 0.2981 Acc: 0.8333\n",
      "Epoch 15/15 | Train Loss: 0.2815 Acc: 0.8620\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5880 Acc: 0.7803\n",
      "Epoch 2/15 | Train Loss: 0.4681 Acc: 0.7962\n",
      "Epoch 3/15 | Train Loss: 0.3830 Acc: 0.8217\n",
      "Epoch 4/15 | Train Loss: 0.4188 Acc: 0.8089\n",
      "Epoch 5/15 | Train Loss: 0.3766 Acc: 0.8280\n",
      "Epoch 6/15 | Train Loss: 0.3244 Acc: 0.8631\n",
      "Epoch 7/15 | Train Loss: 0.3783 Acc: 0.8471\n",
      "Epoch 8/15 | Train Loss: 0.3289 Acc: 0.8535\n",
      "Epoch 9/15 | Train Loss: 0.3035 Acc: 0.8631\n",
      "Epoch 10/15 | Train Loss: 0.3086 Acc: 0.8694\n",
      "Epoch 11/15 | Train Loss: 0.3001 Acc: 0.8694\n",
      "Epoch 12/15 | Train Loss: 0.2805 Acc: 0.8822\n",
      "Epoch 13/15 | Train Loss: 0.2774 Acc: 0.8790\n",
      "Epoch 14/15 | Train Loss: 0.2668 Acc: 0.8949\n",
      "Epoch 15/15 | Train Loss: 0.3040 Acc: 0.8662\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.4581 Acc: 0.8357\n",
      "Epoch 2/15 | Train Loss: 0.4293 Acc: 0.8321\n",
      "Epoch 3/15 | Train Loss: 0.3583 Acc: 0.8714\n",
      "Epoch 4/15 | Train Loss: 0.3100 Acc: 0.8857\n",
      "Epoch 5/15 | Train Loss: 0.3278 Acc: 0.8679\n",
      "Epoch 6/15 | Train Loss: 0.3022 Acc: 0.8893\n",
      "Epoch 7/15 | Train Loss: 0.2804 Acc: 0.8964\n",
      "Epoch 8/15 | Train Loss: 0.2622 Acc: 0.9107\n",
      "Epoch 9/15 | Train Loss: 0.2423 Acc: 0.9143\n",
      "Epoch 10/15 | Train Loss: 0.2423 Acc: 0.9179\n",
      "Epoch 11/15 | Train Loss: 0.2256 Acc: 0.9143\n",
      "Epoch 12/15 | Train Loss: 0.2407 Acc: 0.9107\n",
      "Epoch 13/15 | Train Loss: 0.2359 Acc: 0.9036\n",
      "Epoch 14/15 | Train Loss: 0.2013 Acc: 0.9143\n",
      "Epoch 15/15 | Train Loss: 0.1948 Acc: 0.9357\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6959 Acc: 0.6429\n",
      "Epoch 2/15 | Train Loss: 0.5621 Acc: 0.7262\n",
      "Epoch 3/15 | Train Loss: 0.5689 Acc: 0.6825\n",
      "Epoch 4/15 | Train Loss: 0.4882 Acc: 0.7302\n",
      "Epoch 5/15 | Train Loss: 0.4756 Acc: 0.7659\n",
      "Epoch 6/15 | Train Loss: 0.5226 Acc: 0.7262\n",
      "Epoch 7/15 | Train Loss: 0.4384 Acc: 0.7817\n",
      "Epoch 8/15 | Train Loss: 0.3459 Acc: 0.8413\n",
      "Epoch 9/15 | Train Loss: 0.4548 Acc: 0.7738\n",
      "Epoch 10/15 | Train Loss: 0.4100 Acc: 0.8175\n",
      "Epoch 11/15 | Train Loss: 0.3700 Acc: 0.8254\n",
      "Epoch 12/15 | Train Loss: 0.3498 Acc: 0.8214\n",
      "Epoch 13/15 | Train Loss: 0.3934 Acc: 0.8413\n",
      "Epoch 14/15 | Train Loss: 0.3219 Acc: 0.8571\n",
      "Epoch 15/15 | Train Loss: 0.3423 Acc: 0.8532\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7659 Acc: 0.5992\n",
      "Epoch 2/15 | Train Loss: 0.5877 Acc: 0.6984\n",
      "Epoch 3/15 | Train Loss: 0.5279 Acc: 0.7183\n",
      "Epoch 4/15 | Train Loss: 0.5179 Acc: 0.7222\n",
      "Epoch 5/15 | Train Loss: 0.5679 Acc: 0.7063\n",
      "Epoch 6/15 | Train Loss: 0.4902 Acc: 0.7381\n",
      "Epoch 7/15 | Train Loss: 0.4585 Acc: 0.7976\n",
      "Epoch 8/15 | Train Loss: 0.4750 Acc: 0.7421\n",
      "Epoch 9/15 | Train Loss: 0.4293 Acc: 0.7857\n",
      "Epoch 10/15 | Train Loss: 0.4188 Acc: 0.7897\n",
      "Epoch 11/15 | Train Loss: 0.4027 Acc: 0.8016\n",
      "Epoch 12/15 | Train Loss: 0.3701 Acc: 0.8413\n",
      "Epoch 13/15 | Train Loss: 0.4335 Acc: 0.7937\n",
      "Epoch 14/15 | Train Loss: 0.4130 Acc: 0.8056\n",
      "Epoch 15/15 | Train Loss: 0.3292 Acc: 0.8373\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6559 Acc: 0.6601\n",
      "Epoch 2/15 | Train Loss: 0.6179 Acc: 0.6759\n",
      "Epoch 3/15 | Train Loss: 0.6158 Acc: 0.6561\n",
      "Epoch 4/15 | Train Loss: 0.5004 Acc: 0.7628\n",
      "Epoch 5/15 | Train Loss: 0.4670 Acc: 0.7470\n",
      "Epoch 6/15 | Train Loss: 0.4970 Acc: 0.7747\n",
      "Epoch 7/15 | Train Loss: 0.4928 Acc: 0.7668\n",
      "Epoch 8/15 | Train Loss: 0.4345 Acc: 0.7826\n",
      "Epoch 9/15 | Train Loss: 0.4327 Acc: 0.8261\n",
      "Epoch 10/15 | Train Loss: 0.4101 Acc: 0.8182\n",
      "Epoch 11/15 | Train Loss: 0.4246 Acc: 0.7945\n",
      "Epoch 12/15 | Train Loss: 0.4003 Acc: 0.8103\n",
      "Epoch 13/15 | Train Loss: 0.3999 Acc: 0.8221\n",
      "Epoch 14/15 | Train Loss: 0.3759 Acc: 0.8340\n",
      "Epoch 15/15 | Train Loss: 0.3968 Acc: 0.7984\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6220 Acc: 0.6610\n",
      "Epoch 2/15 | Train Loss: 0.5905 Acc: 0.7627\n",
      "Epoch 3/15 | Train Loss: 0.5107 Acc: 0.7754\n",
      "Epoch 4/15 | Train Loss: 0.5252 Acc: 0.7585\n",
      "Epoch 5/15 | Train Loss: 0.4756 Acc: 0.7754\n",
      "Epoch 6/15 | Train Loss: 0.4842 Acc: 0.7924\n",
      "Epoch 7/15 | Train Loss: 0.4646 Acc: 0.8008\n",
      "Epoch 8/15 | Train Loss: 0.4098 Acc: 0.8347\n",
      "Epoch 9/15 | Train Loss: 0.3882 Acc: 0.8347\n",
      "Epoch 10/15 | Train Loss: 0.3916 Acc: 0.8178\n",
      "Epoch 11/15 | Train Loss: 0.3945 Acc: 0.8390\n",
      "Epoch 12/15 | Train Loss: 0.3627 Acc: 0.8432\n",
      "Epoch 13/15 | Train Loss: 0.4001 Acc: 0.8178\n",
      "Epoch 14/15 | Train Loss: 0.4156 Acc: 0.8136\n",
      "Epoch 15/15 | Train Loss: 0.3735 Acc: 0.8136\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5354 Acc: 0.7401\n",
      "Epoch 2/15 | Train Loss: 0.4558 Acc: 0.8150\n",
      "Epoch 3/15 | Train Loss: 0.3783 Acc: 0.8414\n",
      "Epoch 4/15 | Train Loss: 0.3520 Acc: 0.8458\n",
      "Epoch 5/15 | Train Loss: 0.3537 Acc: 0.9031\n",
      "Epoch 6/15 | Train Loss: 0.3376 Acc: 0.8326\n",
      "Epoch 7/15 | Train Loss: 0.3221 Acc: 0.8678\n",
      "Epoch 8/15 | Train Loss: 0.2350 Acc: 0.9119\n",
      "Epoch 9/15 | Train Loss: 0.3082 Acc: 0.8634\n",
      "Epoch 10/15 | Train Loss: 0.2799 Acc: 0.9163\n",
      "Epoch 11/15 | Train Loss: 0.2343 Acc: 0.8987\n",
      "Epoch 12/15 | Train Loss: 0.3069 Acc: 0.8634\n",
      "Epoch 13/15 | Train Loss: 0.3189 Acc: 0.8722\n",
      "Epoch 14/15 | Train Loss: 0.2480 Acc: 0.9119\n",
      "Epoch 15/15 | Train Loss: 0.2349 Acc: 0.9251\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5404 Acc: 0.7477\n",
      "Epoch 2/15 | Train Loss: 0.4174 Acc: 0.8028\n",
      "Epoch 3/15 | Train Loss: 0.4620 Acc: 0.7890\n",
      "Epoch 4/15 | Train Loss: 0.3818 Acc: 0.8257\n",
      "Epoch 5/15 | Train Loss: 0.3749 Acc: 0.8096\n",
      "Epoch 6/15 | Train Loss: 0.3158 Acc: 0.8440\n",
      "Epoch 7/15 | Train Loss: 0.3640 Acc: 0.8349\n",
      "Epoch 8/15 | Train Loss: 0.3194 Acc: 0.8647\n",
      "Epoch 9/15 | Train Loss: 0.3013 Acc: 0.8647\n",
      "Epoch 10/15 | Train Loss: 0.2777 Acc: 0.8761\n",
      "Epoch 11/15 | Train Loss: 0.2824 Acc: 0.8693\n",
      "Epoch 12/15 | Train Loss: 0.2657 Acc: 0.8876\n",
      "Epoch 13/15 | Train Loss: 0.2789 Acc: 0.8670\n",
      "Epoch 14/15 | Train Loss: 0.2768 Acc: 0.8807\n",
      "Epoch 15/15 | Train Loss: 0.2695 Acc: 0.8761\n",
      "Fold 3 Test Accuracy: 0.6250\n",
      "===== Fold 4 =====\n",
      "Epoch 1: Generator Loss = 10.5444, Discriminator Loss = 8.9029\n",
      "Epoch 2: Generator Loss = 13.3193, Discriminator Loss = 5.1469\n",
      "Epoch 3: Generator Loss = 18.2388, Discriminator Loss = 4.1868\n",
      "Epoch 4: Generator Loss = 29.9670, Discriminator Loss = 4.3363\n",
      "Epoch 5: Generator Loss = 33.1760, Discriminator Loss = 4.1176\n",
      "Epoch 6: Generator Loss = 36.9053, Discriminator Loss = 4.5071\n",
      "Epoch 7: Generator Loss = 33.9565, Discriminator Loss = 6.5691\n",
      "Epoch 8: Generator Loss = 30.4528, Discriminator Loss = 5.8847\n",
      "Epoch 9: Generator Loss = 28.4456, Discriminator Loss = 7.8393\n",
      "Epoch 10: Generator Loss = 25.6580, Discriminator Loss = 7.3826\n",
      "Epoch 11: Generator Loss = 24.7477, Discriminator Loss = 6.3122\n",
      "Epoch 12: Generator Loss = 25.1536, Discriminator Loss = 5.9197\n",
      "Epoch 13: Generator Loss = 19.5263, Discriminator Loss = 7.4983\n",
      "Epoch 14: Generator Loss = 26.4323, Discriminator Loss = 7.5073\n",
      "Epoch 15: Generator Loss = 23.8153, Discriminator Loss = 6.5643\n",
      "Epoch 16: Generator Loss = 19.3827, Discriminator Loss = 8.3392\n",
      "Epoch 17: Generator Loss = 22.8801, Discriminator Loss = 8.4430\n",
      "Epoch 18: Generator Loss = 21.9127, Discriminator Loss = 8.9771\n",
      "Epoch 19: Generator Loss = 27.3832, Discriminator Loss = 7.6881\n",
      "Epoch 20: Generator Loss = 25.6450, Discriminator Loss = 7.1278\n",
      "Epoch 21: Generator Loss = 23.5083, Discriminator Loss = 6.4058\n",
      "Epoch 22: Generator Loss = 22.7921, Discriminator Loss = 6.8970\n",
      "Epoch 23: Generator Loss = 19.1131, Discriminator Loss = 8.5702\n",
      "Epoch 24: Generator Loss = 22.2230, Discriminator Loss = 7.8413\n",
      "Epoch 25: Generator Loss = 16.5681, Discriminator Loss = 8.2554\n",
      "Epoch 26: Generator Loss = 17.7890, Discriminator Loss = 8.2407\n",
      "Epoch 27: Generator Loss = 19.9243, Discriminator Loss = 7.5365\n",
      "Epoch 28: Generator Loss = 20.7453, Discriminator Loss = 7.7592\n",
      "Epoch 29: Generator Loss = 18.8161, Discriminator Loss = 8.2588\n",
      "Epoch 30: Generator Loss = 21.9704, Discriminator Loss = 7.7903\n",
      "Epoch 31: Generator Loss = 18.3377, Discriminator Loss = 10.0484\n",
      "Epoch 32: Generator Loss = 16.1265, Discriminator Loss = 8.3894\n",
      "Epoch 33: Generator Loss = 18.7131, Discriminator Loss = 8.2272\n",
      "Epoch 34: Generator Loss = 19.3390, Discriminator Loss = 8.4786\n",
      "Epoch 35: Generator Loss = 22.9687, Discriminator Loss = 8.2051\n",
      "Epoch 36: Generator Loss = 21.0110, Discriminator Loss = 8.7889\n",
      "Epoch 37: Generator Loss = 14.7435, Discriminator Loss = 8.4124\n",
      "Epoch 38: Generator Loss = 22.1745, Discriminator Loss = 7.0508\n",
      "Epoch 39: Generator Loss = 21.7778, Discriminator Loss = 8.1769\n",
      "Epoch 40: Generator Loss = 23.9790, Discriminator Loss = 7.6024\n",
      "Epoch 41: Generator Loss = 23.2015, Discriminator Loss = 6.4905\n",
      "Epoch 42: Generator Loss = 21.0993, Discriminator Loss = 7.3136\n",
      "Epoch 43: Generator Loss = 15.9555, Discriminator Loss = 8.5734\n",
      "Epoch 44: Generator Loss = 17.3134, Discriminator Loss = 9.3401\n",
      "Epoch 45: Generator Loss = 16.6038, Discriminator Loss = 7.4750\n",
      "Epoch 46: Generator Loss = 19.3941, Discriminator Loss = 7.0171\n",
      "Epoch 47: Generator Loss = 21.7219, Discriminator Loss = 6.0071\n",
      "Epoch 48: Generator Loss = 25.6166, Discriminator Loss = 9.6883\n",
      "Epoch 49: Generator Loss = 17.7049, Discriminator Loss = 7.4208\n",
      "Epoch 50: Generator Loss = 22.1268, Discriminator Loss = 7.4381\n",
      "Epoch 51: Generator Loss = 15.4191, Discriminator Loss = 6.7947\n",
      "Epoch 52: Generator Loss = 26.7527, Discriminator Loss = 6.6702\n",
      "Epoch 53: Generator Loss = 26.1182, Discriminator Loss = 6.9506\n",
      "Epoch 54: Generator Loss = 25.8464, Discriminator Loss = 7.1604\n",
      "Epoch 55: Generator Loss = 22.7597, Discriminator Loss = 7.0986\n",
      "Epoch 56: Generator Loss = 21.5901, Discriminator Loss = 5.8148\n",
      "Epoch 57: Generator Loss = 27.9065, Discriminator Loss = 5.9149\n",
      "Epoch 58: Generator Loss = 29.9570, Discriminator Loss = 5.3300\n",
      "Epoch 59: Generator Loss = 27.6773, Discriminator Loss = 5.2736\n",
      "Epoch 60: Generator Loss = 29.6580, Discriminator Loss = 3.5401\n",
      "Epoch 61: Generator Loss = 36.5137, Discriminator Loss = 4.7356\n",
      "Epoch 62: Generator Loss = 30.9824, Discriminator Loss = 4.2787\n",
      "Epoch 63: Generator Loss = 36.1262, Discriminator Loss = 5.4751\n",
      "Epoch 64: Generator Loss = 40.1438, Discriminator Loss = 2.5282\n",
      "Epoch 65: Generator Loss = 61.9339, Discriminator Loss = 2.4716\n",
      "Epoch 66: Generator Loss = 41.0635, Discriminator Loss = 2.8879\n",
      "Epoch 67: Generator Loss = 42.4820, Discriminator Loss = 3.7284\n",
      "Epoch 68: Generator Loss = 41.0949, Discriminator Loss = 3.8753\n",
      "Epoch 69: Generator Loss = 39.5080, Discriminator Loss = 3.7581\n",
      "Epoch 70: Generator Loss = 36.8045, Discriminator Loss = 2.2290\n",
      "Epoch 71: Generator Loss = 44.8147, Discriminator Loss = 3.3776\n",
      "Epoch 72: Generator Loss = 40.5122, Discriminator Loss = 2.8235\n",
      "Epoch 73: Generator Loss = 48.5899, Discriminator Loss = 3.5047\n",
      "Epoch 74: Generator Loss = 43.7557, Discriminator Loss = 5.1085\n",
      "Epoch 75: Generator Loss = 45.7996, Discriminator Loss = 3.0817\n",
      "Epoch 76: Generator Loss = 38.0520, Discriminator Loss = 2.2258\n",
      "Epoch 77: Generator Loss = 65.6162, Discriminator Loss = 1.4639\n",
      "Epoch 78: Generator Loss = 59.1116, Discriminator Loss = 3.6780\n",
      "Epoch 79: Generator Loss = 51.8365, Discriminator Loss = 3.9434\n",
      "Epoch 80: Generator Loss = 49.4060, Discriminator Loss = 1.8201\n",
      "Epoch 81: Generator Loss = 59.1216, Discriminator Loss = 2.0175\n",
      "Epoch 82: Generator Loss = 49.7800, Discriminator Loss = 1.0200\n",
      "Epoch 83: Generator Loss = 65.3173, Discriminator Loss = 1.8029\n",
      "Epoch 84: Generator Loss = 54.9705, Discriminator Loss = 4.6587\n",
      "Epoch 85: Generator Loss = 61.3895, Discriminator Loss = 1.1475\n",
      "Epoch 86: Generator Loss = 71.8671, Discriminator Loss = 1.2319\n",
      "Epoch 87: Generator Loss = 56.1491, Discriminator Loss = 1.8986\n",
      "Epoch 88: Generator Loss = 54.5128, Discriminator Loss = 0.8609\n",
      "Epoch 89: Generator Loss = 72.9632, Discriminator Loss = 1.4734\n",
      "Epoch 90: Generator Loss = 73.1518, Discriminator Loss = 1.2973\n",
      "Epoch 91: Generator Loss = 64.3449, Discriminator Loss = 1.2466\n",
      "Epoch 92: Generator Loss = 48.5659, Discriminator Loss = 7.8919\n",
      "Epoch 93: Generator Loss = 55.6402, Discriminator Loss = 2.3880\n",
      "Epoch 94: Generator Loss = 61.3485, Discriminator Loss = 1.2343\n",
      "Epoch 95: Generator Loss = 67.5042, Discriminator Loss = 1.1801\n",
      "Epoch 96: Generator Loss = 60.6457, Discriminator Loss = 0.5599\n",
      "Epoch 97: Generator Loss = 76.2551, Discriminator Loss = 0.7585\n",
      "Epoch 98: Generator Loss = 71.4250, Discriminator Loss = 0.6841\n",
      "Epoch 99: Generator Loss = 61.5849, Discriminator Loss = 1.0816\n",
      "Epoch 100: Generator Loss = 66.2243, Discriminator Loss = 0.9835\n",
      "Epoch 101: Generator Loss = 79.3786, Discriminator Loss = 2.1087\n",
      "Epoch 102: Generator Loss = 83.6000, Discriminator Loss = 1.0952\n",
      "Epoch 103: Generator Loss = 61.8163, Discriminator Loss = 1.5532\n",
      "Epoch 104: Generator Loss = 70.9807, Discriminator Loss = 1.0436\n",
      "Epoch 105: Generator Loss = 68.5428, Discriminator Loss = 0.9292\n",
      "Epoch 106: Generator Loss = 72.0638, Discriminator Loss = 0.7007\n",
      "Epoch 107: Generator Loss = 65.1589, Discriminator Loss = 1.0246\n",
      "Epoch 108: Generator Loss = 70.3199, Discriminator Loss = 1.3258\n",
      "Epoch 109: Generator Loss = 71.4932, Discriminator Loss = 0.6888\n",
      "Epoch 110: Generator Loss = 71.5694, Discriminator Loss = 1.3214\n",
      "Epoch 111: Generator Loss = 57.7371, Discriminator Loss = 3.0147\n",
      "Epoch 112: Generator Loss = 65.8895, Discriminator Loss = 1.6077\n",
      "Epoch 113: Generator Loss = 94.2149, Discriminator Loss = 0.9434\n",
      "Epoch 114: Generator Loss = 71.5539, Discriminator Loss = 1.0830\n",
      "Epoch 115: Generator Loss = 67.5289, Discriminator Loss = 0.9279\n",
      "Epoch 116: Generator Loss = 76.5340, Discriminator Loss = 1.7204\n",
      "Epoch 117: Generator Loss = 83.9422, Discriminator Loss = 1.5321\n",
      "Epoch 118: Generator Loss = 73.1996, Discriminator Loss = 0.8630\n",
      "Epoch 119: Generator Loss = 84.5143, Discriminator Loss = 1.6079\n",
      "Epoch 120: Generator Loss = 54.1507, Discriminator Loss = 5.3150\n",
      "Epoch 121: Generator Loss = 60.1515, Discriminator Loss = 1.6182\n",
      "Epoch 122: Generator Loss = 68.7654, Discriminator Loss = 2.2210\n",
      "Epoch 123: Generator Loss = 73.7032, Discriminator Loss = 5.6905\n",
      "Epoch 124: Generator Loss = 78.2482, Discriminator Loss = 0.7897\n",
      "Epoch 125: Generator Loss = 69.7682, Discriminator Loss = 0.8862\n",
      "Epoch 126: Generator Loss = 71.3134, Discriminator Loss = 0.5119\n",
      "Epoch 127: Generator Loss = 82.5695, Discriminator Loss = 0.6478\n",
      "Epoch 128: Generator Loss = 80.8561, Discriminator Loss = 0.7791\n",
      "Epoch 129: Generator Loss = 82.5853, Discriminator Loss = 0.5575\n",
      "Epoch 130: Generator Loss = 75.7734, Discriminator Loss = 0.7245\n",
      "Epoch 131: Generator Loss = 73.3373, Discriminator Loss = 1.2716\n",
      "Epoch 132: Generator Loss = 63.2041, Discriminator Loss = 1.4651\n",
      "Epoch 133: Generator Loss = 85.8014, Discriminator Loss = 0.8539\n",
      "Epoch 134: Generator Loss = 60.2605, Discriminator Loss = 1.1869\n",
      "Epoch 135: Generator Loss = 71.4324, Discriminator Loss = 0.6142\n",
      "Epoch 136: Generator Loss = 72.5062, Discriminator Loss = 0.9015\n",
      "Epoch 137: Generator Loss = 80.2472, Discriminator Loss = 1.3036\n",
      "Epoch 138: Generator Loss = 63.6203, Discriminator Loss = 9.8815\n",
      "Epoch 139: Generator Loss = 42.9397, Discriminator Loss = 10.2599\n",
      "Epoch 140: Generator Loss = 31.8645, Discriminator Loss = 6.2796\n",
      "Epoch 141: Generator Loss = 38.9781, Discriminator Loss = 2.7504\n",
      "Epoch 142: Generator Loss = 60.0487, Discriminator Loss = 1.9377\n",
      "Epoch 143: Generator Loss = 59.9658, Discriminator Loss = 2.3307\n",
      "Epoch 144: Generator Loss = 70.2287, Discriminator Loss = 6.3459\n",
      "Epoch 145: Generator Loss = 58.4015, Discriminator Loss = 2.1348\n",
      "Epoch 146: Generator Loss = 53.3141, Discriminator Loss = 2.1398\n",
      "Epoch 147: Generator Loss = 57.8350, Discriminator Loss = 2.0097\n",
      "Epoch 148: Generator Loss = 64.7417, Discriminator Loss = 2.2861\n",
      "Epoch 149: Generator Loss = 62.3372, Discriminator Loss = 1.7333\n",
      "Epoch 150: Generator Loss = 59.9580, Discriminator Loss = 1.2216\n",
      "Epoch 151: Generator Loss = 65.4342, Discriminator Loss = 0.5866\n",
      "Epoch 152: Generator Loss = 71.1968, Discriminator Loss = 0.7534\n",
      "Epoch 153: Generator Loss = 66.5869, Discriminator Loss = 2.1233\n",
      "Epoch 154: Generator Loss = 66.4933, Discriminator Loss = 2.1457\n",
      "Epoch 155: Generator Loss = 74.6566, Discriminator Loss = 0.8224\n",
      "Epoch 156: Generator Loss = 64.6860, Discriminator Loss = 0.8400\n",
      "Epoch 157: Generator Loss = 67.1281, Discriminator Loss = 0.9140\n",
      "Epoch 158: Generator Loss = 66.3380, Discriminator Loss = 1.1275\n",
      "Epoch 159: Generator Loss = 52.2304, Discriminator Loss = 1.3922\n",
      "Epoch 160: Generator Loss = 57.9184, Discriminator Loss = 1.6633\n",
      "Epoch 161: Generator Loss = 61.2336, Discriminator Loss = 1.3031\n",
      "Epoch 162: Generator Loss = 71.8343, Discriminator Loss = 0.7038\n",
      "Epoch 163: Generator Loss = 79.9703, Discriminator Loss = 0.7295\n",
      "Epoch 164: Generator Loss = 60.5740, Discriminator Loss = 1.3617\n",
      "Epoch 165: Generator Loss = 85.4053, Discriminator Loss = 1.2876\n",
      "Epoch 166: Generator Loss = 74.9815, Discriminator Loss = 6.6835\n",
      "Epoch 167: Generator Loss = 56.4148, Discriminator Loss = 4.0337\n",
      "Epoch 168: Generator Loss = 63.9900, Discriminator Loss = 5.2260\n",
      "Epoch 169: Generator Loss = 66.8151, Discriminator Loss = 4.1265\n",
      "Epoch 170: Generator Loss = 73.2056, Discriminator Loss = 1.8501\n",
      "Epoch 171: Generator Loss = 71.7664, Discriminator Loss = 0.7425\n",
      "Epoch 172: Generator Loss = 67.5610, Discriminator Loss = 1.2897\n",
      "Epoch 173: Generator Loss = 73.4039, Discriminator Loss = 0.9690\n",
      "Epoch 174: Generator Loss = 54.1663, Discriminator Loss = 2.2970\n",
      "Epoch 175: Generator Loss = 64.3890, Discriminator Loss = 2.0473\n",
      "Epoch 176: Generator Loss = 76.7582, Discriminator Loss = 1.6671\n",
      "Epoch 177: Generator Loss = 59.4091, Discriminator Loss = 6.2873\n",
      "Epoch 178: Generator Loss = 50.0371, Discriminator Loss = 2.5764\n",
      "Epoch 179: Generator Loss = 56.3922, Discriminator Loss = 1.7011\n",
      "Epoch 180: Generator Loss = 74.7435, Discriminator Loss = 3.9301\n",
      "Epoch 181: Generator Loss = 71.3434, Discriminator Loss = 0.9363\n",
      "Epoch 182: Generator Loss = 64.0851, Discriminator Loss = 0.7984\n",
      "Epoch 183: Generator Loss = 75.4155, Discriminator Loss = 1.0534\n",
      "Epoch 184: Generator Loss = 61.1451, Discriminator Loss = 1.1297\n",
      "Epoch 185: Generator Loss = 77.7794, Discriminator Loss = 0.6193\n",
      "Epoch 186: Generator Loss = 70.1639, Discriminator Loss = 0.8557\n",
      "Epoch 187: Generator Loss = 77.8773, Discriminator Loss = 0.5256\n",
      "Epoch 188: Generator Loss = 82.1610, Discriminator Loss = 0.7421\n",
      "Epoch 189: Generator Loss = 73.5315, Discriminator Loss = 1.3546\n",
      "Epoch 190: Generator Loss = 60.3411, Discriminator Loss = 12.0231\n",
      "Epoch 191: Generator Loss = 42.2724, Discriminator Loss = 10.3071\n",
      "Epoch 192: Generator Loss = 35.2831, Discriminator Loss = 3.6812\n",
      "Epoch 193: Generator Loss = 47.1784, Discriminator Loss = 3.3236\n",
      "Epoch 194: Generator Loss = 57.5491, Discriminator Loss = 4.4879\n",
      "Epoch 195: Generator Loss = 46.1070, Discriminator Loss = 2.4923\n",
      "Epoch 196: Generator Loss = 52.5614, Discriminator Loss = 2.9875\n",
      "Epoch 197: Generator Loss = 51.8422, Discriminator Loss = 1.9010\n",
      "Epoch 198: Generator Loss = 62.0344, Discriminator Loss = 2.1549\n",
      "Epoch 199: Generator Loss = 60.0496, Discriminator Loss = 3.6099\n",
      "Epoch 200: Generator Loss = 44.1151, Discriminator Loss = 2.4505\n",
      "Epoch 201: Generator Loss = 72.1757, Discriminator Loss = 1.2641\n",
      "Epoch 202: Generator Loss = 53.1136, Discriminator Loss = 1.9968\n",
      "Epoch 203: Generator Loss = 49.2232, Discriminator Loss = 6.4345\n",
      "Epoch 204: Generator Loss = 44.8453, Discriminator Loss = 3.3650\n",
      "Epoch 205: Generator Loss = 58.4298, Discriminator Loss = 5.7296\n",
      "Epoch 206: Generator Loss = 45.8089, Discriminator Loss = 4.2580\n",
      "Epoch 207: Generator Loss = 47.4518, Discriminator Loss = 1.7801\n",
      "Epoch 208: Generator Loss = 78.0818, Discriminator Loss = 4.3246\n",
      "Epoch 209: Generator Loss = 54.3188, Discriminator Loss = 5.7486\n",
      "Epoch 210: Generator Loss = 58.2474, Discriminator Loss = 1.7065\n",
      "Epoch 211: Generator Loss = 55.5515, Discriminator Loss = 1.6559\n",
      "Epoch 212: Generator Loss = 54.3579, Discriminator Loss = 0.8985\n",
      "Epoch 213: Generator Loss = 45.4503, Discriminator Loss = 1.9303\n",
      "Epoch 214: Generator Loss = 62.6244, Discriminator Loss = 8.3285\n",
      "Epoch 215: Generator Loss = 43.5104, Discriminator Loss = 3.4848\n",
      "Epoch 216: Generator Loss = 48.9493, Discriminator Loss = 2.3342\n",
      "Epoch 217: Generator Loss = 53.5569, Discriminator Loss = 1.9143\n",
      "Epoch 218: Generator Loss = 62.7019, Discriminator Loss = 7.2127\n",
      "Epoch 219: Generator Loss = 53.5378, Discriminator Loss = 2.4190\n",
      "Epoch 220: Generator Loss = 69.7044, Discriminator Loss = 1.0112\n",
      "Epoch 221: Generator Loss = 70.0879, Discriminator Loss = 0.8639\n",
      "Epoch 222: Generator Loss = 80.6569, Discriminator Loss = 1.1107\n",
      "Epoch 223: Generator Loss = 59.7539, Discriminator Loss = 0.8985\n",
      "Epoch 224: Generator Loss = 56.2254, Discriminator Loss = 1.1734\n",
      "Epoch 225: Generator Loss = 79.1138, Discriminator Loss = 2.4318\n",
      "Epoch 226: Generator Loss = 65.8928, Discriminator Loss = 1.3748\n",
      "Epoch 227: Generator Loss = 72.5738, Discriminator Loss = 5.2115\n",
      "Epoch 228: Generator Loss = 61.0131, Discriminator Loss = 1.6298\n",
      "Epoch 229: Generator Loss = 54.8664, Discriminator Loss = 1.0785\n",
      "Epoch 230: Generator Loss = 55.0568, Discriminator Loss = 0.5398\n",
      "Epoch 231: Generator Loss = 75.6373, Discriminator Loss = 4.5884\n",
      "Epoch 232: Generator Loss = 75.3980, Discriminator Loss = 2.0310\n",
      "Epoch 233: Generator Loss = 63.4108, Discriminator Loss = 1.0209\n",
      "Epoch 234: Generator Loss = 66.6858, Discriminator Loss = 1.8765\n",
      "Epoch 235: Generator Loss = 63.3526, Discriminator Loss = 1.5448\n",
      "Epoch 236: Generator Loss = 73.9068, Discriminator Loss = 0.8304\n",
      "Epoch 237: Generator Loss = 71.6723, Discriminator Loss = 1.7933\n",
      "Epoch 238: Generator Loss = 98.9947, Discriminator Loss = 4.2849\n",
      "Epoch 239: Generator Loss = 54.3913, Discriminator Loss = 2.9102\n",
      "Epoch 240: Generator Loss = 60.9842, Discriminator Loss = 1.1446\n",
      "Epoch 241: Generator Loss = 67.2065, Discriminator Loss = 2.2282\n",
      "Epoch 242: Generator Loss = 57.5238, Discriminator Loss = 1.2107\n",
      "Epoch 243: Generator Loss = 70.6448, Discriminator Loss = 0.6840\n",
      "Epoch 244: Generator Loss = 79.2151, Discriminator Loss = 0.9029\n",
      "Epoch 245: Generator Loss = 49.3587, Discriminator Loss = 1.2354\n",
      "Epoch 246: Generator Loss = 72.8651, Discriminator Loss = 0.6383\n",
      "Epoch 247: Generator Loss = 95.0790, Discriminator Loss = 3.1365\n",
      "Epoch 248: Generator Loss = 48.2838, Discriminator Loss = 12.2650\n",
      "Epoch 249: Generator Loss = 60.6846, Discriminator Loss = 1.7321\n",
      "Epoch 250: Generator Loss = 53.0210, Discriminator Loss = 1.6297\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Epoch 1/15 | Train Loss: 0.4881 Acc: 0.7565\n",
      "Epoch 2/15 | Train Loss: 0.3886 Acc: 0.8135\n",
      "Epoch 3/15 | Train Loss: 0.3896 Acc: 0.7953\n",
      "Epoch 4/15 | Train Loss: 0.3696 Acc: 0.7876\n",
      "Epoch 5/15 | Train Loss: 0.3352 Acc: 0.8135\n",
      "Epoch 6/15 | Train Loss: 0.3726 Acc: 0.7979\n",
      "Epoch 7/15 | Train Loss: 0.3415 Acc: 0.8472\n",
      "Epoch 8/15 | Train Loss: 0.2919 Acc: 0.8472\n",
      "Epoch 9/15 | Train Loss: 0.2913 Acc: 0.8627\n",
      "Epoch 10/15 | Train Loss: 0.2780 Acc: 0.8653\n",
      "Epoch 11/15 | Train Loss: 0.2667 Acc: 0.8782\n",
      "Epoch 12/15 | Train Loss: 0.2804 Acc: 0.8705\n",
      "Epoch 13/15 | Train Loss: 0.2944 Acc: 0.8497\n",
      "Epoch 14/15 | Train Loss: 0.2775 Acc: 0.8756\n",
      "Epoch 15/15 | Train Loss: 0.2711 Acc: 0.8653\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 3.0min\n",
      "Epoch 1/15 | Train Loss: 0.5948 Acc: 0.7513\n",
      "Epoch 2/15 | Train Loss: 0.4695 Acc: 0.7746\n",
      "Epoch 3/15 | Train Loss: 0.4191 Acc: 0.7850\n",
      "Epoch 4/15 | Train Loss: 0.3571 Acc: 0.8135\n",
      "Epoch 5/15 | Train Loss: 0.3817 Acc: 0.7953\n",
      "Epoch 6/15 | Train Loss: 0.3417 Acc: 0.8031\n",
      "Epoch 7/15 | Train Loss: 0.3748 Acc: 0.8161\n",
      "Epoch 8/15 | Train Loss: 0.3147 Acc: 0.8290\n",
      "Epoch 9/15 | Train Loss: 0.3257 Acc: 0.8264\n",
      "Epoch 10/15 | Train Loss: 0.3118 Acc: 0.8394\n",
      "Epoch 11/15 | Train Loss: 0.2945 Acc: 0.8679\n",
      "Epoch 12/15 | Train Loss: 0.2967 Acc: 0.8497\n",
      "Epoch 13/15 | Train Loss: 0.2887 Acc: 0.8705\n",
      "Epoch 14/15 | Train Loss: 0.3104 Acc: 0.8497\n",
      "Epoch 15/15 | Train Loss: 0.2790 Acc: 0.8731\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.5318 Acc: 0.7513\n",
      "Epoch 2/15 | Train Loss: 0.3968 Acc: 0.7824\n",
      "Epoch 3/15 | Train Loss: 0.3637 Acc: 0.8005\n",
      "Epoch 4/15 | Train Loss: 0.3562 Acc: 0.7979\n",
      "Epoch 5/15 | Train Loss: 0.3433 Acc: 0.8109\n",
      "Epoch 6/15 | Train Loss: 0.3418 Acc: 0.8212\n",
      "Epoch 7/15 | Train Loss: 0.3442 Acc: 0.8187\n",
      "Epoch 8/15 | Train Loss: 0.3582 Acc: 0.8212\n",
      "Epoch 9/15 | Train Loss: 0.3170 Acc: 0.8368\n",
      "Epoch 10/15 | Train Loss: 0.3175 Acc: 0.8575\n",
      "Epoch 11/15 | Train Loss: 0.2919 Acc: 0.8446\n",
      "Epoch 12/15 | Train Loss: 0.2971 Acc: 0.8472\n",
      "Epoch 13/15 | Train Loss: 0.2882 Acc: 0.8549\n",
      "Epoch 14/15 | Train Loss: 0.3086 Acc: 0.8497\n",
      "Epoch 15/15 | Train Loss: 0.2785 Acc: 0.8653\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.4982 Acc: 0.7810\n",
      "Epoch 2/15 | Train Loss: 0.4208 Acc: 0.8063\n",
      "Epoch 3/15 | Train Loss: 0.3828 Acc: 0.8476\n",
      "Epoch 4/15 | Train Loss: 0.3853 Acc: 0.8159\n",
      "Epoch 5/15 | Train Loss: 0.3689 Acc: 0.8381\n",
      "Epoch 6/15 | Train Loss: 0.3490 Acc: 0.8444\n",
      "Epoch 7/15 | Train Loss: 0.3447 Acc: 0.8603\n",
      "Epoch 8/15 | Train Loss: 0.2837 Acc: 0.8825\n",
      "Epoch 9/15 | Train Loss: 0.3344 Acc: 0.8571\n",
      "Epoch 10/15 | Train Loss: 0.3249 Acc: 0.8444\n",
      "Epoch 11/15 | Train Loss: 0.3115 Acc: 0.8825\n",
      "Epoch 12/15 | Train Loss: 0.3334 Acc: 0.8571\n",
      "Epoch 13/15 | Train Loss: 0.2746 Acc: 0.8825\n",
      "Epoch 14/15 | Train Loss: 0.2831 Acc: 0.8921\n",
      "Epoch 15/15 | Train Loss: 0.2883 Acc: 0.8762\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.4514 Acc: 0.8163\n",
      "Epoch 2/15 | Train Loss: 0.4008 Acc: 0.8516\n",
      "Epoch 3/15 | Train Loss: 0.3575 Acc: 0.8375\n",
      "Epoch 4/15 | Train Loss: 0.3069 Acc: 0.8693\n",
      "Epoch 5/15 | Train Loss: 0.3000 Acc: 0.8834\n",
      "Epoch 6/15 | Train Loss: 0.3224 Acc: 0.8834\n",
      "Epoch 7/15 | Train Loss: 0.3470 Acc: 0.8587\n",
      "Epoch 8/15 | Train Loss: 0.2521 Acc: 0.9011\n",
      "Epoch 9/15 | Train Loss: 0.2988 Acc: 0.8905\n",
      "Epoch 10/15 | Train Loss: 0.2568 Acc: 0.8940\n",
      "Epoch 11/15 | Train Loss: 0.2769 Acc: 0.8905\n",
      "Epoch 12/15 | Train Loss: 0.2360 Acc: 0.9011\n",
      "Epoch 13/15 | Train Loss: 0.2357 Acc: 0.9152\n",
      "Epoch 14/15 | Train Loss: 0.2552 Acc: 0.8869\n",
      "Epoch 15/15 | Train Loss: 0.2328 Acc: 0.9046\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7529 Acc: 0.6220\n",
      "Epoch 2/15 | Train Loss: 0.4711 Acc: 0.7874\n",
      "Epoch 3/15 | Train Loss: 0.6065 Acc: 0.6417\n",
      "Epoch 4/15 | Train Loss: 0.5686 Acc: 0.6890\n",
      "Epoch 5/15 | Train Loss: 0.4842 Acc: 0.7402\n",
      "Epoch 6/15 | Train Loss: 0.5076 Acc: 0.7795\n",
      "Epoch 7/15 | Train Loss: 0.5500 Acc: 0.7165\n",
      "Epoch 8/15 | Train Loss: 0.4481 Acc: 0.7559\n",
      "Epoch 9/15 | Train Loss: 0.4249 Acc: 0.7992\n",
      "Epoch 10/15 | Train Loss: 0.4176 Acc: 0.8425\n",
      "Epoch 11/15 | Train Loss: 0.4139 Acc: 0.7953\n",
      "Epoch 12/15 | Train Loss: 0.3957 Acc: 0.8228\n",
      "Epoch 13/15 | Train Loss: 0.3757 Acc: 0.8189\n",
      "Epoch 14/15 | Train Loss: 0.3897 Acc: 0.8425\n",
      "Epoch 15/15 | Train Loss: 0.4166 Acc: 0.8110\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6619 Acc: 0.6260\n",
      "Epoch 2/15 | Train Loss: 0.6592 Acc: 0.6890\n",
      "Epoch 3/15 | Train Loss: 0.5703 Acc: 0.6929\n",
      "Epoch 4/15 | Train Loss: 0.5242 Acc: 0.7323\n",
      "Epoch 5/15 | Train Loss: 0.5886 Acc: 0.6575\n",
      "Epoch 6/15 | Train Loss: 0.4869 Acc: 0.7677\n",
      "Epoch 7/15 | Train Loss: 0.4754 Acc: 0.7441\n",
      "Epoch 8/15 | Train Loss: 0.4634 Acc: 0.7480\n",
      "Epoch 9/15 | Train Loss: 0.4228 Acc: 0.7992\n",
      "Epoch 10/15 | Train Loss: 0.4887 Acc: 0.7835\n",
      "Epoch 11/15 | Train Loss: 0.4557 Acc: 0.7677\n",
      "Epoch 12/15 | Train Loss: 0.4210 Acc: 0.7717\n",
      "Epoch 13/15 | Train Loss: 0.4254 Acc: 0.7795\n",
      "Epoch 14/15 | Train Loss: 0.4466 Acc: 0.7756\n",
      "Epoch 15/15 | Train Loss: 0.3998 Acc: 0.8268\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7054 Acc: 0.6063\n",
      "Epoch 2/15 | Train Loss: 0.5830 Acc: 0.6732\n",
      "Epoch 3/15 | Train Loss: 0.5399 Acc: 0.7126\n",
      "Epoch 4/15 | Train Loss: 0.5760 Acc: 0.7008\n",
      "Epoch 5/15 | Train Loss: 0.5405 Acc: 0.7244\n",
      "Epoch 6/15 | Train Loss: 0.5561 Acc: 0.6772\n",
      "Epoch 7/15 | Train Loss: 0.4809 Acc: 0.7559\n",
      "Epoch 8/15 | Train Loss: 0.4621 Acc: 0.7638\n",
      "Epoch 9/15 | Train Loss: 0.4626 Acc: 0.7559\n",
      "Epoch 10/15 | Train Loss: 0.4471 Acc: 0.7756\n",
      "Epoch 11/15 | Train Loss: 0.4352 Acc: 0.8031\n",
      "Epoch 12/15 | Train Loss: 0.4292 Acc: 0.7795\n",
      "Epoch 13/15 | Train Loss: 0.4337 Acc: 0.7717\n",
      "Epoch 14/15 | Train Loss: 0.4774 Acc: 0.7598\n",
      "Epoch 15/15 | Train Loss: 0.3848 Acc: 0.8346\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6449 Acc: 0.6667\n",
      "Epoch 2/15 | Train Loss: 0.5430 Acc: 0.7679\n",
      "Epoch 3/15 | Train Loss: 0.4769 Acc: 0.8186\n",
      "Epoch 4/15 | Train Loss: 0.4934 Acc: 0.7764\n",
      "Epoch 5/15 | Train Loss: 0.4291 Acc: 0.7975\n",
      "Epoch 6/15 | Train Loss: 0.4857 Acc: 0.7890\n",
      "Epoch 7/15 | Train Loss: 0.4796 Acc: 0.7848\n",
      "Epoch 8/15 | Train Loss: 0.4067 Acc: 0.8439\n",
      "Epoch 9/15 | Train Loss: 0.4379 Acc: 0.8059\n",
      "Epoch 10/15 | Train Loss: 0.3772 Acc: 0.8734\n",
      "Epoch 11/15 | Train Loss: 0.4218 Acc: 0.8101\n",
      "Epoch 12/15 | Train Loss: 0.4435 Acc: 0.8186\n",
      "Epoch 13/15 | Train Loss: 0.3894 Acc: 0.8481\n",
      "Epoch 14/15 | Train Loss: 0.3828 Acc: 0.8354\n",
      "Epoch 15/15 | Train Loss: 0.3633 Acc: 0.8481\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6592 Acc: 0.6812\n",
      "Epoch 2/15 | Train Loss: 0.4809 Acc: 0.8079\n",
      "Epoch 3/15 | Train Loss: 0.3742 Acc: 0.8515\n",
      "Epoch 4/15 | Train Loss: 0.4139 Acc: 0.8428\n",
      "Epoch 5/15 | Train Loss: 0.3375 Acc: 0.8210\n",
      "Epoch 6/15 | Train Loss: 0.4364 Acc: 0.8384\n",
      "Epoch 7/15 | Train Loss: 0.3308 Acc: 0.8777\n",
      "Epoch 8/15 | Train Loss: 0.3213 Acc: 0.8865\n",
      "Epoch 9/15 | Train Loss: 0.3589 Acc: 0.8690\n",
      "Epoch 10/15 | Train Loss: 0.2777 Acc: 0.8908\n",
      "Epoch 11/15 | Train Loss: 0.3227 Acc: 0.8777\n",
      "Epoch 12/15 | Train Loss: 0.2784 Acc: 0.8865\n",
      "Epoch 13/15 | Train Loss: 0.2726 Acc: 0.8996\n",
      "Epoch 14/15 | Train Loss: 0.2830 Acc: 0.8865\n",
      "Epoch 15/15 | Train Loss: 0.2718 Acc: 0.8908\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6885 Acc: 0.6611\n",
      "Epoch 2/15 | Train Loss: 0.5409 Acc: 0.7349\n",
      "Epoch 3/15 | Train Loss: 0.4710 Acc: 0.7517\n",
      "Epoch 4/15 | Train Loss: 0.5128 Acc: 0.7517\n",
      "Epoch 5/15 | Train Loss: 0.4608 Acc: 0.7383\n",
      "Epoch 6/15 | Train Loss: 0.4418 Acc: 0.7685\n",
      "Epoch 7/15 | Train Loss: 0.4592 Acc: 0.7819\n",
      "Epoch 8/15 | Train Loss: 0.3771 Acc: 0.8154\n",
      "Epoch 9/15 | Train Loss: 0.3315 Acc: 0.8523\n",
      "Epoch 10/15 | Train Loss: 0.3413 Acc: 0.8490\n",
      "Epoch 11/15 | Train Loss: 0.3012 Acc: 0.8893\n",
      "Epoch 12/15 | Train Loss: 0.3451 Acc: 0.8456\n",
      "Epoch 13/15 | Train Loss: 0.3817 Acc: 0.8154\n",
      "Epoch 14/15 | Train Loss: 0.3111 Acc: 0.8658\n",
      "Epoch 15/15 | Train Loss: 0.2695 Acc: 0.8960\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6048 Acc: 0.6879\n",
      "Epoch 2/15 | Train Loss: 0.4499 Acc: 0.7349\n",
      "Epoch 3/15 | Train Loss: 0.5370 Acc: 0.7013\n",
      "Epoch 4/15 | Train Loss: 0.4827 Acc: 0.7383\n",
      "Epoch 5/15 | Train Loss: 0.4423 Acc: 0.7651\n",
      "Epoch 6/15 | Train Loss: 0.4395 Acc: 0.7987\n",
      "Epoch 7/15 | Train Loss: 0.4272 Acc: 0.7785\n",
      "Epoch 8/15 | Train Loss: 0.4286 Acc: 0.7953\n",
      "Epoch 9/15 | Train Loss: 0.4060 Acc: 0.7953\n",
      "Epoch 10/15 | Train Loss: 0.3833 Acc: 0.8188\n",
      "Epoch 11/15 | Train Loss: 0.3782 Acc: 0.8020\n",
      "Epoch 12/15 | Train Loss: 0.3714 Acc: 0.8154\n",
      "Epoch 13/15 | Train Loss: 0.3921 Acc: 0.7953\n",
      "Epoch 14/15 | Train Loss: 0.3596 Acc: 0.8456\n",
      "Epoch 15/15 | Train Loss: 0.3641 Acc: 0.8322\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6200 Acc: 0.7047\n",
      "Epoch 2/15 | Train Loss: 0.5137 Acc: 0.7181\n",
      "Epoch 3/15 | Train Loss: 0.4968 Acc: 0.7416\n",
      "Epoch 4/15 | Train Loss: 0.4642 Acc: 0.7517\n",
      "Epoch 5/15 | Train Loss: 0.4276 Acc: 0.7617\n",
      "Epoch 6/15 | Train Loss: 0.4259 Acc: 0.7852\n",
      "Epoch 7/15 | Train Loss: 0.3955 Acc: 0.7919\n",
      "Epoch 8/15 | Train Loss: 0.4395 Acc: 0.7718\n",
      "Epoch 9/15 | Train Loss: 0.3701 Acc: 0.8221\n",
      "Epoch 10/15 | Train Loss: 0.3747 Acc: 0.8020\n",
      "Epoch 11/15 | Train Loss: 0.3620 Acc: 0.8255\n",
      "Epoch 12/15 | Train Loss: 0.3607 Acc: 0.8289\n",
      "Epoch 13/15 | Train Loss: 0.4391 Acc: 0.8054\n",
      "Epoch 14/15 | Train Loss: 0.3551 Acc: 0.8423\n",
      "Epoch 15/15 | Train Loss: 0.3713 Acc: 0.8289\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5651 Acc: 0.7452\n",
      "Epoch 2/15 | Train Loss: 0.5363 Acc: 0.7414\n",
      "Epoch 3/15 | Train Loss: 0.4863 Acc: 0.8061\n",
      "Epoch 4/15 | Train Loss: 0.4414 Acc: 0.7909\n",
      "Epoch 5/15 | Train Loss: 0.4091 Acc: 0.8023\n",
      "Epoch 6/15 | Train Loss: 0.4401 Acc: 0.8137\n",
      "Epoch 7/15 | Train Loss: 0.4294 Acc: 0.8137\n",
      "Epoch 8/15 | Train Loss: 0.4207 Acc: 0.8137\n",
      "Epoch 9/15 | Train Loss: 0.3581 Acc: 0.8441\n",
      "Epoch 10/15 | Train Loss: 0.3578 Acc: 0.8403\n",
      "Epoch 11/15 | Train Loss: 0.4124 Acc: 0.8327\n",
      "Epoch 12/15 | Train Loss: 0.3501 Acc: 0.8441\n",
      "Epoch 13/15 | Train Loss: 0.3667 Acc: 0.8441\n",
      "Epoch 14/15 | Train Loss: 0.3953 Acc: 0.8289\n",
      "Epoch 15/15 | Train Loss: 0.3493 Acc: 0.8441\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5669 Acc: 0.7733\n",
      "Epoch 2/15 | Train Loss: 0.4756 Acc: 0.8138\n",
      "Epoch 3/15 | Train Loss: 0.3842 Acc: 0.8381\n",
      "Epoch 4/15 | Train Loss: 0.3763 Acc: 0.8219\n",
      "Epoch 5/15 | Train Loss: 0.4177 Acc: 0.8340\n",
      "Epoch 6/15 | Train Loss: 0.3499 Acc: 0.8745\n",
      "Epoch 7/15 | Train Loss: 0.3433 Acc: 0.8502\n",
      "Epoch 8/15 | Train Loss: 0.3189 Acc: 0.8583\n",
      "Epoch 9/15 | Train Loss: 0.3415 Acc: 0.8704\n",
      "Epoch 10/15 | Train Loss: 0.3317 Acc: 0.8421\n",
      "Epoch 11/15 | Train Loss: 0.3059 Acc: 0.8785\n",
      "Epoch 12/15 | Train Loss: 0.2998 Acc: 0.8826\n",
      "Epoch 13/15 | Train Loss: 0.3233 Acc: 0.8543\n",
      "Epoch 14/15 | Train Loss: 0.2833 Acc: 0.8907\n",
      "Epoch 15/15 | Train Loss: 0.2961 Acc: 0.8623\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7264 Acc: 0.6181\n",
      "Epoch 2/15 | Train Loss: 0.6384 Acc: 0.6654\n",
      "Epoch 3/15 | Train Loss: 0.5535 Acc: 0.7283\n",
      "Epoch 4/15 | Train Loss: 0.5320 Acc: 0.7244\n",
      "Epoch 5/15 | Train Loss: 0.5159 Acc: 0.7441\n",
      "Epoch 6/15 | Train Loss: 0.5076 Acc: 0.7323\n",
      "Epoch 7/15 | Train Loss: 0.4768 Acc: 0.7677\n",
      "Epoch 8/15 | Train Loss: 0.4393 Acc: 0.7638\n",
      "Epoch 9/15 | Train Loss: 0.3770 Acc: 0.8228\n",
      "Epoch 10/15 | Train Loss: 0.4125 Acc: 0.8110\n",
      "Epoch 11/15 | Train Loss: 0.3832 Acc: 0.8268\n",
      "Epoch 12/15 | Train Loss: 0.3987 Acc: 0.7835\n",
      "Epoch 13/15 | Train Loss: 0.3718 Acc: 0.8150\n",
      "Epoch 14/15 | Train Loss: 0.3678 Acc: 0.8268\n",
      "Epoch 15/15 | Train Loss: 0.3704 Acc: 0.8346\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7137 Acc: 0.5984\n",
      "Epoch 2/15 | Train Loss: 0.6360 Acc: 0.6417\n",
      "Epoch 3/15 | Train Loss: 0.5473 Acc: 0.7047\n",
      "Epoch 4/15 | Train Loss: 0.5172 Acc: 0.7008\n",
      "Epoch 5/15 | Train Loss: 0.4987 Acc: 0.7441\n",
      "Epoch 6/15 | Train Loss: 0.5596 Acc: 0.6929\n",
      "Epoch 7/15 | Train Loss: 0.4672 Acc: 0.7598\n",
      "Epoch 8/15 | Train Loss: 0.4380 Acc: 0.7992\n",
      "Epoch 9/15 | Train Loss: 0.4535 Acc: 0.7598\n",
      "Epoch 10/15 | Train Loss: 0.3980 Acc: 0.8110\n",
      "Epoch 11/15 | Train Loss: 0.3693 Acc: 0.8465\n",
      "Epoch 12/15 | Train Loss: 0.4221 Acc: 0.7874\n",
      "Epoch 13/15 | Train Loss: 0.4357 Acc: 0.7795\n",
      "Epoch 14/15 | Train Loss: 0.4282 Acc: 0.7835\n",
      "Epoch 15/15 | Train Loss: 0.4646 Acc: 0.7480\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7346 Acc: 0.6299\n",
      "Epoch 2/15 | Train Loss: 0.5791 Acc: 0.6969\n",
      "Epoch 3/15 | Train Loss: 0.6205 Acc: 0.6614\n",
      "Epoch 4/15 | Train Loss: 0.5472 Acc: 0.7480\n",
      "Epoch 5/15 | Train Loss: 0.5745 Acc: 0.7126\n",
      "Epoch 6/15 | Train Loss: 0.4810 Acc: 0.7126\n",
      "Epoch 7/15 | Train Loss: 0.5144 Acc: 0.7323\n",
      "Epoch 8/15 | Train Loss: 0.5168 Acc: 0.7520\n",
      "Epoch 9/15 | Train Loss: 0.4240 Acc: 0.7795\n",
      "Epoch 10/15 | Train Loss: 0.4464 Acc: 0.7795\n",
      "Epoch 11/15 | Train Loss: 0.4226 Acc: 0.8031\n",
      "Epoch 12/15 | Train Loss: 0.3922 Acc: 0.8031\n",
      "Epoch 13/15 | Train Loss: 0.4282 Acc: 0.7717\n",
      "Epoch 14/15 | Train Loss: 0.4248 Acc: 0.7992\n",
      "Epoch 15/15 | Train Loss: 0.3809 Acc: 0.8110\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6546 Acc: 0.6582\n",
      "Epoch 2/15 | Train Loss: 0.5767 Acc: 0.7553\n",
      "Epoch 3/15 | Train Loss: 0.4867 Acc: 0.8017\n",
      "Epoch 4/15 | Train Loss: 0.4805 Acc: 0.8101\n",
      "Epoch 5/15 | Train Loss: 0.4924 Acc: 0.7932\n",
      "Epoch 6/15 | Train Loss: 0.4496 Acc: 0.7932\n",
      "Epoch 7/15 | Train Loss: 0.4288 Acc: 0.8270\n",
      "Epoch 8/15 | Train Loss: 0.4724 Acc: 0.7932\n",
      "Epoch 9/15 | Train Loss: 0.4457 Acc: 0.8059\n",
      "Epoch 10/15 | Train Loss: 0.4288 Acc: 0.8017\n",
      "Epoch 11/15 | Train Loss: 0.3985 Acc: 0.8228\n",
      "Epoch 12/15 | Train Loss: 0.4034 Acc: 0.8397\n",
      "Epoch 13/15 | Train Loss: 0.3936 Acc: 0.8312\n",
      "Epoch 14/15 | Train Loss: 0.3797 Acc: 0.8481\n",
      "Epoch 15/15 | Train Loss: 0.3899 Acc: 0.8439\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5633 Acc: 0.7817\n",
      "Epoch 2/15 | Train Loss: 0.5062 Acc: 0.8210\n",
      "Epoch 3/15 | Train Loss: 0.4277 Acc: 0.8210\n",
      "Epoch 4/15 | Train Loss: 0.4110 Acc: 0.8603\n",
      "Epoch 5/15 | Train Loss: 0.4421 Acc: 0.8472\n",
      "Epoch 6/15 | Train Loss: 0.4548 Acc: 0.8297\n",
      "Epoch 7/15 | Train Loss: 0.3920 Acc: 0.8297\n",
      "Epoch 8/15 | Train Loss: 0.3392 Acc: 0.8821\n",
      "Epoch 9/15 | Train Loss: 0.3339 Acc: 0.8690\n",
      "Epoch 10/15 | Train Loss: 0.3184 Acc: 0.8690\n",
      "Epoch 11/15 | Train Loss: 0.3178 Acc: 0.8952\n",
      "Epoch 12/15 | Train Loss: 0.2777 Acc: 0.8952\n",
      "Epoch 13/15 | Train Loss: 0.2888 Acc: 0.8821\n",
      "Epoch 14/15 | Train Loss: 0.2706 Acc: 0.8996\n",
      "Epoch 15/15 | Train Loss: 0.2728 Acc: 0.8996\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5565 Acc: 0.7383\n",
      "Epoch 2/15 | Train Loss: 0.4690 Acc: 0.7850\n",
      "Epoch 3/15 | Train Loss: 0.3997 Acc: 0.8083\n",
      "Epoch 4/15 | Train Loss: 0.3771 Acc: 0.7772\n",
      "Epoch 5/15 | Train Loss: 0.3290 Acc: 0.8238\n",
      "Epoch 6/15 | Train Loss: 0.3499 Acc: 0.8238\n",
      "Epoch 7/15 | Train Loss: 0.3492 Acc: 0.8135\n",
      "Epoch 8/15 | Train Loss: 0.2912 Acc: 0.8601\n",
      "Epoch 9/15 | Train Loss: 0.2951 Acc: 0.8575\n",
      "Epoch 10/15 | Train Loss: 0.2812 Acc: 0.8756\n",
      "Epoch 11/15 | Train Loss: 0.2839 Acc: 0.8523\n",
      "Epoch 12/15 | Train Loss: 0.2563 Acc: 0.8938\n",
      "Epoch 13/15 | Train Loss: 0.2655 Acc: 0.8756\n",
      "Epoch 14/15 | Train Loss: 0.2334 Acc: 0.8964\n",
      "Epoch 15/15 | Train Loss: 0.2319 Acc: 0.9119\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.6462 Acc: 0.7383\n",
      "Epoch 2/15 | Train Loss: 0.4074 Acc: 0.7720\n",
      "Epoch 3/15 | Train Loss: 0.3613 Acc: 0.8083\n",
      "Epoch 4/15 | Train Loss: 0.3751 Acc: 0.8109\n",
      "Epoch 5/15 | Train Loss: 0.3762 Acc: 0.8057\n",
      "Epoch 6/15 | Train Loss: 0.3886 Acc: 0.7979\n",
      "Epoch 7/15 | Train Loss: 0.3204 Acc: 0.8446\n",
      "Epoch 8/15 | Train Loss: 0.4076 Acc: 0.8135\n",
      "Epoch 9/15 | Train Loss: 0.2835 Acc: 0.8601\n",
      "Epoch 10/15 | Train Loss: 0.3220 Acc: 0.8238\n",
      "Epoch 11/15 | Train Loss: 0.2866 Acc: 0.8653\n",
      "Epoch 12/15 | Train Loss: 0.2924 Acc: 0.8446\n",
      "Epoch 13/15 | Train Loss: 0.2653 Acc: 0.8731\n",
      "Epoch 14/15 | Train Loss: 0.2896 Acc: 0.8575\n",
      "Epoch 15/15 | Train Loss: 0.2746 Acc: 0.8575\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.6266 Acc: 0.7202\n",
      "Epoch 2/15 | Train Loss: 0.4251 Acc: 0.7772\n",
      "Epoch 3/15 | Train Loss: 0.4412 Acc: 0.7746\n",
      "Epoch 4/15 | Train Loss: 0.3610 Acc: 0.8031\n",
      "Epoch 5/15 | Train Loss: 0.3571 Acc: 0.8109\n",
      "Epoch 6/15 | Train Loss: 0.3323 Acc: 0.8238\n",
      "Epoch 7/15 | Train Loss: 0.3300 Acc: 0.8290\n",
      "Epoch 8/15 | Train Loss: 0.3098 Acc: 0.8342\n",
      "Epoch 9/15 | Train Loss: 0.3222 Acc: 0.8446\n",
      "Epoch 10/15 | Train Loss: 0.3153 Acc: 0.8420\n",
      "Epoch 11/15 | Train Loss: 0.2938 Acc: 0.8549\n",
      "Epoch 12/15 | Train Loss: 0.2769 Acc: 0.8808\n",
      "Epoch 13/15 | Train Loss: 0.3038 Acc: 0.8342\n",
      "Epoch 14/15 | Train Loss: 0.2873 Acc: 0.8523\n",
      "Epoch 15/15 | Train Loss: 0.2972 Acc: 0.8446\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5151 Acc: 0.7587\n",
      "Epoch 2/15 | Train Loss: 0.3984 Acc: 0.8317\n",
      "Epoch 3/15 | Train Loss: 0.3689 Acc: 0.8349\n",
      "Epoch 4/15 | Train Loss: 0.3591 Acc: 0.8381\n",
      "Epoch 5/15 | Train Loss: 0.3330 Acc: 0.8635\n",
      "Epoch 6/15 | Train Loss: 0.3198 Acc: 0.8635\n",
      "Epoch 7/15 | Train Loss: 0.3452 Acc: 0.8254\n",
      "Epoch 8/15 | Train Loss: 0.3173 Acc: 0.8413\n",
      "Epoch 9/15 | Train Loss: 0.3175 Acc: 0.8825\n",
      "Epoch 10/15 | Train Loss: 0.2852 Acc: 0.8698\n",
      "Epoch 11/15 | Train Loss: 0.3281 Acc: 0.8444\n",
      "Epoch 12/15 | Train Loss: 0.2873 Acc: 0.8794\n",
      "Epoch 13/15 | Train Loss: 0.2985 Acc: 0.8762\n",
      "Epoch 14/15 | Train Loss: 0.3113 Acc: 0.8508\n",
      "Epoch 15/15 | Train Loss: 0.2966 Acc: 0.8603\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5262 Acc: 0.7845\n",
      "Epoch 2/15 | Train Loss: 0.4083 Acc: 0.8339\n",
      "Epoch 3/15 | Train Loss: 0.3941 Acc: 0.8445\n",
      "Epoch 4/15 | Train Loss: 0.3245 Acc: 0.8622\n",
      "Epoch 5/15 | Train Loss: 0.2689 Acc: 0.8834\n",
      "Epoch 6/15 | Train Loss: 0.3441 Acc: 0.8622\n",
      "Epoch 7/15 | Train Loss: 0.3402 Acc: 0.8657\n",
      "Epoch 8/15 | Train Loss: 0.2702 Acc: 0.8869\n",
      "Epoch 9/15 | Train Loss: 0.2677 Acc: 0.8905\n",
      "Epoch 10/15 | Train Loss: 0.2615 Acc: 0.8905\n",
      "Epoch 11/15 | Train Loss: 0.3091 Acc: 0.8763\n",
      "Epoch 12/15 | Train Loss: 0.3078 Acc: 0.8587\n",
      "Epoch 13/15 | Train Loss: 0.2442 Acc: 0.9117\n",
      "Epoch 14/15 | Train Loss: 0.2318 Acc: 0.8975\n",
      "Epoch 15/15 | Train Loss: 0.2363 Acc: 0.9046\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7176 Acc: 0.6142\n",
      "Epoch 2/15 | Train Loss: 0.5925 Acc: 0.6693\n",
      "Epoch 3/15 | Train Loss: 0.5303 Acc: 0.7087\n",
      "Epoch 4/15 | Train Loss: 0.4712 Acc: 0.7480\n",
      "Epoch 5/15 | Train Loss: 0.4596 Acc: 0.7402\n",
      "Epoch 6/15 | Train Loss: 0.5158 Acc: 0.7677\n",
      "Epoch 7/15 | Train Loss: 0.4492 Acc: 0.7677\n",
      "Epoch 8/15 | Train Loss: 0.4071 Acc: 0.8228\n",
      "Epoch 9/15 | Train Loss: 0.4283 Acc: 0.7756\n",
      "Epoch 10/15 | Train Loss: 0.3591 Acc: 0.8268\n",
      "Epoch 11/15 | Train Loss: 0.4284 Acc: 0.7992\n",
      "Epoch 12/15 | Train Loss: 0.4008 Acc: 0.8346\n",
      "Epoch 13/15 | Train Loss: 0.4135 Acc: 0.8031\n",
      "Epoch 14/15 | Train Loss: 0.3528 Acc: 0.8268\n",
      "Epoch 15/15 | Train Loss: 0.3614 Acc: 0.8465\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6986 Acc: 0.6654\n",
      "Epoch 2/15 | Train Loss: 0.6942 Acc: 0.6378\n",
      "Epoch 3/15 | Train Loss: 0.5599 Acc: 0.6614\n",
      "Epoch 4/15 | Train Loss: 0.5608 Acc: 0.7008\n",
      "Epoch 5/15 | Train Loss: 0.6188 Acc: 0.6693\n",
      "Epoch 6/15 | Train Loss: 0.5580 Acc: 0.7087\n",
      "Epoch 7/15 | Train Loss: 0.5142 Acc: 0.7244\n",
      "Epoch 8/15 | Train Loss: 0.4700 Acc: 0.7638\n",
      "Epoch 9/15 | Train Loss: 0.4360 Acc: 0.7598\n",
      "Epoch 10/15 | Train Loss: 0.4589 Acc: 0.7559\n",
      "Epoch 11/15 | Train Loss: 0.4612 Acc: 0.7520\n",
      "Epoch 12/15 | Train Loss: 0.4297 Acc: 0.7756\n",
      "Epoch 13/15 | Train Loss: 0.4257 Acc: 0.7913\n",
      "Epoch 14/15 | Train Loss: 0.4314 Acc: 0.8031\n",
      "Epoch 15/15 | Train Loss: 0.4486 Acc: 0.7835\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7021 Acc: 0.6378\n",
      "Epoch 2/15 | Train Loss: 0.6446 Acc: 0.6299\n",
      "Epoch 3/15 | Train Loss: 0.6117 Acc: 0.7008\n",
      "Epoch 4/15 | Train Loss: 0.5238 Acc: 0.7441\n",
      "Epoch 5/15 | Train Loss: 0.4939 Acc: 0.7520\n",
      "Epoch 6/15 | Train Loss: 0.4790 Acc: 0.7992\n",
      "Epoch 7/15 | Train Loss: 0.4959 Acc: 0.7402\n",
      "Epoch 8/15 | Train Loss: 0.5116 Acc: 0.7323\n",
      "Epoch 9/15 | Train Loss: 0.4569 Acc: 0.7756\n",
      "Epoch 10/15 | Train Loss: 0.4068 Acc: 0.8228\n",
      "Epoch 11/15 | Train Loss: 0.4505 Acc: 0.7835\n",
      "Epoch 12/15 | Train Loss: 0.4345 Acc: 0.7992\n",
      "Epoch 13/15 | Train Loss: 0.4571 Acc: 0.7638\n",
      "Epoch 14/15 | Train Loss: 0.4128 Acc: 0.8071\n",
      "Epoch 15/15 | Train Loss: 0.4036 Acc: 0.8110\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6539 Acc: 0.7131\n",
      "Epoch 2/15 | Train Loss: 0.5261 Acc: 0.7764\n",
      "Epoch 3/15 | Train Loss: 0.5514 Acc: 0.7764\n",
      "Epoch 4/15 | Train Loss: 0.4850 Acc: 0.7637\n",
      "Epoch 5/15 | Train Loss: 0.4815 Acc: 0.7848\n",
      "Epoch 6/15 | Train Loss: 0.4714 Acc: 0.7722\n",
      "Epoch 7/15 | Train Loss: 0.4241 Acc: 0.8101\n",
      "Epoch 8/15 | Train Loss: 0.4159 Acc: 0.8143\n",
      "Epoch 9/15 | Train Loss: 0.4269 Acc: 0.7848\n",
      "Epoch 10/15 | Train Loss: 0.3938 Acc: 0.8186\n",
      "Epoch 11/15 | Train Loss: 0.4138 Acc: 0.8143\n",
      "Epoch 12/15 | Train Loss: 0.4105 Acc: 0.8312\n",
      "Epoch 13/15 | Train Loss: 0.4660 Acc: 0.8143\n",
      "Epoch 14/15 | Train Loss: 0.3961 Acc: 0.8228\n",
      "Epoch 15/15 | Train Loss: 0.4266 Acc: 0.8312\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5869 Acc: 0.7511\n",
      "Epoch 2/15 | Train Loss: 0.4858 Acc: 0.8166\n",
      "Epoch 3/15 | Train Loss: 0.4639 Acc: 0.8079\n",
      "Epoch 4/15 | Train Loss: 0.3830 Acc: 0.8646\n",
      "Epoch 5/15 | Train Loss: 0.3939 Acc: 0.8210\n",
      "Epoch 6/15 | Train Loss: 0.4199 Acc: 0.8166\n",
      "Epoch 7/15 | Train Loss: 0.3981 Acc: 0.8603\n",
      "Epoch 8/15 | Train Loss: 0.3245 Acc: 0.8603\n",
      "Epoch 9/15 | Train Loss: 0.3083 Acc: 0.8690\n",
      "Epoch 10/15 | Train Loss: 0.2962 Acc: 0.8690\n",
      "Epoch 11/15 | Train Loss: 0.3146 Acc: 0.8690\n",
      "Epoch 12/15 | Train Loss: 0.2732 Acc: 0.8865\n",
      "Epoch 13/15 | Train Loss: 0.2990 Acc: 0.8865\n",
      "Epoch 14/15 | Train Loss: 0.3651 Acc: 0.8690\n",
      "Epoch 15/15 | Train Loss: 0.3078 Acc: 0.8603\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5226 Acc: 0.7563\n",
      "Epoch 2/15 | Train Loss: 0.4390 Acc: 0.7950\n",
      "Epoch 3/15 | Train Loss: 0.4118 Acc: 0.7790\n",
      "Epoch 4/15 | Train Loss: 0.3521 Acc: 0.8360\n",
      "Epoch 5/15 | Train Loss: 0.3593 Acc: 0.8246\n",
      "Epoch 6/15 | Train Loss: 0.3624 Acc: 0.8178\n",
      "Epoch 7/15 | Train Loss: 0.3296 Acc: 0.8292\n",
      "Epoch 8/15 | Train Loss: 0.2773 Acc: 0.8702\n",
      "Epoch 9/15 | Train Loss: 0.3131 Acc: 0.8451\n",
      "Epoch 10/15 | Train Loss: 0.2980 Acc: 0.8519\n",
      "Epoch 11/15 | Train Loss: 0.2794 Acc: 0.8838\n",
      "Epoch 12/15 | Train Loss: 0.2835 Acc: 0.8497\n",
      "Epoch 13/15 | Train Loss: 0.2757 Acc: 0.8815\n",
      "Epoch 14/15 | Train Loss: 0.2810 Acc: 0.8702\n",
      "Epoch 15/15 | Train Loss: 0.2729 Acc: 0.8679\n",
      "Fold 4 Test Accuracy: 0.6109\n",
      "===== Fold 5 =====\n",
      "Epoch 1: Generator Loss = 10.4278, Discriminator Loss = 8.6638\n",
      "Epoch 2: Generator Loss = 12.4684, Discriminator Loss = 5.3335\n",
      "Epoch 3: Generator Loss = 19.1822, Discriminator Loss = 4.0775\n",
      "Epoch 4: Generator Loss = 25.9127, Discriminator Loss = 4.2167\n",
      "Epoch 5: Generator Loss = 28.5039, Discriminator Loss = 5.6558\n",
      "Epoch 6: Generator Loss = 26.1750, Discriminator Loss = 4.9620\n",
      "Epoch 7: Generator Loss = 27.5218, Discriminator Loss = 5.6498\n",
      "Epoch 8: Generator Loss = 29.9207, Discriminator Loss = 4.1683\n",
      "Epoch 9: Generator Loss = 26.0372, Discriminator Loss = 6.5213\n",
      "Epoch 10: Generator Loss = 26.5688, Discriminator Loss = 5.7550\n",
      "Epoch 11: Generator Loss = 31.6470, Discriminator Loss = 10.8314\n",
      "Epoch 12: Generator Loss = 15.6511, Discriminator Loss = 6.7988\n",
      "Epoch 13: Generator Loss = 22.5157, Discriminator Loss = 13.2851\n",
      "Epoch 14: Generator Loss = 16.2587, Discriminator Loss = 8.8863\n",
      "Epoch 15: Generator Loss = 14.9672, Discriminator Loss = 8.2303\n",
      "Epoch 16: Generator Loss = 18.0516, Discriminator Loss = 8.7361\n",
      "Epoch 17: Generator Loss = 16.1222, Discriminator Loss = 9.4560\n",
      "Epoch 18: Generator Loss = 17.0544, Discriminator Loss = 9.0427\n",
      "Epoch 19: Generator Loss = 17.5988, Discriminator Loss = 8.0451\n",
      "Epoch 20: Generator Loss = 18.0812, Discriminator Loss = 9.8418\n",
      "Epoch 21: Generator Loss = 15.1704, Discriminator Loss = 8.5319\n",
      "Epoch 22: Generator Loss = 15.9350, Discriminator Loss = 9.1374\n",
      "Epoch 23: Generator Loss = 16.0013, Discriminator Loss = 8.2747\n",
      "Epoch 24: Generator Loss = 16.4772, Discriminator Loss = 9.0129\n",
      "Epoch 25: Generator Loss = 16.4254, Discriminator Loss = 8.2854\n",
      "Epoch 26: Generator Loss = 21.3645, Discriminator Loss = 8.7436\n",
      "Epoch 27: Generator Loss = 16.0621, Discriminator Loss = 8.4587\n",
      "Epoch 28: Generator Loss = 17.5824, Discriminator Loss = 8.2090\n",
      "Epoch 29: Generator Loss = 17.0410, Discriminator Loss = 9.2554\n",
      "Epoch 30: Generator Loss = 15.9513, Discriminator Loss = 8.3410\n",
      "Epoch 31: Generator Loss = 13.9649, Discriminator Loss = 8.5278\n",
      "Epoch 32: Generator Loss = 17.8442, Discriminator Loss = 8.2646\n",
      "Epoch 33: Generator Loss = 17.9823, Discriminator Loss = 8.8029\n",
      "Epoch 34: Generator Loss = 17.4365, Discriminator Loss = 8.7775\n",
      "Epoch 35: Generator Loss = 14.0225, Discriminator Loss = 9.1224\n",
      "Epoch 36: Generator Loss = 14.5926, Discriminator Loss = 8.5536\n",
      "Epoch 37: Generator Loss = 17.7517, Discriminator Loss = 7.9212\n",
      "Epoch 38: Generator Loss = 15.4361, Discriminator Loss = 8.5225\n",
      "Epoch 39: Generator Loss = 17.4152, Discriminator Loss = 9.3804\n",
      "Epoch 40: Generator Loss = 16.3245, Discriminator Loss = 7.5650\n",
      "Epoch 41: Generator Loss = 15.9714, Discriminator Loss = 9.3269\n",
      "Epoch 42: Generator Loss = 16.7974, Discriminator Loss = 8.4114\n",
      "Epoch 43: Generator Loss = 16.6784, Discriminator Loss = 7.7564\n",
      "Epoch 44: Generator Loss = 21.1625, Discriminator Loss = 7.6466\n",
      "Epoch 45: Generator Loss = 17.7692, Discriminator Loss = 9.0702\n",
      "Epoch 46: Generator Loss = 20.2246, Discriminator Loss = 7.3791\n",
      "Epoch 47: Generator Loss = 19.6672, Discriminator Loss = 8.6554\n",
      "Epoch 48: Generator Loss = 16.9254, Discriminator Loss = 7.4399\n",
      "Epoch 49: Generator Loss = 19.5679, Discriminator Loss = 6.2535\n",
      "Epoch 50: Generator Loss = 22.3975, Discriminator Loss = 7.5325\n",
      "Epoch 51: Generator Loss = 23.2651, Discriminator Loss = 5.1223\n",
      "Epoch 52: Generator Loss = 21.6473, Discriminator Loss = 5.8212\n",
      "Epoch 53: Generator Loss = 21.5107, Discriminator Loss = 8.4862\n",
      "Epoch 54: Generator Loss = 25.3762, Discriminator Loss = 5.6762\n",
      "Epoch 55: Generator Loss = 32.8984, Discriminator Loss = 4.0491\n",
      "Epoch 56: Generator Loss = 28.8057, Discriminator Loss = 6.2914\n",
      "Epoch 57: Generator Loss = 34.1065, Discriminator Loss = 4.2782\n",
      "Epoch 58: Generator Loss = 30.6036, Discriminator Loss = 3.7603\n",
      "Epoch 59: Generator Loss = 36.8122, Discriminator Loss = 3.3707\n",
      "Epoch 60: Generator Loss = 38.4313, Discriminator Loss = 4.0312\n",
      "Epoch 61: Generator Loss = 37.4220, Discriminator Loss = 2.6492\n",
      "Epoch 62: Generator Loss = 41.9374, Discriminator Loss = 4.3432\n",
      "Epoch 63: Generator Loss = 34.5809, Discriminator Loss = 3.0584\n",
      "Epoch 64: Generator Loss = 49.7318, Discriminator Loss = 3.7218\n",
      "Epoch 65: Generator Loss = 44.6740, Discriminator Loss = 3.3558\n",
      "Epoch 66: Generator Loss = 39.7071, Discriminator Loss = 3.1205\n",
      "Epoch 67: Generator Loss = 54.0130, Discriminator Loss = 4.0995\n",
      "Epoch 68: Generator Loss = 32.8636, Discriminator Loss = 5.1701\n",
      "Epoch 69: Generator Loss = 52.6062, Discriminator Loss = 2.7465\n",
      "Epoch 70: Generator Loss = 52.9748, Discriminator Loss = 1.9960\n",
      "Epoch 71: Generator Loss = 51.8889, Discriminator Loss = 2.0292\n",
      "Epoch 72: Generator Loss = 42.0923, Discriminator Loss = 1.2568\n",
      "Epoch 73: Generator Loss = 54.4603, Discriminator Loss = 1.4397\n",
      "Epoch 74: Generator Loss = 58.1514, Discriminator Loss = 1.0205\n",
      "Epoch 75: Generator Loss = 57.7867, Discriminator Loss = 1.3053\n",
      "Epoch 76: Generator Loss = 56.5105, Discriminator Loss = 1.6419\n",
      "Epoch 77: Generator Loss = 57.4372, Discriminator Loss = 1.2130\n",
      "Epoch 78: Generator Loss = 58.0744, Discriminator Loss = 0.9906\n",
      "Epoch 79: Generator Loss = 49.0300, Discriminator Loss = 1.1392\n",
      "Epoch 80: Generator Loss = 63.0694, Discriminator Loss = 3.8304\n",
      "Epoch 81: Generator Loss = 39.3517, Discriminator Loss = 3.3785\n",
      "Epoch 82: Generator Loss = 63.0606, Discriminator Loss = 1.4483\n",
      "Epoch 83: Generator Loss = 63.4566, Discriminator Loss = 1.3076\n",
      "Epoch 84: Generator Loss = 63.1337, Discriminator Loss = 1.2167\n",
      "Epoch 85: Generator Loss = 79.2051, Discriminator Loss = 0.6685\n",
      "Epoch 86: Generator Loss = 73.4739, Discriminator Loss = 1.2391\n",
      "Epoch 87: Generator Loss = 68.4569, Discriminator Loss = 0.8548\n",
      "Epoch 88: Generator Loss = 71.7655, Discriminator Loss = 1.4089\n",
      "Epoch 89: Generator Loss = 70.2719, Discriminator Loss = 2.2248\n",
      "Epoch 90: Generator Loss = 60.5277, Discriminator Loss = 1.5418\n",
      "Epoch 91: Generator Loss = 70.2891, Discriminator Loss = 1.0272\n",
      "Epoch 92: Generator Loss = 71.2778, Discriminator Loss = 0.8665\n",
      "Epoch 93: Generator Loss = 78.3798, Discriminator Loss = 0.9999\n",
      "Epoch 94: Generator Loss = 74.2063, Discriminator Loss = 0.7091\n",
      "Epoch 95: Generator Loss = 81.4060, Discriminator Loss = 0.4618\n",
      "Epoch 96: Generator Loss = 75.0760, Discriminator Loss = 0.7328\n",
      "Epoch 97: Generator Loss = 94.6465, Discriminator Loss = 0.2977\n",
      "Epoch 98: Generator Loss = 110.8233, Discriminator Loss = 0.7483\n",
      "Epoch 99: Generator Loss = 127.5344, Discriminator Loss = 1.2266\n",
      "Epoch 100: Generator Loss = 113.7938, Discriminator Loss = 0.1121\n",
      "Epoch 101: Generator Loss = 100.6059, Discriminator Loss = 0.0908\n",
      "Epoch 102: Generator Loss = 104.9242, Discriminator Loss = 0.2418\n",
      "Epoch 103: Generator Loss = 91.6366, Discriminator Loss = 0.1306\n",
      "Epoch 104: Generator Loss = 101.7079, Discriminator Loss = 0.1102\n",
      "Epoch 105: Generator Loss = 86.2567, Discriminator Loss = 0.0982\n",
      "Epoch 106: Generator Loss = 85.6278, Discriminator Loss = 0.0968\n",
      "Epoch 107: Generator Loss = 85.8023, Discriminator Loss = 0.0536\n",
      "Epoch 108: Generator Loss = 76.0112, Discriminator Loss = 0.0870\n",
      "Epoch 109: Generator Loss = 86.5612, Discriminator Loss = 0.0524\n",
      "Epoch 110: Generator Loss = 81.0877, Discriminator Loss = 0.0721\n",
      "Epoch 111: Generator Loss = 89.3451, Discriminator Loss = 0.0540\n",
      "Epoch 112: Generator Loss = 90.1674, Discriminator Loss = 0.0681\n",
      "Epoch 113: Generator Loss = 84.7160, Discriminator Loss = 0.0684\n",
      "Epoch 114: Generator Loss = 99.8423, Discriminator Loss = 0.0567\n",
      "Epoch 115: Generator Loss = 94.1255, Discriminator Loss = 0.0540\n",
      "Epoch 116: Generator Loss = 104.8044, Discriminator Loss = 0.0305\n",
      "Epoch 117: Generator Loss = 104.9838, Discriminator Loss = 0.0449\n",
      "Epoch 118: Generator Loss = 108.8390, Discriminator Loss = 0.3862\n",
      "Epoch 119: Generator Loss = 116.7224, Discriminator Loss = 24.2531\n",
      "Epoch 120: Generator Loss = 71.6978, Discriminator Loss = 5.3760\n",
      "Epoch 121: Generator Loss = 66.7959, Discriminator Loss = 1.6967\n",
      "Epoch 122: Generator Loss = 63.4553, Discriminator Loss = 1.3018\n",
      "Epoch 123: Generator Loss = 68.2912, Discriminator Loss = 1.6902\n",
      "Epoch 124: Generator Loss = 60.3662, Discriminator Loss = 3.6401\n",
      "Epoch 125: Generator Loss = 62.4931, Discriminator Loss = 1.3064\n",
      "Epoch 126: Generator Loss = 65.8260, Discriminator Loss = 0.5187\n",
      "Epoch 127: Generator Loss = 61.7989, Discriminator Loss = 0.8969\n",
      "Epoch 128: Generator Loss = 66.6803, Discriminator Loss = 1.1624\n",
      "Epoch 129: Generator Loss = 73.8095, Discriminator Loss = 1.4062\n",
      "Epoch 130: Generator Loss = 62.6604, Discriminator Loss = 1.5170\n",
      "Epoch 131: Generator Loss = 64.5649, Discriminator Loss = 1.2869\n",
      "Epoch 132: Generator Loss = 66.6122, Discriminator Loss = 1.0296\n",
      "Epoch 133: Generator Loss = 75.1147, Discriminator Loss = 1.3527\n",
      "Epoch 134: Generator Loss = 66.2595, Discriminator Loss = 0.9928\n",
      "Epoch 135: Generator Loss = 67.9354, Discriminator Loss = 0.9559\n",
      "Epoch 136: Generator Loss = 69.6869, Discriminator Loss = 0.7328\n",
      "Epoch 137: Generator Loss = 81.6201, Discriminator Loss = 3.2492\n",
      "Epoch 138: Generator Loss = 64.4736, Discriminator Loss = 1.1903\n",
      "Epoch 139: Generator Loss = 72.3265, Discriminator Loss = 1.1452\n",
      "Epoch 140: Generator Loss = 71.1788, Discriminator Loss = 0.9128\n",
      "Epoch 141: Generator Loss = 81.5892, Discriminator Loss = 0.5786\n",
      "Epoch 142: Generator Loss = 84.1481, Discriminator Loss = 0.5288\n",
      "Epoch 143: Generator Loss = 66.2471, Discriminator Loss = 0.7442\n",
      "Epoch 144: Generator Loss = 73.0149, Discriminator Loss = 0.6656\n",
      "Epoch 145: Generator Loss = 83.3873, Discriminator Loss = 0.3224\n",
      "Epoch 146: Generator Loss = 82.3503, Discriminator Loss = 0.7250\n",
      "Epoch 147: Generator Loss = 84.3443, Discriminator Loss = 1.1781\n",
      "Epoch 148: Generator Loss = 77.4194, Discriminator Loss = 0.5864\n",
      "Epoch 149: Generator Loss = 81.2369, Discriminator Loss = 0.5588\n",
      "Epoch 150: Generator Loss = 85.6591, Discriminator Loss = 0.6840\n",
      "Epoch 151: Generator Loss = 77.6110, Discriminator Loss = 0.5600\n",
      "Epoch 152: Generator Loss = 82.5807, Discriminator Loss = 0.8902\n",
      "Epoch 153: Generator Loss = 87.6277, Discriminator Loss = 0.6022\n",
      "Epoch 154: Generator Loss = 88.4998, Discriminator Loss = 1.1550\n",
      "Epoch 155: Generator Loss = 63.7440, Discriminator Loss = 2.1067\n",
      "Epoch 156: Generator Loss = 75.4224, Discriminator Loss = 0.6900\n",
      "Epoch 157: Generator Loss = 79.3113, Discriminator Loss = 0.5487\n",
      "Epoch 158: Generator Loss = 76.9823, Discriminator Loss = 0.6128\n",
      "Epoch 159: Generator Loss = 80.6773, Discriminator Loss = 1.2817\n",
      "Epoch 160: Generator Loss = 81.1534, Discriminator Loss = 0.7914\n",
      "Epoch 161: Generator Loss = 77.1902, Discriminator Loss = 0.9372\n",
      "Epoch 162: Generator Loss = 104.8336, Discriminator Loss = 0.4232\n",
      "Epoch 163: Generator Loss = 92.3884, Discriminator Loss = 0.3887\n",
      "Epoch 164: Generator Loss = 71.2907, Discriminator Loss = 0.3895\n",
      "Epoch 165: Generator Loss = 86.8676, Discriminator Loss = 0.2944\n",
      "Epoch 166: Generator Loss = 89.3313, Discriminator Loss = 0.2515\n",
      "Epoch 167: Generator Loss = 80.5179, Discriminator Loss = 0.3005\n",
      "Epoch 168: Generator Loss = 84.2548, Discriminator Loss = 0.3501\n",
      "Epoch 169: Generator Loss = 104.9336, Discriminator Loss = 0.2815\n",
      "Epoch 170: Generator Loss = 98.0006, Discriminator Loss = 0.2032\n",
      "Epoch 171: Generator Loss = 78.0702, Discriminator Loss = 0.3667\n",
      "Epoch 172: Generator Loss = 78.1233, Discriminator Loss = 0.6496\n",
      "Epoch 173: Generator Loss = 66.7236, Discriminator Loss = 4.8921\n",
      "Epoch 174: Generator Loss = 95.4853, Discriminator Loss = 0.9957\n",
      "Epoch 175: Generator Loss = 59.2155, Discriminator Loss = 2.7374\n",
      "Epoch 176: Generator Loss = 64.9226, Discriminator Loss = 1.1014\n",
      "Epoch 177: Generator Loss = 80.2647, Discriminator Loss = 1.7923\n",
      "Epoch 178: Generator Loss = 80.7478, Discriminator Loss = 1.1014\n",
      "Epoch 179: Generator Loss = 68.2577, Discriminator Loss = 1.6783\n",
      "Epoch 180: Generator Loss = 67.0886, Discriminator Loss = 1.4261\n",
      "Epoch 181: Generator Loss = 80.0783, Discriminator Loss = 0.4508\n",
      "Epoch 182: Generator Loss = 65.3007, Discriminator Loss = 2.1854\n",
      "Epoch 183: Generator Loss = 74.0665, Discriminator Loss = 1.1427\n",
      "Epoch 184: Generator Loss = 78.2314, Discriminator Loss = 1.1731\n",
      "Epoch 185: Generator Loss = 67.2970, Discriminator Loss = 0.8156\n",
      "Epoch 186: Generator Loss = 80.9389, Discriminator Loss = 0.7831\n",
      "Epoch 187: Generator Loss = 84.6929, Discriminator Loss = 1.4136\n",
      "Epoch 188: Generator Loss = 64.6484, Discriminator Loss = 1.9288\n",
      "Epoch 189: Generator Loss = 92.5765, Discriminator Loss = 3.8016\n",
      "Epoch 190: Generator Loss = 60.7359, Discriminator Loss = 3.3514\n",
      "Epoch 191: Generator Loss = 61.6682, Discriminator Loss = 1.7162\n",
      "Epoch 192: Generator Loss = 78.2733, Discriminator Loss = 0.7834\n",
      "Epoch 193: Generator Loss = 71.3434, Discriminator Loss = 1.2212\n",
      "Epoch 194: Generator Loss = 73.8907, Discriminator Loss = 1.0946\n",
      "Epoch 195: Generator Loss = 81.7447, Discriminator Loss = 0.8622\n",
      "Epoch 196: Generator Loss = 56.4581, Discriminator Loss = 0.9027\n",
      "Epoch 197: Generator Loss = 79.8070, Discriminator Loss = 0.8042\n",
      "Epoch 198: Generator Loss = 76.5843, Discriminator Loss = 0.8799\n",
      "Epoch 199: Generator Loss = 67.4533, Discriminator Loss = 0.9151\n",
      "Epoch 200: Generator Loss = 78.3955, Discriminator Loss = 0.7418\n",
      "Epoch 201: Generator Loss = 82.6806, Discriminator Loss = 1.6120\n",
      "Epoch 202: Generator Loss = 68.5950, Discriminator Loss = 0.9820\n",
      "Epoch 203: Generator Loss = 79.6819, Discriminator Loss = 1.3717\n",
      "Epoch 204: Generator Loss = 66.9628, Discriminator Loss = 0.5343\n",
      "Epoch 205: Generator Loss = 89.6801, Discriminator Loss = 0.8470\n",
      "Epoch 206: Generator Loss = 70.7517, Discriminator Loss = 2.9028\n",
      "Epoch 207: Generator Loss = 64.8025, Discriminator Loss = 1.4396\n",
      "Epoch 208: Generator Loss = 62.8975, Discriminator Loss = 2.0044\n",
      "Epoch 209: Generator Loss = 83.3125, Discriminator Loss = 0.7164\n",
      "Epoch 210: Generator Loss = 81.3661, Discriminator Loss = 1.2420\n",
      "Epoch 211: Generator Loss = 60.0198, Discriminator Loss = 6.1429\n",
      "Epoch 212: Generator Loss = 42.4596, Discriminator Loss = 7.8893\n",
      "Epoch 213: Generator Loss = 42.8896, Discriminator Loss = 3.2150\n",
      "Epoch 214: Generator Loss = 65.8409, Discriminator Loss = 1.4250\n",
      "Epoch 215: Generator Loss = 54.0951, Discriminator Loss = 4.4376\n",
      "Epoch 216: Generator Loss = 60.9137, Discriminator Loss = 2.7261\n",
      "Epoch 217: Generator Loss = 50.5352, Discriminator Loss = 2.2903\n",
      "Epoch 218: Generator Loss = 55.8817, Discriminator Loss = 1.3288\n",
      "Epoch 219: Generator Loss = 77.0113, Discriminator Loss = 1.3826\n",
      "Epoch 220: Generator Loss = 61.0217, Discriminator Loss = 1.3818\n",
      "Epoch 221: Generator Loss = 72.2141, Discriminator Loss = 2.1264\n",
      "Epoch 222: Generator Loss = 64.3134, Discriminator Loss = 1.3647\n",
      "Epoch 223: Generator Loss = 62.0188, Discriminator Loss = 1.1284\n",
      "Epoch 224: Generator Loss = 55.1955, Discriminator Loss = 5.8707\n",
      "Epoch 225: Generator Loss = 45.0758, Discriminator Loss = 2.0621\n",
      "Epoch 226: Generator Loss = 71.3513, Discriminator Loss = 2.6194\n",
      "Epoch 227: Generator Loss = 51.9528, Discriminator Loss = 3.3276\n",
      "Epoch 228: Generator Loss = 70.6180, Discriminator Loss = 1.6531\n",
      "Epoch 229: Generator Loss = 67.7765, Discriminator Loss = 2.2091\n",
      "Epoch 230: Generator Loss = 73.6604, Discriminator Loss = 1.5184\n",
      "Epoch 231: Generator Loss = 77.2761, Discriminator Loss = 1.0177\n",
      "Epoch 232: Generator Loss = 73.7996, Discriminator Loss = 2.3182\n",
      "Epoch 233: Generator Loss = 73.8912, Discriminator Loss = 1.0490\n",
      "Epoch 234: Generator Loss = 56.9863, Discriminator Loss = 1.0561\n",
      "Epoch 235: Generator Loss = 70.2025, Discriminator Loss = 0.9416\n",
      "Epoch 236: Generator Loss = 77.0087, Discriminator Loss = 1.0071\n",
      "Epoch 237: Generator Loss = 72.0649, Discriminator Loss = 0.9582\n",
      "Epoch 238: Generator Loss = 70.2697, Discriminator Loss = 0.5790\n",
      "Epoch 239: Generator Loss = 80.4355, Discriminator Loss = 0.4942\n",
      "Epoch 240: Generator Loss = 84.9617, Discriminator Loss = 0.6994\n",
      "Epoch 241: Generator Loss = 112.7757, Discriminator Loss = 0.4428\n",
      "Epoch 242: Generator Loss = 93.3086, Discriminator Loss = 0.2158\n",
      "Epoch 243: Generator Loss = 78.8807, Discriminator Loss = 0.7250\n",
      "Epoch 244: Generator Loss = 76.4614, Discriminator Loss = 1.1618\n",
      "Epoch 245: Generator Loss = 85.5422, Discriminator Loss = 1.3357\n",
      "Epoch 246: Generator Loss = 90.7743, Discriminator Loss = 1.0040\n",
      "Epoch 247: Generator Loss = 61.9440, Discriminator Loss = 6.8718\n",
      "Epoch 248: Generator Loss = 56.4081, Discriminator Loss = 2.9535\n",
      "Epoch 249: Generator Loss = 66.2665, Discriminator Loss = 2.4836\n",
      "Epoch 250: Generator Loss = 80.5924, Discriminator Loss = 0.8755\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Epoch 1/15 | Train Loss: 0.5239 Acc: 0.7318\n",
      "Epoch 2/15 | Train Loss: 0.4125 Acc: 0.7786\n",
      "Epoch 3/15 | Train Loss: 0.3666 Acc: 0.8073\n",
      "Epoch 4/15 | Train Loss: 0.3583 Acc: 0.7891\n",
      "Epoch 5/15 | Train Loss: 0.3361 Acc: 0.8255\n",
      "Epoch 6/15 | Train Loss: 0.3700 Acc: 0.7917\n",
      "Epoch 7/15 | Train Loss: 0.3112 Acc: 0.8438\n",
      "Epoch 8/15 | Train Loss: 0.3028 Acc: 0.8672\n",
      "Epoch 9/15 | Train Loss: 0.2780 Acc: 0.8672\n",
      "Epoch 10/15 | Train Loss: 0.2788 Acc: 0.8672\n",
      "Epoch 11/15 | Train Loss: 0.2745 Acc: 0.8724\n",
      "Epoch 12/15 | Train Loss: 0.2554 Acc: 0.8906\n",
      "Epoch 13/15 | Train Loss: 0.2974 Acc: 0.8620\n",
      "Epoch 14/15 | Train Loss: 0.2682 Acc: 0.8698\n",
      "Epoch 15/15 | Train Loss: 0.2535 Acc: 0.8906\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.5477 Acc: 0.7656\n",
      "Epoch 2/15 | Train Loss: 0.4501 Acc: 0.7578\n",
      "Epoch 3/15 | Train Loss: 0.4070 Acc: 0.7552\n",
      "Epoch 4/15 | Train Loss: 0.3820 Acc: 0.8099\n",
      "Epoch 5/15 | Train Loss: 0.3499 Acc: 0.8073\n",
      "Epoch 6/15 | Train Loss: 0.3654 Acc: 0.8307\n",
      "Epoch 7/15 | Train Loss: 0.3552 Acc: 0.8177\n",
      "Epoch 8/15 | Train Loss: 0.3268 Acc: 0.8542\n",
      "Epoch 9/15 | Train Loss: 0.3177 Acc: 0.8464\n",
      "Epoch 10/15 | Train Loss: 0.3469 Acc: 0.8151\n",
      "Epoch 11/15 | Train Loss: 0.3232 Acc: 0.8333\n",
      "Epoch 12/15 | Train Loss: 0.3114 Acc: 0.8542\n",
      "Epoch 13/15 | Train Loss: 0.3028 Acc: 0.8464\n",
      "Epoch 14/15 | Train Loss: 0.2850 Acc: 0.8802\n",
      "Epoch 15/15 | Train Loss: 0.2940 Acc: 0.8438\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5186 Acc: 0.7682\n",
      "Epoch 2/15 | Train Loss: 0.4125 Acc: 0.7500\n",
      "Epoch 3/15 | Train Loss: 0.4021 Acc: 0.7552\n",
      "Epoch 4/15 | Train Loss: 0.3733 Acc: 0.8021\n",
      "Epoch 5/15 | Train Loss: 0.3544 Acc: 0.8151\n",
      "Epoch 6/15 | Train Loss: 0.3476 Acc: 0.7969\n",
      "Epoch 7/15 | Train Loss: 0.3487 Acc: 0.7943\n",
      "Epoch 8/15 | Train Loss: 0.3179 Acc: 0.8307\n",
      "Epoch 9/15 | Train Loss: 0.3405 Acc: 0.8255\n",
      "Epoch 10/15 | Train Loss: 0.2964 Acc: 0.8516\n",
      "Epoch 11/15 | Train Loss: 0.3164 Acc: 0.8464\n",
      "Epoch 12/15 | Train Loss: 0.3119 Acc: 0.8568\n",
      "Epoch 13/15 | Train Loss: 0.3100 Acc: 0.8464\n",
      "Epoch 14/15 | Train Loss: 0.2951 Acc: 0.8698\n",
      "Epoch 15/15 | Train Loss: 0.2777 Acc: 0.8724\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5088 Acc: 0.7651\n",
      "Epoch 2/15 | Train Loss: 0.4387 Acc: 0.8381\n",
      "Epoch 3/15 | Train Loss: 0.4193 Acc: 0.8159\n",
      "Epoch 4/15 | Train Loss: 0.3691 Acc: 0.8508\n",
      "Epoch 5/15 | Train Loss: 0.3724 Acc: 0.8317\n",
      "Epoch 6/15 | Train Loss: 0.3206 Acc: 0.8540\n",
      "Epoch 7/15 | Train Loss: 0.3745 Acc: 0.8603\n",
      "Epoch 8/15 | Train Loss: 0.3544 Acc: 0.8349\n",
      "Epoch 9/15 | Train Loss: 0.3172 Acc: 0.8635\n",
      "Epoch 10/15 | Train Loss: 0.3221 Acc: 0.8603\n",
      "Epoch 11/15 | Train Loss: 0.3297 Acc: 0.8444\n",
      "Epoch 12/15 | Train Loss: 0.3205 Acc: 0.8730\n",
      "Epoch 13/15 | Train Loss: 0.3133 Acc: 0.8540\n",
      "Epoch 14/15 | Train Loss: 0.3353 Acc: 0.8317\n",
      "Epoch 15/15 | Train Loss: 0.3376 Acc: 0.8540\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.4322 Acc: 0.8327\n",
      "Epoch 2/15 | Train Loss: 0.4114 Acc: 0.8648\n",
      "Epoch 3/15 | Train Loss: 0.3680 Acc: 0.8327\n",
      "Epoch 4/15 | Train Loss: 0.3748 Acc: 0.8612\n",
      "Epoch 5/15 | Train Loss: 0.2925 Acc: 0.8754\n",
      "Epoch 6/15 | Train Loss: 0.3099 Acc: 0.8648\n",
      "Epoch 7/15 | Train Loss: 0.2948 Acc: 0.8968\n",
      "Epoch 8/15 | Train Loss: 0.2689 Acc: 0.8932\n",
      "Epoch 9/15 | Train Loss: 0.2297 Acc: 0.9181\n",
      "Epoch 10/15 | Train Loss: 0.2319 Acc: 0.9110\n",
      "Epoch 11/15 | Train Loss: 0.2341 Acc: 0.9075\n",
      "Epoch 12/15 | Train Loss: 0.2240 Acc: 0.9110\n",
      "Epoch 13/15 | Train Loss: 0.2144 Acc: 0.9253\n",
      "Epoch 14/15 | Train Loss: 0.2125 Acc: 0.8968\n",
      "Epoch 15/15 | Train Loss: 0.1967 Acc: 0.9146\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7042 Acc: 0.5968\n",
      "Epoch 2/15 | Train Loss: 0.5940 Acc: 0.6759\n",
      "Epoch 3/15 | Train Loss: 0.5316 Acc: 0.6996\n",
      "Epoch 4/15 | Train Loss: 0.5187 Acc: 0.7273\n",
      "Epoch 5/15 | Train Loss: 0.5383 Acc: 0.7194\n",
      "Epoch 6/15 | Train Loss: 0.4868 Acc: 0.7747\n",
      "Epoch 7/15 | Train Loss: 0.4550 Acc: 0.7628\n",
      "Epoch 8/15 | Train Loss: 0.4712 Acc: 0.7866\n",
      "Epoch 9/15 | Train Loss: 0.4397 Acc: 0.7945\n",
      "Epoch 10/15 | Train Loss: 0.3904 Acc: 0.8063\n",
      "Epoch 11/15 | Train Loss: 0.3902 Acc: 0.8261\n",
      "Epoch 12/15 | Train Loss: 0.3717 Acc: 0.8261\n",
      "Epoch 13/15 | Train Loss: 0.3905 Acc: 0.8221\n",
      "Epoch 14/15 | Train Loss: 0.3305 Acc: 0.8775\n",
      "Epoch 15/15 | Train Loss: 0.4028 Acc: 0.7945\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7215 Acc: 0.6482\n",
      "Epoch 2/15 | Train Loss: 0.6100 Acc: 0.6759\n",
      "Epoch 3/15 | Train Loss: 0.5761 Acc: 0.6759\n",
      "Epoch 4/15 | Train Loss: 0.4836 Acc: 0.7628\n",
      "Epoch 5/15 | Train Loss: 0.5559 Acc: 0.6996\n",
      "Epoch 6/15 | Train Loss: 0.5275 Acc: 0.7115\n",
      "Epoch 7/15 | Train Loss: 0.4735 Acc: 0.7628\n",
      "Epoch 8/15 | Train Loss: 0.4601 Acc: 0.7787\n",
      "Epoch 9/15 | Train Loss: 0.4805 Acc: 0.7391\n",
      "Epoch 10/15 | Train Loss: 0.4653 Acc: 0.7510\n",
      "Epoch 11/15 | Train Loss: 0.4678 Acc: 0.7510\n",
      "Epoch 12/15 | Train Loss: 0.4524 Acc: 0.7826\n",
      "Epoch 13/15 | Train Loss: 0.4536 Acc: 0.7668\n",
      "Epoch 14/15 | Train Loss: 0.4173 Acc: 0.8024\n",
      "Epoch 15/15 | Train Loss: 0.4134 Acc: 0.7826\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6856 Acc: 0.6561\n",
      "Epoch 2/15 | Train Loss: 0.6773 Acc: 0.6245\n",
      "Epoch 3/15 | Train Loss: 0.5814 Acc: 0.6996\n",
      "Epoch 4/15 | Train Loss: 0.5923 Acc: 0.6917\n",
      "Epoch 5/15 | Train Loss: 0.5045 Acc: 0.7431\n",
      "Epoch 6/15 | Train Loss: 0.4675 Acc: 0.7787\n",
      "Epoch 7/15 | Train Loss: 0.4709 Acc: 0.7708\n",
      "Epoch 8/15 | Train Loss: 0.5064 Acc: 0.7668\n",
      "Epoch 9/15 | Train Loss: 0.4322 Acc: 0.7747\n",
      "Epoch 10/15 | Train Loss: 0.4671 Acc: 0.7747\n",
      "Epoch 11/15 | Train Loss: 0.4426 Acc: 0.7589\n",
      "Epoch 12/15 | Train Loss: 0.4309 Acc: 0.7787\n",
      "Epoch 13/15 | Train Loss: 0.4131 Acc: 0.8142\n",
      "Epoch 14/15 | Train Loss: 0.4517 Acc: 0.7708\n",
      "Epoch 15/15 | Train Loss: 0.4342 Acc: 0.7708\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6172 Acc: 0.7426\n",
      "Epoch 2/15 | Train Loss: 0.5671 Acc: 0.7553\n",
      "Epoch 3/15 | Train Loss: 0.5495 Acc: 0.7300\n",
      "Epoch 4/15 | Train Loss: 0.5179 Acc: 0.7637\n",
      "Epoch 5/15 | Train Loss: 0.4930 Acc: 0.8101\n",
      "Epoch 6/15 | Train Loss: 0.4767 Acc: 0.7932\n",
      "Epoch 7/15 | Train Loss: 0.4771 Acc: 0.7595\n",
      "Epoch 8/15 | Train Loss: 0.4547 Acc: 0.8101\n",
      "Epoch 9/15 | Train Loss: 0.4036 Acc: 0.8186\n",
      "Epoch 10/15 | Train Loss: 0.4222 Acc: 0.8101\n",
      "Epoch 11/15 | Train Loss: 0.4130 Acc: 0.8101\n",
      "Epoch 12/15 | Train Loss: 0.4438 Acc: 0.8017\n",
      "Epoch 13/15 | Train Loss: 0.4118 Acc: 0.8270\n",
      "Epoch 14/15 | Train Loss: 0.3784 Acc: 0.8186\n",
      "Epoch 15/15 | Train Loss: 0.3854 Acc: 0.8354\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 1.0046 Acc: 0.5044\n",
      "Epoch 2/15 | Train Loss: 0.4917 Acc: 0.7851\n",
      "Epoch 3/15 | Train Loss: 0.4351 Acc: 0.7982\n",
      "Epoch 4/15 | Train Loss: 0.3979 Acc: 0.8421\n",
      "Epoch 5/15 | Train Loss: 0.3418 Acc: 0.8596\n",
      "Epoch 6/15 | Train Loss: 0.3358 Acc: 0.8640\n",
      "Epoch 7/15 | Train Loss: 0.3640 Acc: 0.8377\n",
      "Epoch 8/15 | Train Loss: 0.3510 Acc: 0.8728\n",
      "Epoch 9/15 | Train Loss: 0.3014 Acc: 0.8904\n",
      "Epoch 10/15 | Train Loss: 0.2877 Acc: 0.9035\n",
      "Epoch 11/15 | Train Loss: 0.2935 Acc: 0.9123\n",
      "Epoch 12/15 | Train Loss: 0.2848 Acc: 0.8728\n",
      "Epoch 13/15 | Train Loss: 0.2466 Acc: 0.9035\n",
      "Epoch 14/15 | Train Loss: 0.2909 Acc: 0.8816\n",
      "Epoch 15/15 | Train Loss: 0.2685 Acc: 0.8947\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.8077 Acc: 0.6869\n",
      "Epoch 2/15 | Train Loss: 0.5500 Acc: 0.7071\n",
      "Epoch 3/15 | Train Loss: 0.4569 Acc: 0.7475\n",
      "Epoch 4/15 | Train Loss: 0.4827 Acc: 0.7306\n",
      "Epoch 5/15 | Train Loss: 0.4180 Acc: 0.7778\n",
      "Epoch 6/15 | Train Loss: 0.4321 Acc: 0.7811\n",
      "Epoch 7/15 | Train Loss: 0.3795 Acc: 0.8350\n",
      "Epoch 8/15 | Train Loss: 0.4478 Acc: 0.7710\n",
      "Epoch 9/15 | Train Loss: 0.3713 Acc: 0.8148\n",
      "Epoch 10/15 | Train Loss: 0.3467 Acc: 0.8350\n",
      "Epoch 11/15 | Train Loss: 0.3556 Acc: 0.8316\n",
      "Epoch 12/15 | Train Loss: 0.3603 Acc: 0.8148\n",
      "Epoch 13/15 | Train Loss: 0.3016 Acc: 0.8788\n",
      "Epoch 14/15 | Train Loss: 0.3063 Acc: 0.8653\n",
      "Epoch 15/15 | Train Loss: 0.3318 Acc: 0.8552\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6138 Acc: 0.6936\n",
      "Epoch 2/15 | Train Loss: 0.5110 Acc: 0.7407\n",
      "Epoch 3/15 | Train Loss: 0.4360 Acc: 0.7811\n",
      "Epoch 4/15 | Train Loss: 0.4703 Acc: 0.7609\n",
      "Epoch 5/15 | Train Loss: 0.4686 Acc: 0.7542\n",
      "Epoch 6/15 | Train Loss: 0.4961 Acc: 0.7071\n",
      "Epoch 7/15 | Train Loss: 0.4307 Acc: 0.7643\n",
      "Epoch 8/15 | Train Loss: 0.4064 Acc: 0.8013\n",
      "Epoch 9/15 | Train Loss: 0.4278 Acc: 0.7778\n",
      "Epoch 10/15 | Train Loss: 0.3729 Acc: 0.8418\n",
      "Epoch 11/15 | Train Loss: 0.3707 Acc: 0.8114\n",
      "Epoch 12/15 | Train Loss: 0.3709 Acc: 0.8350\n",
      "Epoch 13/15 | Train Loss: 0.3651 Acc: 0.8182\n",
      "Epoch 14/15 | Train Loss: 0.3920 Acc: 0.8013\n",
      "Epoch 15/15 | Train Loss: 0.3878 Acc: 0.8283\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6165 Acc: 0.6498\n",
      "Epoch 2/15 | Train Loss: 0.5300 Acc: 0.7104\n",
      "Epoch 3/15 | Train Loss: 0.4776 Acc: 0.7374\n",
      "Epoch 4/15 | Train Loss: 0.4478 Acc: 0.7744\n",
      "Epoch 5/15 | Train Loss: 0.4656 Acc: 0.7677\n",
      "Epoch 6/15 | Train Loss: 0.4577 Acc: 0.7576\n",
      "Epoch 7/15 | Train Loss: 0.4512 Acc: 0.7643\n",
      "Epoch 8/15 | Train Loss: 0.3891 Acc: 0.8148\n",
      "Epoch 9/15 | Train Loss: 0.3935 Acc: 0.7980\n",
      "Epoch 10/15 | Train Loss: 0.3690 Acc: 0.8148\n",
      "Epoch 11/15 | Train Loss: 0.4001 Acc: 0.7912\n",
      "Epoch 12/15 | Train Loss: 0.3701 Acc: 0.8114\n",
      "Epoch 13/15 | Train Loss: 0.3900 Acc: 0.7946\n",
      "Epoch 14/15 | Train Loss: 0.3601 Acc: 0.8215\n",
      "Epoch 15/15 | Train Loss: 0.3856 Acc: 0.7912\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6257 Acc: 0.7452\n",
      "Epoch 2/15 | Train Loss: 0.4898 Acc: 0.7757\n",
      "Epoch 3/15 | Train Loss: 0.4715 Acc: 0.7833\n",
      "Epoch 4/15 | Train Loss: 0.4962 Acc: 0.7490\n",
      "Epoch 5/15 | Train Loss: 0.4535 Acc: 0.8137\n",
      "Epoch 6/15 | Train Loss: 0.4159 Acc: 0.8175\n",
      "Epoch 7/15 | Train Loss: 0.4141 Acc: 0.8061\n",
      "Epoch 8/15 | Train Loss: 0.3982 Acc: 0.8099\n",
      "Epoch 9/15 | Train Loss: 0.3745 Acc: 0.8175\n",
      "Epoch 10/15 | Train Loss: 0.3809 Acc: 0.8327\n",
      "Epoch 11/15 | Train Loss: 0.3589 Acc: 0.8327\n",
      "Epoch 12/15 | Train Loss: 0.3742 Acc: 0.8403\n",
      "Epoch 13/15 | Train Loss: 0.4162 Acc: 0.7757\n",
      "Epoch 14/15 | Train Loss: 0.3774 Acc: 0.8175\n",
      "Epoch 15/15 | Train Loss: 0.3935 Acc: 0.8327\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5344 Acc: 0.7683\n",
      "Epoch 2/15 | Train Loss: 0.4103 Acc: 0.8537\n",
      "Epoch 3/15 | Train Loss: 0.4218 Acc: 0.8415\n",
      "Epoch 4/15 | Train Loss: 0.4141 Acc: 0.8333\n",
      "Epoch 5/15 | Train Loss: 0.4281 Acc: 0.8211\n",
      "Epoch 6/15 | Train Loss: 0.3859 Acc: 0.8537\n",
      "Epoch 7/15 | Train Loss: 0.3060 Acc: 0.8821\n",
      "Epoch 8/15 | Train Loss: 0.3284 Acc: 0.8943\n",
      "Epoch 9/15 | Train Loss: 0.2850 Acc: 0.8902\n",
      "Epoch 10/15 | Train Loss: 0.3102 Acc: 0.8902\n",
      "Epoch 11/15 | Train Loss: 0.3156 Acc: 0.8821\n",
      "Epoch 12/15 | Train Loss: 0.2901 Acc: 0.8943\n",
      "Epoch 13/15 | Train Loss: 0.2907 Acc: 0.9024\n",
      "Epoch 14/15 | Train Loss: 0.2884 Acc: 0.8943\n",
      "Epoch 15/15 | Train Loss: 0.2972 Acc: 0.9024\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7056 Acc: 0.5731\n",
      "Epoch 2/15 | Train Loss: 0.5882 Acc: 0.7115\n",
      "Epoch 3/15 | Train Loss: 0.5289 Acc: 0.7115\n",
      "Epoch 4/15 | Train Loss: 0.5305 Acc: 0.7075\n",
      "Epoch 5/15 | Train Loss: 0.4491 Acc: 0.7866\n",
      "Epoch 6/15 | Train Loss: 0.4619 Acc: 0.7668\n",
      "Epoch 7/15 | Train Loss: 0.4232 Acc: 0.8182\n",
      "Epoch 8/15 | Train Loss: 0.4730 Acc: 0.7668\n",
      "Epoch 9/15 | Train Loss: 0.4195 Acc: 0.8024\n",
      "Epoch 10/15 | Train Loss: 0.4038 Acc: 0.7984\n",
      "Epoch 11/15 | Train Loss: 0.3705 Acc: 0.8182\n",
      "Epoch 12/15 | Train Loss: 0.3834 Acc: 0.8261\n",
      "Epoch 13/15 | Train Loss: 0.3703 Acc: 0.8340\n",
      "Epoch 14/15 | Train Loss: 0.3867 Acc: 0.8063\n",
      "Epoch 15/15 | Train Loss: 0.3776 Acc: 0.8577\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7354 Acc: 0.6403\n",
      "Epoch 2/15 | Train Loss: 0.6127 Acc: 0.6917\n",
      "Epoch 3/15 | Train Loss: 0.5308 Acc: 0.7233\n",
      "Epoch 4/15 | Train Loss: 0.5722 Acc: 0.7075\n",
      "Epoch 5/15 | Train Loss: 0.5031 Acc: 0.7233\n",
      "Epoch 6/15 | Train Loss: 0.5255 Acc: 0.7312\n",
      "Epoch 7/15 | Train Loss: 0.4303 Acc: 0.8063\n",
      "Epoch 8/15 | Train Loss: 0.5154 Acc: 0.7549\n",
      "Epoch 9/15 | Train Loss: 0.4391 Acc: 0.7905\n",
      "Epoch 10/15 | Train Loss: 0.4430 Acc: 0.7826\n",
      "Epoch 11/15 | Train Loss: 0.4295 Acc: 0.7708\n",
      "Epoch 12/15 | Train Loss: 0.4663 Acc: 0.7826\n",
      "Epoch 13/15 | Train Loss: 0.4166 Acc: 0.7787\n",
      "Epoch 14/15 | Train Loss: 0.4640 Acc: 0.7826\n",
      "Epoch 15/15 | Train Loss: 0.4224 Acc: 0.7984\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7249 Acc: 0.6324\n",
      "Epoch 2/15 | Train Loss: 0.6079 Acc: 0.6917\n",
      "Epoch 3/15 | Train Loss: 0.5946 Acc: 0.6798\n",
      "Epoch 4/15 | Train Loss: 0.5389 Acc: 0.7431\n",
      "Epoch 5/15 | Train Loss: 0.5460 Acc: 0.7352\n",
      "Epoch 6/15 | Train Loss: 0.5166 Acc: 0.7391\n",
      "Epoch 7/15 | Train Loss: 0.4416 Acc: 0.7747\n",
      "Epoch 8/15 | Train Loss: 0.4693 Acc: 0.7866\n",
      "Epoch 9/15 | Train Loss: 0.4571 Acc: 0.7628\n",
      "Epoch 10/15 | Train Loss: 0.4254 Acc: 0.7787\n",
      "Epoch 11/15 | Train Loss: 0.4030 Acc: 0.8103\n",
      "Epoch 12/15 | Train Loss: 0.4570 Acc: 0.7668\n",
      "Epoch 13/15 | Train Loss: 0.4429 Acc: 0.7668\n",
      "Epoch 14/15 | Train Loss: 0.4085 Acc: 0.8024\n",
      "Epoch 15/15 | Train Loss: 0.4012 Acc: 0.7905\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7731 Acc: 0.5696\n",
      "Epoch 2/15 | Train Loss: 0.6096 Acc: 0.7637\n",
      "Epoch 3/15 | Train Loss: 0.5513 Acc: 0.7384\n",
      "Epoch 4/15 | Train Loss: 0.5291 Acc: 0.7553\n",
      "Epoch 5/15 | Train Loss: 0.5746 Acc: 0.7679\n",
      "Epoch 6/15 | Train Loss: 0.4885 Acc: 0.7848\n",
      "Epoch 7/15 | Train Loss: 0.4961 Acc: 0.7975\n",
      "Epoch 8/15 | Train Loss: 0.4740 Acc: 0.7764\n",
      "Epoch 9/15 | Train Loss: 0.4542 Acc: 0.7890\n",
      "Epoch 10/15 | Train Loss: 0.4177 Acc: 0.7932\n",
      "Epoch 11/15 | Train Loss: 0.4352 Acc: 0.7764\n",
      "Epoch 12/15 | Train Loss: 0.4307 Acc: 0.7848\n",
      "Epoch 13/15 | Train Loss: 0.4737 Acc: 0.7975\n",
      "Epoch 14/15 | Train Loss: 0.4391 Acc: 0.7932\n",
      "Epoch 15/15 | Train Loss: 0.4286 Acc: 0.7975\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5536 Acc: 0.7675\n",
      "Epoch 2/15 | Train Loss: 0.4662 Acc: 0.8026\n",
      "Epoch 3/15 | Train Loss: 0.4133 Acc: 0.8333\n",
      "Epoch 4/15 | Train Loss: 0.3874 Acc: 0.8553\n",
      "Epoch 5/15 | Train Loss: 0.3746 Acc: 0.8509\n",
      "Epoch 6/15 | Train Loss: 0.4183 Acc: 0.8333\n",
      "Epoch 7/15 | Train Loss: 0.3621 Acc: 0.8596\n",
      "Epoch 8/15 | Train Loss: 0.3461 Acc: 0.8596\n",
      "Epoch 9/15 | Train Loss: 0.3092 Acc: 0.8904\n",
      "Epoch 10/15 | Train Loss: 0.3471 Acc: 0.8728\n",
      "Epoch 11/15 | Train Loss: 0.2945 Acc: 0.8816\n",
      "Epoch 12/15 | Train Loss: 0.2959 Acc: 0.8904\n",
      "Epoch 13/15 | Train Loss: 0.2789 Acc: 0.8772\n",
      "Epoch 14/15 | Train Loss: 0.3135 Acc: 0.8772\n",
      "Epoch 15/15 | Train Loss: 0.2752 Acc: 0.8947\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5033 Acc: 0.7708\n",
      "Epoch 2/15 | Train Loss: 0.4337 Acc: 0.7708\n",
      "Epoch 3/15 | Train Loss: 0.3754 Acc: 0.7760\n",
      "Epoch 4/15 | Train Loss: 0.3594 Acc: 0.8047\n",
      "Epoch 5/15 | Train Loss: 0.3498 Acc: 0.8073\n",
      "Epoch 6/15 | Train Loss: 0.3079 Acc: 0.8542\n",
      "Epoch 7/15 | Train Loss: 0.3393 Acc: 0.8229\n",
      "Epoch 8/15 | Train Loss: 0.2830 Acc: 0.8828\n",
      "Epoch 9/15 | Train Loss: 0.2705 Acc: 0.8698\n",
      "Epoch 10/15 | Train Loss: 0.2787 Acc: 0.8620\n",
      "Epoch 11/15 | Train Loss: 0.2593 Acc: 0.8750\n",
      "Epoch 12/15 | Train Loss: 0.2478 Acc: 0.8802\n",
      "Epoch 13/15 | Train Loss: 0.2468 Acc: 0.8776\n",
      "Epoch 14/15 | Train Loss: 0.2859 Acc: 0.8516\n",
      "Epoch 15/15 | Train Loss: 0.2534 Acc: 0.8854\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5702 Acc: 0.6927\n",
      "Epoch 2/15 | Train Loss: 0.4314 Acc: 0.7526\n",
      "Epoch 3/15 | Train Loss: 0.3650 Acc: 0.7995\n",
      "Epoch 4/15 | Train Loss: 0.3959 Acc: 0.7656\n",
      "Epoch 5/15 | Train Loss: 0.4022 Acc: 0.7656\n",
      "Epoch 6/15 | Train Loss: 0.3474 Acc: 0.8177\n",
      "Epoch 7/15 | Train Loss: 0.3242 Acc: 0.8125\n",
      "Epoch 8/15 | Train Loss: 0.3166 Acc: 0.8281\n",
      "Epoch 9/15 | Train Loss: 0.3072 Acc: 0.8542\n",
      "Epoch 10/15 | Train Loss: 0.3230 Acc: 0.8359\n",
      "Epoch 11/15 | Train Loss: 0.3048 Acc: 0.8464\n",
      "Epoch 12/15 | Train Loss: 0.2964 Acc: 0.8750\n",
      "Epoch 13/15 | Train Loss: 0.3240 Acc: 0.8255\n",
      "Epoch 14/15 | Train Loss: 0.2926 Acc: 0.8542\n",
      "Epoch 15/15 | Train Loss: 0.2782 Acc: 0.8750\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.7671 Acc: 0.7474\n",
      "Epoch 2/15 | Train Loss: 0.4337 Acc: 0.8021\n",
      "Epoch 3/15 | Train Loss: 0.4108 Acc: 0.7839\n",
      "Epoch 4/15 | Train Loss: 0.3788 Acc: 0.8073\n",
      "Epoch 5/15 | Train Loss: 0.3426 Acc: 0.8359\n",
      "Epoch 6/15 | Train Loss: 0.3973 Acc: 0.7630\n",
      "Epoch 7/15 | Train Loss: 0.3564 Acc: 0.8047\n",
      "Epoch 8/15 | Train Loss: 0.3333 Acc: 0.8490\n",
      "Epoch 9/15 | Train Loss: 0.3303 Acc: 0.8333\n",
      "Epoch 10/15 | Train Loss: 0.3105 Acc: 0.8516\n",
      "Epoch 11/15 | Train Loss: 0.2778 Acc: 0.8750\n",
      "Epoch 12/15 | Train Loss: 0.2800 Acc: 0.8750\n",
      "Epoch 13/15 | Train Loss: 0.2878 Acc: 0.8672\n",
      "Epoch 14/15 | Train Loss: 0.2841 Acc: 0.8516\n",
      "Epoch 15/15 | Train Loss: 0.3167 Acc: 0.8438\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5492 Acc: 0.8127\n",
      "Epoch 2/15 | Train Loss: 0.4342 Acc: 0.8127\n",
      "Epoch 3/15 | Train Loss: 0.4262 Acc: 0.7905\n",
      "Epoch 4/15 | Train Loss: 0.3743 Acc: 0.8286\n",
      "Epoch 5/15 | Train Loss: 0.3598 Acc: 0.8413\n",
      "Epoch 6/15 | Train Loss: 0.3851 Acc: 0.8381\n",
      "Epoch 7/15 | Train Loss: 0.3405 Acc: 0.8540\n",
      "Epoch 8/15 | Train Loss: 0.3575 Acc: 0.8444\n",
      "Epoch 9/15 | Train Loss: 0.3483 Acc: 0.8413\n",
      "Epoch 10/15 | Train Loss: 0.3387 Acc: 0.8381\n",
      "Epoch 11/15 | Train Loss: 0.3152 Acc: 0.8413\n",
      "Epoch 12/15 | Train Loss: 0.3076 Acc: 0.8698\n",
      "Epoch 13/15 | Train Loss: 0.3111 Acc: 0.8508\n",
      "Epoch 14/15 | Train Loss: 0.3241 Acc: 0.8508\n",
      "Epoch 15/15 | Train Loss: 0.3229 Acc: 0.8635\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.4838 Acc: 0.8434\n",
      "Epoch 2/15 | Train Loss: 0.3852 Acc: 0.8505\n",
      "Epoch 3/15 | Train Loss: 0.3612 Acc: 0.8754\n",
      "Epoch 4/15 | Train Loss: 0.3236 Acc: 0.8754\n",
      "Epoch 5/15 | Train Loss: 0.3404 Acc: 0.8826\n",
      "Epoch 6/15 | Train Loss: 0.2917 Acc: 0.8968\n",
      "Epoch 7/15 | Train Loss: 0.2873 Acc: 0.8719\n",
      "Epoch 8/15 | Train Loss: 0.2893 Acc: 0.9075\n",
      "Epoch 9/15 | Train Loss: 0.2790 Acc: 0.9039\n",
      "Epoch 10/15 | Train Loss: 0.2599 Acc: 0.9146\n",
      "Epoch 11/15 | Train Loss: 0.2745 Acc: 0.8968\n",
      "Epoch 12/15 | Train Loss: 0.2472 Acc: 0.9004\n",
      "Epoch 13/15 | Train Loss: 0.2398 Acc: 0.9146\n",
      "Epoch 14/15 | Train Loss: 0.2316 Acc: 0.9075\n",
      "Epoch 15/15 | Train Loss: 0.2289 Acc: 0.9004\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7700 Acc: 0.6403\n",
      "Epoch 2/15 | Train Loss: 0.6530 Acc: 0.6561\n",
      "Epoch 3/15 | Train Loss: 0.5898 Acc: 0.7075\n",
      "Epoch 4/15 | Train Loss: 0.5341 Acc: 0.7115\n",
      "Epoch 5/15 | Train Loss: 0.5148 Acc: 0.7431\n",
      "Epoch 6/15 | Train Loss: 0.4876 Acc: 0.7668\n",
      "Epoch 7/15 | Train Loss: 0.4670 Acc: 0.7549\n",
      "Epoch 8/15 | Train Loss: 0.3844 Acc: 0.8024\n",
      "Epoch 9/15 | Train Loss: 0.4781 Acc: 0.7787\n",
      "Epoch 10/15 | Train Loss: 0.4155 Acc: 0.7945\n",
      "Epoch 11/15 | Train Loss: 0.4046 Acc: 0.8063\n",
      "Epoch 12/15 | Train Loss: 0.3632 Acc: 0.8221\n",
      "Epoch 13/15 | Train Loss: 0.3694 Acc: 0.8261\n",
      "Epoch 14/15 | Train Loss: 0.3768 Acc: 0.8142\n",
      "Epoch 15/15 | Train Loss: 0.3797 Acc: 0.8261\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7366 Acc: 0.5692\n",
      "Epoch 2/15 | Train Loss: 0.6051 Acc: 0.6561\n",
      "Epoch 3/15 | Train Loss: 0.5767 Acc: 0.6640\n",
      "Epoch 4/15 | Train Loss: 0.5410 Acc: 0.7115\n",
      "Epoch 5/15 | Train Loss: 0.5360 Acc: 0.6877\n",
      "Epoch 6/15 | Train Loss: 0.5223 Acc: 0.7154\n",
      "Epoch 7/15 | Train Loss: 0.4921 Acc: 0.7391\n",
      "Epoch 8/15 | Train Loss: 0.4644 Acc: 0.7510\n",
      "Epoch 9/15 | Train Loss: 0.3917 Acc: 0.8142\n",
      "Epoch 10/15 | Train Loss: 0.5083 Acc: 0.7470\n",
      "Epoch 11/15 | Train Loss: 0.4554 Acc: 0.7787\n",
      "Epoch 12/15 | Train Loss: 0.4286 Acc: 0.7826\n",
      "Epoch 13/15 | Train Loss: 0.4146 Acc: 0.7945\n",
      "Epoch 14/15 | Train Loss: 0.3895 Acc: 0.8300\n",
      "Epoch 15/15 | Train Loss: 0.3964 Acc: 0.8142\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7519 Acc: 0.6245\n",
      "Epoch 2/15 | Train Loss: 0.6509 Acc: 0.6364\n",
      "Epoch 3/15 | Train Loss: 0.6427 Acc: 0.6364\n",
      "Epoch 4/15 | Train Loss: 0.5843 Acc: 0.6759\n",
      "Epoch 5/15 | Train Loss: 0.5495 Acc: 0.6680\n",
      "Epoch 6/15 | Train Loss: 0.5104 Acc: 0.7352\n",
      "Epoch 7/15 | Train Loss: 0.5243 Acc: 0.6877\n",
      "Epoch 8/15 | Train Loss: 0.4809 Acc: 0.7708\n",
      "Epoch 9/15 | Train Loss: 0.4342 Acc: 0.7787\n",
      "Epoch 10/15 | Train Loss: 0.4350 Acc: 0.7945\n",
      "Epoch 11/15 | Train Loss: 0.4775 Acc: 0.7391\n",
      "Epoch 12/15 | Train Loss: 0.4420 Acc: 0.7984\n",
      "Epoch 13/15 | Train Loss: 0.4221 Acc: 0.8024\n",
      "Epoch 14/15 | Train Loss: 0.4370 Acc: 0.7787\n",
      "Epoch 15/15 | Train Loss: 0.4323 Acc: 0.7984\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6457 Acc: 0.6709\n",
      "Epoch 2/15 | Train Loss: 0.5371 Acc: 0.7637\n",
      "Epoch 3/15 | Train Loss: 0.5486 Acc: 0.7679\n",
      "Epoch 4/15 | Train Loss: 0.5004 Acc: 0.7637\n",
      "Epoch 5/15 | Train Loss: 0.4665 Acc: 0.8101\n",
      "Epoch 6/15 | Train Loss: 0.5193 Acc: 0.7511\n",
      "Epoch 7/15 | Train Loss: 0.4543 Acc: 0.8017\n",
      "Epoch 8/15 | Train Loss: 0.4896 Acc: 0.7890\n",
      "Epoch 9/15 | Train Loss: 0.4285 Acc: 0.8143\n",
      "Epoch 10/15 | Train Loss: 0.4562 Acc: 0.8101\n",
      "Epoch 11/15 | Train Loss: 0.3853 Acc: 0.8397\n",
      "Epoch 12/15 | Train Loss: 0.4065 Acc: 0.8059\n",
      "Epoch 13/15 | Train Loss: 0.4374 Acc: 0.7975\n",
      "Epoch 14/15 | Train Loss: 0.4441 Acc: 0.7932\n",
      "Epoch 15/15 | Train Loss: 0.4123 Acc: 0.7932\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5218 Acc: 0.7588\n",
      "Epoch 2/15 | Train Loss: 0.4820 Acc: 0.8070\n",
      "Epoch 3/15 | Train Loss: 0.4698 Acc: 0.7851\n",
      "Epoch 4/15 | Train Loss: 0.4117 Acc: 0.8246\n",
      "Epoch 5/15 | Train Loss: 0.4079 Acc: 0.8509\n",
      "Epoch 6/15 | Train Loss: 0.3451 Acc: 0.8640\n",
      "Epoch 7/15 | Train Loss: 0.3688 Acc: 0.8509\n",
      "Epoch 8/15 | Train Loss: 0.3394 Acc: 0.8684\n",
      "Epoch 9/15 | Train Loss: 0.3509 Acc: 0.8640\n",
      "Epoch 10/15 | Train Loss: 0.2813 Acc: 0.8816\n",
      "Epoch 11/15 | Train Loss: 0.3345 Acc: 0.8816\n",
      "Epoch 12/15 | Train Loss: 0.2845 Acc: 0.9035\n",
      "Epoch 13/15 | Train Loss: 0.2901 Acc: 0.8860\n",
      "Epoch 14/15 | Train Loss: 0.2891 Acc: 0.8860\n",
      "Epoch 15/15 | Train Loss: 0.3272 Acc: 0.8816\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.4942 Acc: 0.7643\n",
      "Epoch 2/15 | Train Loss: 0.3972 Acc: 0.7918\n",
      "Epoch 3/15 | Train Loss: 0.3773 Acc: 0.8078\n",
      "Epoch 4/15 | Train Loss: 0.4212 Acc: 0.7780\n",
      "Epoch 5/15 | Train Loss: 0.3586 Acc: 0.8192\n",
      "Epoch 6/15 | Train Loss: 0.3591 Acc: 0.8215\n",
      "Epoch 7/15 | Train Loss: 0.3647 Acc: 0.8261\n",
      "Epoch 8/15 | Train Loss: 0.3168 Acc: 0.8581\n",
      "Epoch 9/15 | Train Loss: 0.3150 Acc: 0.8490\n",
      "Epoch 10/15 | Train Loss: 0.3032 Acc: 0.8558\n",
      "Epoch 11/15 | Train Loss: 0.3145 Acc: 0.8352\n",
      "Epoch 12/15 | Train Loss: 0.3057 Acc: 0.8558\n",
      "Epoch 13/15 | Train Loss: 0.2925 Acc: 0.8787\n",
      "Epoch 14/15 | Train Loss: 0.2979 Acc: 0.8673\n",
      "Epoch 15/15 | Train Loss: 0.2825 Acc: 0.8650\n",
      "Fold 5 Test Accuracy: 0.6020\n",
      "===== Fold 6 =====\n",
      "Epoch 1: Generator Loss = 9.8455, Discriminator Loss = 8.9545\n",
      "Epoch 2: Generator Loss = 11.2567, Discriminator Loss = 7.5655\n",
      "Epoch 3: Generator Loss = 14.0504, Discriminator Loss = 6.6251\n",
      "Epoch 4: Generator Loss = 20.5567, Discriminator Loss = 4.5125\n",
      "Epoch 5: Generator Loss = 28.7053, Discriminator Loss = 3.9463\n",
      "Epoch 6: Generator Loss = 30.8618, Discriminator Loss = 5.7373\n",
      "Epoch 7: Generator Loss = 30.1257, Discriminator Loss = 4.7496\n",
      "Epoch 8: Generator Loss = 31.1952, Discriminator Loss = 6.3207\n",
      "Epoch 9: Generator Loss = 29.5499, Discriminator Loss = 5.6930\n",
      "Epoch 10: Generator Loss = 26.8598, Discriminator Loss = 6.0132\n",
      "Epoch 11: Generator Loss = 30.1101, Discriminator Loss = 5.2516\n",
      "Epoch 12: Generator Loss = 31.7225, Discriminator Loss = 6.9956\n",
      "Epoch 13: Generator Loss = 24.4232, Discriminator Loss = 5.8610\n",
      "Epoch 14: Generator Loss = 27.8197, Discriminator Loss = 8.2275\n",
      "Epoch 15: Generator Loss = 24.2730, Discriminator Loss = 8.3876\n",
      "Epoch 16: Generator Loss = 21.3040, Discriminator Loss = 8.1020\n",
      "Epoch 17: Generator Loss = 21.2473, Discriminator Loss = 6.3763\n",
      "Epoch 18: Generator Loss = 24.5864, Discriminator Loss = 8.1789\n",
      "Epoch 19: Generator Loss = 19.9437, Discriminator Loss = 5.9581\n",
      "Epoch 20: Generator Loss = 27.6077, Discriminator Loss = 5.6368\n",
      "Epoch 21: Generator Loss = 23.0861, Discriminator Loss = 7.2982\n",
      "Epoch 22: Generator Loss = 20.9001, Discriminator Loss = 9.3098\n",
      "Epoch 23: Generator Loss = 16.5484, Discriminator Loss = 7.6783\n",
      "Epoch 24: Generator Loss = 21.4084, Discriminator Loss = 8.1540\n",
      "Epoch 25: Generator Loss = 17.4782, Discriminator Loss = 7.7156\n",
      "Epoch 26: Generator Loss = 18.6638, Discriminator Loss = 7.5910\n",
      "Epoch 27: Generator Loss = 20.1368, Discriminator Loss = 7.6299\n",
      "Epoch 28: Generator Loss = 23.1604, Discriminator Loss = 7.0715\n",
      "Epoch 29: Generator Loss = 19.5818, Discriminator Loss = 7.1534\n",
      "Epoch 30: Generator Loss = 21.6598, Discriminator Loss = 7.6816\n",
      "Epoch 31: Generator Loss = 21.6146, Discriminator Loss = 8.3383\n",
      "Epoch 32: Generator Loss = 15.7393, Discriminator Loss = 8.4411\n",
      "Epoch 33: Generator Loss = 18.3376, Discriminator Loss = 6.6708\n",
      "Epoch 34: Generator Loss = 26.1517, Discriminator Loss = 6.3174\n",
      "Epoch 35: Generator Loss = 19.5321, Discriminator Loss = 8.4061\n",
      "Epoch 36: Generator Loss = 25.3150, Discriminator Loss = 9.1025\n",
      "Epoch 37: Generator Loss = 19.8818, Discriminator Loss = 8.9133\n",
      "Epoch 38: Generator Loss = 16.7583, Discriminator Loss = 8.5302\n",
      "Epoch 39: Generator Loss = 18.6405, Discriminator Loss = 7.6354\n",
      "Epoch 40: Generator Loss = 20.4764, Discriminator Loss = 8.2739\n",
      "Epoch 41: Generator Loss = 16.1264, Discriminator Loss = 8.4520\n",
      "Epoch 42: Generator Loss = 18.2648, Discriminator Loss = 8.2295\n",
      "Epoch 43: Generator Loss = 18.4843, Discriminator Loss = 6.0740\n",
      "Epoch 44: Generator Loss = 19.5121, Discriminator Loss = 9.4476\n",
      "Epoch 45: Generator Loss = 18.1617, Discriminator Loss = 7.6227\n",
      "Epoch 46: Generator Loss = 16.9126, Discriminator Loss = 7.1575\n",
      "Epoch 47: Generator Loss = 21.0166, Discriminator Loss = 5.7955\n",
      "Epoch 48: Generator Loss = 23.3669, Discriminator Loss = 6.5269\n",
      "Epoch 49: Generator Loss = 28.5975, Discriminator Loss = 6.4283\n",
      "Epoch 50: Generator Loss = 22.6312, Discriminator Loss = 6.4881\n",
      "Epoch 51: Generator Loss = 22.0088, Discriminator Loss = 6.1135\n",
      "Epoch 52: Generator Loss = 26.4758, Discriminator Loss = 7.6315\n",
      "Epoch 53: Generator Loss = 25.1107, Discriminator Loss = 5.7783\n",
      "Epoch 54: Generator Loss = 29.9586, Discriminator Loss = 4.9883\n",
      "Epoch 55: Generator Loss = 24.5608, Discriminator Loss = 5.2599\n",
      "Epoch 56: Generator Loss = 27.6671, Discriminator Loss = 4.3396\n",
      "Epoch 57: Generator Loss = 30.0163, Discriminator Loss = 3.7544\n",
      "Epoch 58: Generator Loss = 31.8079, Discriminator Loss = 4.3827\n",
      "Epoch 59: Generator Loss = 35.9633, Discriminator Loss = 3.1114\n",
      "Epoch 60: Generator Loss = 43.7636, Discriminator Loss = 4.1293\n",
      "Epoch 61: Generator Loss = 27.4347, Discriminator Loss = 7.1696\n",
      "Epoch 62: Generator Loss = 30.9029, Discriminator Loss = 4.0725\n",
      "Epoch 63: Generator Loss = 37.7845, Discriminator Loss = 2.8079\n",
      "Epoch 64: Generator Loss = 29.5079, Discriminator Loss = 5.8441\n",
      "Epoch 65: Generator Loss = 37.3134, Discriminator Loss = 2.7292\n",
      "Epoch 66: Generator Loss = 29.9396, Discriminator Loss = 2.7791\n",
      "Epoch 67: Generator Loss = 41.0523, Discriminator Loss = 1.9724\n",
      "Epoch 68: Generator Loss = 40.7103, Discriminator Loss = 2.0198\n",
      "Epoch 69: Generator Loss = 54.2925, Discriminator Loss = 4.9929\n",
      "Epoch 70: Generator Loss = 53.8568, Discriminator Loss = 2.9132\n",
      "Epoch 71: Generator Loss = 36.9659, Discriminator Loss = 6.4267\n",
      "Epoch 72: Generator Loss = 46.6165, Discriminator Loss = 3.3402\n",
      "Epoch 73: Generator Loss = 39.5361, Discriminator Loss = 2.1120\n",
      "Epoch 74: Generator Loss = 58.6511, Discriminator Loss = 1.3665\n",
      "Epoch 75: Generator Loss = 52.1927, Discriminator Loss = 1.1992\n",
      "Epoch 76: Generator Loss = 41.0890, Discriminator Loss = 3.4210\n",
      "Epoch 77: Generator Loss = 46.8892, Discriminator Loss = 4.2663\n",
      "Epoch 78: Generator Loss = 46.0763, Discriminator Loss = 1.7842\n",
      "Epoch 79: Generator Loss = 60.9618, Discriminator Loss = 1.7659\n",
      "Epoch 80: Generator Loss = 49.5310, Discriminator Loss = 1.0163\n",
      "Epoch 81: Generator Loss = 61.2966, Discriminator Loss = 2.0884\n",
      "Epoch 82: Generator Loss = 53.6376, Discriminator Loss = 1.6390\n",
      "Epoch 83: Generator Loss = 57.6285, Discriminator Loss = 1.5326\n",
      "Epoch 84: Generator Loss = 50.9181, Discriminator Loss = 2.5642\n",
      "Epoch 85: Generator Loss = 71.0089, Discriminator Loss = 4.8443\n",
      "Epoch 86: Generator Loss = 54.0196, Discriminator Loss = 1.1552\n",
      "Epoch 87: Generator Loss = 54.6115, Discriminator Loss = 1.4309\n",
      "Epoch 88: Generator Loss = 72.5700, Discriminator Loss = 0.8443\n",
      "Epoch 89: Generator Loss = 70.5795, Discriminator Loss = 0.7622\n",
      "Epoch 90: Generator Loss = 66.2782, Discriminator Loss = 1.0490\n",
      "Epoch 91: Generator Loss = 72.9620, Discriminator Loss = 0.3774\n",
      "Epoch 92: Generator Loss = 82.9696, Discriminator Loss = 0.7023\n",
      "Epoch 93: Generator Loss = 142.3973, Discriminator Loss = 3.2489\n",
      "Epoch 94: Generator Loss = 190.7125, Discriminator Loss = 5.5941\n",
      "Epoch 95: Generator Loss = 177.5531, Discriminator Loss = 0.8168\n",
      "Epoch 96: Generator Loss = 142.0710, Discriminator Loss = 0.1715\n",
      "Epoch 97: Generator Loss = 107.5708, Discriminator Loss = 0.3203\n",
      "Epoch 98: Generator Loss = 96.7976, Discriminator Loss = 8.8716\n",
      "Epoch 99: Generator Loss = 102.7142, Discriminator Loss = 0.9913\n",
      "Epoch 100: Generator Loss = 97.2211, Discriminator Loss = 0.7517\n",
      "Epoch 101: Generator Loss = 86.7472, Discriminator Loss = 0.9504\n",
      "Epoch 102: Generator Loss = 77.7589, Discriminator Loss = 0.4135\n",
      "Epoch 103: Generator Loss = 61.5793, Discriminator Loss = 1.1893\n",
      "Epoch 104: Generator Loss = 73.4704, Discriminator Loss = 1.0513\n",
      "Epoch 105: Generator Loss = 78.5207, Discriminator Loss = 0.9013\n",
      "Epoch 106: Generator Loss = 77.7038, Discriminator Loss = 2.0622\n",
      "Epoch 107: Generator Loss = 72.3750, Discriminator Loss = 4.0645\n",
      "Epoch 108: Generator Loss = 72.3974, Discriminator Loss = 0.9253\n",
      "Epoch 109: Generator Loss = 87.0307, Discriminator Loss = 1.2134\n",
      "Epoch 110: Generator Loss = 81.0115, Discriminator Loss = 0.6684\n",
      "Epoch 111: Generator Loss = 83.2394, Discriminator Loss = 0.6211\n",
      "Epoch 112: Generator Loss = 85.7124, Discriminator Loss = 0.5145\n",
      "Epoch 113: Generator Loss = 74.7360, Discriminator Loss = 1.5134\n",
      "Epoch 114: Generator Loss = 91.0753, Discriminator Loss = 0.6799\n",
      "Epoch 115: Generator Loss = 72.4751, Discriminator Loss = 0.6005\n",
      "Epoch 116: Generator Loss = 78.6330, Discriminator Loss = 0.5839\n",
      "Epoch 117: Generator Loss = 70.6636, Discriminator Loss = 0.4217\n",
      "Epoch 118: Generator Loss = 71.0112, Discriminator Loss = 0.9007\n",
      "Epoch 119: Generator Loss = 74.6050, Discriminator Loss = 0.7867\n",
      "Epoch 120: Generator Loss = 79.2145, Discriminator Loss = 0.8614\n",
      "Epoch 121: Generator Loss = 75.0487, Discriminator Loss = 0.6344\n",
      "Epoch 122: Generator Loss = 83.9731, Discriminator Loss = 0.5313\n",
      "Epoch 123: Generator Loss = 80.2972, Discriminator Loss = 0.9039\n",
      "Epoch 124: Generator Loss = 77.6327, Discriminator Loss = 0.7466\n",
      "Epoch 125: Generator Loss = 72.0655, Discriminator Loss = 0.4150\n",
      "Epoch 126: Generator Loss = 80.8775, Discriminator Loss = 0.5477\n",
      "Epoch 127: Generator Loss = 65.9487, Discriminator Loss = 0.7995\n",
      "Epoch 128: Generator Loss = 65.8525, Discriminator Loss = 0.5891\n",
      "Epoch 129: Generator Loss = 79.0921, Discriminator Loss = 1.3378\n",
      "Epoch 130: Generator Loss = 85.6396, Discriminator Loss = 0.6933\n",
      "Epoch 131: Generator Loss = 82.7136, Discriminator Loss = 0.6037\n",
      "Epoch 132: Generator Loss = 67.8355, Discriminator Loss = 1.0187\n",
      "Epoch 133: Generator Loss = 75.8080, Discriminator Loss = 0.9588\n",
      "Epoch 134: Generator Loss = 86.5815, Discriminator Loss = 0.6577\n",
      "Epoch 135: Generator Loss = 90.9648, Discriminator Loss = 0.5264\n",
      "Epoch 136: Generator Loss = 75.0651, Discriminator Loss = 0.6968\n",
      "Epoch 137: Generator Loss = 82.3171, Discriminator Loss = 2.9587\n",
      "Epoch 138: Generator Loss = 69.4870, Discriminator Loss = 1.1243\n",
      "Epoch 139: Generator Loss = 68.6609, Discriminator Loss = 0.8052\n",
      "Epoch 140: Generator Loss = 74.4960, Discriminator Loss = 0.5511\n",
      "Epoch 141: Generator Loss = 80.7201, Discriminator Loss = 0.9031\n",
      "Epoch 142: Generator Loss = 72.3668, Discriminator Loss = 0.7093\n",
      "Epoch 143: Generator Loss = 73.2553, Discriminator Loss = 0.7214\n",
      "Epoch 144: Generator Loss = 80.1702, Discriminator Loss = 0.7210\n",
      "Epoch 145: Generator Loss = 79.0951, Discriminator Loss = 1.1281\n",
      "Epoch 146: Generator Loss = 108.3090, Discriminator Loss = 0.4124\n",
      "Epoch 147: Generator Loss = 129.2357, Discriminator Loss = 0.3846\n",
      "Epoch 148: Generator Loss = 117.0036, Discriminator Loss = 0.3432\n",
      "Epoch 149: Generator Loss = 134.7312, Discriminator Loss = 1.1656\n",
      "Epoch 150: Generator Loss = 96.3479, Discriminator Loss = 0.2010\n",
      "Epoch 151: Generator Loss = 112.6535, Discriminator Loss = 0.2990\n",
      "Epoch 152: Generator Loss = 90.5342, Discriminator Loss = 0.1517\n",
      "Epoch 153: Generator Loss = 122.8832, Discriminator Loss = 0.4634\n",
      "Epoch 154: Generator Loss = 100.7691, Discriminator Loss = 0.1230\n",
      "Epoch 155: Generator Loss = 98.6875, Discriminator Loss = 0.0761\n",
      "Epoch 156: Generator Loss = 89.5046, Discriminator Loss = 0.0979\n",
      "Epoch 157: Generator Loss = 90.9564, Discriminator Loss = 0.1684\n",
      "Epoch 158: Generator Loss = 82.9310, Discriminator Loss = 0.1170\n",
      "Epoch 159: Generator Loss = 79.5146, Discriminator Loss = 0.1907\n",
      "Epoch 160: Generator Loss = 90.2851, Discriminator Loss = 0.0668\n",
      "Epoch 161: Generator Loss = 111.7896, Discriminator Loss = 0.0562\n",
      "Epoch 162: Generator Loss = 85.1829, Discriminator Loss = 0.1341\n",
      "Epoch 163: Generator Loss = 102.9524, Discriminator Loss = 0.0350\n",
      "Epoch 164: Generator Loss = 103.4054, Discriminator Loss = 0.0279\n",
      "Epoch 165: Generator Loss = 92.6340, Discriminator Loss = 0.0838\n",
      "Epoch 166: Generator Loss = 84.1590, Discriminator Loss = 0.1253\n",
      "Epoch 167: Generator Loss = 104.7107, Discriminator Loss = 0.0775\n",
      "Epoch 168: Generator Loss = 100.6213, Discriminator Loss = 0.0806\n",
      "Epoch 169: Generator Loss = 104.8567, Discriminator Loss = 0.0432\n",
      "Epoch 170: Generator Loss = 102.6792, Discriminator Loss = 0.0529\n",
      "Epoch 171: Generator Loss = 104.2935, Discriminator Loss = 0.4267\n",
      "Epoch 172: Generator Loss = 88.9888, Discriminator Loss = 0.6209\n",
      "Epoch 173: Generator Loss = 96.4805, Discriminator Loss = 20.1451\n",
      "Epoch 174: Generator Loss = 61.9755, Discriminator Loss = 8.2224\n",
      "Epoch 175: Generator Loss = 61.0682, Discriminator Loss = 0.8875\n",
      "Epoch 176: Generator Loss = 81.0878, Discriminator Loss = 1.1620\n",
      "Epoch 177: Generator Loss = 73.9183, Discriminator Loss = 0.2941\n",
      "Epoch 178: Generator Loss = 82.3713, Discriminator Loss = 0.3077\n",
      "Epoch 179: Generator Loss = 82.3222, Discriminator Loss = 0.2343\n",
      "Epoch 180: Generator Loss = 83.8057, Discriminator Loss = 0.1837\n",
      "Epoch 181: Generator Loss = 86.2887, Discriminator Loss = 0.2416\n",
      "Epoch 182: Generator Loss = 82.4387, Discriminator Loss = 0.2846\n",
      "Epoch 183: Generator Loss = 143.6423, Discriminator Loss = 7.6630\n",
      "Epoch 184: Generator Loss = 102.9530, Discriminator Loss = 11.4707\n",
      "Epoch 185: Generator Loss = 73.6196, Discriminator Loss = 0.9945\n",
      "Epoch 186: Generator Loss = 66.1201, Discriminator Loss = 0.8766\n",
      "Epoch 187: Generator Loss = 83.6051, Discriminator Loss = 9.6471\n",
      "Epoch 188: Generator Loss = 70.4089, Discriminator Loss = 2.3475\n",
      "Epoch 189: Generator Loss = 66.8714, Discriminator Loss = 1.9625\n",
      "Epoch 190: Generator Loss = 66.1441, Discriminator Loss = 1.3355\n",
      "Epoch 191: Generator Loss = 70.8819, Discriminator Loss = 1.1987\n",
      "Epoch 192: Generator Loss = 72.1336, Discriminator Loss = 1.0931\n",
      "Epoch 193: Generator Loss = 65.2571, Discriminator Loss = 1.0506\n",
      "Epoch 194: Generator Loss = 61.0315, Discriminator Loss = 1.9323\n",
      "Epoch 195: Generator Loss = 68.3649, Discriminator Loss = 1.0146\n",
      "Epoch 196: Generator Loss = 60.1247, Discriminator Loss = 1.1125\n",
      "Epoch 197: Generator Loss = 54.9901, Discriminator Loss = 3.9815\n",
      "Epoch 198: Generator Loss = 62.9839, Discriminator Loss = 3.8636\n",
      "Epoch 199: Generator Loss = 55.6671, Discriminator Loss = 1.6821\n",
      "Epoch 200: Generator Loss = 55.6231, Discriminator Loss = 1.3135\n",
      "Epoch 201: Generator Loss = 59.7909, Discriminator Loss = 1.2010\n",
      "Epoch 202: Generator Loss = 64.3889, Discriminator Loss = 0.7489\n",
      "Epoch 203: Generator Loss = 65.3288, Discriminator Loss = 0.7853\n",
      "Epoch 204: Generator Loss = 63.6304, Discriminator Loss = 0.8871\n",
      "Epoch 205: Generator Loss = 74.3603, Discriminator Loss = 1.3588\n",
      "Epoch 206: Generator Loss = 60.9989, Discriminator Loss = 0.8442\n",
      "Epoch 207: Generator Loss = 61.7302, Discriminator Loss = 2.3502\n",
      "Epoch 208: Generator Loss = 78.2946, Discriminator Loss = 2.9160\n",
      "Epoch 209: Generator Loss = 53.8575, Discriminator Loss = 3.5227\n",
      "Epoch 210: Generator Loss = 60.5133, Discriminator Loss = 0.9441\n",
      "Epoch 211: Generator Loss = 57.7672, Discriminator Loss = 1.1891\n",
      "Epoch 212: Generator Loss = 84.7633, Discriminator Loss = 0.9558\n",
      "Epoch 213: Generator Loss = 61.4906, Discriminator Loss = 1.2094\n",
      "Epoch 214: Generator Loss = 70.1411, Discriminator Loss = 0.7437\n",
      "Epoch 215: Generator Loss = 83.3023, Discriminator Loss = 1.1305\n",
      "Epoch 216: Generator Loss = 77.5797, Discriminator Loss = 1.2259\n",
      "Epoch 217: Generator Loss = 67.7520, Discriminator Loss = 1.2305\n",
      "Epoch 218: Generator Loss = 85.5696, Discriminator Loss = 1.8146\n",
      "Epoch 219: Generator Loss = 72.3549, Discriminator Loss = 0.8356\n",
      "Epoch 220: Generator Loss = 76.9042, Discriminator Loss = 1.2232\n",
      "Epoch 221: Generator Loss = 96.4222, Discriminator Loss = 0.7207\n",
      "Epoch 222: Generator Loss = 80.7363, Discriminator Loss = 1.6912\n",
      "Epoch 223: Generator Loss = 70.4847, Discriminator Loss = 1.0537\n",
      "Epoch 224: Generator Loss = 75.8924, Discriminator Loss = 0.8397\n",
      "Epoch 225: Generator Loss = 77.7534, Discriminator Loss = 0.9326\n",
      "Epoch 226: Generator Loss = 82.5484, Discriminator Loss = 1.4251\n",
      "Epoch 227: Generator Loss = 71.1224, Discriminator Loss = 1.1684\n",
      "Epoch 228: Generator Loss = 94.9461, Discriminator Loss = 0.8533\n",
      "Epoch 229: Generator Loss = 79.0471, Discriminator Loss = 0.6685\n",
      "Epoch 230: Generator Loss = 72.0123, Discriminator Loss = 0.7313\n",
      "Epoch 231: Generator Loss = 67.1752, Discriminator Loss = 5.0465\n",
      "Epoch 232: Generator Loss = 67.4396, Discriminator Loss = 2.4032\n",
      "Epoch 233: Generator Loss = 55.4430, Discriminator Loss = 1.6311\n",
      "Epoch 234: Generator Loss = 68.5769, Discriminator Loss = 1.4051\n",
      "Epoch 235: Generator Loss = 67.4749, Discriminator Loss = 1.1399\n",
      "Epoch 236: Generator Loss = 68.9712, Discriminator Loss = 1.3174\n",
      "Epoch 237: Generator Loss = 73.2524, Discriminator Loss = 1.6401\n",
      "Epoch 238: Generator Loss = 79.6252, Discriminator Loss = 2.4878\n",
      "Epoch 239: Generator Loss = 79.4310, Discriminator Loss = 0.6824\n",
      "Epoch 240: Generator Loss = 75.9845, Discriminator Loss = 0.9665\n",
      "Epoch 241: Generator Loss = 62.8012, Discriminator Loss = 1.0327\n",
      "Epoch 242: Generator Loss = 65.9158, Discriminator Loss = 1.0999\n",
      "Epoch 243: Generator Loss = 66.1439, Discriminator Loss = 0.9072\n",
      "Epoch 244: Generator Loss = 66.8046, Discriminator Loss = 0.5368\n",
      "Epoch 245: Generator Loss = 81.7610, Discriminator Loss = 0.7577\n",
      "Epoch 246: Generator Loss = 69.8856, Discriminator Loss = 1.2309\n",
      "Epoch 247: Generator Loss = 74.1356, Discriminator Loss = 0.9072\n",
      "Epoch 248: Generator Loss = 70.4658, Discriminator Loss = 0.4787\n",
      "Epoch 249: Generator Loss = 102.9804, Discriminator Loss = 1.1746\n",
      "Epoch 250: Generator Loss = 55.9588, Discriminator Loss = 3.3093\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Epoch 1/15 | Train Loss: 0.4909 Acc: 0.7702\n",
      "Epoch 2/15 | Train Loss: 0.4091 Acc: 0.7885\n",
      "Epoch 3/15 | Train Loss: 0.4226 Acc: 0.7598\n",
      "Epoch 4/15 | Train Loss: 0.3525 Acc: 0.8146\n",
      "Epoch 5/15 | Train Loss: 0.3384 Acc: 0.8303\n",
      "Epoch 6/15 | Train Loss: 0.3069 Acc: 0.8407\n",
      "Epoch 7/15 | Train Loss: 0.2908 Acc: 0.8538\n",
      "Epoch 8/15 | Train Loss: 0.2439 Acc: 0.8956\n",
      "Epoch 9/15 | Train Loss: 0.2256 Acc: 0.8930\n",
      "Epoch 10/15 | Train Loss: 0.2616 Acc: 0.8668\n",
      "Epoch 11/15 | Train Loss: 0.2470 Acc: 0.8877\n",
      "Epoch 12/15 | Train Loss: 0.2732 Acc: 0.8486\n",
      "Epoch 13/15 | Train Loss: 0.2791 Acc: 0.8616\n",
      "Epoch 14/15 | Train Loss: 0.2448 Acc: 0.8877\n",
      "Epoch 15/15 | Train Loss: 0.2553 Acc: 0.8903\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5209 Acc: 0.7389\n",
      "Epoch 2/15 | Train Loss: 0.3758 Acc: 0.7885\n",
      "Epoch 3/15 | Train Loss: 0.3601 Acc: 0.7990\n",
      "Epoch 4/15 | Train Loss: 0.3543 Acc: 0.8172\n",
      "Epoch 5/15 | Train Loss: 0.3585 Acc: 0.8172\n",
      "Epoch 6/15 | Train Loss: 0.3286 Acc: 0.8277\n",
      "Epoch 7/15 | Train Loss: 0.2702 Acc: 0.8642\n",
      "Epoch 8/15 | Train Loss: 0.3429 Acc: 0.8512\n",
      "Epoch 9/15 | Train Loss: 0.3077 Acc: 0.8460\n",
      "Epoch 10/15 | Train Loss: 0.3231 Acc: 0.8460\n",
      "Epoch 11/15 | Train Loss: 0.3103 Acc: 0.8329\n",
      "Epoch 12/15 | Train Loss: 0.2930 Acc: 0.8433\n",
      "Epoch 13/15 | Train Loss: 0.2755 Acc: 0.8590\n",
      "Epoch 14/15 | Train Loss: 0.2626 Acc: 0.8747\n",
      "Epoch 15/15 | Train Loss: 0.2804 Acc: 0.8616\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5038 Acc: 0.7630\n",
      "Epoch 2/15 | Train Loss: 0.3906 Acc: 0.7969\n",
      "Epoch 3/15 | Train Loss: 0.4017 Acc: 0.8151\n",
      "Epoch 4/15 | Train Loss: 0.3542 Acc: 0.7969\n",
      "Epoch 5/15 | Train Loss: 0.3864 Acc: 0.7995\n",
      "Epoch 6/15 | Train Loss: 0.3545 Acc: 0.8151\n",
      "Epoch 7/15 | Train Loss: 0.3387 Acc: 0.8229\n",
      "Epoch 8/15 | Train Loss: 0.3214 Acc: 0.8151\n",
      "Epoch 9/15 | Train Loss: 0.2968 Acc: 0.8490\n",
      "Epoch 10/15 | Train Loss: 0.2932 Acc: 0.8542\n",
      "Epoch 11/15 | Train Loss: 0.2920 Acc: 0.8542\n",
      "Epoch 12/15 | Train Loss: 0.3058 Acc: 0.8568\n",
      "Epoch 13/15 | Train Loss: 0.2683 Acc: 0.8672\n",
      "Epoch 14/15 | Train Loss: 0.2688 Acc: 0.8542\n",
      "Epoch 15/15 | Train Loss: 0.2827 Acc: 0.8568\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5815 Acc: 0.7962\n",
      "Epoch 2/15 | Train Loss: 0.4538 Acc: 0.7930\n",
      "Epoch 3/15 | Train Loss: 0.3954 Acc: 0.8376\n",
      "Epoch 4/15 | Train Loss: 0.3909 Acc: 0.7898\n",
      "Epoch 5/15 | Train Loss: 0.3614 Acc: 0.8503\n",
      "Epoch 6/15 | Train Loss: 0.3625 Acc: 0.8408\n",
      "Epoch 7/15 | Train Loss: 0.3692 Acc: 0.8439\n",
      "Epoch 8/15 | Train Loss: 0.4041 Acc: 0.8312\n",
      "Epoch 9/15 | Train Loss: 0.3153 Acc: 0.8631\n",
      "Epoch 10/15 | Train Loss: 0.2949 Acc: 0.8631\n",
      "Epoch 11/15 | Train Loss: 0.2918 Acc: 0.8854\n",
      "Epoch 12/15 | Train Loss: 0.3046 Acc: 0.8726\n",
      "Epoch 13/15 | Train Loss: 0.3042 Acc: 0.8599\n",
      "Epoch 14/15 | Train Loss: 0.3141 Acc: 0.8631\n",
      "Epoch 15/15 | Train Loss: 0.3278 Acc: 0.8503\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.4610 Acc: 0.8107\n",
      "Epoch 2/15 | Train Loss: 0.3470 Acc: 0.8750\n",
      "Epoch 3/15 | Train Loss: 0.2910 Acc: 0.8714\n",
      "Epoch 4/15 | Train Loss: 0.3221 Acc: 0.8750\n",
      "Epoch 5/15 | Train Loss: 0.3196 Acc: 0.8714\n",
      "Epoch 6/15 | Train Loss: 0.3184 Acc: 0.8571\n",
      "Epoch 7/15 | Train Loss: 0.3043 Acc: 0.8643\n",
      "Epoch 8/15 | Train Loss: 0.3005 Acc: 0.8893\n",
      "Epoch 9/15 | Train Loss: 0.2724 Acc: 0.9071\n",
      "Epoch 10/15 | Train Loss: 0.2514 Acc: 0.9214\n",
      "Epoch 11/15 | Train Loss: 0.2446 Acc: 0.9000\n",
      "Epoch 12/15 | Train Loss: 0.2229 Acc: 0.9214\n",
      "Epoch 13/15 | Train Loss: 0.2728 Acc: 0.8929\n",
      "Epoch 14/15 | Train Loss: 0.2234 Acc: 0.9214\n",
      "Epoch 15/15 | Train Loss: 0.1957 Acc: 0.9250\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6966 Acc: 0.6825\n",
      "Epoch 2/15 | Train Loss: 0.5866 Acc: 0.6746\n",
      "Epoch 3/15 | Train Loss: 0.5778 Acc: 0.7103\n",
      "Epoch 4/15 | Train Loss: 0.5365 Acc: 0.7262\n",
      "Epoch 5/15 | Train Loss: 0.4747 Acc: 0.7619\n",
      "Epoch 6/15 | Train Loss: 0.5259 Acc: 0.7500\n",
      "Epoch 7/15 | Train Loss: 0.4271 Acc: 0.8175\n",
      "Epoch 8/15 | Train Loss: 0.4357 Acc: 0.7976\n",
      "Epoch 9/15 | Train Loss: 0.3901 Acc: 0.8294\n",
      "Epoch 10/15 | Train Loss: 0.4292 Acc: 0.7579\n",
      "Epoch 11/15 | Train Loss: 0.3707 Acc: 0.8373\n",
      "Epoch 12/15 | Train Loss: 0.4384 Acc: 0.7738\n",
      "Epoch 13/15 | Train Loss: 0.3492 Acc: 0.8452\n",
      "Epoch 14/15 | Train Loss: 0.3433 Acc: 0.8413\n",
      "Epoch 15/15 | Train Loss: 0.3535 Acc: 0.8333\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7107 Acc: 0.6310\n",
      "Epoch 2/15 | Train Loss: 0.6164 Acc: 0.6548\n",
      "Epoch 3/15 | Train Loss: 0.5468 Acc: 0.7063\n",
      "Epoch 4/15 | Train Loss: 0.5245 Acc: 0.7262\n",
      "Epoch 5/15 | Train Loss: 0.5646 Acc: 0.6984\n",
      "Epoch 6/15 | Train Loss: 0.4505 Acc: 0.7698\n",
      "Epoch 7/15 | Train Loss: 0.5249 Acc: 0.7500\n",
      "Epoch 8/15 | Train Loss: 0.4346 Acc: 0.7738\n",
      "Epoch 9/15 | Train Loss: 0.3999 Acc: 0.8175\n",
      "Epoch 10/15 | Train Loss: 0.4191 Acc: 0.7897\n",
      "Epoch 11/15 | Train Loss: 0.4136 Acc: 0.7937\n",
      "Epoch 12/15 | Train Loss: 0.4139 Acc: 0.8214\n",
      "Epoch 13/15 | Train Loss: 0.3716 Acc: 0.8571\n",
      "Epoch 14/15 | Train Loss: 0.4542 Acc: 0.7857\n",
      "Epoch 15/15 | Train Loss: 0.4122 Acc: 0.8214\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7537 Acc: 0.6285\n",
      "Epoch 2/15 | Train Loss: 0.6238 Acc: 0.6561\n",
      "Epoch 3/15 | Train Loss: 0.5518 Acc: 0.7352\n",
      "Epoch 4/15 | Train Loss: 0.5617 Acc: 0.7391\n",
      "Epoch 5/15 | Train Loss: 0.4979 Acc: 0.7628\n",
      "Epoch 6/15 | Train Loss: 0.4960 Acc: 0.7431\n",
      "Epoch 7/15 | Train Loss: 0.4857 Acc: 0.7549\n",
      "Epoch 8/15 | Train Loss: 0.4516 Acc: 0.7747\n",
      "Epoch 9/15 | Train Loss: 0.4412 Acc: 0.7826\n",
      "Epoch 10/15 | Train Loss: 0.4157 Acc: 0.8142\n",
      "Epoch 11/15 | Train Loss: 0.3654 Acc: 0.8300\n",
      "Epoch 12/15 | Train Loss: 0.4403 Acc: 0.8024\n",
      "Epoch 13/15 | Train Loss: 0.4261 Acc: 0.7905\n",
      "Epoch 14/15 | Train Loss: 0.4484 Acc: 0.7905\n",
      "Epoch 15/15 | Train Loss: 0.4354 Acc: 0.7787\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6317 Acc: 0.6992\n",
      "Epoch 2/15 | Train Loss: 0.4953 Acc: 0.7797\n",
      "Epoch 3/15 | Train Loss: 0.5619 Acc: 0.7373\n",
      "Epoch 4/15 | Train Loss: 0.4893 Acc: 0.7797\n",
      "Epoch 5/15 | Train Loss: 0.5566 Acc: 0.7500\n",
      "Epoch 6/15 | Train Loss: 0.4668 Acc: 0.7924\n",
      "Epoch 7/15 | Train Loss: 0.4268 Acc: 0.7839\n",
      "Epoch 8/15 | Train Loss: 0.3891 Acc: 0.8136\n",
      "Epoch 9/15 | Train Loss: 0.4800 Acc: 0.7881\n",
      "Epoch 10/15 | Train Loss: 0.3751 Acc: 0.8263\n",
      "Epoch 11/15 | Train Loss: 0.3893 Acc: 0.8220\n",
      "Epoch 12/15 | Train Loss: 0.3956 Acc: 0.8347\n",
      "Epoch 13/15 | Train Loss: 0.4092 Acc: 0.7881\n",
      "Epoch 14/15 | Train Loss: 0.3990 Acc: 0.8263\n",
      "Epoch 15/15 | Train Loss: 0.3766 Acc: 0.8432\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.8352 Acc: 0.5727\n",
      "Epoch 2/15 | Train Loss: 0.5163 Acc: 0.8062\n",
      "Epoch 3/15 | Train Loss: 0.3754 Acc: 0.8546\n",
      "Epoch 4/15 | Train Loss: 0.3780 Acc: 0.8458\n",
      "Epoch 5/15 | Train Loss: 0.3776 Acc: 0.8458\n",
      "Epoch 6/15 | Train Loss: 0.3055 Acc: 0.8722\n",
      "Epoch 7/15 | Train Loss: 0.3462 Acc: 0.8590\n",
      "Epoch 8/15 | Train Loss: 0.2760 Acc: 0.8899\n",
      "Epoch 9/15 | Train Loss: 0.2767 Acc: 0.8811\n",
      "Epoch 10/15 | Train Loss: 0.3235 Acc: 0.8811\n",
      "Epoch 11/15 | Train Loss: 0.2810 Acc: 0.8899\n",
      "Epoch 12/15 | Train Loss: 0.2762 Acc: 0.8811\n",
      "Epoch 13/15 | Train Loss: 0.3303 Acc: 0.8722\n",
      "Epoch 14/15 | Train Loss: 0.2727 Acc: 0.8943\n",
      "Epoch 15/15 | Train Loss: 0.2617 Acc: 0.8943\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.5min\n",
      "Epoch 1/15 | Train Loss: 0.7089 Acc: 0.6622\n",
      "Epoch 2/15 | Train Loss: 0.5255 Acc: 0.7264\n",
      "Epoch 3/15 | Train Loss: 0.5162 Acc: 0.7196\n",
      "Epoch 4/15 | Train Loss: 0.4472 Acc: 0.7770\n",
      "Epoch 5/15 | Train Loss: 0.4568 Acc: 0.7669\n",
      "Epoch 6/15 | Train Loss: 0.4479 Acc: 0.8007\n",
      "Epoch 7/15 | Train Loss: 0.3605 Acc: 0.8378\n",
      "Epoch 8/15 | Train Loss: 0.3189 Acc: 0.8682\n",
      "Epoch 9/15 | Train Loss: 0.3317 Acc: 0.8514\n",
      "Epoch 10/15 | Train Loss: 0.3844 Acc: 0.8142\n",
      "Epoch 11/15 | Train Loss: 0.3683 Acc: 0.8311\n",
      "Epoch 12/15 | Train Loss: 0.3118 Acc: 0.8649\n",
      "Epoch 13/15 | Train Loss: 0.2963 Acc: 0.8581\n",
      "Epoch 14/15 | Train Loss: 0.3387 Acc: 0.8311\n",
      "Epoch 15/15 | Train Loss: 0.3362 Acc: 0.8446\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6066 Acc: 0.6926\n",
      "Epoch 2/15 | Train Loss: 0.5241 Acc: 0.6892\n",
      "Epoch 3/15 | Train Loss: 0.4356 Acc: 0.7432\n",
      "Epoch 4/15 | Train Loss: 0.4836 Acc: 0.7432\n",
      "Epoch 5/15 | Train Loss: 0.4568 Acc: 0.7500\n",
      "Epoch 6/15 | Train Loss: 0.4437 Acc: 0.7568\n",
      "Epoch 7/15 | Train Loss: 0.3691 Acc: 0.7939\n",
      "Epoch 8/15 | Train Loss: 0.3831 Acc: 0.8041\n",
      "Epoch 9/15 | Train Loss: 0.3483 Acc: 0.8311\n",
      "Epoch 10/15 | Train Loss: 0.3931 Acc: 0.7736\n",
      "Epoch 11/15 | Train Loss: 0.3591 Acc: 0.8243\n",
      "Epoch 12/15 | Train Loss: 0.3554 Acc: 0.8311\n",
      "Epoch 13/15 | Train Loss: 0.3733 Acc: 0.8041\n",
      "Epoch 14/15 | Train Loss: 0.3500 Acc: 0.8412\n",
      "Epoch 15/15 | Train Loss: 0.3540 Acc: 0.8480\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5999 Acc: 0.6599\n",
      "Epoch 2/15 | Train Loss: 0.4822 Acc: 0.7576\n",
      "Epoch 3/15 | Train Loss: 0.4504 Acc: 0.7643\n",
      "Epoch 4/15 | Train Loss: 0.4134 Acc: 0.7946\n",
      "Epoch 5/15 | Train Loss: 0.4448 Acc: 0.7879\n",
      "Epoch 6/15 | Train Loss: 0.4246 Acc: 0.7643\n",
      "Epoch 7/15 | Train Loss: 0.3957 Acc: 0.8047\n",
      "Epoch 8/15 | Train Loss: 0.3610 Acc: 0.8148\n",
      "Epoch 9/15 | Train Loss: 0.3419 Acc: 0.8350\n",
      "Epoch 10/15 | Train Loss: 0.3549 Acc: 0.8485\n",
      "Epoch 11/15 | Train Loss: 0.3518 Acc: 0.8316\n",
      "Epoch 12/15 | Train Loss: 0.3511 Acc: 0.8283\n",
      "Epoch 13/15 | Train Loss: 0.3556 Acc: 0.8249\n",
      "Epoch 14/15 | Train Loss: 0.3608 Acc: 0.8451\n",
      "Epoch 15/15 | Train Loss: 0.3698 Acc: 0.8047\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6064 Acc: 0.7176\n",
      "Epoch 2/15 | Train Loss: 0.5452 Acc: 0.7634\n",
      "Epoch 3/15 | Train Loss: 0.4836 Acc: 0.7748\n",
      "Epoch 4/15 | Train Loss: 0.4293 Acc: 0.8015\n",
      "Epoch 5/15 | Train Loss: 0.4707 Acc: 0.8092\n",
      "Epoch 6/15 | Train Loss: 0.4408 Acc: 0.8015\n",
      "Epoch 7/15 | Train Loss: 0.4243 Acc: 0.8206\n",
      "Epoch 8/15 | Train Loss: 0.3684 Acc: 0.8244\n",
      "Epoch 9/15 | Train Loss: 0.3621 Acc: 0.8435\n",
      "Epoch 10/15 | Train Loss: 0.3768 Acc: 0.8282\n",
      "Epoch 11/15 | Train Loss: 0.3906 Acc: 0.8244\n",
      "Epoch 12/15 | Train Loss: 0.3620 Acc: 0.8397\n",
      "Epoch 13/15 | Train Loss: 0.3878 Acc: 0.8282\n",
      "Epoch 14/15 | Train Loss: 0.3556 Acc: 0.8282\n",
      "Epoch 15/15 | Train Loss: 0.3435 Acc: 0.8664\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5238 Acc: 0.7755\n",
      "Epoch 2/15 | Train Loss: 0.3627 Acc: 0.8571\n",
      "Epoch 3/15 | Train Loss: 0.3850 Acc: 0.8367\n",
      "Epoch 4/15 | Train Loss: 0.3623 Acc: 0.8612\n",
      "Epoch 5/15 | Train Loss: 0.3316 Acc: 0.8939\n",
      "Epoch 6/15 | Train Loss: 0.3118 Acc: 0.8857\n",
      "Epoch 7/15 | Train Loss: 0.3011 Acc: 0.8776\n",
      "Epoch 8/15 | Train Loss: 0.3418 Acc: 0.8612\n",
      "Epoch 9/15 | Train Loss: 0.2715 Acc: 0.8653\n",
      "Epoch 10/15 | Train Loss: 0.2747 Acc: 0.9061\n",
      "Epoch 11/15 | Train Loss: 0.2692 Acc: 0.8816\n",
      "Epoch 12/15 | Train Loss: 0.2555 Acc: 0.9143\n",
      "Epoch 13/15 | Train Loss: 0.2743 Acc: 0.8980\n",
      "Epoch 14/15 | Train Loss: 0.2764 Acc: 0.9020\n",
      "Epoch 15/15 | Train Loss: 0.2796 Acc: 0.9184\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7141 Acc: 0.5873\n",
      "Epoch 2/15 | Train Loss: 0.5529 Acc: 0.7063\n",
      "Epoch 3/15 | Train Loss: 0.5344 Acc: 0.7302\n",
      "Epoch 4/15 | Train Loss: 0.5042 Acc: 0.7381\n",
      "Epoch 5/15 | Train Loss: 0.4782 Acc: 0.7976\n",
      "Epoch 6/15 | Train Loss: 0.5094 Acc: 0.7341\n",
      "Epoch 7/15 | Train Loss: 0.4489 Acc: 0.7778\n",
      "Epoch 8/15 | Train Loss: 0.4285 Acc: 0.8016\n",
      "Epoch 9/15 | Train Loss: 0.3695 Acc: 0.8492\n",
      "Epoch 10/15 | Train Loss: 0.3913 Acc: 0.7857\n",
      "Epoch 11/15 | Train Loss: 0.3884 Acc: 0.8373\n",
      "Epoch 12/15 | Train Loss: 0.3721 Acc: 0.8214\n",
      "Epoch 13/15 | Train Loss: 0.3280 Acc: 0.8413\n",
      "Epoch 14/15 | Train Loss: 0.3597 Acc: 0.8413\n",
      "Epoch 15/15 | Train Loss: 0.4193 Acc: 0.8095\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7029 Acc: 0.6151\n",
      "Epoch 2/15 | Train Loss: 0.6266 Acc: 0.6667\n",
      "Epoch 3/15 | Train Loss: 0.5975 Acc: 0.6786\n",
      "Epoch 4/15 | Train Loss: 0.5108 Acc: 0.7103\n",
      "Epoch 5/15 | Train Loss: 0.5158 Acc: 0.7341\n",
      "Epoch 6/15 | Train Loss: 0.4830 Acc: 0.7659\n",
      "Epoch 7/15 | Train Loss: 0.4462 Acc: 0.7857\n",
      "Epoch 8/15 | Train Loss: 0.4777 Acc: 0.7500\n",
      "Epoch 9/15 | Train Loss: 0.4155 Acc: 0.7937\n",
      "Epoch 10/15 | Train Loss: 0.4670 Acc: 0.7698\n",
      "Epoch 11/15 | Train Loss: 0.4185 Acc: 0.7976\n",
      "Epoch 12/15 | Train Loss: 0.4394 Acc: 0.7976\n",
      "Epoch 13/15 | Train Loss: 0.4129 Acc: 0.8095\n",
      "Epoch 14/15 | Train Loss: 0.3979 Acc: 0.8333\n",
      "Epoch 15/15 | Train Loss: 0.3840 Acc: 0.8254\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6994 Acc: 0.6443\n",
      "Epoch 2/15 | Train Loss: 0.5686 Acc: 0.6798\n",
      "Epoch 3/15 | Train Loss: 0.5543 Acc: 0.7036\n",
      "Epoch 4/15 | Train Loss: 0.5333 Acc: 0.7154\n",
      "Epoch 5/15 | Train Loss: 0.4949 Acc: 0.7431\n",
      "Epoch 6/15 | Train Loss: 0.4998 Acc: 0.7549\n",
      "Epoch 7/15 | Train Loss: 0.4829 Acc: 0.7668\n",
      "Epoch 8/15 | Train Loss: 0.4752 Acc: 0.7747\n",
      "Epoch 9/15 | Train Loss: 0.4703 Acc: 0.7549\n",
      "Epoch 10/15 | Train Loss: 0.4261 Acc: 0.7747\n",
      "Epoch 11/15 | Train Loss: 0.3962 Acc: 0.8221\n",
      "Epoch 12/15 | Train Loss: 0.3759 Acc: 0.8340\n",
      "Epoch 13/15 | Train Loss: 0.3765 Acc: 0.8379\n",
      "Epoch 14/15 | Train Loss: 0.3883 Acc: 0.8221\n",
      "Epoch 15/15 | Train Loss: 0.3998 Acc: 0.7747\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7518 Acc: 0.5890\n",
      "Epoch 2/15 | Train Loss: 0.5926 Acc: 0.7246\n",
      "Epoch 3/15 | Train Loss: 0.5192 Acc: 0.7119\n",
      "Epoch 4/15 | Train Loss: 0.4796 Acc: 0.7669\n",
      "Epoch 5/15 | Train Loss: 0.4916 Acc: 0.7542\n",
      "Epoch 6/15 | Train Loss: 0.4873 Acc: 0.8136\n",
      "Epoch 7/15 | Train Loss: 0.4282 Acc: 0.8305\n",
      "Epoch 8/15 | Train Loss: 0.4176 Acc: 0.8220\n",
      "Epoch 9/15 | Train Loss: 0.3791 Acc: 0.8178\n",
      "Epoch 10/15 | Train Loss: 0.4478 Acc: 0.7966\n",
      "Epoch 11/15 | Train Loss: 0.4513 Acc: 0.7797\n",
      "Epoch 12/15 | Train Loss: 0.4088 Acc: 0.8136\n",
      "Epoch 13/15 | Train Loss: 0.3939 Acc: 0.8051\n",
      "Epoch 14/15 | Train Loss: 0.4135 Acc: 0.8559\n",
      "Epoch 15/15 | Train Loss: 0.3934 Acc: 0.8178\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.5min\n",
      "Epoch 1/15 | Train Loss: 0.5368 Acc: 0.8018\n",
      "Epoch 2/15 | Train Loss: 0.4620 Acc: 0.8062\n",
      "Epoch 3/15 | Train Loss: 0.4203 Acc: 0.8458\n",
      "Epoch 4/15 | Train Loss: 0.4052 Acc: 0.8282\n",
      "Epoch 5/15 | Train Loss: 0.3986 Acc: 0.8326\n",
      "Epoch 6/15 | Train Loss: 0.3472 Acc: 0.8634\n",
      "Epoch 7/15 | Train Loss: 0.3487 Acc: 0.8811\n",
      "Epoch 8/15 | Train Loss: 0.4317 Acc: 0.8370\n",
      "Epoch 9/15 | Train Loss: 0.3267 Acc: 0.8899\n",
      "Epoch 10/15 | Train Loss: 0.3693 Acc: 0.8546\n",
      "Epoch 11/15 | Train Loss: 0.2771 Acc: 0.8811\n",
      "Epoch 12/15 | Train Loss: 0.3099 Acc: 0.8767\n",
      "Epoch 13/15 | Train Loss: 0.3587 Acc: 0.8634\n",
      "Epoch 14/15 | Train Loss: 0.3220 Acc: 0.8678\n",
      "Epoch 15/15 | Train Loss: 0.2574 Acc: 0.8943\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.5min\n",
      "Epoch 1/15 | Train Loss: 0.5456 Acc: 0.7598\n",
      "Epoch 2/15 | Train Loss: 0.4158 Acc: 0.7598\n",
      "Epoch 3/15 | Train Loss: 0.3640 Acc: 0.8042\n",
      "Epoch 4/15 | Train Loss: 0.3367 Acc: 0.8303\n",
      "Epoch 5/15 | Train Loss: 0.3427 Acc: 0.8381\n",
      "Epoch 6/15 | Train Loss: 0.3126 Acc: 0.8512\n",
      "Epoch 7/15 | Train Loss: 0.2730 Acc: 0.8747\n",
      "Epoch 8/15 | Train Loss: 0.2868 Acc: 0.8851\n",
      "Epoch 9/15 | Train Loss: 0.2364 Acc: 0.9008\n",
      "Epoch 10/15 | Train Loss: 0.2668 Acc: 0.8825\n",
      "Epoch 11/15 | Train Loss: 0.2501 Acc: 0.8825\n",
      "Epoch 12/15 | Train Loss: 0.2513 Acc: 0.8851\n",
      "Epoch 13/15 | Train Loss: 0.2645 Acc: 0.8642\n",
      "Epoch 14/15 | Train Loss: 0.2350 Acc: 0.8877\n",
      "Epoch 15/15 | Train Loss: 0.2411 Acc: 0.8851\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5265 Acc: 0.7493\n",
      "Epoch 2/15 | Train Loss: 0.4171 Acc: 0.7807\n",
      "Epoch 3/15 | Train Loss: 0.3686 Acc: 0.8016\n",
      "Epoch 4/15 | Train Loss: 0.3571 Acc: 0.8251\n",
      "Epoch 5/15 | Train Loss: 0.3538 Acc: 0.8094\n",
      "Epoch 6/15 | Train Loss: 0.3742 Acc: 0.8094\n",
      "Epoch 7/15 | Train Loss: 0.3980 Acc: 0.7885\n",
      "Epoch 8/15 | Train Loss: 0.3036 Acc: 0.8355\n",
      "Epoch 9/15 | Train Loss: 0.2804 Acc: 0.8668\n",
      "Epoch 10/15 | Train Loss: 0.2799 Acc: 0.8590\n",
      "Epoch 11/15 | Train Loss: 0.2668 Acc: 0.8616\n",
      "Epoch 12/15 | Train Loss: 0.2854 Acc: 0.8460\n",
      "Epoch 13/15 | Train Loss: 0.2689 Acc: 0.8799\n",
      "Epoch 14/15 | Train Loss: 0.2676 Acc: 0.8799\n",
      "Epoch 15/15 | Train Loss: 0.2426 Acc: 0.9008\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5016 Acc: 0.7448\n",
      "Epoch 2/15 | Train Loss: 0.4207 Acc: 0.7734\n",
      "Epoch 3/15 | Train Loss: 0.3997 Acc: 0.7682\n",
      "Epoch 4/15 | Train Loss: 0.3625 Acc: 0.7812\n",
      "Epoch 5/15 | Train Loss: 0.3325 Acc: 0.8411\n",
      "Epoch 6/15 | Train Loss: 0.3153 Acc: 0.8255\n",
      "Epoch 7/15 | Train Loss: 0.3294 Acc: 0.8438\n",
      "Epoch 8/15 | Train Loss: 0.3357 Acc: 0.8151\n",
      "Epoch 9/15 | Train Loss: 0.3048 Acc: 0.8516\n",
      "Epoch 10/15 | Train Loss: 0.2761 Acc: 0.8568\n",
      "Epoch 11/15 | Train Loss: 0.2673 Acc: 0.8828\n",
      "Epoch 12/15 | Train Loss: 0.2598 Acc: 0.8698\n",
      "Epoch 13/15 | Train Loss: 0.2998 Acc: 0.8385\n",
      "Epoch 14/15 | Train Loss: 0.2690 Acc: 0.8750\n",
      "Epoch 15/15 | Train Loss: 0.2984 Acc: 0.8542\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.4740 Acc: 0.7771\n",
      "Epoch 2/15 | Train Loss: 0.4075 Acc: 0.8153\n",
      "Epoch 3/15 | Train Loss: 0.3929 Acc: 0.8280\n",
      "Epoch 4/15 | Train Loss: 0.3636 Acc: 0.8503\n",
      "Epoch 5/15 | Train Loss: 0.3037 Acc: 0.8567\n",
      "Epoch 6/15 | Train Loss: 0.3707 Acc: 0.8312\n",
      "Epoch 7/15 | Train Loss: 0.3244 Acc: 0.8567\n",
      "Epoch 8/15 | Train Loss: 0.3307 Acc: 0.8567\n",
      "Epoch 9/15 | Train Loss: 0.3085 Acc: 0.8631\n",
      "Epoch 10/15 | Train Loss: 0.2733 Acc: 0.8854\n",
      "Epoch 11/15 | Train Loss: 0.3501 Acc: 0.8471\n",
      "Epoch 12/15 | Train Loss: 0.3078 Acc: 0.8535\n",
      "Epoch 13/15 | Train Loss: 0.2889 Acc: 0.8694\n",
      "Epoch 14/15 | Train Loss: 0.2787 Acc: 0.8885\n",
      "Epoch 15/15 | Train Loss: 0.2823 Acc: 0.8790\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.4609 Acc: 0.8107\n",
      "Epoch 2/15 | Train Loss: 0.4000 Acc: 0.8571\n",
      "Epoch 3/15 | Train Loss: 0.3519 Acc: 0.8643\n",
      "Epoch 4/15 | Train Loss: 0.3235 Acc: 0.8714\n",
      "Epoch 5/15 | Train Loss: 0.3334 Acc: 0.8750\n",
      "Epoch 6/15 | Train Loss: 0.2866 Acc: 0.8786\n",
      "Epoch 7/15 | Train Loss: 0.2386 Acc: 0.8964\n",
      "Epoch 8/15 | Train Loss: 0.2864 Acc: 0.9000\n",
      "Epoch 9/15 | Train Loss: 0.2411 Acc: 0.8929\n",
      "Epoch 10/15 | Train Loss: 0.2172 Acc: 0.9214\n",
      "Epoch 11/15 | Train Loss: 0.2564 Acc: 0.9107\n",
      "Epoch 12/15 | Train Loss: 0.2255 Acc: 0.9036\n",
      "Epoch 13/15 | Train Loss: 0.1920 Acc: 0.9250\n",
      "Epoch 14/15 | Train Loss: 0.2049 Acc: 0.9321\n",
      "Epoch 15/15 | Train Loss: 0.2035 Acc: 0.9036\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.8756 Acc: 0.6349\n",
      "Epoch 2/15 | Train Loss: 0.5823 Acc: 0.7262\n",
      "Epoch 3/15 | Train Loss: 0.5391 Acc: 0.7103\n",
      "Epoch 4/15 | Train Loss: 0.5842 Acc: 0.7024\n",
      "Epoch 5/15 | Train Loss: 0.4789 Acc: 0.7738\n",
      "Epoch 6/15 | Train Loss: 0.4221 Acc: 0.8056\n",
      "Epoch 7/15 | Train Loss: 0.4550 Acc: 0.7778\n",
      "Epoch 8/15 | Train Loss: 0.4229 Acc: 0.7738\n",
      "Epoch 9/15 | Train Loss: 0.3760 Acc: 0.8214\n",
      "Epoch 10/15 | Train Loss: 0.3903 Acc: 0.8413\n",
      "Epoch 11/15 | Train Loss: 0.3506 Acc: 0.8690\n",
      "Epoch 12/15 | Train Loss: 0.3856 Acc: 0.8294\n",
      "Epoch 13/15 | Train Loss: 0.3746 Acc: 0.8373\n",
      "Epoch 14/15 | Train Loss: 0.4181 Acc: 0.7976\n",
      "Epoch 15/15 | Train Loss: 0.3579 Acc: 0.8135\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7642 Acc: 0.6270\n",
      "Epoch 2/15 | Train Loss: 0.6067 Acc: 0.6825\n",
      "Epoch 3/15 | Train Loss: 0.5546 Acc: 0.7063\n",
      "Epoch 4/15 | Train Loss: 0.5404 Acc: 0.7063\n",
      "Epoch 5/15 | Train Loss: 0.5460 Acc: 0.7143\n",
      "Epoch 6/15 | Train Loss: 0.5331 Acc: 0.6786\n",
      "Epoch 7/15 | Train Loss: 0.5215 Acc: 0.7460\n",
      "Epoch 8/15 | Train Loss: 0.4794 Acc: 0.7302\n",
      "Epoch 9/15 | Train Loss: 0.4286 Acc: 0.7937\n",
      "Epoch 10/15 | Train Loss: 0.3993 Acc: 0.7897\n",
      "Epoch 11/15 | Train Loss: 0.4388 Acc: 0.7738\n",
      "Epoch 12/15 | Train Loss: 0.4133 Acc: 0.8214\n",
      "Epoch 13/15 | Train Loss: 0.3839 Acc: 0.8452\n",
      "Epoch 14/15 | Train Loss: 0.4224 Acc: 0.8056\n",
      "Epoch 15/15 | Train Loss: 0.4429 Acc: 0.7540\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6747 Acc: 0.6245\n",
      "Epoch 2/15 | Train Loss: 0.6045 Acc: 0.6680\n",
      "Epoch 3/15 | Train Loss: 0.5636 Acc: 0.6917\n",
      "Epoch 4/15 | Train Loss: 0.5505 Acc: 0.7233\n",
      "Epoch 5/15 | Train Loss: 0.4661 Acc: 0.7589\n",
      "Epoch 6/15 | Train Loss: 0.4477 Acc: 0.7668\n",
      "Epoch 7/15 | Train Loss: 0.4956 Acc: 0.7866\n",
      "Epoch 8/15 | Train Loss: 0.4400 Acc: 0.7866\n",
      "Epoch 9/15 | Train Loss: 0.4183 Acc: 0.7984\n",
      "Epoch 10/15 | Train Loss: 0.4321 Acc: 0.7945\n",
      "Epoch 11/15 | Train Loss: 0.3893 Acc: 0.7984\n",
      "Epoch 12/15 | Train Loss: 0.4372 Acc: 0.7826\n",
      "Epoch 13/15 | Train Loss: 0.4844 Acc: 0.7312\n",
      "Epoch 14/15 | Train Loss: 0.3860 Acc: 0.8300\n",
      "Epoch 15/15 | Train Loss: 0.3719 Acc: 0.8538\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6313 Acc: 0.6949\n",
      "Epoch 2/15 | Train Loss: 0.5386 Acc: 0.7246\n",
      "Epoch 3/15 | Train Loss: 0.5403 Acc: 0.7712\n",
      "Epoch 4/15 | Train Loss: 0.5127 Acc: 0.7924\n",
      "Epoch 5/15 | Train Loss: 0.5112 Acc: 0.7966\n",
      "Epoch 6/15 | Train Loss: 0.4725 Acc: 0.8093\n",
      "Epoch 7/15 | Train Loss: 0.4632 Acc: 0.8093\n",
      "Epoch 8/15 | Train Loss: 0.4022 Acc: 0.8432\n",
      "Epoch 9/15 | Train Loss: 0.4035 Acc: 0.8136\n",
      "Epoch 10/15 | Train Loss: 0.4099 Acc: 0.8093\n",
      "Epoch 11/15 | Train Loss: 0.4453 Acc: 0.8051\n",
      "Epoch 12/15 | Train Loss: 0.4044 Acc: 0.7881\n",
      "Epoch 13/15 | Train Loss: 0.3956 Acc: 0.8220\n",
      "Epoch 14/15 | Train Loss: 0.4018 Acc: 0.8136\n",
      "Epoch 15/15 | Train Loss: 0.3402 Acc: 0.8390\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5443 Acc: 0.7841\n",
      "Epoch 2/15 | Train Loss: 0.4454 Acc: 0.8326\n",
      "Epoch 3/15 | Train Loss: 0.4084 Acc: 0.8414\n",
      "Epoch 4/15 | Train Loss: 0.4047 Acc: 0.8370\n",
      "Epoch 5/15 | Train Loss: 0.4132 Acc: 0.8282\n",
      "Epoch 6/15 | Train Loss: 0.4214 Acc: 0.8326\n",
      "Epoch 7/15 | Train Loss: 0.3291 Acc: 0.8546\n",
      "Epoch 8/15 | Train Loss: 0.3476 Acc: 0.8634\n",
      "Epoch 9/15 | Train Loss: 0.3528 Acc: 0.8678\n",
      "Epoch 10/15 | Train Loss: 0.2568 Acc: 0.9119\n",
      "Epoch 11/15 | Train Loss: 0.3104 Acc: 0.8899\n",
      "Epoch 12/15 | Train Loss: 0.3176 Acc: 0.8767\n",
      "Epoch 13/15 | Train Loss: 0.2899 Acc: 0.8811\n",
      "Epoch 14/15 | Train Loss: 0.2911 Acc: 0.8767\n",
      "Epoch 15/15 | Train Loss: 0.2615 Acc: 0.8943\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.5min\n",
      "Epoch 1/15 | Train Loss: 0.5053 Acc: 0.7798\n",
      "Epoch 2/15 | Train Loss: 0.4656 Acc: 0.7867\n",
      "Epoch 3/15 | Train Loss: 0.3904 Acc: 0.7798\n",
      "Epoch 4/15 | Train Loss: 0.3673 Acc: 0.8028\n",
      "Epoch 5/15 | Train Loss: 0.3305 Acc: 0.8349\n",
      "Epoch 6/15 | Train Loss: 0.3711 Acc: 0.8211\n",
      "Epoch 7/15 | Train Loss: 0.3399 Acc: 0.8096\n",
      "Epoch 8/15 | Train Loss: 0.3096 Acc: 0.8532\n",
      "Epoch 9/15 | Train Loss: 0.3026 Acc: 0.8440\n",
      "Epoch 10/15 | Train Loss: 0.2838 Acc: 0.8876\n",
      "Epoch 11/15 | Train Loss: 0.2824 Acc: 0.8716\n",
      "Epoch 12/15 | Train Loss: 0.2673 Acc: 0.8807\n",
      "Epoch 13/15 | Train Loss: 0.2676 Acc: 0.8853\n",
      "Epoch 14/15 | Train Loss: 0.2713 Acc: 0.8807\n",
      "Epoch 15/15 | Train Loss: 0.2432 Acc: 0.9037\n",
      "Fold 6 Test Accuracy: 0.7159\n",
      "===== Fold 7 =====\n",
      "Epoch 1: Generator Loss = 9.9714, Discriminator Loss = 8.9068\n",
      "Epoch 2: Generator Loss = 11.7684, Discriminator Loss = 7.2323\n",
      "Epoch 3: Generator Loss = 17.2658, Discriminator Loss = 5.1557\n",
      "Epoch 4: Generator Loss = 25.6594, Discriminator Loss = 4.0362\n",
      "Epoch 5: Generator Loss = 28.6369, Discriminator Loss = 4.1217\n",
      "Epoch 6: Generator Loss = 29.9361, Discriminator Loss = 5.8886\n",
      "Epoch 7: Generator Loss = 33.6654, Discriminator Loss = 6.7328\n",
      "Epoch 8: Generator Loss = 22.3155, Discriminator Loss = 7.6517\n",
      "Epoch 9: Generator Loss = 22.9510, Discriminator Loss = 8.1961\n",
      "Epoch 10: Generator Loss = 20.4796, Discriminator Loss = 6.1569\n",
      "Epoch 11: Generator Loss = 17.4183, Discriminator Loss = 8.0675\n",
      "Epoch 12: Generator Loss = 22.4282, Discriminator Loss = 7.0245\n",
      "Epoch 13: Generator Loss = 19.3236, Discriminator Loss = 7.7447\n",
      "Epoch 14: Generator Loss = 21.9205, Discriminator Loss = 9.2476\n",
      "Epoch 15: Generator Loss = 21.6504, Discriminator Loss = 7.3313\n",
      "Epoch 16: Generator Loss = 20.1511, Discriminator Loss = 9.0904\n",
      "Epoch 17: Generator Loss = 18.9432, Discriminator Loss = 8.1815\n",
      "Epoch 18: Generator Loss = 16.3218, Discriminator Loss = 8.7447\n",
      "Epoch 19: Generator Loss = 18.9600, Discriminator Loss = 8.8067\n",
      "Epoch 20: Generator Loss = 16.1648, Discriminator Loss = 8.4280\n",
      "Epoch 21: Generator Loss = 17.2251, Discriminator Loss = 8.7536\n",
      "Epoch 22: Generator Loss = 17.4112, Discriminator Loss = 9.9065\n",
      "Epoch 23: Generator Loss = 17.8152, Discriminator Loss = 7.8494\n",
      "Epoch 24: Generator Loss = 14.9039, Discriminator Loss = 8.5106\n",
      "Epoch 25: Generator Loss = 15.8976, Discriminator Loss = 8.5084\n",
      "Epoch 26: Generator Loss = 14.8428, Discriminator Loss = 8.6829\n",
      "Epoch 27: Generator Loss = 15.5847, Discriminator Loss = 8.2389\n",
      "Epoch 28: Generator Loss = 16.2398, Discriminator Loss = 6.6635\n",
      "Epoch 29: Generator Loss = 16.4921, Discriminator Loss = 7.6812\n",
      "Epoch 30: Generator Loss = 16.2227, Discriminator Loss = 7.9608\n",
      "Epoch 31: Generator Loss = 16.8617, Discriminator Loss = 8.0884\n",
      "Epoch 32: Generator Loss = 18.0154, Discriminator Loss = 9.1978\n",
      "Epoch 33: Generator Loss = 17.8308, Discriminator Loss = 9.0805\n",
      "Epoch 34: Generator Loss = 18.9477, Discriminator Loss = 8.1314\n",
      "Epoch 35: Generator Loss = 16.8831, Discriminator Loss = 8.6934\n",
      "Epoch 36: Generator Loss = 14.2560, Discriminator Loss = 7.6118\n",
      "Epoch 37: Generator Loss = 16.8586, Discriminator Loss = 9.5037\n",
      "Epoch 38: Generator Loss = 16.7013, Discriminator Loss = 7.8908\n",
      "Epoch 39: Generator Loss = 19.4071, Discriminator Loss = 7.4070\n",
      "Epoch 40: Generator Loss = 23.3410, Discriminator Loss = 6.6049\n",
      "Epoch 41: Generator Loss = 24.1207, Discriminator Loss = 9.3062\n",
      "Epoch 42: Generator Loss = 18.2326, Discriminator Loss = 7.4666\n",
      "Epoch 43: Generator Loss = 16.2858, Discriminator Loss = 7.7506\n",
      "Epoch 44: Generator Loss = 22.9728, Discriminator Loss = 7.1821\n",
      "Epoch 45: Generator Loss = 19.6304, Discriminator Loss = 7.2339\n",
      "Epoch 46: Generator Loss = 25.1407, Discriminator Loss = 6.8842\n",
      "Epoch 47: Generator Loss = 23.0277, Discriminator Loss = 7.6788\n",
      "Epoch 48: Generator Loss = 21.3507, Discriminator Loss = 5.8925\n",
      "Epoch 49: Generator Loss = 24.2304, Discriminator Loss = 7.4813\n",
      "Epoch 50: Generator Loss = 19.1299, Discriminator Loss = 5.5339\n",
      "Epoch 51: Generator Loss = 24.2370, Discriminator Loss = 7.2610\n",
      "Epoch 52: Generator Loss = 23.8459, Discriminator Loss = 7.0462\n",
      "Epoch 53: Generator Loss = 30.8799, Discriminator Loss = 5.4757\n",
      "Epoch 54: Generator Loss = 24.4418, Discriminator Loss = 6.3699\n",
      "Epoch 55: Generator Loss = 26.4407, Discriminator Loss = 5.5612\n",
      "Epoch 56: Generator Loss = 24.0109, Discriminator Loss = 5.8633\n",
      "Epoch 57: Generator Loss = 26.9572, Discriminator Loss = 4.1146\n",
      "Epoch 58: Generator Loss = 33.6010, Discriminator Loss = 3.6470\n",
      "Epoch 59: Generator Loss = 28.6847, Discriminator Loss = 3.4078\n",
      "Epoch 60: Generator Loss = 34.3088, Discriminator Loss = 4.7574\n",
      "Epoch 61: Generator Loss = 27.8131, Discriminator Loss = 5.3961\n",
      "Epoch 62: Generator Loss = 28.6881, Discriminator Loss = 4.9243\n",
      "Epoch 63: Generator Loss = 30.8430, Discriminator Loss = 3.6901\n",
      "Epoch 64: Generator Loss = 29.9173, Discriminator Loss = 3.1830\n",
      "Epoch 65: Generator Loss = 35.6717, Discriminator Loss = 3.7019\n",
      "Epoch 66: Generator Loss = 43.1892, Discriminator Loss = 4.4453\n",
      "Epoch 67: Generator Loss = 28.1587, Discriminator Loss = 4.6141\n",
      "Epoch 68: Generator Loss = 31.1087, Discriminator Loss = 3.8977\n",
      "Epoch 69: Generator Loss = 36.9192, Discriminator Loss = 3.8742\n",
      "Epoch 70: Generator Loss = 40.3701, Discriminator Loss = 3.5343\n",
      "Epoch 71: Generator Loss = 43.3349, Discriminator Loss = 2.7041\n",
      "Epoch 72: Generator Loss = 41.2642, Discriminator Loss = 3.1770\n",
      "Epoch 73: Generator Loss = 46.9400, Discriminator Loss = 3.2273\n",
      "Epoch 74: Generator Loss = 42.8866, Discriminator Loss = 1.8698\n",
      "Epoch 75: Generator Loss = 52.1969, Discriminator Loss = 1.7937\n",
      "Epoch 76: Generator Loss = 50.0735, Discriminator Loss = 2.0640\n",
      "Epoch 77: Generator Loss = 50.4366, Discriminator Loss = 1.6842\n",
      "Epoch 78: Generator Loss = 47.5877, Discriminator Loss = 2.9336\n",
      "Epoch 79: Generator Loss = 39.4137, Discriminator Loss = 2.5842\n",
      "Epoch 80: Generator Loss = 62.4252, Discriminator Loss = 1.5086\n",
      "Epoch 81: Generator Loss = 52.8368, Discriminator Loss = 2.0274\n",
      "Epoch 82: Generator Loss = 56.2733, Discriminator Loss = 1.9756\n",
      "Epoch 83: Generator Loss = 45.0938, Discriminator Loss = 3.8943\n",
      "Epoch 84: Generator Loss = 47.0474, Discriminator Loss = 1.5248\n",
      "Epoch 85: Generator Loss = 61.3204, Discriminator Loss = 1.9499\n",
      "Epoch 86: Generator Loss = 42.7525, Discriminator Loss = 5.4336\n",
      "Epoch 87: Generator Loss = 52.3166, Discriminator Loss = 1.8294\n",
      "Epoch 88: Generator Loss = 46.1312, Discriminator Loss = 1.8971\n",
      "Epoch 89: Generator Loss = 53.1601, Discriminator Loss = 2.2535\n",
      "Epoch 90: Generator Loss = 54.3772, Discriminator Loss = 1.8937\n",
      "Epoch 91: Generator Loss = 69.6402, Discriminator Loss = 1.3455\n",
      "Epoch 92: Generator Loss = 59.6052, Discriminator Loss = 1.5092\n",
      "Epoch 93: Generator Loss = 56.9208, Discriminator Loss = 1.1154\n",
      "Epoch 94: Generator Loss = 60.6779, Discriminator Loss = 1.3848\n",
      "Epoch 95: Generator Loss = 49.8748, Discriminator Loss = 1.4630\n",
      "Epoch 96: Generator Loss = 59.4311, Discriminator Loss = 1.1833\n",
      "Epoch 97: Generator Loss = 62.8264, Discriminator Loss = 1.1486\n",
      "Epoch 98: Generator Loss = 58.4926, Discriminator Loss = 2.5762\n",
      "Epoch 99: Generator Loss = 59.4981, Discriminator Loss = 2.5480\n",
      "Epoch 100: Generator Loss = 72.3327, Discriminator Loss = 1.1588\n",
      "Epoch 101: Generator Loss = 63.4392, Discriminator Loss = 0.9466\n",
      "Epoch 102: Generator Loss = 58.2489, Discriminator Loss = 1.2192\n",
      "Epoch 103: Generator Loss = 59.3031, Discriminator Loss = 0.9615\n",
      "Epoch 104: Generator Loss = 73.6126, Discriminator Loss = 0.5370\n",
      "Epoch 105: Generator Loss = 63.4072, Discriminator Loss = 0.7750\n",
      "Epoch 106: Generator Loss = 55.6860, Discriminator Loss = 1.4292\n",
      "Epoch 107: Generator Loss = 70.7825, Discriminator Loss = 0.8624\n",
      "Epoch 108: Generator Loss = 75.7040, Discriminator Loss = 0.7155\n",
      "Epoch 109: Generator Loss = 63.6788, Discriminator Loss = 1.1153\n",
      "Epoch 110: Generator Loss = 58.5165, Discriminator Loss = 3.6178\n",
      "Epoch 111: Generator Loss = 61.0592, Discriminator Loss = 1.6053\n",
      "Epoch 112: Generator Loss = 67.7064, Discriminator Loss = 1.5665\n",
      "Epoch 113: Generator Loss = 58.1678, Discriminator Loss = 2.5561\n",
      "Epoch 114: Generator Loss = 68.8196, Discriminator Loss = 1.8575\n",
      "Epoch 115: Generator Loss = 65.8626, Discriminator Loss = 0.8073\n",
      "Epoch 116: Generator Loss = 57.9249, Discriminator Loss = 0.9700\n",
      "Epoch 117: Generator Loss = 76.0431, Discriminator Loss = 0.6886\n",
      "Epoch 118: Generator Loss = 68.9043, Discriminator Loss = 0.7846\n",
      "Epoch 119: Generator Loss = 87.0544, Discriminator Loss = 0.8193\n",
      "Epoch 120: Generator Loss = 65.9877, Discriminator Loss = 1.5280\n",
      "Epoch 121: Generator Loss = 76.1589, Discriminator Loss = 0.7012\n",
      "Epoch 122: Generator Loss = 74.8700, Discriminator Loss = 1.2095\n",
      "Epoch 123: Generator Loss = 74.9242, Discriminator Loss = 0.6686\n",
      "Epoch 124: Generator Loss = 59.9504, Discriminator Loss = 1.3972\n",
      "Epoch 125: Generator Loss = 71.7981, Discriminator Loss = 1.2307\n",
      "Epoch 126: Generator Loss = 80.5962, Discriminator Loss = 0.5380\n",
      "Epoch 127: Generator Loss = 78.6360, Discriminator Loss = 0.5978\n",
      "Epoch 128: Generator Loss = 82.0071, Discriminator Loss = 1.7219\n",
      "Epoch 129: Generator Loss = 70.8049, Discriminator Loss = 0.9624\n",
      "Epoch 130: Generator Loss = 64.8281, Discriminator Loss = 1.0082\n",
      "Epoch 131: Generator Loss = 69.2040, Discriminator Loss = 1.0515\n",
      "Epoch 132: Generator Loss = 75.8430, Discriminator Loss = 0.6987\n",
      "Epoch 133: Generator Loss = 80.7140, Discriminator Loss = 0.4809\n",
      "Epoch 134: Generator Loss = 74.3464, Discriminator Loss = 0.5346\n",
      "Epoch 135: Generator Loss = 89.8981, Discriminator Loss = 0.8682\n",
      "Epoch 136: Generator Loss = 67.2680, Discriminator Loss = 0.9364\n",
      "Epoch 137: Generator Loss = 74.6395, Discriminator Loss = 0.8806\n",
      "Epoch 138: Generator Loss = 60.1188, Discriminator Loss = 9.5321\n",
      "Epoch 139: Generator Loss = 44.7613, Discriminator Loss = 3.6185\n",
      "Epoch 140: Generator Loss = 65.6664, Discriminator Loss = 1.8286\n",
      "Epoch 141: Generator Loss = 61.6158, Discriminator Loss = 1.1413\n",
      "Epoch 142: Generator Loss = 60.7146, Discriminator Loss = 0.9724\n",
      "Epoch 143: Generator Loss = 85.3766, Discriminator Loss = 0.9704\n",
      "Epoch 144: Generator Loss = 77.9039, Discriminator Loss = 0.7197\n",
      "Epoch 145: Generator Loss = 67.7407, Discriminator Loss = 0.9791\n",
      "Epoch 146: Generator Loss = 88.8635, Discriminator Loss = 0.5401\n",
      "Epoch 147: Generator Loss = 78.3109, Discriminator Loss = 0.8225\n",
      "Epoch 148: Generator Loss = 66.7880, Discriminator Loss = 0.9772\n",
      "Epoch 149: Generator Loss = 71.5992, Discriminator Loss = 3.7098\n",
      "Epoch 150: Generator Loss = 52.4753, Discriminator Loss = 1.3259\n",
      "Epoch 151: Generator Loss = 76.2059, Discriminator Loss = 1.0775\n",
      "Epoch 152: Generator Loss = 74.2157, Discriminator Loss = 0.5859\n",
      "Epoch 153: Generator Loss = 65.0220, Discriminator Loss = 1.3553\n",
      "Epoch 154: Generator Loss = 61.3135, Discriminator Loss = 0.7321\n",
      "Epoch 155: Generator Loss = 70.4825, Discriminator Loss = 0.6953\n",
      "Epoch 156: Generator Loss = 64.3567, Discriminator Loss = 0.4918\n",
      "Epoch 157: Generator Loss = 92.8949, Discriminator Loss = 0.3047\n",
      "Epoch 158: Generator Loss = 85.1256, Discriminator Loss = 0.6686\n",
      "Epoch 159: Generator Loss = 83.8886, Discriminator Loss = 0.5315\n",
      "Epoch 160: Generator Loss = 63.1531, Discriminator Loss = 0.6051\n",
      "Epoch 161: Generator Loss = 64.6986, Discriminator Loss = 16.3160\n",
      "Epoch 162: Generator Loss = 73.9983, Discriminator Loss = 5.2673\n",
      "Epoch 163: Generator Loss = 52.2335, Discriminator Loss = 2.7483\n",
      "Epoch 164: Generator Loss = 69.0078, Discriminator Loss = 1.4187\n",
      "Epoch 165: Generator Loss = 78.0334, Discriminator Loss = 0.9397\n",
      "Epoch 166: Generator Loss = 63.2059, Discriminator Loss = 0.8471\n",
      "Epoch 167: Generator Loss = 63.8819, Discriminator Loss = 0.4221\n",
      "Epoch 168: Generator Loss = 85.6582, Discriminator Loss = 0.5776\n",
      "Epoch 169: Generator Loss = 72.0209, Discriminator Loss = 0.6083\n",
      "Epoch 170: Generator Loss = 67.4706, Discriminator Loss = 0.8554\n",
      "Epoch 171: Generator Loss = 73.9613, Discriminator Loss = 0.9099\n",
      "Epoch 172: Generator Loss = 72.2838, Discriminator Loss = 0.5444\n",
      "Epoch 173: Generator Loss = 90.8594, Discriminator Loss = 0.3235\n",
      "Epoch 174: Generator Loss = 69.7590, Discriminator Loss = 0.6578\n",
      "Epoch 175: Generator Loss = 75.5242, Discriminator Loss = 0.5120\n",
      "Epoch 176: Generator Loss = 90.3981, Discriminator Loss = 0.7471\n",
      "Epoch 177: Generator Loss = 74.7890, Discriminator Loss = 0.4694\n",
      "Epoch 178: Generator Loss = 83.1057, Discriminator Loss = 0.3681\n",
      "Epoch 179: Generator Loss = 96.1086, Discriminator Loss = 0.3376\n",
      "Epoch 180: Generator Loss = 85.7964, Discriminator Loss = 0.5123\n",
      "Epoch 181: Generator Loss = 103.2652, Discriminator Loss = 1.7327\n",
      "Epoch 182: Generator Loss = 88.5380, Discriminator Loss = 0.7416\n",
      "Epoch 183: Generator Loss = 80.4451, Discriminator Loss = 0.5034\n",
      "Epoch 184: Generator Loss = 96.7836, Discriminator Loss = 0.3656\n",
      "Epoch 185: Generator Loss = 87.1157, Discriminator Loss = 0.7091\n",
      "Epoch 186: Generator Loss = 64.6347, Discriminator Loss = 1.2933\n",
      "Epoch 187: Generator Loss = 80.8216, Discriminator Loss = 0.5200\n",
      "Epoch 188: Generator Loss = 90.4298, Discriminator Loss = 0.3665\n",
      "Epoch 189: Generator Loss = 83.5777, Discriminator Loss = 0.5198\n",
      "Epoch 190: Generator Loss = 90.5798, Discriminator Loss = 2.3975\n",
      "Epoch 191: Generator Loss = 80.9146, Discriminator Loss = 1.9550\n",
      "Epoch 192: Generator Loss = 68.4717, Discriminator Loss = 0.8229\n",
      "Epoch 193: Generator Loss = 78.0993, Discriminator Loss = 0.5195\n",
      "Epoch 194: Generator Loss = 79.0043, Discriminator Loss = 0.4443\n",
      "Epoch 195: Generator Loss = 85.4105, Discriminator Loss = 0.3844\n",
      "Epoch 196: Generator Loss = 86.1603, Discriminator Loss = 1.1206\n",
      "Epoch 197: Generator Loss = 82.4971, Discriminator Loss = 0.6721\n",
      "Epoch 198: Generator Loss = 89.3795, Discriminator Loss = 0.6403\n",
      "Epoch 199: Generator Loss = 88.1221, Discriminator Loss = 0.3708\n",
      "Epoch 200: Generator Loss = 89.1429, Discriminator Loss = 0.4014\n",
      "Epoch 201: Generator Loss = 86.9221, Discriminator Loss = 0.5229\n",
      "Epoch 202: Generator Loss = 88.6437, Discriminator Loss = 0.6412\n",
      "Epoch 203: Generator Loss = 79.3675, Discriminator Loss = 0.6008\n",
      "Epoch 204: Generator Loss = 112.7619, Discriminator Loss = 0.4376\n",
      "Epoch 205: Generator Loss = 90.3958, Discriminator Loss = 0.4153\n",
      "Epoch 206: Generator Loss = 87.9165, Discriminator Loss = 0.2469\n",
      "Epoch 207: Generator Loss = 97.0939, Discriminator Loss = 1.7436\n",
      "Epoch 208: Generator Loss = 79.8740, Discriminator Loss = 1.0916\n",
      "Epoch 209: Generator Loss = 90.1657, Discriminator Loss = 0.9167\n",
      "Epoch 210: Generator Loss = 77.0825, Discriminator Loss = 0.7797\n",
      "Epoch 211: Generator Loss = 68.0903, Discriminator Loss = 0.4241\n",
      "Epoch 212: Generator Loss = 85.5656, Discriminator Loss = 0.4837\n",
      "Epoch 213: Generator Loss = 88.3516, Discriminator Loss = 0.8737\n",
      "Epoch 214: Generator Loss = 66.9068, Discriminator Loss = 3.5317\n",
      "Epoch 215: Generator Loss = 74.4302, Discriminator Loss = 0.8405\n",
      "Epoch 216: Generator Loss = 90.8202, Discriminator Loss = 0.6278\n",
      "Epoch 217: Generator Loss = 96.1314, Discriminator Loss = 0.7084\n",
      "Epoch 218: Generator Loss = 87.0503, Discriminator Loss = 1.5603\n",
      "Epoch 219: Generator Loss = 94.3307, Discriminator Loss = 0.2862\n",
      "Epoch 220: Generator Loss = 84.4582, Discriminator Loss = 1.6549\n",
      "Epoch 221: Generator Loss = 79.7010, Discriminator Loss = 0.8635\n",
      "Epoch 222: Generator Loss = 91.4875, Discriminator Loss = 0.3562\n",
      "Epoch 223: Generator Loss = 92.3479, Discriminator Loss = 0.5606\n",
      "Epoch 224: Generator Loss = 84.6223, Discriminator Loss = 0.3558\n",
      "Epoch 225: Generator Loss = 94.6585, Discriminator Loss = 0.4991\n",
      "Epoch 226: Generator Loss = 84.8239, Discriminator Loss = 0.4919\n",
      "Epoch 227: Generator Loss = 93.5738, Discriminator Loss = 0.4706\n",
      "Epoch 228: Generator Loss = 92.2969, Discriminator Loss = 0.5436\n",
      "Epoch 229: Generator Loss = 129.2200, Discriminator Loss = 0.3820\n",
      "Epoch 230: Generator Loss = 113.5009, Discriminator Loss = 1.3623\n",
      "Epoch 231: Generator Loss = 86.6428, Discriminator Loss = 0.5766\n",
      "Epoch 232: Generator Loss = 100.2886, Discriminator Loss = 0.6726\n",
      "Epoch 233: Generator Loss = 73.8699, Discriminator Loss = 0.1538\n",
      "Epoch 234: Generator Loss = 95.4770, Discriminator Loss = 0.2284\n",
      "Epoch 235: Generator Loss = 95.5056, Discriminator Loss = 0.8524\n",
      "Epoch 236: Generator Loss = 90.4983, Discriminator Loss = 1.5987\n",
      "Epoch 237: Generator Loss = 85.7151, Discriminator Loss = 22.4566\n",
      "Epoch 238: Generator Loss = 71.3577, Discriminator Loss = 16.0013\n",
      "Epoch 239: Generator Loss = 44.9816, Discriminator Loss = 6.7142\n",
      "Epoch 240: Generator Loss = 42.5208, Discriminator Loss = 3.4424\n",
      "Epoch 241: Generator Loss = 66.5555, Discriminator Loss = 1.8838\n",
      "Epoch 242: Generator Loss = 62.8487, Discriminator Loss = 2.2241\n",
      "Epoch 243: Generator Loss = 86.2783, Discriminator Loss = 7.5294\n",
      "Epoch 244: Generator Loss = 59.6422, Discriminator Loss = 3.1995\n",
      "Epoch 245: Generator Loss = 51.0420, Discriminator Loss = 1.7305\n",
      "Epoch 246: Generator Loss = 64.1175, Discriminator Loss = 1.0384\n",
      "Epoch 247: Generator Loss = 69.5446, Discriminator Loss = 1.0072\n",
      "Epoch 248: Generator Loss = 69.3792, Discriminator Loss = 1.7769\n",
      "Epoch 249: Generator Loss = 58.1510, Discriminator Loss = 1.0935\n",
      "Epoch 250: Generator Loss = 74.1519, Discriminator Loss = 1.1000\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Epoch 1/15 | Train Loss: 0.6274 Acc: 0.7154\n",
      "Epoch 2/15 | Train Loss: 0.3882 Acc: 0.7963\n",
      "Epoch 3/15 | Train Loss: 0.3453 Acc: 0.8329\n",
      "Epoch 4/15 | Train Loss: 0.3855 Acc: 0.8016\n",
      "Epoch 5/15 | Train Loss: 0.3306 Acc: 0.8277\n",
      "Epoch 6/15 | Train Loss: 0.3407 Acc: 0.8277\n",
      "Epoch 7/15 | Train Loss: 0.2988 Acc: 0.8695\n",
      "Epoch 8/15 | Train Loss: 0.2946 Acc: 0.8695\n",
      "Epoch 9/15 | Train Loss: 0.2723 Acc: 0.8721\n",
      "Epoch 10/15 | Train Loss: 0.2737 Acc: 0.8773\n",
      "Epoch 11/15 | Train Loss: 0.2307 Acc: 0.8851\n",
      "Epoch 12/15 | Train Loss: 0.2455 Acc: 0.9060\n",
      "Epoch 13/15 | Train Loss: 0.2263 Acc: 0.9164\n",
      "Epoch 14/15 | Train Loss: 0.2188 Acc: 0.8903\n",
      "Epoch 15/15 | Train Loss: 0.2452 Acc: 0.8799\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.4933 Acc: 0.7755\n",
      "Epoch 2/15 | Train Loss: 0.4052 Acc: 0.7885\n",
      "Epoch 3/15 | Train Loss: 0.3705 Acc: 0.7781\n",
      "Epoch 4/15 | Train Loss: 0.3539 Acc: 0.8120\n",
      "Epoch 5/15 | Train Loss: 0.3452 Acc: 0.8355\n",
      "Epoch 6/15 | Train Loss: 0.3362 Acc: 0.8120\n",
      "Epoch 7/15 | Train Loss: 0.3224 Acc: 0.8355\n",
      "Epoch 8/15 | Train Loss: 0.2635 Acc: 0.8799\n",
      "Epoch 9/15 | Train Loss: 0.3284 Acc: 0.8355\n",
      "Epoch 10/15 | Train Loss: 0.2576 Acc: 0.8642\n",
      "Epoch 11/15 | Train Loss: 0.2847 Acc: 0.8668\n",
      "Epoch 12/15 | Train Loss: 0.2578 Acc: 0.8642\n",
      "Epoch 13/15 | Train Loss: 0.2708 Acc: 0.8590\n",
      "Epoch 14/15 | Train Loss: 0.2945 Acc: 0.8590\n",
      "Epoch 15/15 | Train Loss: 0.2753 Acc: 0.8773\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5282 Acc: 0.7578\n",
      "Epoch 2/15 | Train Loss: 0.4383 Acc: 0.7760\n",
      "Epoch 3/15 | Train Loss: 0.3845 Acc: 0.7969\n",
      "Epoch 4/15 | Train Loss: 0.3778 Acc: 0.8047\n",
      "Epoch 5/15 | Train Loss: 0.3308 Acc: 0.8359\n",
      "Epoch 6/15 | Train Loss: 0.3294 Acc: 0.8411\n",
      "Epoch 7/15 | Train Loss: 0.3232 Acc: 0.8281\n",
      "Epoch 8/15 | Train Loss: 0.2687 Acc: 0.8958\n",
      "Epoch 9/15 | Train Loss: 0.3110 Acc: 0.8411\n",
      "Epoch 10/15 | Train Loss: 0.2686 Acc: 0.8958\n",
      "Epoch 11/15 | Train Loss: 0.2545 Acc: 0.8880\n",
      "Epoch 12/15 | Train Loss: 0.2791 Acc: 0.8646\n",
      "Epoch 13/15 | Train Loss: 0.2768 Acc: 0.8672\n",
      "Epoch 14/15 | Train Loss: 0.2714 Acc: 0.8646\n",
      "Epoch 15/15 | Train Loss: 0.2649 Acc: 0.8594\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5443 Acc: 0.7898\n",
      "Epoch 2/15 | Train Loss: 0.4039 Acc: 0.8057\n",
      "Epoch 3/15 | Train Loss: 0.4000 Acc: 0.8280\n",
      "Epoch 4/15 | Train Loss: 0.3949 Acc: 0.8153\n",
      "Epoch 5/15 | Train Loss: 0.4017 Acc: 0.8217\n",
      "Epoch 6/15 | Train Loss: 0.3482 Acc: 0.8503\n",
      "Epoch 7/15 | Train Loss: 0.3164 Acc: 0.8567\n",
      "Epoch 8/15 | Train Loss: 0.3197 Acc: 0.8535\n",
      "Epoch 9/15 | Train Loss: 0.2806 Acc: 0.8854\n",
      "Epoch 10/15 | Train Loss: 0.2810 Acc: 0.8854\n",
      "Epoch 11/15 | Train Loss: 0.3045 Acc: 0.8854\n",
      "Epoch 12/15 | Train Loss: 0.2904 Acc: 0.8694\n",
      "Epoch 13/15 | Train Loss: 0.2647 Acc: 0.8694\n",
      "Epoch 14/15 | Train Loss: 0.3073 Acc: 0.8439\n",
      "Epoch 15/15 | Train Loss: 0.2927 Acc: 0.8885\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.4786 Acc: 0.7893\n",
      "Epoch 2/15 | Train Loss: 0.3605 Acc: 0.8679\n",
      "Epoch 3/15 | Train Loss: 0.3282 Acc: 0.8714\n",
      "Epoch 4/15 | Train Loss: 0.3250 Acc: 0.8750\n",
      "Epoch 5/15 | Train Loss: 0.2877 Acc: 0.8821\n",
      "Epoch 6/15 | Train Loss: 0.2264 Acc: 0.9107\n",
      "Epoch 7/15 | Train Loss: 0.2731 Acc: 0.8893\n",
      "Epoch 8/15 | Train Loss: 0.2818 Acc: 0.8821\n",
      "Epoch 9/15 | Train Loss: 0.2421 Acc: 0.8929\n",
      "Epoch 10/15 | Train Loss: 0.2669 Acc: 0.8893\n",
      "Epoch 11/15 | Train Loss: 0.2275 Acc: 0.9036\n",
      "Epoch 12/15 | Train Loss: 0.2189 Acc: 0.9107\n",
      "Epoch 13/15 | Train Loss: 0.2217 Acc: 0.9250\n",
      "Epoch 14/15 | Train Loss: 0.2116 Acc: 0.9286\n",
      "Epoch 15/15 | Train Loss: 0.2257 Acc: 0.9107\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7073 Acc: 0.6389\n",
      "Epoch 2/15 | Train Loss: 0.6151 Acc: 0.7103\n",
      "Epoch 3/15 | Train Loss: 0.5183 Acc: 0.7381\n",
      "Epoch 4/15 | Train Loss: 0.5154 Acc: 0.7421\n",
      "Epoch 5/15 | Train Loss: 0.4821 Acc: 0.7500\n",
      "Epoch 6/15 | Train Loss: 0.4810 Acc: 0.7937\n",
      "Epoch 7/15 | Train Loss: 0.4361 Acc: 0.7698\n",
      "Epoch 8/15 | Train Loss: 0.4614 Acc: 0.7897\n",
      "Epoch 9/15 | Train Loss: 0.4319 Acc: 0.7738\n",
      "Epoch 10/15 | Train Loss: 0.3553 Acc: 0.8532\n",
      "Epoch 11/15 | Train Loss: 0.3885 Acc: 0.8254\n",
      "Epoch 12/15 | Train Loss: 0.3534 Acc: 0.8492\n",
      "Epoch 13/15 | Train Loss: 0.3224 Acc: 0.8690\n",
      "Epoch 14/15 | Train Loss: 0.3619 Acc: 0.8571\n",
      "Epoch 15/15 | Train Loss: 0.3496 Acc: 0.8730\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6692 Acc: 0.6587\n",
      "Epoch 2/15 | Train Loss: 0.6486 Acc: 0.6468\n",
      "Epoch 3/15 | Train Loss: 0.5601 Acc: 0.7222\n",
      "Epoch 4/15 | Train Loss: 0.5417 Acc: 0.7103\n",
      "Epoch 5/15 | Train Loss: 0.4811 Acc: 0.7540\n",
      "Epoch 6/15 | Train Loss: 0.5046 Acc: 0.7659\n",
      "Epoch 7/15 | Train Loss: 0.4416 Acc: 0.8016\n",
      "Epoch 8/15 | Train Loss: 0.3823 Acc: 0.8373\n",
      "Epoch 9/15 | Train Loss: 0.4809 Acc: 0.7619\n",
      "Epoch 10/15 | Train Loss: 0.4344 Acc: 0.7857\n",
      "Epoch 11/15 | Train Loss: 0.4131 Acc: 0.8016\n",
      "Epoch 12/15 | Train Loss: 0.3899 Acc: 0.8175\n",
      "Epoch 13/15 | Train Loss: 0.3586 Acc: 0.8333\n",
      "Epoch 14/15 | Train Loss: 0.3847 Acc: 0.8135\n",
      "Epoch 15/15 | Train Loss: 0.3922 Acc: 0.8056\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6666 Acc: 0.6719\n",
      "Epoch 2/15 | Train Loss: 0.5822 Acc: 0.6759\n",
      "Epoch 3/15 | Train Loss: 0.5187 Acc: 0.7391\n",
      "Epoch 4/15 | Train Loss: 0.5947 Acc: 0.6601\n",
      "Epoch 5/15 | Train Loss: 0.5460 Acc: 0.7352\n",
      "Epoch 6/15 | Train Loss: 0.5198 Acc: 0.7549\n",
      "Epoch 7/15 | Train Loss: 0.4633 Acc: 0.7589\n",
      "Epoch 8/15 | Train Loss: 0.4927 Acc: 0.7549\n",
      "Epoch 9/15 | Train Loss: 0.4186 Acc: 0.8221\n",
      "Epoch 10/15 | Train Loss: 0.3571 Acc: 0.8379\n",
      "Epoch 11/15 | Train Loss: 0.4066 Acc: 0.8221\n",
      "Epoch 12/15 | Train Loss: 0.4154 Acc: 0.8221\n",
      "Epoch 13/15 | Train Loss: 0.4137 Acc: 0.8221\n",
      "Epoch 14/15 | Train Loss: 0.3576 Acc: 0.8696\n",
      "Epoch 15/15 | Train Loss: 0.3941 Acc: 0.8379\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6775 Acc: 0.6568\n",
      "Epoch 2/15 | Train Loss: 0.5182 Acc: 0.7881\n",
      "Epoch 3/15 | Train Loss: 0.5383 Acc: 0.7585\n",
      "Epoch 4/15 | Train Loss: 0.4600 Acc: 0.7924\n",
      "Epoch 5/15 | Train Loss: 0.4565 Acc: 0.7754\n",
      "Epoch 6/15 | Train Loss: 0.4455 Acc: 0.8136\n",
      "Epoch 7/15 | Train Loss: 0.4313 Acc: 0.8093\n",
      "Epoch 8/15 | Train Loss: 0.4641 Acc: 0.7839\n",
      "Epoch 9/15 | Train Loss: 0.4447 Acc: 0.8008\n",
      "Epoch 10/15 | Train Loss: 0.3802 Acc: 0.8305\n",
      "Epoch 11/15 | Train Loss: 0.4069 Acc: 0.8559\n",
      "Epoch 12/15 | Train Loss: 0.4092 Acc: 0.8305\n",
      "Epoch 13/15 | Train Loss: 0.3785 Acc: 0.8432\n",
      "Epoch 14/15 | Train Loss: 0.4179 Acc: 0.8178\n",
      "Epoch 15/15 | Train Loss: 0.4159 Acc: 0.8347\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5646 Acc: 0.7137\n",
      "Epoch 2/15 | Train Loss: 0.3961 Acc: 0.8282\n",
      "Epoch 3/15 | Train Loss: 0.4633 Acc: 0.8194\n",
      "Epoch 4/15 | Train Loss: 0.3599 Acc: 0.8546\n",
      "Epoch 5/15 | Train Loss: 0.4260 Acc: 0.8370\n",
      "Epoch 6/15 | Train Loss: 0.3640 Acc: 0.8546\n",
      "Epoch 7/15 | Train Loss: 0.3894 Acc: 0.8414\n",
      "Epoch 8/15 | Train Loss: 0.3401 Acc: 0.8811\n",
      "Epoch 9/15 | Train Loss: 0.3338 Acc: 0.8722\n",
      "Epoch 10/15 | Train Loss: 0.2386 Acc: 0.9163\n",
      "Epoch 11/15 | Train Loss: 0.2567 Acc: 0.9075\n",
      "Epoch 12/15 | Train Loss: 0.2648 Acc: 0.8899\n",
      "Epoch 13/15 | Train Loss: 0.2636 Acc: 0.8987\n",
      "Epoch 14/15 | Train Loss: 0.2714 Acc: 0.8722\n",
      "Epoch 15/15 | Train Loss: 0.2709 Acc: 0.8987\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.5min\n",
      "Epoch 1/15 | Train Loss: 0.7044 Acc: 0.6689\n",
      "Epoch 2/15 | Train Loss: 0.5415 Acc: 0.7534\n",
      "Epoch 3/15 | Train Loss: 0.4752 Acc: 0.7804\n",
      "Epoch 4/15 | Train Loss: 0.5233 Acc: 0.7162\n",
      "Epoch 5/15 | Train Loss: 0.4371 Acc: 0.7905\n",
      "Epoch 6/15 | Train Loss: 0.3892 Acc: 0.8041\n",
      "Epoch 7/15 | Train Loss: 0.3468 Acc: 0.8345\n",
      "Epoch 8/15 | Train Loss: 0.3963 Acc: 0.8176\n",
      "Epoch 9/15 | Train Loss: 0.3460 Acc: 0.8480\n",
      "Epoch 10/15 | Train Loss: 0.3339 Acc: 0.8446\n",
      "Epoch 11/15 | Train Loss: 0.3238 Acc: 0.8750\n",
      "Epoch 12/15 | Train Loss: 0.2970 Acc: 0.8649\n",
      "Epoch 13/15 | Train Loss: 0.3222 Acc: 0.8547\n",
      "Epoch 14/15 | Train Loss: 0.2973 Acc: 0.8851\n",
      "Epoch 15/15 | Train Loss: 0.2845 Acc: 0.8750\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5661 Acc: 0.6892\n",
      "Epoch 2/15 | Train Loss: 0.4903 Acc: 0.7432\n",
      "Epoch 3/15 | Train Loss: 0.4514 Acc: 0.7365\n",
      "Epoch 4/15 | Train Loss: 0.4147 Acc: 0.7804\n",
      "Epoch 5/15 | Train Loss: 0.4620 Acc: 0.7601\n",
      "Epoch 6/15 | Train Loss: 0.4235 Acc: 0.7500\n",
      "Epoch 7/15 | Train Loss: 0.4086 Acc: 0.7939\n",
      "Epoch 8/15 | Train Loss: 0.4065 Acc: 0.7872\n",
      "Epoch 9/15 | Train Loss: 0.3599 Acc: 0.8209\n",
      "Epoch 10/15 | Train Loss: 0.3947 Acc: 0.7973\n",
      "Epoch 11/15 | Train Loss: 0.3475 Acc: 0.8176\n",
      "Epoch 12/15 | Train Loss: 0.3347 Acc: 0.8480\n",
      "Epoch 13/15 | Train Loss: 0.3464 Acc: 0.8311\n",
      "Epoch 14/15 | Train Loss: 0.3627 Acc: 0.8277\n",
      "Epoch 15/15 | Train Loss: 0.3963 Acc: 0.8041\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6539 Acc: 0.6330\n",
      "Epoch 2/15 | Train Loss: 0.4966 Acc: 0.7475\n",
      "Epoch 3/15 | Train Loss: 0.5407 Acc: 0.7037\n",
      "Epoch 4/15 | Train Loss: 0.4708 Acc: 0.7576\n",
      "Epoch 5/15 | Train Loss: 0.4031 Acc: 0.8081\n",
      "Epoch 6/15 | Train Loss: 0.4177 Acc: 0.7845\n",
      "Epoch 7/15 | Train Loss: 0.4063 Acc: 0.8047\n",
      "Epoch 8/15 | Train Loss: 0.3570 Acc: 0.8182\n",
      "Epoch 9/15 | Train Loss: 0.3622 Acc: 0.8182\n",
      "Epoch 10/15 | Train Loss: 0.3214 Acc: 0.8552\n",
      "Epoch 11/15 | Train Loss: 0.2970 Acc: 0.8788\n",
      "Epoch 12/15 | Train Loss: 0.3178 Acc: 0.8316\n",
      "Epoch 13/15 | Train Loss: 0.3340 Acc: 0.8114\n",
      "Epoch 14/15 | Train Loss: 0.3227 Acc: 0.8451\n",
      "Epoch 15/15 | Train Loss: 0.3459 Acc: 0.8316\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5682 Acc: 0.7443\n",
      "Epoch 2/15 | Train Loss: 0.4721 Acc: 0.8015\n",
      "Epoch 3/15 | Train Loss: 0.4434 Acc: 0.8168\n",
      "Epoch 4/15 | Train Loss: 0.4642 Acc: 0.7824\n",
      "Epoch 5/15 | Train Loss: 0.4788 Acc: 0.7710\n",
      "Epoch 6/15 | Train Loss: 0.3875 Acc: 0.8206\n",
      "Epoch 7/15 | Train Loss: 0.4046 Acc: 0.8244\n",
      "Epoch 8/15 | Train Loss: 0.3565 Acc: 0.8321\n",
      "Epoch 9/15 | Train Loss: 0.3240 Acc: 0.8626\n",
      "Epoch 10/15 | Train Loss: 0.3816 Acc: 0.8168\n",
      "Epoch 11/15 | Train Loss: 0.3311 Acc: 0.8473\n",
      "Epoch 12/15 | Train Loss: 0.3553 Acc: 0.8511\n",
      "Epoch 13/15 | Train Loss: 0.3718 Acc: 0.8359\n",
      "Epoch 14/15 | Train Loss: 0.3715 Acc: 0.8244\n",
      "Epoch 15/15 | Train Loss: 0.3292 Acc: 0.8550\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6108 Acc: 0.6898\n",
      "Epoch 2/15 | Train Loss: 0.4082 Acc: 0.8449\n",
      "Epoch 3/15 | Train Loss: 0.3990 Acc: 0.8612\n",
      "Epoch 4/15 | Train Loss: 0.3450 Acc: 0.8612\n",
      "Epoch 5/15 | Train Loss: 0.3530 Acc: 0.8653\n",
      "Epoch 6/15 | Train Loss: 0.3464 Acc: 0.8571\n",
      "Epoch 7/15 | Train Loss: 0.3374 Acc: 0.8571\n",
      "Epoch 8/15 | Train Loss: 0.3086 Acc: 0.8816\n",
      "Epoch 9/15 | Train Loss: 0.2663 Acc: 0.8939\n",
      "Epoch 10/15 | Train Loss: 0.2603 Acc: 0.9020\n",
      "Epoch 11/15 | Train Loss: 0.2775 Acc: 0.8980\n",
      "Epoch 12/15 | Train Loss: 0.2866 Acc: 0.8531\n",
      "Epoch 13/15 | Train Loss: 0.2542 Acc: 0.8939\n",
      "Epoch 14/15 | Train Loss: 0.2434 Acc: 0.9102\n",
      "Epoch 15/15 | Train Loss: 0.3019 Acc: 0.8694\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7334 Acc: 0.6429\n",
      "Epoch 2/15 | Train Loss: 0.6782 Acc: 0.6429\n",
      "Epoch 3/15 | Train Loss: 0.5382 Acc: 0.7183\n",
      "Epoch 4/15 | Train Loss: 0.5129 Acc: 0.7341\n",
      "Epoch 5/15 | Train Loss: 0.4716 Acc: 0.7579\n",
      "Epoch 6/15 | Train Loss: 0.4006 Acc: 0.7857\n",
      "Epoch 7/15 | Train Loss: 0.4198 Acc: 0.8333\n",
      "Epoch 8/15 | Train Loss: 0.3976 Acc: 0.8175\n",
      "Epoch 9/15 | Train Loss: 0.3900 Acc: 0.8214\n",
      "Epoch 10/15 | Train Loss: 0.3871 Acc: 0.8254\n",
      "Epoch 11/15 | Train Loss: 0.3452 Acc: 0.8135\n",
      "Epoch 12/15 | Train Loss: 0.3462 Acc: 0.8611\n",
      "Epoch 13/15 | Train Loss: 0.2993 Acc: 0.8770\n",
      "Epoch 14/15 | Train Loss: 0.3490 Acc: 0.8452\n",
      "Epoch 15/15 | Train Loss: 0.3097 Acc: 0.8690\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7707 Acc: 0.5952\n",
      "Epoch 2/15 | Train Loss: 0.5787 Acc: 0.7222\n",
      "Epoch 3/15 | Train Loss: 0.6423 Acc: 0.6587\n",
      "Epoch 4/15 | Train Loss: 0.5919 Acc: 0.6905\n",
      "Epoch 5/15 | Train Loss: 0.4796 Acc: 0.7897\n",
      "Epoch 6/15 | Train Loss: 0.4456 Acc: 0.7659\n",
      "Epoch 7/15 | Train Loss: 0.4897 Acc: 0.7698\n",
      "Epoch 8/15 | Train Loss: 0.4865 Acc: 0.7500\n",
      "Epoch 9/15 | Train Loss: 0.4280 Acc: 0.8175\n",
      "Epoch 10/15 | Train Loss: 0.4186 Acc: 0.8135\n",
      "Epoch 11/15 | Train Loss: 0.4272 Acc: 0.7738\n",
      "Epoch 12/15 | Train Loss: 0.4932 Acc: 0.7778\n",
      "Epoch 13/15 | Train Loss: 0.3537 Acc: 0.8452\n",
      "Epoch 14/15 | Train Loss: 0.4295 Acc: 0.8056\n",
      "Epoch 15/15 | Train Loss: 0.3875 Acc: 0.8214\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6775 Acc: 0.6047\n",
      "Epoch 2/15 | Train Loss: 0.6101 Acc: 0.6640\n",
      "Epoch 3/15 | Train Loss: 0.5192 Acc: 0.7233\n",
      "Epoch 4/15 | Train Loss: 0.5054 Acc: 0.7431\n",
      "Epoch 5/15 | Train Loss: 0.5341 Acc: 0.7194\n",
      "Epoch 6/15 | Train Loss: 0.5019 Acc: 0.7510\n",
      "Epoch 7/15 | Train Loss: 0.4537 Acc: 0.7866\n",
      "Epoch 8/15 | Train Loss: 0.4131 Acc: 0.8142\n",
      "Epoch 9/15 | Train Loss: 0.4614 Acc: 0.7549\n",
      "Epoch 10/15 | Train Loss: 0.4238 Acc: 0.7984\n",
      "Epoch 11/15 | Train Loss: 0.4704 Acc: 0.7510\n",
      "Epoch 12/15 | Train Loss: 0.4181 Acc: 0.8063\n",
      "Epoch 13/15 | Train Loss: 0.3956 Acc: 0.8261\n",
      "Epoch 14/15 | Train Loss: 0.3731 Acc: 0.8458\n",
      "Epoch 15/15 | Train Loss: 0.4215 Acc: 0.7708\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7007 Acc: 0.6314\n",
      "Epoch 2/15 | Train Loss: 0.5818 Acc: 0.7373\n",
      "Epoch 3/15 | Train Loss: 0.5239 Acc: 0.7585\n",
      "Epoch 4/15 | Train Loss: 0.4822 Acc: 0.7669\n",
      "Epoch 5/15 | Train Loss: 0.5045 Acc: 0.7754\n",
      "Epoch 6/15 | Train Loss: 0.4804 Acc: 0.7881\n",
      "Epoch 7/15 | Train Loss: 0.4283 Acc: 0.7966\n",
      "Epoch 8/15 | Train Loss: 0.4497 Acc: 0.8008\n",
      "Epoch 9/15 | Train Loss: 0.4068 Acc: 0.8347\n",
      "Epoch 10/15 | Train Loss: 0.3933 Acc: 0.8136\n",
      "Epoch 11/15 | Train Loss: 0.3875 Acc: 0.8347\n",
      "Epoch 12/15 | Train Loss: 0.4259 Acc: 0.8220\n",
      "Epoch 13/15 | Train Loss: 0.3825 Acc: 0.8178\n",
      "Epoch 14/15 | Train Loss: 0.3830 Acc: 0.8602\n",
      "Epoch 15/15 | Train Loss: 0.3743 Acc: 0.8432\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5312 Acc: 0.7357\n",
      "Epoch 2/15 | Train Loss: 0.4459 Acc: 0.8370\n",
      "Epoch 3/15 | Train Loss: 0.4522 Acc: 0.8458\n",
      "Epoch 4/15 | Train Loss: 0.3775 Acc: 0.8546\n",
      "Epoch 5/15 | Train Loss: 0.3841 Acc: 0.8370\n",
      "Epoch 6/15 | Train Loss: 0.3536 Acc: 0.8767\n",
      "Epoch 7/15 | Train Loss: 0.3273 Acc: 0.8370\n",
      "Epoch 8/15 | Train Loss: 0.2716 Acc: 0.8987\n",
      "Epoch 9/15 | Train Loss: 0.3232 Acc: 0.8899\n",
      "Epoch 10/15 | Train Loss: 0.3243 Acc: 0.8634\n",
      "Epoch 11/15 | Train Loss: 0.3223 Acc: 0.8722\n",
      "Epoch 12/15 | Train Loss: 0.2960 Acc: 0.8767\n",
      "Epoch 13/15 | Train Loss: 0.2947 Acc: 0.8811\n",
      "Epoch 14/15 | Train Loss: 0.2446 Acc: 0.9119\n",
      "Epoch 15/15 | Train Loss: 0.2870 Acc: 0.8987\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6175 Acc: 0.7546\n",
      "Epoch 2/15 | Train Loss: 0.4532 Acc: 0.7676\n",
      "Epoch 3/15 | Train Loss: 0.3837 Acc: 0.7885\n",
      "Epoch 4/15 | Train Loss: 0.3429 Acc: 0.8068\n",
      "Epoch 5/15 | Train Loss: 0.2959 Acc: 0.8773\n",
      "Epoch 6/15 | Train Loss: 0.3452 Acc: 0.8303\n",
      "Epoch 7/15 | Train Loss: 0.3283 Acc: 0.8277\n",
      "Epoch 8/15 | Train Loss: 0.2829 Acc: 0.8564\n",
      "Epoch 9/15 | Train Loss: 0.2302 Acc: 0.8851\n",
      "Epoch 10/15 | Train Loss: 0.2592 Acc: 0.8695\n",
      "Epoch 11/15 | Train Loss: 0.2581 Acc: 0.8799\n",
      "Epoch 12/15 | Train Loss: 0.2478 Acc: 0.8903\n",
      "Epoch 13/15 | Train Loss: 0.2483 Acc: 0.8825\n",
      "Epoch 14/15 | Train Loss: 0.2206 Acc: 0.9138\n",
      "Epoch 15/15 | Train Loss: 0.2176 Acc: 0.9086\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5099 Acc: 0.7493\n",
      "Epoch 2/15 | Train Loss: 0.3614 Acc: 0.7990\n",
      "Epoch 3/15 | Train Loss: 0.3841 Acc: 0.7963\n",
      "Epoch 4/15 | Train Loss: 0.3602 Acc: 0.8120\n",
      "Epoch 5/15 | Train Loss: 0.3339 Acc: 0.8407\n",
      "Epoch 6/15 | Train Loss: 0.3699 Acc: 0.8042\n",
      "Epoch 7/15 | Train Loss: 0.3502 Acc: 0.8120\n",
      "Epoch 8/15 | Train Loss: 0.3103 Acc: 0.8486\n",
      "Epoch 9/15 | Train Loss: 0.2776 Acc: 0.8668\n",
      "Epoch 10/15 | Train Loss: 0.2994 Acc: 0.8616\n",
      "Epoch 11/15 | Train Loss: 0.2876 Acc: 0.8695\n",
      "Epoch 12/15 | Train Loss: 0.2741 Acc: 0.8747\n",
      "Epoch 13/15 | Train Loss: 0.2961 Acc: 0.8433\n",
      "Epoch 14/15 | Train Loss: 0.2659 Acc: 0.8695\n",
      "Epoch 15/15 | Train Loss: 0.2613 Acc: 0.8825\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5211 Acc: 0.7448\n",
      "Epoch 2/15 | Train Loss: 0.4233 Acc: 0.7891\n",
      "Epoch 3/15 | Train Loss: 0.4180 Acc: 0.7760\n",
      "Epoch 4/15 | Train Loss: 0.3479 Acc: 0.8125\n",
      "Epoch 5/15 | Train Loss: 0.3362 Acc: 0.8203\n",
      "Epoch 6/15 | Train Loss: 0.3614 Acc: 0.8151\n",
      "Epoch 7/15 | Train Loss: 0.3244 Acc: 0.8359\n",
      "Epoch 8/15 | Train Loss: 0.3227 Acc: 0.8333\n",
      "Epoch 9/15 | Train Loss: 0.3029 Acc: 0.8516\n",
      "Epoch 10/15 | Train Loss: 0.2725 Acc: 0.8724\n",
      "Epoch 11/15 | Train Loss: 0.2971 Acc: 0.8568\n",
      "Epoch 12/15 | Train Loss: 0.3110 Acc: 0.8594\n",
      "Epoch 13/15 | Train Loss: 0.2609 Acc: 0.8828\n",
      "Epoch 14/15 | Train Loss: 0.2745 Acc: 0.8750\n",
      "Epoch 15/15 | Train Loss: 0.2393 Acc: 0.9062\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5061 Acc: 0.7611\n",
      "Epoch 2/15 | Train Loss: 0.3897 Acc: 0.8217\n",
      "Epoch 3/15 | Train Loss: 0.3550 Acc: 0.8726\n",
      "Epoch 4/15 | Train Loss: 0.3616 Acc: 0.8344\n",
      "Epoch 5/15 | Train Loss: 0.3871 Acc: 0.8280\n",
      "Epoch 6/15 | Train Loss: 0.3269 Acc: 0.8631\n",
      "Epoch 7/15 | Train Loss: 0.3355 Acc: 0.8535\n",
      "Epoch 8/15 | Train Loss: 0.3105 Acc: 0.8631\n",
      "Epoch 9/15 | Train Loss: 0.2815 Acc: 0.8662\n",
      "Epoch 10/15 | Train Loss: 0.2654 Acc: 0.8822\n",
      "Epoch 11/15 | Train Loss: 0.2772 Acc: 0.8822\n",
      "Epoch 12/15 | Train Loss: 0.2843 Acc: 0.8949\n",
      "Epoch 13/15 | Train Loss: 0.2984 Acc: 0.8758\n",
      "Epoch 14/15 | Train Loss: 0.2948 Acc: 0.8758\n",
      "Epoch 15/15 | Train Loss: 0.2726 Acc: 0.8917\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.4827 Acc: 0.8536\n",
      "Epoch 2/15 | Train Loss: 0.3808 Acc: 0.8250\n",
      "Epoch 3/15 | Train Loss: 0.3543 Acc: 0.8750\n",
      "Epoch 4/15 | Train Loss: 0.3471 Acc: 0.8821\n",
      "Epoch 5/15 | Train Loss: 0.3214 Acc: 0.8750\n",
      "Epoch 6/15 | Train Loss: 0.2919 Acc: 0.8929\n",
      "Epoch 7/15 | Train Loss: 0.2875 Acc: 0.8929\n",
      "Epoch 8/15 | Train Loss: 0.2859 Acc: 0.8821\n",
      "Epoch 9/15 | Train Loss: 0.2257 Acc: 0.9179\n",
      "Epoch 10/15 | Train Loss: 0.2447 Acc: 0.9214\n",
      "Epoch 11/15 | Train Loss: 0.2440 Acc: 0.9000\n",
      "Epoch 12/15 | Train Loss: 0.2356 Acc: 0.9000\n",
      "Epoch 13/15 | Train Loss: 0.2422 Acc: 0.9179\n",
      "Epoch 14/15 | Train Loss: 0.2345 Acc: 0.9250\n",
      "Epoch 15/15 | Train Loss: 0.2026 Acc: 0.9357\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6605 Acc: 0.6667\n",
      "Epoch 2/15 | Train Loss: 0.5445 Acc: 0.7143\n",
      "Epoch 3/15 | Train Loss: 0.5225 Acc: 0.7659\n",
      "Epoch 4/15 | Train Loss: 0.5012 Acc: 0.7579\n",
      "Epoch 5/15 | Train Loss: 0.4837 Acc: 0.7778\n",
      "Epoch 6/15 | Train Loss: 0.5038 Acc: 0.7619\n",
      "Epoch 7/15 | Train Loss: 0.4322 Acc: 0.7857\n",
      "Epoch 8/15 | Train Loss: 0.3867 Acc: 0.8056\n",
      "Epoch 9/15 | Train Loss: 0.4074 Acc: 0.7857\n",
      "Epoch 10/15 | Train Loss: 0.3738 Acc: 0.8452\n",
      "Epoch 11/15 | Train Loss: 0.3925 Acc: 0.8333\n",
      "Epoch 12/15 | Train Loss: 0.3351 Acc: 0.8611\n",
      "Epoch 13/15 | Train Loss: 0.3315 Acc: 0.8532\n",
      "Epoch 14/15 | Train Loss: 0.3148 Acc: 0.8611\n",
      "Epoch 15/15 | Train Loss: 0.3316 Acc: 0.8571\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7384 Acc: 0.6032\n",
      "Epoch 2/15 | Train Loss: 0.6111 Acc: 0.6905\n",
      "Epoch 3/15 | Train Loss: 0.5223 Acc: 0.7183\n",
      "Epoch 4/15 | Train Loss: 0.5423 Acc: 0.7024\n",
      "Epoch 5/15 | Train Loss: 0.5043 Acc: 0.7540\n",
      "Epoch 6/15 | Train Loss: 0.4534 Acc: 0.7817\n",
      "Epoch 7/15 | Train Loss: 0.4419 Acc: 0.7738\n",
      "Epoch 8/15 | Train Loss: 0.4493 Acc: 0.7857\n",
      "Epoch 9/15 | Train Loss: 0.4335 Acc: 0.7619\n",
      "Epoch 10/15 | Train Loss: 0.4287 Acc: 0.7897\n",
      "Epoch 11/15 | Train Loss: 0.4429 Acc: 0.8016\n",
      "Epoch 12/15 | Train Loss: 0.4172 Acc: 0.8214\n",
      "Epoch 13/15 | Train Loss: 0.3765 Acc: 0.8413\n",
      "Epoch 14/15 | Train Loss: 0.3873 Acc: 0.8135\n",
      "Epoch 15/15 | Train Loss: 0.3816 Acc: 0.8056\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6783 Acc: 0.6482\n",
      "Epoch 2/15 | Train Loss: 0.6352 Acc: 0.6443\n",
      "Epoch 3/15 | Train Loss: 0.5820 Acc: 0.7233\n",
      "Epoch 4/15 | Train Loss: 0.5184 Acc: 0.7194\n",
      "Epoch 5/15 | Train Loss: 0.5436 Acc: 0.6917\n",
      "Epoch 6/15 | Train Loss: 0.4147 Acc: 0.8103\n",
      "Epoch 7/15 | Train Loss: 0.4675 Acc: 0.7905\n",
      "Epoch 8/15 | Train Loss: 0.4964 Acc: 0.7312\n",
      "Epoch 9/15 | Train Loss: 0.4366 Acc: 0.8103\n",
      "Epoch 10/15 | Train Loss: 0.4622 Acc: 0.7549\n",
      "Epoch 11/15 | Train Loss: 0.4668 Acc: 0.7589\n",
      "Epoch 12/15 | Train Loss: 0.4463 Acc: 0.7826\n",
      "Epoch 13/15 | Train Loss: 0.3887 Acc: 0.8221\n",
      "Epoch 14/15 | Train Loss: 0.3857 Acc: 0.8142\n",
      "Epoch 15/15 | Train Loss: 0.3965 Acc: 0.8221\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6112 Acc: 0.6653\n",
      "Epoch 2/15 | Train Loss: 0.5249 Acc: 0.7797\n",
      "Epoch 3/15 | Train Loss: 0.5105 Acc: 0.7542\n",
      "Epoch 4/15 | Train Loss: 0.4854 Acc: 0.7585\n",
      "Epoch 5/15 | Train Loss: 0.4216 Acc: 0.7881\n",
      "Epoch 6/15 | Train Loss: 0.4921 Acc: 0.7839\n",
      "Epoch 7/15 | Train Loss: 0.4634 Acc: 0.7839\n",
      "Epoch 8/15 | Train Loss: 0.4442 Acc: 0.7966\n",
      "Epoch 9/15 | Train Loss: 0.3698 Acc: 0.8263\n",
      "Epoch 10/15 | Train Loss: 0.4265 Acc: 0.8220\n",
      "Epoch 11/15 | Train Loss: 0.3776 Acc: 0.8390\n",
      "Epoch 12/15 | Train Loss: 0.3584 Acc: 0.8305\n",
      "Epoch 13/15 | Train Loss: 0.3266 Acc: 0.8517\n",
      "Epoch 14/15 | Train Loss: 0.3554 Acc: 0.8559\n",
      "Epoch 15/15 | Train Loss: 0.4116 Acc: 0.8263\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.4886 Acc: 0.7974\n",
      "Epoch 2/15 | Train Loss: 0.4216 Acc: 0.8326\n",
      "Epoch 3/15 | Train Loss: 0.4103 Acc: 0.8546\n",
      "Epoch 4/15 | Train Loss: 0.3909 Acc: 0.8282\n",
      "Epoch 5/15 | Train Loss: 0.3799 Acc: 0.8634\n",
      "Epoch 6/15 | Train Loss: 0.3856 Acc: 0.8238\n",
      "Epoch 7/15 | Train Loss: 0.3358 Acc: 0.8590\n",
      "Epoch 8/15 | Train Loss: 0.2995 Acc: 0.8855\n",
      "Epoch 9/15 | Train Loss: 0.3131 Acc: 0.8634\n",
      "Epoch 10/15 | Train Loss: 0.3111 Acc: 0.8943\n",
      "Epoch 11/15 | Train Loss: 0.2364 Acc: 0.8987\n",
      "Epoch 12/15 | Train Loss: 0.3248 Acc: 0.8811\n",
      "Epoch 13/15 | Train Loss: 0.2536 Acc: 0.9031\n",
      "Epoch 14/15 | Train Loss: 0.2542 Acc: 0.9075\n",
      "Epoch 15/15 | Train Loss: 0.2615 Acc: 0.9075\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5273 Acc: 0.7362\n",
      "Epoch 2/15 | Train Loss: 0.3886 Acc: 0.8234\n",
      "Epoch 3/15 | Train Loss: 0.3954 Acc: 0.8005\n",
      "Epoch 4/15 | Train Loss: 0.3559 Acc: 0.8303\n",
      "Epoch 5/15 | Train Loss: 0.3181 Acc: 0.8417\n",
      "Epoch 6/15 | Train Loss: 0.3433 Acc: 0.8234\n",
      "Epoch 7/15 | Train Loss: 0.3271 Acc: 0.8486\n",
      "Epoch 8/15 | Train Loss: 0.3040 Acc: 0.8601\n",
      "Epoch 9/15 | Train Loss: 0.2690 Acc: 0.8716\n",
      "Epoch 10/15 | Train Loss: 0.2798 Acc: 0.8693\n",
      "Epoch 11/15 | Train Loss: 0.2766 Acc: 0.8693\n",
      "Epoch 12/15 | Train Loss: 0.2797 Acc: 0.8830\n",
      "Epoch 13/15 | Train Loss: 0.2720 Acc: 0.8853\n",
      "Epoch 14/15 | Train Loss: 0.2614 Acc: 0.8876\n",
      "Epoch 15/15 | Train Loss: 0.2598 Acc: 0.8830\n",
      "Fold 7 Test Accuracy: 0.5795\n",
      "===== Fold 8 =====\n",
      "Epoch 1: Generator Loss = 9.7821, Discriminator Loss = 8.7727\n",
      "Epoch 2: Generator Loss = 10.5485, Discriminator Loss = 8.3433\n",
      "Epoch 3: Generator Loss = 16.5651, Discriminator Loss = 5.6799\n",
      "Epoch 4: Generator Loss = 20.1779, Discriminator Loss = 7.0633\n",
      "Epoch 5: Generator Loss = 21.8184, Discriminator Loss = 5.7899\n",
      "Epoch 6: Generator Loss = 24.0720, Discriminator Loss = 6.4973\n",
      "Epoch 7: Generator Loss = 26.0699, Discriminator Loss = 5.0997\n",
      "Epoch 8: Generator Loss = 28.8037, Discriminator Loss = 4.8067\n",
      "Epoch 9: Generator Loss = 27.7610, Discriminator Loss = 3.9936\n",
      "Epoch 10: Generator Loss = 23.5198, Discriminator Loss = 7.8450\n",
      "Epoch 11: Generator Loss = 24.0802, Discriminator Loss = 10.8947\n",
      "Epoch 12: Generator Loss = 20.6014, Discriminator Loss = 7.1368\n",
      "Epoch 13: Generator Loss = 16.0696, Discriminator Loss = 9.6293\n",
      "Epoch 14: Generator Loss = 13.1277, Discriminator Loss = 9.0490\n",
      "Epoch 15: Generator Loss = 15.4033, Discriminator Loss = 9.7302\n",
      "Epoch 16: Generator Loss = 14.9084, Discriminator Loss = 8.1649\n",
      "Epoch 17: Generator Loss = 19.6705, Discriminator Loss = 7.7383\n",
      "Epoch 18: Generator Loss = 21.2503, Discriminator Loss = 9.3601\n",
      "Epoch 19: Generator Loss = 22.3437, Discriminator Loss = 7.2834\n",
      "Epoch 20: Generator Loss = 18.1885, Discriminator Loss = 7.0705\n",
      "Epoch 21: Generator Loss = 19.1499, Discriminator Loss = 8.7929\n",
      "Epoch 22: Generator Loss = 22.0372, Discriminator Loss = 9.6955\n",
      "Epoch 23: Generator Loss = 19.3316, Discriminator Loss = 7.2699\n",
      "Epoch 24: Generator Loss = 20.3177, Discriminator Loss = 7.9325\n",
      "Epoch 25: Generator Loss = 18.7560, Discriminator Loss = 8.7593\n",
      "Epoch 26: Generator Loss = 20.5018, Discriminator Loss = 8.7049\n",
      "Epoch 27: Generator Loss = 24.9821, Discriminator Loss = 8.4516\n",
      "Epoch 28: Generator Loss = 25.0734, Discriminator Loss = 7.2832\n",
      "Epoch 29: Generator Loss = 22.9938, Discriminator Loss = 7.4438\n",
      "Epoch 30: Generator Loss = 18.9510, Discriminator Loss = 7.3391\n",
      "Epoch 31: Generator Loss = 21.4267, Discriminator Loss = 8.5296\n",
      "Epoch 32: Generator Loss = 20.7727, Discriminator Loss = 7.8666\n",
      "Epoch 33: Generator Loss = 15.2085, Discriminator Loss = 9.2935\n",
      "Epoch 34: Generator Loss = 19.6727, Discriminator Loss = 7.3925\n",
      "Epoch 35: Generator Loss = 18.3605, Discriminator Loss = 8.7624\n",
      "Epoch 36: Generator Loss = 15.1956, Discriminator Loss = 7.0708\n",
      "Epoch 37: Generator Loss = 19.5379, Discriminator Loss = 7.7551\n",
      "Epoch 38: Generator Loss = 17.8070, Discriminator Loss = 8.2606\n",
      "Epoch 39: Generator Loss = 18.7964, Discriminator Loss = 7.6292\n",
      "Epoch 40: Generator Loss = 14.9938, Discriminator Loss = 8.5041\n",
      "Epoch 41: Generator Loss = 18.0600, Discriminator Loss = 9.1979\n",
      "Epoch 42: Generator Loss = 16.1311, Discriminator Loss = 7.4673\n",
      "Epoch 43: Generator Loss = 18.3180, Discriminator Loss = 7.3228\n",
      "Epoch 44: Generator Loss = 17.1233, Discriminator Loss = 8.7288\n",
      "Epoch 45: Generator Loss = 14.7796, Discriminator Loss = 8.6307\n",
      "Epoch 46: Generator Loss = 17.6077, Discriminator Loss = 9.0115\n",
      "Epoch 47: Generator Loss = 16.5264, Discriminator Loss = 7.2681\n",
      "Epoch 48: Generator Loss = 18.0271, Discriminator Loss = 8.2699\n",
      "Epoch 49: Generator Loss = 14.8097, Discriminator Loss = 8.1684\n",
      "Epoch 50: Generator Loss = 19.1940, Discriminator Loss = 6.8660\n",
      "Epoch 51: Generator Loss = 15.2313, Discriminator Loss = 8.1770\n",
      "Epoch 52: Generator Loss = 19.8641, Discriminator Loss = 9.0448\n",
      "Epoch 53: Generator Loss = 19.3421, Discriminator Loss = 7.8760\n",
      "Epoch 54: Generator Loss = 15.9520, Discriminator Loss = 6.7902\n",
      "Epoch 55: Generator Loss = 20.8627, Discriminator Loss = 6.9300\n",
      "Epoch 56: Generator Loss = 18.8682, Discriminator Loss = 8.4295\n",
      "Epoch 57: Generator Loss = 17.2508, Discriminator Loss = 7.0390\n",
      "Epoch 58: Generator Loss = 25.9233, Discriminator Loss = 5.5866\n",
      "Epoch 59: Generator Loss = 21.6839, Discriminator Loss = 10.5968\n",
      "Epoch 60: Generator Loss = 15.5181, Discriminator Loss = 7.3592\n",
      "Epoch 61: Generator Loss = 22.1953, Discriminator Loss = 6.5839\n",
      "Epoch 62: Generator Loss = 23.6928, Discriminator Loss = 7.6563\n",
      "Epoch 63: Generator Loss = 21.0324, Discriminator Loss = 7.0664\n",
      "Epoch 64: Generator Loss = 21.9354, Discriminator Loss = 5.1339\n",
      "Epoch 65: Generator Loss = 27.0611, Discriminator Loss = 6.7018\n",
      "Epoch 66: Generator Loss = 25.0295, Discriminator Loss = 4.7739\n",
      "Epoch 67: Generator Loss = 27.6455, Discriminator Loss = 6.1375\n",
      "Epoch 68: Generator Loss = 29.7826, Discriminator Loss = 4.0550\n",
      "Epoch 69: Generator Loss = 36.2188, Discriminator Loss = 4.1459\n",
      "Epoch 70: Generator Loss = 36.4932, Discriminator Loss = 5.9194\n",
      "Epoch 71: Generator Loss = 20.3585, Discriminator Loss = 6.3972\n",
      "Epoch 72: Generator Loss = 40.3406, Discriminator Loss = 3.6952\n",
      "Epoch 73: Generator Loss = 25.4471, Discriminator Loss = 7.0237\n",
      "Epoch 74: Generator Loss = 34.6792, Discriminator Loss = 3.2686\n",
      "Epoch 75: Generator Loss = 30.3283, Discriminator Loss = 4.3206\n",
      "Epoch 76: Generator Loss = 34.0509, Discriminator Loss = 3.6663\n",
      "Epoch 77: Generator Loss = 33.8218, Discriminator Loss = 3.4283\n",
      "Epoch 78: Generator Loss = 35.7976, Discriminator Loss = 2.3170\n",
      "Epoch 79: Generator Loss = 42.0167, Discriminator Loss = 4.1784\n",
      "Epoch 80: Generator Loss = 44.3794, Discriminator Loss = 2.2960\n",
      "Epoch 81: Generator Loss = 51.0016, Discriminator Loss = 1.9891\n",
      "Epoch 82: Generator Loss = 49.6359, Discriminator Loss = 1.6500\n",
      "Epoch 83: Generator Loss = 47.4338, Discriminator Loss = 4.2547\n",
      "Epoch 84: Generator Loss = 39.1936, Discriminator Loss = 3.0276\n",
      "Epoch 85: Generator Loss = 41.0760, Discriminator Loss = 2.1562\n",
      "Epoch 86: Generator Loss = 54.0365, Discriminator Loss = 1.3805\n",
      "Epoch 87: Generator Loss = 51.9897, Discriminator Loss = 1.7258\n",
      "Epoch 88: Generator Loss = 49.4652, Discriminator Loss = 2.1246\n",
      "Epoch 89: Generator Loss = 54.6078, Discriminator Loss = 1.7697\n",
      "Epoch 90: Generator Loss = 74.0371, Discriminator Loss = 1.2735\n",
      "Epoch 91: Generator Loss = 75.6493, Discriminator Loss = 1.2211\n",
      "Epoch 92: Generator Loss = 72.6402, Discriminator Loss = 1.1616\n",
      "Epoch 93: Generator Loss = 62.6481, Discriminator Loss = 2.6044\n",
      "Epoch 94: Generator Loss = 59.4902, Discriminator Loss = 4.3429\n",
      "Epoch 95: Generator Loss = 60.1467, Discriminator Loss = 2.0203\n",
      "Epoch 96: Generator Loss = 50.0875, Discriminator Loss = 1.3060\n",
      "Epoch 97: Generator Loss = 64.5245, Discriminator Loss = 1.1160\n",
      "Epoch 98: Generator Loss = 81.3686, Discriminator Loss = 2.5060\n",
      "Epoch 99: Generator Loss = 55.8291, Discriminator Loss = 1.5055\n",
      "Epoch 100: Generator Loss = 62.4888, Discriminator Loss = 2.3177\n",
      "Epoch 101: Generator Loss = 58.0550, Discriminator Loss = 1.2037\n",
      "Epoch 102: Generator Loss = 76.4569, Discriminator Loss = 1.4005\n",
      "Epoch 103: Generator Loss = 68.1657, Discriminator Loss = 0.7328\n",
      "Epoch 104: Generator Loss = 51.6017, Discriminator Loss = 0.9232\n",
      "Epoch 105: Generator Loss = 72.4203, Discriminator Loss = 1.0037\n",
      "Epoch 106: Generator Loss = 75.4415, Discriminator Loss = 1.3106\n",
      "Epoch 107: Generator Loss = 58.6178, Discriminator Loss = 1.5398\n",
      "Epoch 108: Generator Loss = 59.5701, Discriminator Loss = 1.6362\n",
      "Epoch 109: Generator Loss = 78.9809, Discriminator Loss = 3.4236\n",
      "Epoch 110: Generator Loss = 51.3117, Discriminator Loss = 3.7182\n",
      "Epoch 111: Generator Loss = 56.7544, Discriminator Loss = 2.0610\n",
      "Epoch 112: Generator Loss = 77.9412, Discriminator Loss = 0.6728\n",
      "Epoch 113: Generator Loss = 75.1033, Discriminator Loss = 0.5864\n",
      "Epoch 114: Generator Loss = 70.4147, Discriminator Loss = 0.8446\n",
      "Epoch 115: Generator Loss = 77.4725, Discriminator Loss = 1.1243\n",
      "Epoch 116: Generator Loss = 84.2181, Discriminator Loss = 0.8597\n",
      "Epoch 117: Generator Loss = 96.9657, Discriminator Loss = 1.5366\n",
      "Epoch 118: Generator Loss = 110.6422, Discriminator Loss = 1.1162\n",
      "Epoch 119: Generator Loss = 83.6464, Discriminator Loss = 3.4008\n",
      "Epoch 120: Generator Loss = 54.1038, Discriminator Loss = 1.9243\n",
      "Epoch 121: Generator Loss = 74.2767, Discriminator Loss = 2.0476\n",
      "Epoch 122: Generator Loss = 74.0336, Discriminator Loss = 0.9285\n",
      "Epoch 123: Generator Loss = 52.3975, Discriminator Loss = 2.7586\n",
      "Epoch 124: Generator Loss = 79.9261, Discriminator Loss = 1.6611\n",
      "Epoch 125: Generator Loss = 69.0007, Discriminator Loss = 1.4714\n",
      "Epoch 126: Generator Loss = 75.6359, Discriminator Loss = 0.7613\n",
      "Epoch 127: Generator Loss = 68.7826, Discriminator Loss = 2.4712\n",
      "Epoch 128: Generator Loss = 87.8610, Discriminator Loss = 1.9320\n",
      "Epoch 129: Generator Loss = 57.3695, Discriminator Loss = 1.8679\n",
      "Epoch 130: Generator Loss = 72.1226, Discriminator Loss = 0.8771\n",
      "Epoch 131: Generator Loss = 84.2667, Discriminator Loss = 0.3721\n",
      "Epoch 132: Generator Loss = 73.8519, Discriminator Loss = 0.9898\n",
      "Epoch 133: Generator Loss = 89.3822, Discriminator Loss = 0.5796\n",
      "Epoch 134: Generator Loss = 59.2100, Discriminator Loss = 6.3630\n",
      "Epoch 135: Generator Loss = 84.6613, Discriminator Loss = 1.9838\n",
      "Epoch 136: Generator Loss = 80.6443, Discriminator Loss = 0.5857\n",
      "Epoch 137: Generator Loss = 76.5169, Discriminator Loss = 0.6452\n",
      "Epoch 138: Generator Loss = 97.3217, Discriminator Loss = 1.3026\n",
      "Epoch 139: Generator Loss = 80.0865, Discriminator Loss = 0.6333\n",
      "Epoch 140: Generator Loss = 69.7124, Discriminator Loss = 1.0227\n",
      "Epoch 141: Generator Loss = 88.5905, Discriminator Loss = 0.7300\n",
      "Epoch 142: Generator Loss = 87.0012, Discriminator Loss = 0.5020\n",
      "Epoch 143: Generator Loss = 89.7006, Discriminator Loss = 0.5426\n",
      "Epoch 144: Generator Loss = 80.0188, Discriminator Loss = 0.3207\n",
      "Epoch 145: Generator Loss = 70.9601, Discriminator Loss = 0.4806\n",
      "Epoch 146: Generator Loss = 72.9044, Discriminator Loss = 1.4813\n",
      "Epoch 147: Generator Loss = 71.2019, Discriminator Loss = 1.5928\n",
      "Epoch 148: Generator Loss = 79.1522, Discriminator Loss = 0.4909\n",
      "Epoch 149: Generator Loss = 78.9416, Discriminator Loss = 0.6736\n",
      "Epoch 150: Generator Loss = 71.3373, Discriminator Loss = 0.7168\n",
      "Epoch 151: Generator Loss = 103.0607, Discriminator Loss = 0.5362\n",
      "Epoch 152: Generator Loss = 90.0811, Discriminator Loss = 0.6071\n",
      "Epoch 153: Generator Loss = 98.6174, Discriminator Loss = 0.5185\n",
      "Epoch 154: Generator Loss = 89.0770, Discriminator Loss = 2.0688\n",
      "Epoch 155: Generator Loss = 71.6753, Discriminator Loss = 0.9123\n",
      "Epoch 156: Generator Loss = 91.5018, Discriminator Loss = 0.4979\n",
      "Epoch 157: Generator Loss = 104.6231, Discriminator Loss = 9.6707\n",
      "Epoch 158: Generator Loss = 46.8693, Discriminator Loss = 8.5896\n",
      "Epoch 159: Generator Loss = 50.9127, Discriminator Loss = 2.3684\n",
      "Epoch 160: Generator Loss = 55.3254, Discriminator Loss = 1.8414\n",
      "Epoch 161: Generator Loss = 54.3320, Discriminator Loss = 2.0422\n",
      "Epoch 162: Generator Loss = 53.7414, Discriminator Loss = 6.9585\n",
      "Epoch 163: Generator Loss = 55.8976, Discriminator Loss = 5.9056\n",
      "Epoch 164: Generator Loss = 47.4456, Discriminator Loss = 4.0598\n",
      "Epoch 165: Generator Loss = 61.9573, Discriminator Loss = 1.7093\n",
      "Epoch 166: Generator Loss = 57.2335, Discriminator Loss = 1.9389\n",
      "Epoch 167: Generator Loss = 51.5886, Discriminator Loss = 2.9865\n",
      "Epoch 168: Generator Loss = 58.0761, Discriminator Loss = 1.8557\n",
      "Epoch 169: Generator Loss = 67.3685, Discriminator Loss = 1.4421\n",
      "Epoch 170: Generator Loss = 58.6045, Discriminator Loss = 1.8616\n",
      "Epoch 171: Generator Loss = 72.6241, Discriminator Loss = 2.1430\n",
      "Epoch 172: Generator Loss = 54.1510, Discriminator Loss = 1.1939\n",
      "Epoch 173: Generator Loss = 53.8895, Discriminator Loss = 0.6222\n",
      "Epoch 174: Generator Loss = 75.7838, Discriminator Loss = 0.9574\n",
      "Epoch 175: Generator Loss = 57.7870, Discriminator Loss = 1.8800\n",
      "Epoch 176: Generator Loss = 81.6391, Discriminator Loss = 2.0885\n",
      "Epoch 177: Generator Loss = 71.3903, Discriminator Loss = 1.9820\n",
      "Epoch 178: Generator Loss = 59.7388, Discriminator Loss = 1.1329\n",
      "Epoch 179: Generator Loss = 62.4051, Discriminator Loss = 1.3433\n",
      "Epoch 180: Generator Loss = 68.2016, Discriminator Loss = 1.3654\n",
      "Epoch 181: Generator Loss = 60.4527, Discriminator Loss = 1.2504\n",
      "Epoch 182: Generator Loss = 69.6117, Discriminator Loss = 0.9340\n",
      "Epoch 183: Generator Loss = 52.4109, Discriminator Loss = 1.0453\n",
      "Epoch 184: Generator Loss = 68.3726, Discriminator Loss = 1.1004\n",
      "Epoch 185: Generator Loss = 49.8019, Discriminator Loss = 0.5983\n",
      "Epoch 186: Generator Loss = 77.5290, Discriminator Loss = 0.4220\n",
      "Epoch 187: Generator Loss = 86.7734, Discriminator Loss = 0.9962\n",
      "Epoch 188: Generator Loss = 51.8302, Discriminator Loss = 7.4775\n",
      "Epoch 189: Generator Loss = 56.7032, Discriminator Loss = 2.2658\n",
      "Epoch 190: Generator Loss = 62.0647, Discriminator Loss = 3.2055\n",
      "Epoch 191: Generator Loss = 53.6841, Discriminator Loss = 1.9885\n",
      "Epoch 192: Generator Loss = 53.7401, Discriminator Loss = 2.8055\n",
      "Epoch 193: Generator Loss = 49.6698, Discriminator Loss = 2.2469\n",
      "Epoch 194: Generator Loss = 59.4628, Discriminator Loss = 1.2790\n",
      "Epoch 195: Generator Loss = 59.2759, Discriminator Loss = 1.0054\n",
      "Epoch 196: Generator Loss = 70.1943, Discriminator Loss = 1.8121\n",
      "Epoch 197: Generator Loss = 53.0130, Discriminator Loss = 3.8270\n",
      "Epoch 198: Generator Loss = 45.3443, Discriminator Loss = 2.9478\n",
      "Epoch 199: Generator Loss = 61.1234, Discriminator Loss = 2.7934\n",
      "Epoch 200: Generator Loss = 59.4734, Discriminator Loss = 1.3474\n",
      "Epoch 201: Generator Loss = 65.2902, Discriminator Loss = 2.6095\n",
      "Epoch 202: Generator Loss = 54.6922, Discriminator Loss = 2.2466\n",
      "Epoch 203: Generator Loss = 79.2310, Discriminator Loss = 0.8524\n",
      "Epoch 204: Generator Loss = 58.9573, Discriminator Loss = 1.3120\n",
      "Epoch 205: Generator Loss = 79.3842, Discriminator Loss = 3.5731\n",
      "Epoch 206: Generator Loss = 39.5393, Discriminator Loss = 9.9039\n",
      "Epoch 207: Generator Loss = 48.2524, Discriminator Loss = 3.6706\n",
      "Epoch 208: Generator Loss = 54.0709, Discriminator Loss = 1.9571\n",
      "Epoch 209: Generator Loss = 59.0555, Discriminator Loss = 3.4350\n",
      "Epoch 210: Generator Loss = 55.8986, Discriminator Loss = 1.9106\n",
      "Epoch 211: Generator Loss = 57.4238, Discriminator Loss = 1.2891\n",
      "Epoch 212: Generator Loss = 54.1732, Discriminator Loss = 4.6014\n",
      "Epoch 213: Generator Loss = 57.4490, Discriminator Loss = 1.7247\n",
      "Epoch 214: Generator Loss = 59.9715, Discriminator Loss = 0.9321\n",
      "Epoch 215: Generator Loss = 91.6192, Discriminator Loss = 0.7123\n",
      "Epoch 216: Generator Loss = 76.8084, Discriminator Loss = 1.3827\n",
      "Epoch 217: Generator Loss = 71.6205, Discriminator Loss = 1.0025\n",
      "Epoch 218: Generator Loss = 63.2644, Discriminator Loss = 1.0802\n",
      "Epoch 219: Generator Loss = 72.5397, Discriminator Loss = 1.6105\n",
      "Epoch 220: Generator Loss = 78.9444, Discriminator Loss = 1.5677\n",
      "Epoch 221: Generator Loss = 70.0894, Discriminator Loss = 3.2886\n",
      "Epoch 222: Generator Loss = 59.7317, Discriminator Loss = 1.0290\n",
      "Epoch 223: Generator Loss = 81.3348, Discriminator Loss = 2.6856\n",
      "Epoch 224: Generator Loss = 62.9199, Discriminator Loss = 1.0714\n",
      "Epoch 225: Generator Loss = 88.0022, Discriminator Loss = 0.7869\n",
      "Epoch 226: Generator Loss = 91.5385, Discriminator Loss = 1.4091\n",
      "Epoch 227: Generator Loss = 111.1346, Discriminator Loss = 1.8812\n",
      "Epoch 228: Generator Loss = 70.9320, Discriminator Loss = 1.0797\n",
      "Epoch 229: Generator Loss = 64.5796, Discriminator Loss = 1.0884\n",
      "Epoch 230: Generator Loss = 87.7234, Discriminator Loss = 2.7123\n",
      "Epoch 231: Generator Loss = 66.0211, Discriminator Loss = 0.5880\n",
      "Epoch 232: Generator Loss = 80.5152, Discriminator Loss = 0.7733\n",
      "Epoch 233: Generator Loss = 80.8021, Discriminator Loss = 1.3061\n",
      "Epoch 234: Generator Loss = 63.4689, Discriminator Loss = 6.1511\n",
      "Epoch 235: Generator Loss = 59.8176, Discriminator Loss = 1.2207\n",
      "Epoch 236: Generator Loss = 71.1664, Discriminator Loss = 2.9709\n",
      "Epoch 237: Generator Loss = 76.1596, Discriminator Loss = 1.3072\n",
      "Epoch 238: Generator Loss = 77.0111, Discriminator Loss = 0.5569\n",
      "Epoch 239: Generator Loss = 66.6104, Discriminator Loss = 0.8864\n",
      "Epoch 240: Generator Loss = 60.5597, Discriminator Loss = 0.7144\n",
      "Epoch 241: Generator Loss = 83.6178, Discriminator Loss = 0.5443\n",
      "Epoch 242: Generator Loss = 83.1717, Discriminator Loss = 0.5892\n",
      "Epoch 243: Generator Loss = 84.4154, Discriminator Loss = 0.7979\n",
      "Epoch 244: Generator Loss = 88.1042, Discriminator Loss = 0.6060\n",
      "Epoch 245: Generator Loss = 77.5583, Discriminator Loss = 1.2168\n",
      "Epoch 246: Generator Loss = 62.4192, Discriminator Loss = 0.7537\n",
      "Epoch 247: Generator Loss = 68.5522, Discriminator Loss = 1.5756\n",
      "Epoch 248: Generator Loss = 105.7897, Discriminator Loss = 2.1316\n",
      "Epoch 249: Generator Loss = 87.2196, Discriminator Loss = 0.8610\n",
      "Epoch 250: Generator Loss = 75.8804, Discriminator Loss = 0.8976\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Epoch 1/15 | Train Loss: 0.7554 Acc: 0.7232\n",
      "Epoch 2/15 | Train Loss: 0.4251 Acc: 0.7781\n",
      "Epoch 3/15 | Train Loss: 0.4365 Acc: 0.7755\n",
      "Epoch 4/15 | Train Loss: 0.4186 Acc: 0.7781\n",
      "Epoch 5/15 | Train Loss: 0.3474 Acc: 0.8407\n",
      "Epoch 6/15 | Train Loss: 0.3151 Acc: 0.8355\n",
      "Epoch 7/15 | Train Loss: 0.3430 Acc: 0.8303\n",
      "Epoch 8/15 | Train Loss: 0.3120 Acc: 0.8590\n",
      "Epoch 9/15 | Train Loss: 0.3305 Acc: 0.8355\n",
      "Epoch 10/15 | Train Loss: 0.3120 Acc: 0.8329\n",
      "Epoch 11/15 | Train Loss: 0.2967 Acc: 0.8538\n",
      "Epoch 12/15 | Train Loss: 0.2506 Acc: 0.8773\n",
      "Epoch 13/15 | Train Loss: 0.2958 Acc: 0.8642\n",
      "Epoch 14/15 | Train Loss: 0.2842 Acc: 0.8642\n",
      "Epoch 15/15 | Train Loss: 0.3046 Acc: 0.8381\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.6065 Acc: 0.7232\n",
      "Epoch 2/15 | Train Loss: 0.4469 Acc: 0.7624\n",
      "Epoch 3/15 | Train Loss: 0.4034 Acc: 0.7885\n",
      "Epoch 4/15 | Train Loss: 0.3484 Acc: 0.8355\n",
      "Epoch 5/15 | Train Loss: 0.3989 Acc: 0.7755\n",
      "Epoch 6/15 | Train Loss: 0.3285 Acc: 0.8225\n",
      "Epoch 7/15 | Train Loss: 0.3381 Acc: 0.8407\n",
      "Epoch 8/15 | Train Loss: 0.3152 Acc: 0.8486\n",
      "Epoch 9/15 | Train Loss: 0.3098 Acc: 0.8564\n",
      "Epoch 10/15 | Train Loss: 0.2594 Acc: 0.8956\n",
      "Epoch 11/15 | Train Loss: 0.2937 Acc: 0.8512\n",
      "Epoch 12/15 | Train Loss: 0.2931 Acc: 0.8460\n",
      "Epoch 13/15 | Train Loss: 0.2679 Acc: 0.8668\n",
      "Epoch 14/15 | Train Loss: 0.2958 Acc: 0.8407\n",
      "Epoch 15/15 | Train Loss: 0.2844 Acc: 0.8433\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.4609 Acc: 0.7578\n",
      "Epoch 2/15 | Train Loss: 0.3978 Acc: 0.7943\n",
      "Epoch 3/15 | Train Loss: 0.3815 Acc: 0.7839\n",
      "Epoch 4/15 | Train Loss: 0.3646 Acc: 0.8047\n",
      "Epoch 5/15 | Train Loss: 0.3702 Acc: 0.7865\n",
      "Epoch 6/15 | Train Loss: 0.3597 Acc: 0.8021\n",
      "Epoch 7/15 | Train Loss: 0.3345 Acc: 0.8177\n",
      "Epoch 8/15 | Train Loss: 0.3143 Acc: 0.8307\n",
      "Epoch 9/15 | Train Loss: 0.3185 Acc: 0.8385\n",
      "Epoch 10/15 | Train Loss: 0.3308 Acc: 0.8333\n",
      "Epoch 11/15 | Train Loss: 0.2945 Acc: 0.8568\n",
      "Epoch 12/15 | Train Loss: 0.2982 Acc: 0.8490\n",
      "Epoch 13/15 | Train Loss: 0.3001 Acc: 0.8411\n",
      "Epoch 14/15 | Train Loss: 0.3047 Acc: 0.8281\n",
      "Epoch 15/15 | Train Loss: 0.2984 Acc: 0.8307\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.5451 Acc: 0.7930\n",
      "Epoch 2/15 | Train Loss: 0.3858 Acc: 0.8312\n",
      "Epoch 3/15 | Train Loss: 0.4160 Acc: 0.8185\n",
      "Epoch 4/15 | Train Loss: 0.3938 Acc: 0.8312\n",
      "Epoch 5/15 | Train Loss: 0.3840 Acc: 0.8439\n",
      "Epoch 6/15 | Train Loss: 0.3391 Acc: 0.8503\n",
      "Epoch 7/15 | Train Loss: 0.3711 Acc: 0.8217\n",
      "Epoch 8/15 | Train Loss: 0.3239 Acc: 0.8599\n",
      "Epoch 9/15 | Train Loss: 0.3188 Acc: 0.8631\n",
      "Epoch 10/15 | Train Loss: 0.3038 Acc: 0.8599\n",
      "Epoch 11/15 | Train Loss: 0.2977 Acc: 0.8822\n",
      "Epoch 12/15 | Train Loss: 0.2796 Acc: 0.8822\n",
      "Epoch 13/15 | Train Loss: 0.3177 Acc: 0.8535\n",
      "Epoch 14/15 | Train Loss: 0.2921 Acc: 0.8822\n",
      "Epoch 15/15 | Train Loss: 0.2936 Acc: 0.8694\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5262 Acc: 0.8143\n",
      "Epoch 2/15 | Train Loss: 0.3896 Acc: 0.8250\n",
      "Epoch 3/15 | Train Loss: 0.3286 Acc: 0.8643\n",
      "Epoch 4/15 | Train Loss: 0.3444 Acc: 0.8750\n",
      "Epoch 5/15 | Train Loss: 0.3099 Acc: 0.8643\n",
      "Epoch 6/15 | Train Loss: 0.3337 Acc: 0.8857\n",
      "Epoch 7/15 | Train Loss: 0.2883 Acc: 0.9000\n",
      "Epoch 8/15 | Train Loss: 0.3063 Acc: 0.8929\n",
      "Epoch 9/15 | Train Loss: 0.2590 Acc: 0.8857\n",
      "Epoch 10/15 | Train Loss: 0.2629 Acc: 0.8893\n",
      "Epoch 11/15 | Train Loss: 0.2769 Acc: 0.8714\n",
      "Epoch 12/15 | Train Loss: 0.2589 Acc: 0.8964\n",
      "Epoch 13/15 | Train Loss: 0.2324 Acc: 0.9107\n",
      "Epoch 14/15 | Train Loss: 0.2165 Acc: 0.9036\n",
      "Epoch 15/15 | Train Loss: 0.2667 Acc: 0.8893\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7410 Acc: 0.6151\n",
      "Epoch 2/15 | Train Loss: 0.6154 Acc: 0.6984\n",
      "Epoch 3/15 | Train Loss: 0.5666 Acc: 0.6905\n",
      "Epoch 4/15 | Train Loss: 0.5510 Acc: 0.7024\n",
      "Epoch 5/15 | Train Loss: 0.4392 Acc: 0.7698\n",
      "Epoch 6/15 | Train Loss: 0.5268 Acc: 0.7302\n",
      "Epoch 7/15 | Train Loss: 0.4680 Acc: 0.7579\n",
      "Epoch 8/15 | Train Loss: 0.4489 Acc: 0.7817\n",
      "Epoch 9/15 | Train Loss: 0.4877 Acc: 0.7619\n",
      "Epoch 10/15 | Train Loss: 0.3860 Acc: 0.8056\n",
      "Epoch 11/15 | Train Loss: 0.3905 Acc: 0.8056\n",
      "Epoch 12/15 | Train Loss: 0.3900 Acc: 0.8175\n",
      "Epoch 13/15 | Train Loss: 0.4084 Acc: 0.7976\n",
      "Epoch 14/15 | Train Loss: 0.3703 Acc: 0.8254\n",
      "Epoch 15/15 | Train Loss: 0.3850 Acc: 0.8135\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6786 Acc: 0.6230\n",
      "Epoch 2/15 | Train Loss: 0.6091 Acc: 0.6905\n",
      "Epoch 3/15 | Train Loss: 0.5110 Acc: 0.7460\n",
      "Epoch 4/15 | Train Loss: 0.5142 Acc: 0.7302\n",
      "Epoch 5/15 | Train Loss: 0.5223 Acc: 0.7341\n",
      "Epoch 6/15 | Train Loss: 0.4897 Acc: 0.7460\n",
      "Epoch 7/15 | Train Loss: 0.4734 Acc: 0.7579\n",
      "Epoch 8/15 | Train Loss: 0.4429 Acc: 0.8016\n",
      "Epoch 9/15 | Train Loss: 0.4534 Acc: 0.7579\n",
      "Epoch 10/15 | Train Loss: 0.4370 Acc: 0.7778\n",
      "Epoch 11/15 | Train Loss: 0.4571 Acc: 0.7619\n",
      "Epoch 12/15 | Train Loss: 0.4305 Acc: 0.7659\n",
      "Epoch 13/15 | Train Loss: 0.4037 Acc: 0.7857\n",
      "Epoch 14/15 | Train Loss: 0.4069 Acc: 0.8095\n",
      "Epoch 15/15 | Train Loss: 0.3859 Acc: 0.8333\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.8116 Acc: 0.5771\n",
      "Epoch 2/15 | Train Loss: 0.5985 Acc: 0.6917\n",
      "Epoch 3/15 | Train Loss: 0.5466 Acc: 0.6957\n",
      "Epoch 4/15 | Train Loss: 0.5070 Acc: 0.7431\n",
      "Epoch 5/15 | Train Loss: 0.4999 Acc: 0.7549\n",
      "Epoch 6/15 | Train Loss: 0.5218 Acc: 0.7194\n",
      "Epoch 7/15 | Train Loss: 0.5003 Acc: 0.7391\n",
      "Epoch 8/15 | Train Loss: 0.4708 Acc: 0.7549\n",
      "Epoch 9/15 | Train Loss: 0.4482 Acc: 0.7708\n",
      "Epoch 10/15 | Train Loss: 0.4283 Acc: 0.7984\n",
      "Epoch 11/15 | Train Loss: 0.4868 Acc: 0.7787\n",
      "Epoch 12/15 | Train Loss: 0.4306 Acc: 0.7787\n",
      "Epoch 13/15 | Train Loss: 0.4085 Acc: 0.8261\n",
      "Epoch 14/15 | Train Loss: 0.4197 Acc: 0.7945\n",
      "Epoch 15/15 | Train Loss: 0.3784 Acc: 0.8024\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6324 Acc: 0.7288\n",
      "Epoch 2/15 | Train Loss: 0.6224 Acc: 0.7288\n",
      "Epoch 3/15 | Train Loss: 0.5230 Acc: 0.7839\n",
      "Epoch 4/15 | Train Loss: 0.4583 Acc: 0.7966\n",
      "Epoch 5/15 | Train Loss: 0.5088 Acc: 0.7458\n",
      "Epoch 6/15 | Train Loss: 0.4560 Acc: 0.8008\n",
      "Epoch 7/15 | Train Loss: 0.4327 Acc: 0.7839\n",
      "Epoch 8/15 | Train Loss: 0.5031 Acc: 0.7458\n",
      "Epoch 9/15 | Train Loss: 0.4298 Acc: 0.8051\n",
      "Epoch 10/15 | Train Loss: 0.4177 Acc: 0.8051\n",
      "Epoch 11/15 | Train Loss: 0.4028 Acc: 0.8263\n",
      "Epoch 12/15 | Train Loss: 0.4292 Acc: 0.7966\n",
      "Epoch 13/15 | Train Loss: 0.4048 Acc: 0.8263\n",
      "Epoch 14/15 | Train Loss: 0.3884 Acc: 0.8432\n",
      "Epoch 15/15 | Train Loss: 0.4126 Acc: 0.8008\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.7820 Acc: 0.5595\n",
      "Epoch 2/15 | Train Loss: 0.5004 Acc: 0.8106\n",
      "Epoch 3/15 | Train Loss: 0.5153 Acc: 0.7930\n",
      "Epoch 4/15 | Train Loss: 0.3937 Acc: 0.8370\n",
      "Epoch 5/15 | Train Loss: 0.3747 Acc: 0.8238\n",
      "Epoch 6/15 | Train Loss: 0.3569 Acc: 0.8502\n",
      "Epoch 7/15 | Train Loss: 0.4057 Acc: 0.8370\n",
      "Epoch 8/15 | Train Loss: 0.3600 Acc: 0.8678\n",
      "Epoch 9/15 | Train Loss: 0.3571 Acc: 0.8678\n",
      "Epoch 10/15 | Train Loss: 0.3247 Acc: 0.8722\n",
      "Epoch 11/15 | Train Loss: 0.3449 Acc: 0.8414\n",
      "Epoch 12/15 | Train Loss: 0.3325 Acc: 0.8767\n",
      "Epoch 13/15 | Train Loss: 0.3175 Acc: 0.8678\n",
      "Epoch 14/15 | Train Loss: 0.3025 Acc: 0.8811\n",
      "Epoch 15/15 | Train Loss: 0.2824 Acc: 0.8987\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6698 Acc: 0.6588\n",
      "Epoch 2/15 | Train Loss: 0.5215 Acc: 0.7297\n",
      "Epoch 3/15 | Train Loss: 0.5140 Acc: 0.7297\n",
      "Epoch 4/15 | Train Loss: 0.4116 Acc: 0.7872\n",
      "Epoch 5/15 | Train Loss: 0.4503 Acc: 0.7838\n",
      "Epoch 6/15 | Train Loss: 0.4148 Acc: 0.7669\n",
      "Epoch 7/15 | Train Loss: 0.4278 Acc: 0.7703\n",
      "Epoch 8/15 | Train Loss: 0.4257 Acc: 0.7905\n",
      "Epoch 9/15 | Train Loss: 0.3808 Acc: 0.8176\n",
      "Epoch 10/15 | Train Loss: 0.3671 Acc: 0.8108\n",
      "Epoch 11/15 | Train Loss: 0.3335 Acc: 0.8378\n",
      "Epoch 12/15 | Train Loss: 0.3515 Acc: 0.8378\n",
      "Epoch 13/15 | Train Loss: 0.3518 Acc: 0.8311\n",
      "Epoch 14/15 | Train Loss: 0.3207 Acc: 0.8480\n",
      "Epoch 15/15 | Train Loss: 0.3887 Acc: 0.8108\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7806 Acc: 0.6824\n",
      "Epoch 2/15 | Train Loss: 0.5915 Acc: 0.6993\n",
      "Epoch 3/15 | Train Loss: 0.5076 Acc: 0.7196\n",
      "Epoch 4/15 | Train Loss: 0.5328 Acc: 0.7196\n",
      "Epoch 5/15 | Train Loss: 0.4831 Acc: 0.7736\n",
      "Epoch 6/15 | Train Loss: 0.3923 Acc: 0.7905\n",
      "Epoch 7/15 | Train Loss: 0.4712 Acc: 0.7669\n",
      "Epoch 8/15 | Train Loss: 0.4268 Acc: 0.7669\n",
      "Epoch 9/15 | Train Loss: 0.3931 Acc: 0.8176\n",
      "Epoch 10/15 | Train Loss: 0.3604 Acc: 0.8277\n",
      "Epoch 11/15 | Train Loss: 0.3502 Acc: 0.8682\n",
      "Epoch 12/15 | Train Loss: 0.3589 Acc: 0.8412\n",
      "Epoch 13/15 | Train Loss: 0.3528 Acc: 0.8311\n",
      "Epoch 14/15 | Train Loss: 0.3610 Acc: 0.7973\n",
      "Epoch 15/15 | Train Loss: 0.3955 Acc: 0.8142\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5924 Acc: 0.6936\n",
      "Epoch 2/15 | Train Loss: 0.5631 Acc: 0.7104\n",
      "Epoch 3/15 | Train Loss: 0.5211 Acc: 0.7172\n",
      "Epoch 4/15 | Train Loss: 0.4767 Acc: 0.7239\n",
      "Epoch 5/15 | Train Loss: 0.4741 Acc: 0.7340\n",
      "Epoch 6/15 | Train Loss: 0.4565 Acc: 0.7374\n",
      "Epoch 7/15 | Train Loss: 0.3857 Acc: 0.8047\n",
      "Epoch 8/15 | Train Loss: 0.4095 Acc: 0.7845\n",
      "Epoch 9/15 | Train Loss: 0.4089 Acc: 0.7946\n",
      "Epoch 10/15 | Train Loss: 0.3275 Acc: 0.8451\n",
      "Epoch 11/15 | Train Loss: 0.3840 Acc: 0.8283\n",
      "Epoch 12/15 | Train Loss: 0.3890 Acc: 0.7946\n",
      "Epoch 13/15 | Train Loss: 0.3502 Acc: 0.8283\n",
      "Epoch 14/15 | Train Loss: 0.3951 Acc: 0.7845\n",
      "Epoch 15/15 | Train Loss: 0.3903 Acc: 0.7879\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.6136 Acc: 0.7099\n",
      "Epoch 2/15 | Train Loss: 0.5004 Acc: 0.7710\n",
      "Epoch 3/15 | Train Loss: 0.4861 Acc: 0.7824\n",
      "Epoch 4/15 | Train Loss: 0.4207 Acc: 0.8092\n",
      "Epoch 5/15 | Train Loss: 0.4216 Acc: 0.8053\n",
      "Epoch 6/15 | Train Loss: 0.4446 Acc: 0.7901\n",
      "Epoch 7/15 | Train Loss: 0.3760 Acc: 0.8244\n",
      "Epoch 8/15 | Train Loss: 0.4534 Acc: 0.7748\n",
      "Epoch 9/15 | Train Loss: 0.3757 Acc: 0.8321\n",
      "Epoch 10/15 | Train Loss: 0.3697 Acc: 0.8511\n",
      "Epoch 11/15 | Train Loss: 0.3849 Acc: 0.8359\n",
      "Epoch 12/15 | Train Loss: 0.3484 Acc: 0.8626\n",
      "Epoch 13/15 | Train Loss: 0.3550 Acc: 0.8435\n",
      "Epoch 14/15 | Train Loss: 0.3897 Acc: 0.8130\n",
      "Epoch 15/15 | Train Loss: 0.3839 Acc: 0.8588\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5850 Acc: 0.7143\n",
      "Epoch 2/15 | Train Loss: 0.4139 Acc: 0.8490\n",
      "Epoch 3/15 | Train Loss: 0.4235 Acc: 0.8245\n",
      "Epoch 4/15 | Train Loss: 0.3635 Acc: 0.8490\n",
      "Epoch 5/15 | Train Loss: 0.3637 Acc: 0.8653\n",
      "Epoch 6/15 | Train Loss: 0.3260 Acc: 0.8490\n",
      "Epoch 7/15 | Train Loss: 0.2558 Acc: 0.9061\n",
      "Epoch 8/15 | Train Loss: 0.3291 Acc: 0.8694\n",
      "Epoch 9/15 | Train Loss: 0.3150 Acc: 0.8898\n",
      "Epoch 10/15 | Train Loss: 0.3133 Acc: 0.8653\n",
      "Epoch 11/15 | Train Loss: 0.3145 Acc: 0.8694\n",
      "Epoch 12/15 | Train Loss: 0.2807 Acc: 0.8694\n",
      "Epoch 13/15 | Train Loss: 0.2457 Acc: 0.8816\n",
      "Epoch 14/15 | Train Loss: 0.2969 Acc: 0.8980\n",
      "Epoch 15/15 | Train Loss: 0.2848 Acc: 0.8857\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6422 Acc: 0.6468\n",
      "Epoch 2/15 | Train Loss: 0.6605 Acc: 0.6667\n",
      "Epoch 3/15 | Train Loss: 0.6222 Acc: 0.6746\n",
      "Epoch 4/15 | Train Loss: 0.4928 Acc: 0.7381\n",
      "Epoch 5/15 | Train Loss: 0.5079 Acc: 0.7778\n",
      "Epoch 6/15 | Train Loss: 0.4799 Acc: 0.7897\n",
      "Epoch 7/15 | Train Loss: 0.4495 Acc: 0.7817\n",
      "Epoch 8/15 | Train Loss: 0.4028 Acc: 0.8452\n",
      "Epoch 9/15 | Train Loss: 0.3882 Acc: 0.8413\n",
      "Epoch 10/15 | Train Loss: 0.4500 Acc: 0.7857\n",
      "Epoch 11/15 | Train Loss: 0.3994 Acc: 0.8095\n",
      "Epoch 12/15 | Train Loss: 0.3980 Acc: 0.8214\n",
      "Epoch 13/15 | Train Loss: 0.3843 Acc: 0.8135\n",
      "Epoch 14/15 | Train Loss: 0.4221 Acc: 0.7778\n",
      "Epoch 15/15 | Train Loss: 0.3348 Acc: 0.8492\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7500 Acc: 0.6190\n",
      "Epoch 2/15 | Train Loss: 0.6601 Acc: 0.6310\n",
      "Epoch 3/15 | Train Loss: 0.6121 Acc: 0.6825\n",
      "Epoch 4/15 | Train Loss: 0.5886 Acc: 0.6746\n",
      "Epoch 5/15 | Train Loss: 0.5616 Acc: 0.6825\n",
      "Epoch 6/15 | Train Loss: 0.5541 Acc: 0.7063\n",
      "Epoch 7/15 | Train Loss: 0.4980 Acc: 0.7222\n",
      "Epoch 8/15 | Train Loss: 0.5081 Acc: 0.7421\n",
      "Epoch 9/15 | Train Loss: 0.4575 Acc: 0.7421\n",
      "Epoch 10/15 | Train Loss: 0.4739 Acc: 0.7659\n",
      "Epoch 11/15 | Train Loss: 0.4073 Acc: 0.8294\n",
      "Epoch 12/15 | Train Loss: 0.4183 Acc: 0.7778\n",
      "Epoch 13/15 | Train Loss: 0.5055 Acc: 0.7302\n",
      "Epoch 14/15 | Train Loss: 0.4519 Acc: 0.7897\n",
      "Epoch 15/15 | Train Loss: 0.4378 Acc: 0.7857\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6721 Acc: 0.6561\n",
      "Epoch 2/15 | Train Loss: 0.6529 Acc: 0.6561\n",
      "Epoch 3/15 | Train Loss: 0.6085 Acc: 0.6640\n",
      "Epoch 4/15 | Train Loss: 0.5216 Acc: 0.7312\n",
      "Epoch 5/15 | Train Loss: 0.5218 Acc: 0.7431\n",
      "Epoch 6/15 | Train Loss: 0.4765 Acc: 0.7194\n",
      "Epoch 7/15 | Train Loss: 0.4489 Acc: 0.7826\n",
      "Epoch 8/15 | Train Loss: 0.4688 Acc: 0.7352\n",
      "Epoch 9/15 | Train Loss: 0.4698 Acc: 0.8024\n",
      "Epoch 10/15 | Train Loss: 0.4795 Acc: 0.7510\n",
      "Epoch 11/15 | Train Loss: 0.4247 Acc: 0.8103\n",
      "Epoch 12/15 | Train Loss: 0.3792 Acc: 0.8340\n",
      "Epoch 13/15 | Train Loss: 0.4024 Acc: 0.8024\n",
      "Epoch 14/15 | Train Loss: 0.4101 Acc: 0.8182\n",
      "Epoch 15/15 | Train Loss: 0.4093 Acc: 0.7905\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7063 Acc: 0.6398\n",
      "Epoch 2/15 | Train Loss: 0.5537 Acc: 0.7415\n",
      "Epoch 3/15 | Train Loss: 0.5244 Acc: 0.7500\n",
      "Epoch 4/15 | Train Loss: 0.4854 Acc: 0.7797\n",
      "Epoch 5/15 | Train Loss: 0.4626 Acc: 0.7712\n",
      "Epoch 6/15 | Train Loss: 0.4958 Acc: 0.8008\n",
      "Epoch 7/15 | Train Loss: 0.4190 Acc: 0.8263\n",
      "Epoch 8/15 | Train Loss: 0.4195 Acc: 0.7881\n",
      "Epoch 9/15 | Train Loss: 0.3823 Acc: 0.8263\n",
      "Epoch 10/15 | Train Loss: 0.3822 Acc: 0.8390\n",
      "Epoch 11/15 | Train Loss: 0.3791 Acc: 0.8220\n",
      "Epoch 12/15 | Train Loss: 0.4060 Acc: 0.8347\n",
      "Epoch 13/15 | Train Loss: 0.4114 Acc: 0.8263\n",
      "Epoch 14/15 | Train Loss: 0.3875 Acc: 0.8475\n",
      "Epoch 15/15 | Train Loss: 0.4231 Acc: 0.8390\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5869 Acc: 0.7181\n",
      "Epoch 2/15 | Train Loss: 0.5167 Acc: 0.8106\n",
      "Epoch 3/15 | Train Loss: 0.3804 Acc: 0.8238\n",
      "Epoch 4/15 | Train Loss: 0.4008 Acc: 0.8326\n",
      "Epoch 5/15 | Train Loss: 0.3529 Acc: 0.8458\n",
      "Epoch 6/15 | Train Loss: 0.3609 Acc: 0.8855\n",
      "Epoch 7/15 | Train Loss: 0.3601 Acc: 0.8634\n",
      "Epoch 8/15 | Train Loss: 0.3617 Acc: 0.8414\n",
      "Epoch 9/15 | Train Loss: 0.3640 Acc: 0.8678\n",
      "Epoch 10/15 | Train Loss: 0.3127 Acc: 0.8943\n",
      "Epoch 11/15 | Train Loss: 0.2842 Acc: 0.8855\n",
      "Epoch 12/15 | Train Loss: 0.3088 Acc: 0.8722\n",
      "Epoch 13/15 | Train Loss: 0.3092 Acc: 0.8855\n",
      "Epoch 14/15 | Train Loss: 0.2697 Acc: 0.9031\n",
      "Epoch 15/15 | Train Loss: 0.2889 Acc: 0.8678\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5664 Acc: 0.7781\n",
      "Epoch 2/15 | Train Loss: 0.4267 Acc: 0.7676\n",
      "Epoch 3/15 | Train Loss: 0.3863 Acc: 0.7911\n",
      "Epoch 4/15 | Train Loss: 0.3883 Acc: 0.7911\n",
      "Epoch 5/15 | Train Loss: 0.3510 Acc: 0.8016\n",
      "Epoch 6/15 | Train Loss: 0.3351 Acc: 0.8277\n",
      "Epoch 7/15 | Train Loss: 0.3639 Acc: 0.8042\n",
      "Epoch 8/15 | Train Loss: 0.3299 Acc: 0.8277\n",
      "Epoch 9/15 | Train Loss: 0.3029 Acc: 0.8616\n",
      "Epoch 10/15 | Train Loss: 0.2950 Acc: 0.8616\n",
      "Epoch 11/15 | Train Loss: 0.2767 Acc: 0.8668\n",
      "Epoch 12/15 | Train Loss: 0.2983 Acc: 0.8564\n",
      "Epoch 13/15 | Train Loss: 0.2922 Acc: 0.8668\n",
      "Epoch 14/15 | Train Loss: 0.2879 Acc: 0.8460\n",
      "Epoch 15/15 | Train Loss: 0.2877 Acc: 0.8512\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.5693 Acc: 0.7337\n",
      "Epoch 2/15 | Train Loss: 0.4563 Acc: 0.7781\n",
      "Epoch 3/15 | Train Loss: 0.4136 Acc: 0.7676\n",
      "Epoch 4/15 | Train Loss: 0.3733 Acc: 0.8042\n",
      "Epoch 5/15 | Train Loss: 0.3593 Acc: 0.8016\n",
      "Epoch 6/15 | Train Loss: 0.3350 Acc: 0.8303\n",
      "Epoch 7/15 | Train Loss: 0.3843 Acc: 0.7990\n",
      "Epoch 8/15 | Train Loss: 0.3112 Acc: 0.8355\n",
      "Epoch 9/15 | Train Loss: 0.3116 Acc: 0.8381\n",
      "Epoch 10/15 | Train Loss: 0.2808 Acc: 0.8747\n",
      "Epoch 11/15 | Train Loss: 0.2984 Acc: 0.8407\n",
      "Epoch 12/15 | Train Loss: 0.2938 Acc: 0.8460\n",
      "Epoch 13/15 | Train Loss: 0.2837 Acc: 0.8642\n",
      "Epoch 14/15 | Train Loss: 0.2825 Acc: 0.8590\n",
      "Epoch 15/15 | Train Loss: 0.2976 Acc: 0.8512\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.6038 Acc: 0.7682\n",
      "Epoch 2/15 | Train Loss: 0.5003 Acc: 0.7526\n",
      "Epoch 3/15 | Train Loss: 0.4018 Acc: 0.7812\n",
      "Epoch 4/15 | Train Loss: 0.3911 Acc: 0.7917\n",
      "Epoch 5/15 | Train Loss: 0.3833 Acc: 0.7891\n",
      "Epoch 6/15 | Train Loss: 0.3449 Acc: 0.8073\n",
      "Epoch 7/15 | Train Loss: 0.3572 Acc: 0.8177\n",
      "Epoch 8/15 | Train Loss: 0.3071 Acc: 0.8594\n",
      "Epoch 9/15 | Train Loss: 0.2944 Acc: 0.8542\n",
      "Epoch 10/15 | Train Loss: 0.2959 Acc: 0.8568\n",
      "Epoch 11/15 | Train Loss: 0.3066 Acc: 0.8490\n",
      "Epoch 12/15 | Train Loss: 0.2886 Acc: 0.8620\n",
      "Epoch 13/15 | Train Loss: 0.3027 Acc: 0.8464\n",
      "Epoch 14/15 | Train Loss: 0.3038 Acc: 0.8359\n",
      "Epoch 15/15 | Train Loss: 0.2927 Acc: 0.8698\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.4720 Acc: 0.7803\n",
      "Epoch 2/15 | Train Loss: 0.4098 Acc: 0.8248\n",
      "Epoch 3/15 | Train Loss: 0.3712 Acc: 0.8344\n",
      "Epoch 4/15 | Train Loss: 0.3940 Acc: 0.8025\n",
      "Epoch 5/15 | Train Loss: 0.3407 Acc: 0.8471\n",
      "Epoch 6/15 | Train Loss: 0.3495 Acc: 0.8471\n",
      "Epoch 7/15 | Train Loss: 0.3479 Acc: 0.8312\n",
      "Epoch 8/15 | Train Loss: 0.3252 Acc: 0.8567\n",
      "Epoch 9/15 | Train Loss: 0.3141 Acc: 0.8567\n",
      "Epoch 10/15 | Train Loss: 0.3066 Acc: 0.8439\n",
      "Epoch 11/15 | Train Loss: 0.2929 Acc: 0.8631\n",
      "Epoch 12/15 | Train Loss: 0.2901 Acc: 0.8726\n",
      "Epoch 13/15 | Train Loss: 0.2907 Acc: 0.8694\n",
      "Epoch 14/15 | Train Loss: 0.3116 Acc: 0.8599\n",
      "Epoch 15/15 | Train Loss: 0.3071 Acc: 0.8567\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.6482 Acc: 0.7393\n",
      "Epoch 2/15 | Train Loss: 0.3661 Acc: 0.8679\n",
      "Epoch 3/15 | Train Loss: 0.3375 Acc: 0.8571\n",
      "Epoch 4/15 | Train Loss: 0.2901 Acc: 0.8857\n",
      "Epoch 5/15 | Train Loss: 0.3164 Acc: 0.8714\n",
      "Epoch 6/15 | Train Loss: 0.3011 Acc: 0.8857\n",
      "Epoch 7/15 | Train Loss: 0.2900 Acc: 0.8857\n",
      "Epoch 8/15 | Train Loss: 0.2926 Acc: 0.8786\n",
      "Epoch 9/15 | Train Loss: 0.3177 Acc: 0.8786\n",
      "Epoch 10/15 | Train Loss: 0.2427 Acc: 0.8964\n",
      "Epoch 11/15 | Train Loss: 0.2878 Acc: 0.8893\n",
      "Epoch 12/15 | Train Loss: 0.2713 Acc: 0.8786\n",
      "Epoch 13/15 | Train Loss: 0.2319 Acc: 0.9250\n",
      "Epoch 14/15 | Train Loss: 0.2352 Acc: 0.9143\n",
      "Epoch 15/15 | Train Loss: 0.2335 Acc: 0.9071\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7553 Acc: 0.6111\n",
      "Epoch 2/15 | Train Loss: 0.5966 Acc: 0.7143\n",
      "Epoch 3/15 | Train Loss: 0.6301 Acc: 0.6587\n",
      "Epoch 4/15 | Train Loss: 0.4818 Acc: 0.7381\n",
      "Epoch 5/15 | Train Loss: 0.5809 Acc: 0.7183\n",
      "Epoch 6/15 | Train Loss: 0.5185 Acc: 0.7063\n",
      "Epoch 7/15 | Train Loss: 0.4725 Acc: 0.7500\n",
      "Epoch 8/15 | Train Loss: 0.4639 Acc: 0.7619\n",
      "Epoch 9/15 | Train Loss: 0.3861 Acc: 0.8135\n",
      "Epoch 10/15 | Train Loss: 0.4308 Acc: 0.7738\n",
      "Epoch 11/15 | Train Loss: 0.3535 Acc: 0.8532\n",
      "Epoch 12/15 | Train Loss: 0.4162 Acc: 0.8254\n",
      "Epoch 13/15 | Train Loss: 0.4379 Acc: 0.7698\n",
      "Epoch 14/15 | Train Loss: 0.4030 Acc: 0.8016\n",
      "Epoch 15/15 | Train Loss: 0.3693 Acc: 0.8333\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6654 Acc: 0.6111\n",
      "Epoch 2/15 | Train Loss: 0.6288 Acc: 0.6627\n",
      "Epoch 3/15 | Train Loss: 0.5424 Acc: 0.7302\n",
      "Epoch 4/15 | Train Loss: 0.5379 Acc: 0.7381\n",
      "Epoch 5/15 | Train Loss: 0.5481 Acc: 0.7143\n",
      "Epoch 6/15 | Train Loss: 0.5314 Acc: 0.7024\n",
      "Epoch 7/15 | Train Loss: 0.4910 Acc: 0.7500\n",
      "Epoch 8/15 | Train Loss: 0.4093 Acc: 0.8135\n",
      "Epoch 9/15 | Train Loss: 0.4565 Acc: 0.7579\n",
      "Epoch 10/15 | Train Loss: 0.4530 Acc: 0.7619\n",
      "Epoch 11/15 | Train Loss: 0.4135 Acc: 0.7897\n",
      "Epoch 12/15 | Train Loss: 0.4137 Acc: 0.7937\n",
      "Epoch 13/15 | Train Loss: 0.4091 Acc: 0.7976\n",
      "Epoch 14/15 | Train Loss: 0.4284 Acc: 0.7778\n",
      "Epoch 15/15 | Train Loss: 0.3917 Acc: 0.8214\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7834 Acc: 0.6640\n",
      "Epoch 2/15 | Train Loss: 0.6912 Acc: 0.6443\n",
      "Epoch 3/15 | Train Loss: 0.5943 Acc: 0.7154\n",
      "Epoch 4/15 | Train Loss: 0.5045 Acc: 0.7233\n",
      "Epoch 5/15 | Train Loss: 0.5593 Acc: 0.7233\n",
      "Epoch 6/15 | Train Loss: 0.6088 Acc: 0.6680\n",
      "Epoch 7/15 | Train Loss: 0.5176 Acc: 0.7233\n",
      "Epoch 8/15 | Train Loss: 0.5224 Acc: 0.7589\n",
      "Epoch 9/15 | Train Loss: 0.4416 Acc: 0.7787\n",
      "Epoch 10/15 | Train Loss: 0.4623 Acc: 0.7668\n",
      "Epoch 11/15 | Train Loss: 0.4501 Acc: 0.7628\n",
      "Epoch 12/15 | Train Loss: 0.4455 Acc: 0.7747\n",
      "Epoch 13/15 | Train Loss: 0.4777 Acc: 0.7549\n",
      "Epoch 14/15 | Train Loss: 0.3787 Acc: 0.8261\n",
      "Epoch 15/15 | Train Loss: 0.4455 Acc: 0.8024\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5687 Acc: 0.7288\n",
      "Epoch 2/15 | Train Loss: 0.6085 Acc: 0.7542\n",
      "Epoch 3/15 | Train Loss: 0.4802 Acc: 0.7754\n",
      "Epoch 4/15 | Train Loss: 0.4330 Acc: 0.8008\n",
      "Epoch 5/15 | Train Loss: 0.5121 Acc: 0.8178\n",
      "Epoch 6/15 | Train Loss: 0.5194 Acc: 0.8051\n",
      "Epoch 7/15 | Train Loss: 0.4571 Acc: 0.7797\n",
      "Epoch 8/15 | Train Loss: 0.3913 Acc: 0.8093\n",
      "Epoch 9/15 | Train Loss: 0.4281 Acc: 0.8136\n",
      "Epoch 10/15 | Train Loss: 0.3886 Acc: 0.8347\n",
      "Epoch 11/15 | Train Loss: 0.4597 Acc: 0.7881\n",
      "Epoch 12/15 | Train Loss: 0.3957 Acc: 0.8136\n",
      "Epoch 13/15 | Train Loss: 0.3886 Acc: 0.8008\n",
      "Epoch 14/15 | Train Loss: 0.3937 Acc: 0.8178\n",
      "Epoch 15/15 | Train Loss: 0.3896 Acc: 0.8305\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.6099 Acc: 0.6740\n",
      "Epoch 2/15 | Train Loss: 0.5078 Acc: 0.7930\n",
      "Epoch 3/15 | Train Loss: 0.4426 Acc: 0.8414\n",
      "Epoch 4/15 | Train Loss: 0.4316 Acc: 0.8282\n",
      "Epoch 5/15 | Train Loss: 0.3760 Acc: 0.8546\n",
      "Epoch 6/15 | Train Loss: 0.3827 Acc: 0.8458\n",
      "Epoch 7/15 | Train Loss: 0.3336 Acc: 0.8855\n",
      "Epoch 8/15 | Train Loss: 0.3218 Acc: 0.8767\n",
      "Epoch 9/15 | Train Loss: 0.3259 Acc: 0.8634\n",
      "Epoch 10/15 | Train Loss: 0.2997 Acc: 0.8811\n",
      "Epoch 11/15 | Train Loss: 0.3225 Acc: 0.8811\n",
      "Epoch 12/15 | Train Loss: 0.3004 Acc: 0.8855\n",
      "Epoch 13/15 | Train Loss: 0.2673 Acc: 0.9119\n",
      "Epoch 14/15 | Train Loss: 0.2760 Acc: 0.8678\n",
      "Epoch 15/15 | Train Loss: 0.2810 Acc: 0.8855\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.6min\n",
      "Epoch 1/15 | Train Loss: 0.5642 Acc: 0.7431\n",
      "Epoch 2/15 | Train Loss: 0.4639 Acc: 0.7752\n",
      "Epoch 3/15 | Train Loss: 0.4178 Acc: 0.7706\n",
      "Epoch 4/15 | Train Loss: 0.3925 Acc: 0.7982\n",
      "Epoch 5/15 | Train Loss: 0.3653 Acc: 0.8211\n",
      "Epoch 6/15 | Train Loss: 0.3764 Acc: 0.8257\n",
      "Epoch 7/15 | Train Loss: 0.3711 Acc: 0.8028\n",
      "Epoch 8/15 | Train Loss: 0.3547 Acc: 0.8028\n",
      "Epoch 9/15 | Train Loss: 0.3222 Acc: 0.8463\n",
      "Epoch 10/15 | Train Loss: 0.3109 Acc: 0.8601\n",
      "Epoch 11/15 | Train Loss: 0.2971 Acc: 0.8578\n",
      "Epoch 12/15 | Train Loss: 0.2931 Acc: 0.8693\n",
      "Epoch 13/15 | Train Loss: 0.3219 Acc: 0.8601\n",
      "Epoch 14/15 | Train Loss: 0.2779 Acc: 0.8624\n",
      "Epoch 15/15 | Train Loss: 0.2763 Acc: 0.8761\n",
      "Fold 8 Test Accuracy: 0.7500\n",
      "===== Fold 9 =====\n",
      "Epoch 1: Generator Loss = 10.0939, Discriminator Loss = 8.7037\n",
      "Epoch 2: Generator Loss = 10.7135, Discriminator Loss = 8.2187\n",
      "Epoch 3: Generator Loss = 14.0313, Discriminator Loss = 5.6718\n",
      "Epoch 4: Generator Loss = 22.7245, Discriminator Loss = 4.8828\n",
      "Epoch 5: Generator Loss = 31.4325, Discriminator Loss = 3.0187\n",
      "Epoch 6: Generator Loss = 31.6343, Discriminator Loss = 4.9045\n",
      "Epoch 7: Generator Loss = 32.2382, Discriminator Loss = 5.5030\n",
      "Epoch 8: Generator Loss = 25.5845, Discriminator Loss = 6.0995\n",
      "Epoch 9: Generator Loss = 25.7251, Discriminator Loss = 6.0081\n",
      "Epoch 10: Generator Loss = 24.0155, Discriminator Loss = 6.0183\n",
      "Epoch 11: Generator Loss = 23.9039, Discriminator Loss = 8.8027\n",
      "Epoch 12: Generator Loss = 22.6841, Discriminator Loss = 7.3616\n",
      "Epoch 13: Generator Loss = 24.9222, Discriminator Loss = 7.1174\n",
      "Epoch 14: Generator Loss = 25.0017, Discriminator Loss = 6.0228\n",
      "Epoch 15: Generator Loss = 24.8859, Discriminator Loss = 8.5940\n",
      "Epoch 16: Generator Loss = 21.7277, Discriminator Loss = 8.6117\n",
      "Epoch 17: Generator Loss = 22.1614, Discriminator Loss = 8.2125\n",
      "Epoch 18: Generator Loss = 21.9429, Discriminator Loss = 7.3992\n",
      "Epoch 19: Generator Loss = 19.3336, Discriminator Loss = 8.1059\n",
      "Epoch 20: Generator Loss = 19.4552, Discriminator Loss = 8.5216\n",
      "Epoch 21: Generator Loss = 20.7448, Discriminator Loss = 7.5537\n",
      "Epoch 22: Generator Loss = 21.1581, Discriminator Loss = 7.9995\n",
      "Epoch 23: Generator Loss = 18.2250, Discriminator Loss = 7.5573\n",
      "Epoch 24: Generator Loss = 21.4872, Discriminator Loss = 7.5549\n",
      "Epoch 25: Generator Loss = 26.1639, Discriminator Loss = 7.8793\n",
      "Epoch 26: Generator Loss = 20.0872, Discriminator Loss = 7.1325\n",
      "Epoch 27: Generator Loss = 23.8574, Discriminator Loss = 8.1411\n",
      "Epoch 28: Generator Loss = 21.1541, Discriminator Loss = 7.4153\n",
      "Epoch 29: Generator Loss = 21.5033, Discriminator Loss = 8.5052\n",
      "Epoch 30: Generator Loss = 19.6781, Discriminator Loss = 11.0008\n",
      "Epoch 31: Generator Loss = 16.4368, Discriminator Loss = 8.0893\n",
      "Epoch 32: Generator Loss = 19.5376, Discriminator Loss = 7.8181\n",
      "Epoch 33: Generator Loss = 18.7449, Discriminator Loss = 7.8017\n",
      "Epoch 34: Generator Loss = 14.7819, Discriminator Loss = 7.8119\n",
      "Epoch 35: Generator Loss = 18.2909, Discriminator Loss = 6.6453\n",
      "Epoch 36: Generator Loss = 21.0638, Discriminator Loss = 8.5726\n",
      "Epoch 37: Generator Loss = 23.8527, Discriminator Loss = 6.4985\n",
      "Epoch 38: Generator Loss = 23.8825, Discriminator Loss = 9.4935\n",
      "Epoch 39: Generator Loss = 19.9401, Discriminator Loss = 7.8649\n",
      "Epoch 40: Generator Loss = 16.9223, Discriminator Loss = 7.8091\n",
      "Epoch 41: Generator Loss = 21.1926, Discriminator Loss = 7.4208\n",
      "Epoch 42: Generator Loss = 21.2919, Discriminator Loss = 7.9164\n",
      "Epoch 43: Generator Loss = 22.9443, Discriminator Loss = 8.1074\n",
      "Epoch 44: Generator Loss = 18.0792, Discriminator Loss = 6.0088\n",
      "Epoch 45: Generator Loss = 25.6036, Discriminator Loss = 6.9456\n",
      "Epoch 46: Generator Loss = 20.1724, Discriminator Loss = 6.4730\n",
      "Epoch 47: Generator Loss = 26.0927, Discriminator Loss = 6.8262\n",
      "Epoch 48: Generator Loss = 18.0062, Discriminator Loss = 6.3644\n",
      "Epoch 49: Generator Loss = 26.4782, Discriminator Loss = 5.9750\n",
      "Epoch 50: Generator Loss = 29.2034, Discriminator Loss = 5.1407\n",
      "Epoch 51: Generator Loss = 27.8777, Discriminator Loss = 4.8951\n",
      "Epoch 52: Generator Loss = 29.4666, Discriminator Loss = 6.4242\n",
      "Epoch 53: Generator Loss = 29.9969, Discriminator Loss = 6.1365\n",
      "Epoch 54: Generator Loss = 28.8928, Discriminator Loss = 7.0255\n",
      "Epoch 55: Generator Loss = 25.9794, Discriminator Loss = 5.4688\n",
      "Epoch 56: Generator Loss = 29.8186, Discriminator Loss = 3.8286\n",
      "Epoch 57: Generator Loss = 27.0787, Discriminator Loss = 5.9725\n",
      "Epoch 58: Generator Loss = 32.8870, Discriminator Loss = 3.5683\n",
      "Epoch 59: Generator Loss = 47.4441, Discriminator Loss = 3.9762\n",
      "Epoch 60: Generator Loss = 30.6079, Discriminator Loss = 4.3634\n",
      "Epoch 61: Generator Loss = 36.7510, Discriminator Loss = 3.3790\n",
      "Epoch 62: Generator Loss = 45.9714, Discriminator Loss = 2.4133\n",
      "Epoch 63: Generator Loss = 45.7062, Discriminator Loss = 2.1994\n",
      "Epoch 64: Generator Loss = 39.9880, Discriminator Loss = 2.1524\n",
      "Epoch 65: Generator Loss = 48.0726, Discriminator Loss = 5.8779\n",
      "Epoch 66: Generator Loss = 40.2613, Discriminator Loss = 2.2755\n",
      "Epoch 67: Generator Loss = 50.1844, Discriminator Loss = 2.6677\n",
      "Epoch 68: Generator Loss = 43.7154, Discriminator Loss = 2.7028\n",
      "Epoch 69: Generator Loss = 39.4746, Discriminator Loss = 2.5500\n",
      "Epoch 70: Generator Loss = 47.5715, Discriminator Loss = 5.7419\n",
      "Epoch 71: Generator Loss = 47.2299, Discriminator Loss = 1.8697\n",
      "Epoch 72: Generator Loss = 43.3573, Discriminator Loss = 1.6850\n",
      "Epoch 73: Generator Loss = 57.9686, Discriminator Loss = 1.3680\n",
      "Epoch 74: Generator Loss = 52.1059, Discriminator Loss = 2.0126\n",
      "Epoch 75: Generator Loss = 55.1389, Discriminator Loss = 1.3917\n",
      "Epoch 76: Generator Loss = 56.1282, Discriminator Loss = 4.0573\n",
      "Epoch 77: Generator Loss = 55.8547, Discriminator Loss = 2.1229\n",
      "Epoch 78: Generator Loss = 47.8777, Discriminator Loss = 1.0851\n",
      "Epoch 79: Generator Loss = 58.1560, Discriminator Loss = 1.3447\n",
      "Epoch 80: Generator Loss = 47.1539, Discriminator Loss = 1.8149\n",
      "Epoch 81: Generator Loss = 66.3213, Discriminator Loss = 2.6458\n",
      "Epoch 82: Generator Loss = 65.4692, Discriminator Loss = 0.7275\n",
      "Epoch 83: Generator Loss = 70.3731, Discriminator Loss = 0.8866\n",
      "Epoch 84: Generator Loss = 96.2535, Discriminator Loss = 0.4718\n",
      "Epoch 85: Generator Loss = 81.0002, Discriminator Loss = 0.6814\n",
      "Epoch 86: Generator Loss = 101.9279, Discriminator Loss = 1.8805\n",
      "Epoch 87: Generator Loss = 148.1084, Discriminator Loss = 2.2007\n",
      "Epoch 88: Generator Loss = 155.6046, Discriminator Loss = 1.1433\n",
      "Epoch 89: Generator Loss = 128.6964, Discriminator Loss = 0.5490\n",
      "Epoch 90: Generator Loss = 130.6067, Discriminator Loss = 0.2120\n",
      "Epoch 91: Generator Loss = 115.2166, Discriminator Loss = 0.1453\n",
      "Epoch 92: Generator Loss = 106.7891, Discriminator Loss = 0.6121\n",
      "Epoch 93: Generator Loss = 99.8645, Discriminator Loss = 0.1538\n",
      "Epoch 94: Generator Loss = 84.5410, Discriminator Loss = 0.2974\n",
      "Epoch 95: Generator Loss = 92.2880, Discriminator Loss = 0.4464\n",
      "Epoch 96: Generator Loss = 62.1994, Discriminator Loss = 2.2595\n",
      "Epoch 97: Generator Loss = 76.8248, Discriminator Loss = 3.0377\n",
      "Epoch 98: Generator Loss = 63.9819, Discriminator Loss = 3.8523\n",
      "Epoch 99: Generator Loss = 49.8583, Discriminator Loss = 2.6226\n",
      "Epoch 100: Generator Loss = 72.5477, Discriminator Loss = 2.3294\n",
      "Epoch 101: Generator Loss = 61.3594, Discriminator Loss = 4.9150\n",
      "Epoch 102: Generator Loss = 65.6844, Discriminator Loss = 2.7792\n",
      "Epoch 103: Generator Loss = 69.1067, Discriminator Loss = 1.1357\n",
      "Epoch 104: Generator Loss = 71.9693, Discriminator Loss = 0.8043\n",
      "Epoch 105: Generator Loss = 53.3721, Discriminator Loss = 1.9202\n",
      "Epoch 106: Generator Loss = 68.2154, Discriminator Loss = 0.8850\n",
      "Epoch 107: Generator Loss = 72.8474, Discriminator Loss = 0.7203\n",
      "Epoch 108: Generator Loss = 70.0664, Discriminator Loss = 0.7400\n",
      "Epoch 109: Generator Loss = 66.7472, Discriminator Loss = 1.0381\n",
      "Epoch 110: Generator Loss = 66.5205, Discriminator Loss = 0.9097\n",
      "Epoch 111: Generator Loss = 75.9615, Discriminator Loss = 1.3186\n",
      "Epoch 112: Generator Loss = 73.0940, Discriminator Loss = 1.0418\n",
      "Epoch 113: Generator Loss = 76.4427, Discriminator Loss = 0.8834\n",
      "Epoch 114: Generator Loss = 65.0327, Discriminator Loss = 0.8832\n",
      "Epoch 115: Generator Loss = 74.5657, Discriminator Loss = 0.5683\n",
      "Epoch 116: Generator Loss = 69.2055, Discriminator Loss = 2.9876\n",
      "Epoch 117: Generator Loss = 69.6852, Discriminator Loss = 1.2815\n",
      "Epoch 118: Generator Loss = 78.6714, Discriminator Loss = 0.5654\n",
      "Epoch 119: Generator Loss = 86.8886, Discriminator Loss = 0.3649\n",
      "Epoch 120: Generator Loss = 81.4219, Discriminator Loss = 0.5956\n",
      "Epoch 121: Generator Loss = 70.8816, Discriminator Loss = 0.6085\n",
      "Epoch 122: Generator Loss = 75.2585, Discriminator Loss = 0.6251\n",
      "Epoch 123: Generator Loss = 94.5030, Discriminator Loss = 1.7022\n",
      "Epoch 124: Generator Loss = 88.1422, Discriminator Loss = 1.1785\n",
      "Epoch 125: Generator Loss = 68.5726, Discriminator Loss = 1.0650\n",
      "Epoch 126: Generator Loss = 54.6814, Discriminator Loss = 13.8158\n",
      "Epoch 127: Generator Loss = 43.7998, Discriminator Loss = 5.1931\n",
      "Epoch 128: Generator Loss = 38.8763, Discriminator Loss = 8.8464\n",
      "Epoch 129: Generator Loss = 45.9413, Discriminator Loss = 2.4437\n",
      "Epoch 130: Generator Loss = 55.5142, Discriminator Loss = 1.8201\n",
      "Epoch 131: Generator Loss = 61.2509, Discriminator Loss = 1.2064\n",
      "Epoch 132: Generator Loss = 68.8284, Discriminator Loss = 0.8703\n",
      "Epoch 133: Generator Loss = 73.0421, Discriminator Loss = 0.6553\n",
      "Epoch 134: Generator Loss = 69.2712, Discriminator Loss = 0.6617\n",
      "Epoch 135: Generator Loss = 70.2900, Discriminator Loss = 0.9842\n",
      "Epoch 136: Generator Loss = 77.1238, Discriminator Loss = 0.8928\n",
      "Epoch 137: Generator Loss = 81.5304, Discriminator Loss = 0.6297\n",
      "Epoch 138: Generator Loss = 73.8360, Discriminator Loss = 1.1020\n",
      "Epoch 139: Generator Loss = 67.8004, Discriminator Loss = 0.7651\n",
      "Epoch 140: Generator Loss = 76.7944, Discriminator Loss = 0.8279\n",
      "Epoch 141: Generator Loss = 84.9118, Discriminator Loss = 0.5891\n",
      "Epoch 142: Generator Loss = 77.5537, Discriminator Loss = 0.5143\n",
      "Epoch 143: Generator Loss = 89.8076, Discriminator Loss = 0.5492\n",
      "Epoch 144: Generator Loss = 71.7037, Discriminator Loss = 0.8841\n",
      "Epoch 145: Generator Loss = 93.5309, Discriminator Loss = 0.5598\n",
      "Epoch 146: Generator Loss = 72.2904, Discriminator Loss = 0.7197\n",
      "Epoch 147: Generator Loss = 73.4929, Discriminator Loss = 0.4411\n",
      "Epoch 148: Generator Loss = 75.3152, Discriminator Loss = 0.4429\n",
      "Epoch 149: Generator Loss = 89.0694, Discriminator Loss = 0.2993\n",
      "Epoch 150: Generator Loss = 82.2698, Discriminator Loss = 0.3183\n",
      "Epoch 151: Generator Loss = 78.8884, Discriminator Loss = 0.5730\n",
      "Epoch 152: Generator Loss = 82.0701, Discriminator Loss = 0.2956\n",
      "Epoch 153: Generator Loss = 85.4353, Discriminator Loss = 0.4364\n",
      "Epoch 154: Generator Loss = 62.5532, Discriminator Loss = 0.7269\n",
      "Epoch 155: Generator Loss = 78.0166, Discriminator Loss = 0.7113\n",
      "Epoch 156: Generator Loss = 89.1413, Discriminator Loss = 1.2328\n",
      "Epoch 157: Generator Loss = 88.5710, Discriminator Loss = 0.7714\n",
      "Epoch 158: Generator Loss = 86.3057, Discriminator Loss = 0.6500\n",
      "Epoch 159: Generator Loss = 75.9908, Discriminator Loss = 1.4010\n",
      "Epoch 160: Generator Loss = 71.3590, Discriminator Loss = 5.8154\n",
      "Epoch 161: Generator Loss = 45.5997, Discriminator Loss = 4.9764\n",
      "Epoch 162: Generator Loss = 56.8088, Discriminator Loss = 1.1330\n",
      "Epoch 163: Generator Loss = 70.5553, Discriminator Loss = 0.8245\n",
      "Epoch 164: Generator Loss = 75.3187, Discriminator Loss = 0.8064\n",
      "Epoch 165: Generator Loss = 77.2128, Discriminator Loss = 2.4542\n",
      "Epoch 166: Generator Loss = 66.3775, Discriminator Loss = 1.5681\n",
      "Epoch 167: Generator Loss = 67.3548, Discriminator Loss = 1.2009\n",
      "Epoch 168: Generator Loss = 86.7332, Discriminator Loss = 1.0280\n",
      "Epoch 169: Generator Loss = 88.4110, Discriminator Loss = 0.6761\n",
      "Epoch 170: Generator Loss = 84.1282, Discriminator Loss = 1.3199\n",
      "Epoch 171: Generator Loss = 78.3189, Discriminator Loss = 1.0831\n",
      "Epoch 172: Generator Loss = 104.7967, Discriminator Loss = 2.3042\n",
      "Epoch 173: Generator Loss = 97.3325, Discriminator Loss = 0.6452\n",
      "Epoch 174: Generator Loss = 67.3096, Discriminator Loss = 0.9246\n",
      "Epoch 175: Generator Loss = 81.5852, Discriminator Loss = 1.1230\n",
      "Epoch 176: Generator Loss = 73.1155, Discriminator Loss = 0.8773\n",
      "Epoch 177: Generator Loss = 54.2456, Discriminator Loss = 0.9811\n",
      "Epoch 178: Generator Loss = 89.0491, Discriminator Loss = 1.3464\n",
      "Epoch 179: Generator Loss = 64.1364, Discriminator Loss = 1.8363\n",
      "Epoch 180: Generator Loss = 69.2393, Discriminator Loss = 1.8313\n",
      "Epoch 181: Generator Loss = 84.3015, Discriminator Loss = 1.2708\n",
      "Epoch 182: Generator Loss = 76.3500, Discriminator Loss = 1.5608\n",
      "Epoch 183: Generator Loss = 64.7876, Discriminator Loss = 4.9143\n",
      "Epoch 184: Generator Loss = 54.6737, Discriminator Loss = 3.3280\n",
      "Epoch 185: Generator Loss = 77.4291, Discriminator Loss = 5.6381\n",
      "Epoch 186: Generator Loss = 57.5521, Discriminator Loss = 4.3012\n",
      "Epoch 187: Generator Loss = 58.7569, Discriminator Loss = 2.3313\n",
      "Epoch 188: Generator Loss = 82.4534, Discriminator Loss = 1.0960\n",
      "Epoch 189: Generator Loss = 56.7658, Discriminator Loss = 2.8100\n",
      "Epoch 190: Generator Loss = 86.5745, Discriminator Loss = 1.1782\n",
      "Epoch 191: Generator Loss = 74.4817, Discriminator Loss = 0.9276\n",
      "Epoch 192: Generator Loss = 74.4208, Discriminator Loss = 0.9954\n",
      "Epoch 193: Generator Loss = 69.5645, Discriminator Loss = 1.2995\n",
      "Epoch 194: Generator Loss = 73.1981, Discriminator Loss = 0.7982\n",
      "Epoch 195: Generator Loss = 72.8869, Discriminator Loss = 0.9500\n",
      "Epoch 196: Generator Loss = 81.5544, Discriminator Loss = 1.7912\n",
      "Epoch 197: Generator Loss = 87.0537, Discriminator Loss = 1.1040\n",
      "Epoch 198: Generator Loss = 82.3844, Discriminator Loss = 0.9536\n",
      "Epoch 199: Generator Loss = 89.1735, Discriminator Loss = 0.7400\n",
      "Epoch 200: Generator Loss = 76.9159, Discriminator Loss = 0.4920\n",
      "Epoch 201: Generator Loss = 75.6192, Discriminator Loss = 1.8041\n",
      "Epoch 202: Generator Loss = 69.8508, Discriminator Loss = 0.4468\n",
      "Epoch 203: Generator Loss = 74.3570, Discriminator Loss = 1.0605\n",
      "Epoch 204: Generator Loss = 88.9036, Discriminator Loss = 0.4941\n",
      "Epoch 205: Generator Loss = 84.8674, Discriminator Loss = 0.7283\n",
      "Epoch 206: Generator Loss = 86.3306, Discriminator Loss = 0.9984\n",
      "Epoch 207: Generator Loss = 76.4891, Discriminator Loss = 1.0094\n",
      "Epoch 208: Generator Loss = 91.4301, Discriminator Loss = 0.4538\n",
      "Epoch 209: Generator Loss = 65.8368, Discriminator Loss = 1.1152\n",
      "Epoch 210: Generator Loss = 89.2763, Discriminator Loss = 0.8762\n",
      "Epoch 211: Generator Loss = 77.3374, Discriminator Loss = 0.8602\n",
      "Epoch 212: Generator Loss = 84.9871, Discriminator Loss = 1.9468\n",
      "Epoch 213: Generator Loss = 65.2883, Discriminator Loss = 3.1732\n",
      "Epoch 214: Generator Loss = 66.8422, Discriminator Loss = 1.8824\n",
      "Epoch 215: Generator Loss = 81.9783, Discriminator Loss = 0.7711\n",
      "Epoch 216: Generator Loss = 75.9326, Discriminator Loss = 4.9068\n",
      "Epoch 217: Generator Loss = 64.0482, Discriminator Loss = 3.0088\n",
      "Epoch 218: Generator Loss = 75.5121, Discriminator Loss = 1.3577\n",
      "Epoch 219: Generator Loss = 69.5094, Discriminator Loss = 1.5726\n",
      "Epoch 220: Generator Loss = 58.0510, Discriminator Loss = 2.0836\n",
      "Epoch 221: Generator Loss = 64.4212, Discriminator Loss = 0.8981\n",
      "Epoch 222: Generator Loss = 74.4206, Discriminator Loss = 1.6413\n",
      "Epoch 223: Generator Loss = 71.8376, Discriminator Loss = 0.6172\n",
      "Epoch 224: Generator Loss = 112.3378, Discriminator Loss = 0.3178\n",
      "Epoch 225: Generator Loss = 84.4034, Discriminator Loss = 0.9561\n",
      "Epoch 226: Generator Loss = 89.2503, Discriminator Loss = 0.3623\n",
      "Epoch 227: Generator Loss = 88.9267, Discriminator Loss = 3.1360\n",
      "Epoch 228: Generator Loss = 78.0765, Discriminator Loss = 1.2499\n",
      "Epoch 229: Generator Loss = 75.6501, Discriminator Loss = 1.7237\n",
      "Epoch 230: Generator Loss = 68.7172, Discriminator Loss = 0.8470\n",
      "Epoch 231: Generator Loss = 76.8138, Discriminator Loss = 1.3207\n",
      "Epoch 232: Generator Loss = 87.7574, Discriminator Loss = 1.0026\n",
      "Epoch 233: Generator Loss = 85.1460, Discriminator Loss = 1.2199\n",
      "Epoch 234: Generator Loss = 69.6808, Discriminator Loss = 0.5641\n",
      "Epoch 235: Generator Loss = 88.3829, Discriminator Loss = 0.4106\n",
      "Epoch 236: Generator Loss = 79.3878, Discriminator Loss = 0.7479\n",
      "Epoch 237: Generator Loss = 89.3625, Discriminator Loss = 0.6223\n",
      "Epoch 238: Generator Loss = 79.5020, Discriminator Loss = 0.9142\n",
      "Epoch 239: Generator Loss = 78.8544, Discriminator Loss = 1.2596\n",
      "Epoch 240: Generator Loss = 80.1734, Discriminator Loss = 0.4671\n",
      "Epoch 241: Generator Loss = 97.2912, Discriminator Loss = 0.4466\n",
      "Epoch 242: Generator Loss = 88.7405, Discriminator Loss = 0.4181\n",
      "Epoch 243: Generator Loss = 67.0817, Discriminator Loss = 1.8762\n",
      "Epoch 244: Generator Loss = 79.1363, Discriminator Loss = 1.4967\n",
      "Epoch 245: Generator Loss = 66.7226, Discriminator Loss = 1.1832\n",
      "Epoch 246: Generator Loss = 74.3007, Discriminator Loss = 1.5292\n",
      "Epoch 247: Generator Loss = 107.8813, Discriminator Loss = 2.2382\n",
      "Epoch 248: Generator Loss = 67.1432, Discriminator Loss = 2.4902\n",
      "Epoch 249: Generator Loss = 82.8526, Discriminator Loss = 3.0314\n",
      "Epoch 250: Generator Loss = 82.8581, Discriminator Loss = 7.2573\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Epoch 1/15 | Train Loss: 0.5892 Acc: 0.7565\n",
      "Epoch 2/15 | Train Loss: 0.4535 Acc: 0.7772\n",
      "Epoch 3/15 | Train Loss: 0.3456 Acc: 0.8187\n",
      "Epoch 4/15 | Train Loss: 0.3492 Acc: 0.8420\n",
      "Epoch 5/15 | Train Loss: 0.3763 Acc: 0.8135\n",
      "Epoch 6/15 | Train Loss: 0.3286 Acc: 0.8290\n",
      "Epoch 7/15 | Train Loss: 0.3280 Acc: 0.8394\n",
      "Epoch 8/15 | Train Loss: 0.2874 Acc: 0.8653\n",
      "Epoch 9/15 | Train Loss: 0.2615 Acc: 0.8834\n",
      "Epoch 10/15 | Train Loss: 0.2548 Acc: 0.8808\n",
      "Epoch 11/15 | Train Loss: 0.2898 Acc: 0.8705\n",
      "Epoch 12/15 | Train Loss: 0.2783 Acc: 0.8679\n",
      "Epoch 13/15 | Train Loss: 0.2803 Acc: 0.8653\n",
      "Epoch 14/15 | Train Loss: 0.2548 Acc: 0.8938\n",
      "Epoch 15/15 | Train Loss: 0.2437 Acc: 0.8886\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 3.0min\n",
      "Epoch 1/15 | Train Loss: 0.6907 Acc: 0.7306\n",
      "Epoch 2/15 | Train Loss: 0.4789 Acc: 0.7617\n",
      "Epoch 3/15 | Train Loss: 0.4218 Acc: 0.7565\n",
      "Epoch 4/15 | Train Loss: 0.3991 Acc: 0.7772\n",
      "Epoch 5/15 | Train Loss: 0.3692 Acc: 0.8109\n",
      "Epoch 6/15 | Train Loss: 0.3782 Acc: 0.7876\n",
      "Epoch 7/15 | Train Loss: 0.3715 Acc: 0.7979\n",
      "Epoch 8/15 | Train Loss: 0.3427 Acc: 0.8083\n",
      "Epoch 9/15 | Train Loss: 0.3199 Acc: 0.8472\n",
      "Epoch 10/15 | Train Loss: 0.3052 Acc: 0.8368\n",
      "Epoch 11/15 | Train Loss: 0.3164 Acc: 0.8368\n",
      "Epoch 12/15 | Train Loss: 0.3054 Acc: 0.8601\n",
      "Epoch 13/15 | Train Loss: 0.2821 Acc: 0.8782\n",
      "Epoch 14/15 | Train Loss: 0.2829 Acc: 0.8756\n",
      "Epoch 15/15 | Train Loss: 0.2879 Acc: 0.8627\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 3.0min\n",
      "Epoch 1/15 | Train Loss: 0.4737 Acc: 0.7617\n",
      "Epoch 2/15 | Train Loss: 0.3819 Acc: 0.8005\n",
      "Epoch 3/15 | Train Loss: 0.3864 Acc: 0.7953\n",
      "Epoch 4/15 | Train Loss: 0.3915 Acc: 0.8031\n",
      "Epoch 5/15 | Train Loss: 0.3481 Acc: 0.8187\n",
      "Epoch 6/15 | Train Loss: 0.3362 Acc: 0.8238\n",
      "Epoch 7/15 | Train Loss: 0.3248 Acc: 0.8109\n",
      "Epoch 8/15 | Train Loss: 0.3286 Acc: 0.8316\n",
      "Epoch 9/15 | Train Loss: 0.2819 Acc: 0.8523\n",
      "Epoch 10/15 | Train Loss: 0.2926 Acc: 0.8368\n",
      "Epoch 11/15 | Train Loss: 0.3067 Acc: 0.8316\n",
      "Epoch 12/15 | Train Loss: 0.2805 Acc: 0.8679\n",
      "Epoch 13/15 | Train Loss: 0.2926 Acc: 0.8731\n",
      "Epoch 14/15 | Train Loss: 0.2840 Acc: 0.8549\n",
      "Epoch 15/15 | Train Loss: 0.2974 Acc: 0.8627\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.4430 Acc: 0.7968\n",
      "Epoch 2/15 | Train Loss: 0.3804 Acc: 0.8286\n",
      "Epoch 3/15 | Train Loss: 0.3784 Acc: 0.8444\n",
      "Epoch 4/15 | Train Loss: 0.3688 Acc: 0.8254\n",
      "Epoch 5/15 | Train Loss: 0.3710 Acc: 0.8444\n",
      "Epoch 6/15 | Train Loss: 0.3706 Acc: 0.8476\n",
      "Epoch 7/15 | Train Loss: 0.3643 Acc: 0.8127\n",
      "Epoch 8/15 | Train Loss: 0.3197 Acc: 0.8508\n",
      "Epoch 9/15 | Train Loss: 0.3204 Acc: 0.8603\n",
      "Epoch 10/15 | Train Loss: 0.2868 Acc: 0.8667\n",
      "Epoch 11/15 | Train Loss: 0.2871 Acc: 0.8698\n",
      "Epoch 12/15 | Train Loss: 0.3071 Acc: 0.8730\n",
      "Epoch 13/15 | Train Loss: 0.2600 Acc: 0.8794\n",
      "Epoch 14/15 | Train Loss: 0.2627 Acc: 0.8857\n",
      "Epoch 15/15 | Train Loss: 0.2930 Acc: 0.8698\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.4922 Acc: 0.8269\n",
      "Epoch 2/15 | Train Loss: 0.3501 Acc: 0.8587\n",
      "Epoch 3/15 | Train Loss: 0.3436 Acc: 0.8657\n",
      "Epoch 4/15 | Train Loss: 0.3490 Acc: 0.8799\n",
      "Epoch 5/15 | Train Loss: 0.3261 Acc: 0.8587\n",
      "Epoch 6/15 | Train Loss: 0.3125 Acc: 0.8799\n",
      "Epoch 7/15 | Train Loss: 0.3101 Acc: 0.8657\n",
      "Epoch 8/15 | Train Loss: 0.2866 Acc: 0.8799\n",
      "Epoch 9/15 | Train Loss: 0.2824 Acc: 0.8834\n",
      "Epoch 10/15 | Train Loss: 0.2997 Acc: 0.8728\n",
      "Epoch 11/15 | Train Loss: 0.2406 Acc: 0.9011\n",
      "Epoch 12/15 | Train Loss: 0.2656 Acc: 0.8975\n",
      "Epoch 13/15 | Train Loss: 0.2461 Acc: 0.9187\n",
      "Epoch 14/15 | Train Loss: 0.2491 Acc: 0.9081\n",
      "Epoch 15/15 | Train Loss: 0.2423 Acc: 0.9046\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.6808 Acc: 0.6260\n",
      "Epoch 2/15 | Train Loss: 0.6429 Acc: 0.7047\n",
      "Epoch 3/15 | Train Loss: 0.5587 Acc: 0.7087\n",
      "Epoch 4/15 | Train Loss: 0.5428 Acc: 0.7008\n",
      "Epoch 5/15 | Train Loss: 0.5408 Acc: 0.7205\n",
      "Epoch 6/15 | Train Loss: 0.4482 Acc: 0.7874\n",
      "Epoch 7/15 | Train Loss: 0.4261 Acc: 0.7913\n",
      "Epoch 8/15 | Train Loss: 0.3839 Acc: 0.8386\n",
      "Epoch 9/15 | Train Loss: 0.4030 Acc: 0.8189\n",
      "Epoch 10/15 | Train Loss: 0.3932 Acc: 0.8465\n",
      "Epoch 11/15 | Train Loss: 0.3473 Acc: 0.8543\n",
      "Epoch 12/15 | Train Loss: 0.3686 Acc: 0.8307\n",
      "Epoch 13/15 | Train Loss: 0.3680 Acc: 0.8346\n",
      "Epoch 14/15 | Train Loss: 0.4074 Acc: 0.8268\n",
      "Epoch 15/15 | Train Loss: 0.3464 Acc: 0.8465\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6992 Acc: 0.6220\n",
      "Epoch 2/15 | Train Loss: 0.6108 Acc: 0.6850\n",
      "Epoch 3/15 | Train Loss: 0.5347 Acc: 0.7165\n",
      "Epoch 4/15 | Train Loss: 0.5733 Acc: 0.7087\n",
      "Epoch 5/15 | Train Loss: 0.5025 Acc: 0.7244\n",
      "Epoch 6/15 | Train Loss: 0.5020 Acc: 0.7480\n",
      "Epoch 7/15 | Train Loss: 0.4700 Acc: 0.7677\n",
      "Epoch 8/15 | Train Loss: 0.4690 Acc: 0.7638\n",
      "Epoch 9/15 | Train Loss: 0.4098 Acc: 0.8189\n",
      "Epoch 10/15 | Train Loss: 0.4762 Acc: 0.7756\n",
      "Epoch 11/15 | Train Loss: 0.4015 Acc: 0.8110\n",
      "Epoch 12/15 | Train Loss: 0.3795 Acc: 0.8110\n",
      "Epoch 13/15 | Train Loss: 0.4277 Acc: 0.7598\n",
      "Epoch 14/15 | Train Loss: 0.4458 Acc: 0.7795\n",
      "Epoch 15/15 | Train Loss: 0.3814 Acc: 0.8228\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6901 Acc: 0.6417\n",
      "Epoch 2/15 | Train Loss: 0.6438 Acc: 0.6378\n",
      "Epoch 3/15 | Train Loss: 0.5575 Acc: 0.6969\n",
      "Epoch 4/15 | Train Loss: 0.5327 Acc: 0.7323\n",
      "Epoch 5/15 | Train Loss: 0.5156 Acc: 0.7441\n",
      "Epoch 6/15 | Train Loss: 0.5015 Acc: 0.7362\n",
      "Epoch 7/15 | Train Loss: 0.4875 Acc: 0.7874\n",
      "Epoch 8/15 | Train Loss: 0.4319 Acc: 0.8031\n",
      "Epoch 9/15 | Train Loss: 0.4493 Acc: 0.7953\n",
      "Epoch 10/15 | Train Loss: 0.4316 Acc: 0.7953\n",
      "Epoch 11/15 | Train Loss: 0.4287 Acc: 0.7953\n",
      "Epoch 12/15 | Train Loss: 0.4120 Acc: 0.7992\n",
      "Epoch 13/15 | Train Loss: 0.4123 Acc: 0.8228\n",
      "Epoch 14/15 | Train Loss: 0.4284 Acc: 0.7953\n",
      "Epoch 15/15 | Train Loss: 0.4129 Acc: 0.7717\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5957 Acc: 0.7257\n",
      "Epoch 2/15 | Train Loss: 0.5408 Acc: 0.7722\n",
      "Epoch 3/15 | Train Loss: 0.4717 Acc: 0.8017\n",
      "Epoch 4/15 | Train Loss: 0.4971 Acc: 0.7468\n",
      "Epoch 5/15 | Train Loss: 0.4589 Acc: 0.7975\n",
      "Epoch 6/15 | Train Loss: 0.4411 Acc: 0.8186\n",
      "Epoch 7/15 | Train Loss: 0.4321 Acc: 0.8228\n",
      "Epoch 8/15 | Train Loss: 0.3676 Acc: 0.8354\n",
      "Epoch 9/15 | Train Loss: 0.3897 Acc: 0.8101\n",
      "Epoch 10/15 | Train Loss: 0.4162 Acc: 0.8059\n",
      "Epoch 11/15 | Train Loss: 0.3733 Acc: 0.8186\n",
      "Epoch 12/15 | Train Loss: 0.3697 Acc: 0.8608\n",
      "Epoch 13/15 | Train Loss: 0.3841 Acc: 0.8228\n",
      "Epoch 14/15 | Train Loss: 0.3148 Acc: 0.8565\n",
      "Epoch 15/15 | Train Loss: 0.4009 Acc: 0.8354\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6554 Acc: 0.6332\n",
      "Epoch 2/15 | Train Loss: 0.4877 Acc: 0.7991\n",
      "Epoch 3/15 | Train Loss: 0.4598 Acc: 0.8079\n",
      "Epoch 4/15 | Train Loss: 0.4264 Acc: 0.8122\n",
      "Epoch 5/15 | Train Loss: 0.3947 Acc: 0.8384\n",
      "Epoch 6/15 | Train Loss: 0.2839 Acc: 0.8908\n",
      "Epoch 7/15 | Train Loss: 0.4350 Acc: 0.8297\n",
      "Epoch 8/15 | Train Loss: 0.3591 Acc: 0.8603\n",
      "Epoch 9/15 | Train Loss: 0.3502 Acc: 0.8603\n",
      "Epoch 10/15 | Train Loss: 0.3180 Acc: 0.8690\n",
      "Epoch 11/15 | Train Loss: 0.3188 Acc: 0.8777\n",
      "Epoch 12/15 | Train Loss: 0.3374 Acc: 0.8646\n",
      "Epoch 13/15 | Train Loss: 0.3217 Acc: 0.8777\n",
      "Epoch 14/15 | Train Loss: 0.3086 Acc: 0.8734\n",
      "Epoch 15/15 | Train Loss: 0.2676 Acc: 0.8821\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6238 Acc: 0.6946\n",
      "Epoch 2/15 | Train Loss: 0.5066 Acc: 0.7282\n",
      "Epoch 3/15 | Train Loss: 0.4256 Acc: 0.7685\n",
      "Epoch 4/15 | Train Loss: 0.4538 Acc: 0.7718\n",
      "Epoch 5/15 | Train Loss: 0.4281 Acc: 0.7685\n",
      "Epoch 6/15 | Train Loss: 0.4018 Acc: 0.8121\n",
      "Epoch 7/15 | Train Loss: 0.3783 Acc: 0.8322\n",
      "Epoch 8/15 | Train Loss: 0.4256 Acc: 0.8087\n",
      "Epoch 9/15 | Train Loss: 0.3761 Acc: 0.8121\n",
      "Epoch 10/15 | Train Loss: 0.3420 Acc: 0.8557\n",
      "Epoch 11/15 | Train Loss: 0.3514 Acc: 0.8389\n",
      "Epoch 12/15 | Train Loss: 0.2969 Acc: 0.8523\n",
      "Epoch 13/15 | Train Loss: 0.3345 Acc: 0.8322\n",
      "Epoch 14/15 | Train Loss: 0.3659 Acc: 0.8188\n",
      "Epoch 15/15 | Train Loss: 0.3283 Acc: 0.8624\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.6097 Acc: 0.6879\n",
      "Epoch 2/15 | Train Loss: 0.5500 Acc: 0.7181\n",
      "Epoch 3/15 | Train Loss: 0.5177 Acc: 0.7483\n",
      "Epoch 4/15 | Train Loss: 0.4485 Acc: 0.7550\n",
      "Epoch 5/15 | Train Loss: 0.4688 Acc: 0.7550\n",
      "Epoch 6/15 | Train Loss: 0.4543 Acc: 0.7718\n",
      "Epoch 7/15 | Train Loss: 0.3887 Acc: 0.7953\n",
      "Epoch 8/15 | Train Loss: 0.4099 Acc: 0.7987\n",
      "Epoch 9/15 | Train Loss: 0.3794 Acc: 0.8054\n",
      "Epoch 10/15 | Train Loss: 0.3362 Acc: 0.8456\n",
      "Epoch 11/15 | Train Loss: 0.3593 Acc: 0.8356\n",
      "Epoch 12/15 | Train Loss: 0.3683 Acc: 0.8221\n",
      "Epoch 13/15 | Train Loss: 0.3606 Acc: 0.8356\n",
      "Epoch 14/15 | Train Loss: 0.3297 Acc: 0.8591\n",
      "Epoch 15/15 | Train Loss: 0.3532 Acc: 0.8322\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5992 Acc: 0.7148\n",
      "Epoch 2/15 | Train Loss: 0.5541 Acc: 0.7450\n",
      "Epoch 3/15 | Train Loss: 0.5352 Acc: 0.7081\n",
      "Epoch 4/15 | Train Loss: 0.4617 Acc: 0.7215\n",
      "Epoch 5/15 | Train Loss: 0.4693 Acc: 0.7752\n",
      "Epoch 6/15 | Train Loss: 0.4328 Acc: 0.7953\n",
      "Epoch 7/15 | Train Loss: 0.4235 Acc: 0.7819\n",
      "Epoch 8/15 | Train Loss: 0.3654 Acc: 0.8322\n",
      "Epoch 9/15 | Train Loss: 0.4004 Acc: 0.7987\n",
      "Epoch 10/15 | Train Loss: 0.3620 Acc: 0.8322\n",
      "Epoch 11/15 | Train Loss: 0.3583 Acc: 0.8188\n",
      "Epoch 12/15 | Train Loss: 0.3634 Acc: 0.8255\n",
      "Epoch 13/15 | Train Loss: 0.3850 Acc: 0.7953\n",
      "Epoch 14/15 | Train Loss: 0.3109 Acc: 0.8725\n",
      "Epoch 15/15 | Train Loss: 0.3914 Acc: 0.7886\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.6436 Acc: 0.6882\n",
      "Epoch 2/15 | Train Loss: 0.4874 Acc: 0.7605\n",
      "Epoch 3/15 | Train Loss: 0.4634 Acc: 0.7985\n",
      "Epoch 4/15 | Train Loss: 0.4304 Acc: 0.8023\n",
      "Epoch 5/15 | Train Loss: 0.3892 Acc: 0.8137\n",
      "Epoch 6/15 | Train Loss: 0.3967 Acc: 0.8365\n",
      "Epoch 7/15 | Train Loss: 0.3982 Acc: 0.8137\n",
      "Epoch 8/15 | Train Loss: 0.3512 Acc: 0.8251\n",
      "Epoch 9/15 | Train Loss: 0.3860 Acc: 0.8213\n",
      "Epoch 10/15 | Train Loss: 0.3609 Acc: 0.8403\n",
      "Epoch 11/15 | Train Loss: 0.3623 Acc: 0.8289\n",
      "Epoch 12/15 | Train Loss: 0.3438 Acc: 0.8631\n",
      "Epoch 13/15 | Train Loss: 0.3442 Acc: 0.8517\n",
      "Epoch 14/15 | Train Loss: 0.3188 Acc: 0.8821\n",
      "Epoch 15/15 | Train Loss: 0.3267 Acc: 0.8403\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.4892 Acc: 0.7935\n",
      "Epoch 2/15 | Train Loss: 0.4585 Acc: 0.8340\n",
      "Epoch 3/15 | Train Loss: 0.3935 Acc: 0.8259\n",
      "Epoch 4/15 | Train Loss: 0.3872 Acc: 0.8623\n",
      "Epoch 5/15 | Train Loss: 0.3535 Acc: 0.8623\n",
      "Epoch 6/15 | Train Loss: 0.3767 Acc: 0.8340\n",
      "Epoch 7/15 | Train Loss: 0.2993 Acc: 0.8866\n",
      "Epoch 8/15 | Train Loss: 0.3530 Acc: 0.8462\n",
      "Epoch 9/15 | Train Loss: 0.2883 Acc: 0.8907\n",
      "Epoch 10/15 | Train Loss: 0.2793 Acc: 0.8745\n",
      "Epoch 11/15 | Train Loss: 0.2485 Acc: 0.8866\n",
      "Epoch 12/15 | Train Loss: 0.2862 Acc: 0.8745\n",
      "Epoch 13/15 | Train Loss: 0.2843 Acc: 0.8704\n",
      "Epoch 14/15 | Train Loss: 0.2549 Acc: 0.9069\n",
      "Epoch 15/15 | Train Loss: 0.2961 Acc: 0.8826\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6280 Acc: 0.6535\n",
      "Epoch 2/15 | Train Loss: 0.6146 Acc: 0.6772\n",
      "Epoch 3/15 | Train Loss: 0.5647 Acc: 0.7165\n",
      "Epoch 4/15 | Train Loss: 0.4908 Acc: 0.7520\n",
      "Epoch 5/15 | Train Loss: 0.4923 Acc: 0.7362\n",
      "Epoch 6/15 | Train Loss: 0.4169 Acc: 0.7953\n",
      "Epoch 7/15 | Train Loss: 0.4846 Acc: 0.7598\n",
      "Epoch 8/15 | Train Loss: 0.4459 Acc: 0.7913\n",
      "Epoch 9/15 | Train Loss: 0.4381 Acc: 0.7953\n",
      "Epoch 10/15 | Train Loss: 0.3868 Acc: 0.8189\n",
      "Epoch 11/15 | Train Loss: 0.3183 Acc: 0.8819\n",
      "Epoch 12/15 | Train Loss: 0.3299 Acc: 0.8661\n",
      "Epoch 13/15 | Train Loss: 0.3188 Acc: 0.8504\n",
      "Epoch 14/15 | Train Loss: 0.2741 Acc: 0.8976\n",
      "Epoch 15/15 | Train Loss: 0.3256 Acc: 0.8661\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6922 Acc: 0.6614\n",
      "Epoch 2/15 | Train Loss: 0.5802 Acc: 0.6969\n",
      "Epoch 3/15 | Train Loss: 0.5972 Acc: 0.6772\n",
      "Epoch 4/15 | Train Loss: 0.5275 Acc: 0.6969\n",
      "Epoch 5/15 | Train Loss: 0.5458 Acc: 0.7087\n",
      "Epoch 6/15 | Train Loss: 0.5127 Acc: 0.7087\n",
      "Epoch 7/15 | Train Loss: 0.5440 Acc: 0.6850\n",
      "Epoch 8/15 | Train Loss: 0.4882 Acc: 0.7520\n",
      "Epoch 9/15 | Train Loss: 0.3973 Acc: 0.7953\n",
      "Epoch 10/15 | Train Loss: 0.4086 Acc: 0.8228\n",
      "Epoch 11/15 | Train Loss: 0.4284 Acc: 0.7913\n",
      "Epoch 12/15 | Train Loss: 0.4617 Acc: 0.7520\n",
      "Epoch 13/15 | Train Loss: 0.4012 Acc: 0.8228\n",
      "Epoch 14/15 | Train Loss: 0.3948 Acc: 0.8307\n",
      "Epoch 15/15 | Train Loss: 0.4333 Acc: 0.7638\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7269 Acc: 0.5945\n",
      "Epoch 2/15 | Train Loss: 0.6049 Acc: 0.6929\n",
      "Epoch 3/15 | Train Loss: 0.5420 Acc: 0.7008\n",
      "Epoch 4/15 | Train Loss: 0.5333 Acc: 0.6929\n",
      "Epoch 5/15 | Train Loss: 0.5266 Acc: 0.7283\n",
      "Epoch 6/15 | Train Loss: 0.5507 Acc: 0.7402\n",
      "Epoch 7/15 | Train Loss: 0.5086 Acc: 0.7047\n",
      "Epoch 8/15 | Train Loss: 0.5175 Acc: 0.7520\n",
      "Epoch 9/15 | Train Loss: 0.4283 Acc: 0.7992\n",
      "Epoch 10/15 | Train Loss: 0.4512 Acc: 0.7795\n",
      "Epoch 11/15 | Train Loss: 0.4029 Acc: 0.8071\n",
      "Epoch 12/15 | Train Loss: 0.4214 Acc: 0.8110\n",
      "Epoch 13/15 | Train Loss: 0.4436 Acc: 0.7677\n",
      "Epoch 14/15 | Train Loss: 0.3641 Acc: 0.8543\n",
      "Epoch 15/15 | Train Loss: 0.4513 Acc: 0.7559\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6350 Acc: 0.7342\n",
      "Epoch 2/15 | Train Loss: 0.5258 Acc: 0.7806\n",
      "Epoch 3/15 | Train Loss: 0.4442 Acc: 0.7722\n",
      "Epoch 4/15 | Train Loss: 0.5334 Acc: 0.7468\n",
      "Epoch 5/15 | Train Loss: 0.4490 Acc: 0.7890\n",
      "Epoch 6/15 | Train Loss: 0.4867 Acc: 0.7806\n",
      "Epoch 7/15 | Train Loss: 0.4284 Acc: 0.7975\n",
      "Epoch 8/15 | Train Loss: 0.4548 Acc: 0.7764\n",
      "Epoch 9/15 | Train Loss: 0.4213 Acc: 0.8017\n",
      "Epoch 10/15 | Train Loss: 0.4256 Acc: 0.8228\n",
      "Epoch 11/15 | Train Loss: 0.3882 Acc: 0.8397\n",
      "Epoch 12/15 | Train Loss: 0.3759 Acc: 0.8354\n",
      "Epoch 13/15 | Train Loss: 0.3884 Acc: 0.8312\n",
      "Epoch 14/15 | Train Loss: 0.3592 Acc: 0.8397\n",
      "Epoch 15/15 | Train Loss: 0.3800 Acc: 0.8270\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5029 Acc: 0.7511\n",
      "Epoch 2/15 | Train Loss: 0.4330 Acc: 0.8253\n",
      "Epoch 3/15 | Train Loss: 0.3771 Acc: 0.8559\n",
      "Epoch 4/15 | Train Loss: 0.4589 Acc: 0.8297\n",
      "Epoch 5/15 | Train Loss: 0.4228 Acc: 0.8297\n",
      "Epoch 6/15 | Train Loss: 0.3730 Acc: 0.8384\n",
      "Epoch 7/15 | Train Loss: 0.3313 Acc: 0.8734\n",
      "Epoch 8/15 | Train Loss: 0.3727 Acc: 0.8079\n",
      "Epoch 9/15 | Train Loss: 0.3127 Acc: 0.8734\n",
      "Epoch 10/15 | Train Loss: 0.3278 Acc: 0.8690\n",
      "Epoch 11/15 | Train Loss: 0.2972 Acc: 0.8996\n",
      "Epoch 12/15 | Train Loss: 0.2756 Acc: 0.8821\n",
      "Epoch 13/15 | Train Loss: 0.2319 Acc: 0.8996\n",
      "Epoch 14/15 | Train Loss: 0.2861 Acc: 0.8821\n",
      "Epoch 15/15 | Train Loss: 0.2673 Acc: 0.8865\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5363 Acc: 0.7461\n",
      "Epoch 2/15 | Train Loss: 0.3956 Acc: 0.7798\n",
      "Epoch 3/15 | Train Loss: 0.4099 Acc: 0.7617\n",
      "Epoch 4/15 | Train Loss: 0.3677 Acc: 0.7979\n",
      "Epoch 5/15 | Train Loss: 0.3643 Acc: 0.8083\n",
      "Epoch 6/15 | Train Loss: 0.3321 Acc: 0.8290\n",
      "Epoch 7/15 | Train Loss: 0.3169 Acc: 0.8523\n",
      "Epoch 8/15 | Train Loss: 0.2737 Acc: 0.8731\n",
      "Epoch 9/15 | Train Loss: 0.2957 Acc: 0.8472\n",
      "Epoch 10/15 | Train Loss: 0.2525 Acc: 0.8834\n",
      "Epoch 11/15 | Train Loss: 0.2443 Acc: 0.8808\n",
      "Epoch 12/15 | Train Loss: 0.2424 Acc: 0.8756\n",
      "Epoch 13/15 | Train Loss: 0.2644 Acc: 0.8705\n",
      "Epoch 14/15 | Train Loss: 0.2767 Acc: 0.8549\n",
      "Epoch 15/15 | Train Loss: 0.2370 Acc: 0.8886\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.6399 Acc: 0.7280\n",
      "Epoch 2/15 | Train Loss: 0.3976 Acc: 0.7824\n",
      "Epoch 3/15 | Train Loss: 0.4139 Acc: 0.7642\n",
      "Epoch 4/15 | Train Loss: 0.3736 Acc: 0.7953\n",
      "Epoch 5/15 | Train Loss: 0.3505 Acc: 0.8135\n",
      "Epoch 6/15 | Train Loss: 0.3613 Acc: 0.7850\n",
      "Epoch 7/15 | Train Loss: 0.3606 Acc: 0.7902\n",
      "Epoch 8/15 | Train Loss: 0.3190 Acc: 0.8264\n",
      "Epoch 9/15 | Train Loss: 0.3226 Acc: 0.8264\n",
      "Epoch 10/15 | Train Loss: 0.3058 Acc: 0.8627\n",
      "Epoch 11/15 | Train Loss: 0.3207 Acc: 0.8264\n",
      "Epoch 12/15 | Train Loss: 0.2976 Acc: 0.8575\n",
      "Epoch 13/15 | Train Loss: 0.2727 Acc: 0.8912\n",
      "Epoch 14/15 | Train Loss: 0.2846 Acc: 0.8731\n",
      "Epoch 15/15 | Train Loss: 0.2573 Acc: 0.8912\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.5314 Acc: 0.7694\n",
      "Epoch 2/15 | Train Loss: 0.4101 Acc: 0.7902\n",
      "Epoch 3/15 | Train Loss: 0.3882 Acc: 0.8083\n",
      "Epoch 4/15 | Train Loss: 0.3750 Acc: 0.7927\n",
      "Epoch 5/15 | Train Loss: 0.3761 Acc: 0.7953\n",
      "Epoch 6/15 | Train Loss: 0.3779 Acc: 0.8135\n",
      "Epoch 7/15 | Train Loss: 0.3274 Acc: 0.8368\n",
      "Epoch 8/15 | Train Loss: 0.2970 Acc: 0.8575\n",
      "Epoch 9/15 | Train Loss: 0.3287 Acc: 0.8238\n",
      "Epoch 10/15 | Train Loss: 0.3163 Acc: 0.8446\n",
      "Epoch 11/15 | Train Loss: 0.2765 Acc: 0.8756\n",
      "Epoch 12/15 | Train Loss: 0.2920 Acc: 0.8549\n",
      "Epoch 13/15 | Train Loss: 0.2846 Acc: 0.8679\n",
      "Epoch 14/15 | Train Loss: 0.3141 Acc: 0.8290\n",
      "Epoch 15/15 | Train Loss: 0.2849 Acc: 0.8446\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.5267 Acc: 0.7746\n",
      "Epoch 2/15 | Train Loss: 0.5320 Acc: 0.7746\n",
      "Epoch 3/15 | Train Loss: 0.4020 Acc: 0.8159\n",
      "Epoch 4/15 | Train Loss: 0.3602 Acc: 0.8413\n",
      "Epoch 5/15 | Train Loss: 0.3804 Acc: 0.8381\n",
      "Epoch 6/15 | Train Loss: 0.3368 Acc: 0.8381\n",
      "Epoch 7/15 | Train Loss: 0.3484 Acc: 0.8476\n",
      "Epoch 8/15 | Train Loss: 0.3093 Acc: 0.8540\n",
      "Epoch 9/15 | Train Loss: 0.2832 Acc: 0.8889\n",
      "Epoch 10/15 | Train Loss: 0.3133 Acc: 0.8667\n",
      "Epoch 11/15 | Train Loss: 0.2751 Acc: 0.8762\n",
      "Epoch 12/15 | Train Loss: 0.2702 Acc: 0.8889\n",
      "Epoch 13/15 | Train Loss: 0.2826 Acc: 0.8635\n",
      "Epoch 14/15 | Train Loss: 0.2967 Acc: 0.8635\n",
      "Epoch 15/15 | Train Loss: 0.2713 Acc: 0.8857\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.4741 Acc: 0.8269\n",
      "Epoch 2/15 | Train Loss: 0.4064 Acc: 0.8693\n",
      "Epoch 3/15 | Train Loss: 0.3519 Acc: 0.8410\n",
      "Epoch 4/15 | Train Loss: 0.3489 Acc: 0.8657\n",
      "Epoch 5/15 | Train Loss: 0.3178 Acc: 0.8834\n",
      "Epoch 6/15 | Train Loss: 0.3234 Acc: 0.8799\n",
      "Epoch 7/15 | Train Loss: 0.2695 Acc: 0.8975\n",
      "Epoch 8/15 | Train Loss: 0.2669 Acc: 0.8869\n",
      "Epoch 9/15 | Train Loss: 0.2674 Acc: 0.8763\n",
      "Epoch 10/15 | Train Loss: 0.2476 Acc: 0.9187\n",
      "Epoch 11/15 | Train Loss: 0.2594 Acc: 0.8975\n",
      "Epoch 12/15 | Train Loss: 0.2261 Acc: 0.9046\n",
      "Epoch 13/15 | Train Loss: 0.2034 Acc: 0.9258\n",
      "Epoch 14/15 | Train Loss: 0.2273 Acc: 0.9046\n",
      "Epoch 15/15 | Train Loss: 0.2207 Acc: 0.9187\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.7402 Acc: 0.5945\n",
      "Epoch 2/15 | Train Loss: 0.5845 Acc: 0.6969\n",
      "Epoch 3/15 | Train Loss: 0.5808 Acc: 0.7087\n",
      "Epoch 4/15 | Train Loss: 0.5547 Acc: 0.7008\n",
      "Epoch 5/15 | Train Loss: 0.4756 Acc: 0.7795\n",
      "Epoch 6/15 | Train Loss: 0.4619 Acc: 0.7874\n",
      "Epoch 7/15 | Train Loss: 0.4097 Acc: 0.8031\n",
      "Epoch 8/15 | Train Loss: 0.4011 Acc: 0.8189\n",
      "Epoch 9/15 | Train Loss: 0.4214 Acc: 0.8228\n",
      "Epoch 10/15 | Train Loss: 0.3645 Acc: 0.8425\n",
      "Epoch 11/15 | Train Loss: 0.4036 Acc: 0.7992\n",
      "Epoch 12/15 | Train Loss: 0.3730 Acc: 0.7756\n",
      "Epoch 13/15 | Train Loss: 0.3555 Acc: 0.8425\n",
      "Epoch 14/15 | Train Loss: 0.3362 Acc: 0.8189\n",
      "Epoch 15/15 | Train Loss: 0.3523 Acc: 0.8504\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6948 Acc: 0.5945\n",
      "Epoch 2/15 | Train Loss: 0.5703 Acc: 0.6732\n",
      "Epoch 3/15 | Train Loss: 0.5321 Acc: 0.7283\n",
      "Epoch 4/15 | Train Loss: 0.5466 Acc: 0.7205\n",
      "Epoch 5/15 | Train Loss: 0.4936 Acc: 0.7480\n",
      "Epoch 6/15 | Train Loss: 0.6211 Acc: 0.7165\n",
      "Epoch 7/15 | Train Loss: 0.4660 Acc: 0.7638\n",
      "Epoch 8/15 | Train Loss: 0.4322 Acc: 0.8071\n",
      "Epoch 9/15 | Train Loss: 0.4716 Acc: 0.7559\n",
      "Epoch 10/15 | Train Loss: 0.4011 Acc: 0.8228\n",
      "Epoch 11/15 | Train Loss: 0.4465 Acc: 0.7756\n",
      "Epoch 12/15 | Train Loss: 0.4155 Acc: 0.8071\n",
      "Epoch 13/15 | Train Loss: 0.4263 Acc: 0.7953\n",
      "Epoch 14/15 | Train Loss: 0.4131 Acc: 0.8031\n",
      "Epoch 15/15 | Train Loss: 0.3966 Acc: 0.7874\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7055 Acc: 0.6378\n",
      "Epoch 2/15 | Train Loss: 0.5866 Acc: 0.7205\n",
      "Epoch 3/15 | Train Loss: 0.5643 Acc: 0.7244\n",
      "Epoch 4/15 | Train Loss: 0.5264 Acc: 0.7165\n",
      "Epoch 5/15 | Train Loss: 0.5342 Acc: 0.7008\n",
      "Epoch 6/15 | Train Loss: 0.4438 Acc: 0.7677\n",
      "Epoch 7/15 | Train Loss: 0.4858 Acc: 0.7559\n",
      "Epoch 8/15 | Train Loss: 0.4722 Acc: 0.7717\n",
      "Epoch 9/15 | Train Loss: 0.4389 Acc: 0.7795\n",
      "Epoch 10/15 | Train Loss: 0.4376 Acc: 0.8031\n",
      "Epoch 11/15 | Train Loss: 0.3971 Acc: 0.8071\n",
      "Epoch 12/15 | Train Loss: 0.4581 Acc: 0.7835\n",
      "Epoch 13/15 | Train Loss: 0.4356 Acc: 0.7913\n",
      "Epoch 14/15 | Train Loss: 0.3846 Acc: 0.7913\n",
      "Epoch 15/15 | Train Loss: 0.4505 Acc: 0.7402\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.6913 Acc: 0.6287\n",
      "Epoch 2/15 | Train Loss: 0.5115 Acc: 0.7468\n",
      "Epoch 3/15 | Train Loss: 0.5356 Acc: 0.7806\n",
      "Epoch 4/15 | Train Loss: 0.4495 Acc: 0.7890\n",
      "Epoch 5/15 | Train Loss: 0.4612 Acc: 0.7932\n",
      "Epoch 6/15 | Train Loss: 0.5001 Acc: 0.7637\n",
      "Epoch 7/15 | Train Loss: 0.4376 Acc: 0.8017\n",
      "Epoch 8/15 | Train Loss: 0.4363 Acc: 0.7848\n",
      "Epoch 9/15 | Train Loss: 0.4550 Acc: 0.7975\n",
      "Epoch 10/15 | Train Loss: 0.3901 Acc: 0.8439\n",
      "Epoch 11/15 | Train Loss: 0.4004 Acc: 0.8228\n",
      "Epoch 12/15 | Train Loss: 0.3891 Acc: 0.8228\n",
      "Epoch 13/15 | Train Loss: 0.3721 Acc: 0.8397\n",
      "Epoch 14/15 | Train Loss: 0.3844 Acc: 0.8481\n",
      "Epoch 15/15 | Train Loss: 0.4047 Acc: 0.8059\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5301 Acc: 0.7380\n",
      "Epoch 2/15 | Train Loss: 0.4602 Acc: 0.8253\n",
      "Epoch 3/15 | Train Loss: 0.3587 Acc: 0.8777\n",
      "Epoch 4/15 | Train Loss: 0.4236 Acc: 0.8253\n",
      "Epoch 5/15 | Train Loss: 0.3668 Acc: 0.8341\n",
      "Epoch 6/15 | Train Loss: 0.3514 Acc: 0.8559\n",
      "Epoch 7/15 | Train Loss: 0.3367 Acc: 0.8646\n",
      "Epoch 8/15 | Train Loss: 0.3525 Acc: 0.8428\n",
      "Epoch 9/15 | Train Loss: 0.3033 Acc: 0.8821\n",
      "Epoch 10/15 | Train Loss: 0.2584 Acc: 0.8865\n",
      "Epoch 11/15 | Train Loss: 0.3155 Acc: 0.8777\n",
      "Epoch 12/15 | Train Loss: 0.3123 Acc: 0.8777\n",
      "Epoch 13/15 | Train Loss: 0.2829 Acc: 0.8952\n",
      "Epoch 14/15 | Train Loss: 0.2979 Acc: 0.8865\n",
      "Epoch 15/15 | Train Loss: 0.2472 Acc: 0.9083\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5080 Acc: 0.7608\n",
      "Epoch 2/15 | Train Loss: 0.4143 Acc: 0.7882\n",
      "Epoch 3/15 | Train Loss: 0.3603 Acc: 0.8087\n",
      "Epoch 4/15 | Train Loss: 0.3572 Acc: 0.8292\n",
      "Epoch 5/15 | Train Loss: 0.3109 Acc: 0.8383\n",
      "Epoch 6/15 | Train Loss: 0.3701 Acc: 0.7950\n",
      "Epoch 7/15 | Train Loss: 0.3363 Acc: 0.8155\n",
      "Epoch 8/15 | Train Loss: 0.3094 Acc: 0.8405\n",
      "Epoch 9/15 | Train Loss: 0.3279 Acc: 0.8360\n",
      "Epoch 10/15 | Train Loss: 0.2716 Acc: 0.8747\n",
      "Epoch 11/15 | Train Loss: 0.2803 Acc: 0.8702\n",
      "Epoch 12/15 | Train Loss: 0.2758 Acc: 0.8679\n",
      "Epoch 13/15 | Train Loss: 0.2612 Acc: 0.8815\n",
      "Epoch 14/15 | Train Loss: 0.2542 Acc: 0.8907\n",
      "Epoch 15/15 | Train Loss: 0.2964 Acc: 0.8610\n",
      "Fold 9 Test Accuracy: 0.7040\n",
      "===== Fold 10 =====\n",
      "Epoch 1: Generator Loss = 9.7758, Discriminator Loss = 8.7374\n",
      "Epoch 2: Generator Loss = 10.3810, Discriminator Loss = 8.8566\n",
      "Epoch 3: Generator Loss = 13.3836, Discriminator Loss = 7.2058\n",
      "Epoch 4: Generator Loss = 18.8253, Discriminator Loss = 5.0699\n",
      "Epoch 5: Generator Loss = 24.4430, Discriminator Loss = 6.4292\n",
      "Epoch 6: Generator Loss = 25.8259, Discriminator Loss = 5.2969\n",
      "Epoch 7: Generator Loss = 21.5308, Discriminator Loss = 5.2595\n",
      "Epoch 8: Generator Loss = 26.0146, Discriminator Loss = 5.4870\n",
      "Epoch 9: Generator Loss = 21.6192, Discriminator Loss = 10.0731\n",
      "Epoch 10: Generator Loss = 17.7018, Discriminator Loss = 9.2805\n",
      "Epoch 11: Generator Loss = 15.6532, Discriminator Loss = 7.7578\n",
      "Epoch 12: Generator Loss = 17.8102, Discriminator Loss = 7.8675\n",
      "Epoch 13: Generator Loss = 18.9025, Discriminator Loss = 7.5409\n",
      "Epoch 14: Generator Loss = 21.1303, Discriminator Loss = 6.8349\n",
      "Epoch 15: Generator Loss = 22.4262, Discriminator Loss = 6.6481\n",
      "Epoch 16: Generator Loss = 22.1953, Discriminator Loss = 8.1486\n",
      "Epoch 17: Generator Loss = 22.1659, Discriminator Loss = 7.2861\n",
      "Epoch 18: Generator Loss = 18.1592, Discriminator Loss = 8.9680\n",
      "Epoch 19: Generator Loss = 16.7173, Discriminator Loss = 7.6458\n",
      "Epoch 20: Generator Loss = 13.0740, Discriminator Loss = 8.3544\n",
      "Epoch 21: Generator Loss = 17.1061, Discriminator Loss = 10.3827\n",
      "Epoch 22: Generator Loss = 14.6167, Discriminator Loss = 9.0205\n",
      "Epoch 23: Generator Loss = 16.1951, Discriminator Loss = 8.7779\n",
      "Epoch 24: Generator Loss = 16.2797, Discriminator Loss = 7.2472\n",
      "Epoch 25: Generator Loss = 17.8212, Discriminator Loss = 10.2458\n",
      "Epoch 26: Generator Loss = 17.1970, Discriminator Loss = 7.8887\n",
      "Epoch 27: Generator Loss = 16.4431, Discriminator Loss = 7.5054\n",
      "Epoch 28: Generator Loss = 25.3017, Discriminator Loss = 6.9173\n",
      "Epoch 29: Generator Loss = 22.2116, Discriminator Loss = 8.1695\n",
      "Epoch 30: Generator Loss = 18.7264, Discriminator Loss = 8.1602\n",
      "Epoch 31: Generator Loss = 21.2335, Discriminator Loss = 7.5146\n",
      "Epoch 32: Generator Loss = 21.1773, Discriminator Loss = 6.1936\n",
      "Epoch 33: Generator Loss = 22.9428, Discriminator Loss = 8.4162\n",
      "Epoch 34: Generator Loss = 20.4307, Discriminator Loss = 8.1198\n",
      "Epoch 35: Generator Loss = 20.0453, Discriminator Loss = 7.9581\n",
      "Epoch 36: Generator Loss = 17.1997, Discriminator Loss = 8.2620\n",
      "Epoch 37: Generator Loss = 15.6286, Discriminator Loss = 9.9121\n",
      "Epoch 38: Generator Loss = 16.6719, Discriminator Loss = 8.0038\n",
      "Epoch 39: Generator Loss = 14.5026, Discriminator Loss = 8.3927\n",
      "Epoch 40: Generator Loss = 19.5693, Discriminator Loss = 6.8426\n",
      "Epoch 41: Generator Loss = 18.1014, Discriminator Loss = 7.3917\n",
      "Epoch 42: Generator Loss = 18.3605, Discriminator Loss = 8.4774\n",
      "Epoch 43: Generator Loss = 15.1990, Discriminator Loss = 8.0050\n",
      "Epoch 44: Generator Loss = 22.5797, Discriminator Loss = 7.3863\n",
      "Epoch 45: Generator Loss = 18.5855, Discriminator Loss = 6.7747\n",
      "Epoch 46: Generator Loss = 23.1011, Discriminator Loss = 5.6917\n",
      "Epoch 47: Generator Loss = 31.3572, Discriminator Loss = 6.5758\n",
      "Epoch 48: Generator Loss = 33.0335, Discriminator Loss = 6.2681\n",
      "Epoch 49: Generator Loss = 20.8429, Discriminator Loss = 7.9483\n",
      "Epoch 50: Generator Loss = 24.5567, Discriminator Loss = 6.7931\n",
      "Epoch 51: Generator Loss = 33.5306, Discriminator Loss = 5.1373\n",
      "Epoch 52: Generator Loss = 27.2367, Discriminator Loss = 5.8098\n",
      "Epoch 53: Generator Loss = 25.4315, Discriminator Loss = 4.5848\n",
      "Epoch 54: Generator Loss = 24.4454, Discriminator Loss = 6.4995\n",
      "Epoch 55: Generator Loss = 32.0291, Discriminator Loss = 4.5577\n",
      "Epoch 56: Generator Loss = 23.1812, Discriminator Loss = 5.4147\n",
      "Epoch 57: Generator Loss = 28.5023, Discriminator Loss = 6.5013\n",
      "Epoch 58: Generator Loss = 32.4855, Discriminator Loss = 3.8174\n",
      "Epoch 59: Generator Loss = 33.1426, Discriminator Loss = 5.0099\n",
      "Epoch 60: Generator Loss = 40.7236, Discriminator Loss = 3.0618\n",
      "Epoch 61: Generator Loss = 42.0572, Discriminator Loss = 6.4795\n",
      "Epoch 62: Generator Loss = 31.9543, Discriminator Loss = 5.8647\n",
      "Epoch 63: Generator Loss = 31.5559, Discriminator Loss = 5.5026\n",
      "Epoch 64: Generator Loss = 36.6537, Discriminator Loss = 4.3108\n",
      "Epoch 65: Generator Loss = 33.2001, Discriminator Loss = 4.3649\n",
      "Epoch 66: Generator Loss = 30.5918, Discriminator Loss = 4.7345\n",
      "Epoch 67: Generator Loss = 48.9129, Discriminator Loss = 3.0188\n",
      "Epoch 68: Generator Loss = 28.1690, Discriminator Loss = 4.1095\n",
      "Epoch 69: Generator Loss = 33.0405, Discriminator Loss = 8.0395\n",
      "Epoch 70: Generator Loss = 35.6589, Discriminator Loss = 4.0549\n",
      "Epoch 71: Generator Loss = 35.2953, Discriminator Loss = 4.0182\n",
      "Epoch 72: Generator Loss = 47.5577, Discriminator Loss = 3.0247\n",
      "Epoch 73: Generator Loss = 41.0558, Discriminator Loss = 4.3022\n",
      "Epoch 74: Generator Loss = 36.2562, Discriminator Loss = 3.8732\n",
      "Epoch 75: Generator Loss = 41.5475, Discriminator Loss = 4.0038\n",
      "Epoch 76: Generator Loss = 45.3245, Discriminator Loss = 3.0706\n",
      "Epoch 77: Generator Loss = 48.8615, Discriminator Loss = 2.2369\n",
      "Epoch 78: Generator Loss = 47.2013, Discriminator Loss = 3.2106\n",
      "Epoch 79: Generator Loss = 37.9197, Discriminator Loss = 3.9891\n",
      "Epoch 80: Generator Loss = 39.0117, Discriminator Loss = 2.6292\n",
      "Epoch 81: Generator Loss = 45.2439, Discriminator Loss = 1.7134\n",
      "Epoch 82: Generator Loss = 69.5725, Discriminator Loss = 2.2940\n",
      "Epoch 83: Generator Loss = 56.0718, Discriminator Loss = 3.2184\n",
      "Epoch 84: Generator Loss = 42.5898, Discriminator Loss = 1.6716\n",
      "Epoch 85: Generator Loss = 49.5894, Discriminator Loss = 2.6810\n",
      "Epoch 86: Generator Loss = 57.6918, Discriminator Loss = 2.7181\n",
      "Epoch 87: Generator Loss = 41.2135, Discriminator Loss = 4.1924\n",
      "Epoch 88: Generator Loss = 58.1972, Discriminator Loss = 2.4166\n",
      "Epoch 89: Generator Loss = 59.7767, Discriminator Loss = 1.6823\n",
      "Epoch 90: Generator Loss = 46.9831, Discriminator Loss = 3.5292\n",
      "Epoch 91: Generator Loss = 57.4308, Discriminator Loss = 1.7854\n",
      "Epoch 92: Generator Loss = 52.5796, Discriminator Loss = 1.2546\n",
      "Epoch 93: Generator Loss = 53.2008, Discriminator Loss = 0.8888\n",
      "Epoch 94: Generator Loss = 55.6413, Discriminator Loss = 1.5536\n",
      "Epoch 95: Generator Loss = 52.5367, Discriminator Loss = 2.0239\n",
      "Epoch 96: Generator Loss = 57.1969, Discriminator Loss = 2.3822\n",
      "Epoch 97: Generator Loss = 62.8532, Discriminator Loss = 1.4333\n",
      "Epoch 98: Generator Loss = 57.8801, Discriminator Loss = 1.5314\n",
      "Epoch 99: Generator Loss = 54.9218, Discriminator Loss = 0.8415\n",
      "Epoch 100: Generator Loss = 79.6535, Discriminator Loss = 1.9708\n",
      "Epoch 101: Generator Loss = 49.4533, Discriminator Loss = 2.2661\n",
      "Epoch 102: Generator Loss = 67.6405, Discriminator Loss = 2.1185\n",
      "Epoch 103: Generator Loss = 65.5684, Discriminator Loss = 0.8213\n",
      "Epoch 104: Generator Loss = 64.5551, Discriminator Loss = 0.9100\n",
      "Epoch 105: Generator Loss = 69.0526, Discriminator Loss = 0.7311\n",
      "Epoch 106: Generator Loss = 63.8524, Discriminator Loss = 1.5709\n",
      "Epoch 107: Generator Loss = 52.1508, Discriminator Loss = 0.9943\n",
      "Epoch 108: Generator Loss = 75.1816, Discriminator Loss = 0.7768\n",
      "Epoch 109: Generator Loss = 81.3232, Discriminator Loss = 1.5171\n",
      "Epoch 110: Generator Loss = 59.3115, Discriminator Loss = 0.9958\n",
      "Epoch 111: Generator Loss = 77.1932, Discriminator Loss = 0.9455\n",
      "Epoch 112: Generator Loss = 76.6148, Discriminator Loss = 0.5674\n",
      "Epoch 113: Generator Loss = 57.7459, Discriminator Loss = 10.8104\n",
      "Epoch 114: Generator Loss = 30.8626, Discriminator Loss = 5.2511\n",
      "Epoch 115: Generator Loss = 50.5079, Discriminator Loss = 4.3079\n",
      "Epoch 116: Generator Loss = 41.2990, Discriminator Loss = 2.7238\n",
      "Epoch 117: Generator Loss = 50.7920, Discriminator Loss = 3.5087\n",
      "Epoch 118: Generator Loss = 49.3389, Discriminator Loss = 3.5559\n",
      "Epoch 119: Generator Loss = 46.5673, Discriminator Loss = 2.4452\n",
      "Epoch 120: Generator Loss = 58.3087, Discriminator Loss = 1.2848\n",
      "Epoch 121: Generator Loss = 54.5286, Discriminator Loss = 1.0116\n",
      "Epoch 122: Generator Loss = 77.5161, Discriminator Loss = 1.5062\n",
      "Epoch 123: Generator Loss = 61.7737, Discriminator Loss = 0.7940\n",
      "Epoch 124: Generator Loss = 69.9791, Discriminator Loss = 1.4278\n",
      "Epoch 125: Generator Loss = 77.6239, Discriminator Loss = 0.9897\n",
      "Epoch 126: Generator Loss = 58.4136, Discriminator Loss = 0.9040\n",
      "Epoch 127: Generator Loss = 56.5276, Discriminator Loss = 0.8959\n",
      "Epoch 128: Generator Loss = 82.8867, Discriminator Loss = 0.9330\n",
      "Epoch 129: Generator Loss = 76.1409, Discriminator Loss = 0.3738\n",
      "Epoch 130: Generator Loss = 93.4877, Discriminator Loss = 0.7336\n",
      "Epoch 131: Generator Loss = 80.3726, Discriminator Loss = 0.5696\n",
      "Epoch 132: Generator Loss = 68.3595, Discriminator Loss = 0.7477\n",
      "Epoch 133: Generator Loss = 69.4270, Discriminator Loss = 0.9527\n",
      "Epoch 134: Generator Loss = 73.0283, Discriminator Loss = 0.8973\n",
      "Epoch 135: Generator Loss = 70.1748, Discriminator Loss = 0.8973\n",
      "Epoch 136: Generator Loss = 72.2849, Discriminator Loss = 1.9452\n",
      "Epoch 137: Generator Loss = 75.7855, Discriminator Loss = 0.7447\n",
      "Epoch 138: Generator Loss = 87.5944, Discriminator Loss = 1.2880\n",
      "Epoch 139: Generator Loss = 79.5059, Discriminator Loss = 0.6810\n",
      "Epoch 140: Generator Loss = 91.4667, Discriminator Loss = 0.7830\n",
      "Epoch 141: Generator Loss = 79.5474, Discriminator Loss = 0.7847\n",
      "Epoch 142: Generator Loss = 76.6112, Discriminator Loss = 0.7420\n",
      "Epoch 143: Generator Loss = 73.6120, Discriminator Loss = 0.9055\n",
      "Epoch 144: Generator Loss = 80.4698, Discriminator Loss = 0.8651\n",
      "Epoch 145: Generator Loss = 85.9770, Discriminator Loss = 0.7132\n",
      "Epoch 146: Generator Loss = 70.8625, Discriminator Loss = 1.6136\n",
      "Epoch 147: Generator Loss = 65.4279, Discriminator Loss = 1.6471\n",
      "Epoch 148: Generator Loss = 57.9474, Discriminator Loss = 1.0167\n",
      "Epoch 149: Generator Loss = 97.0454, Discriminator Loss = 2.1672\n",
      "Epoch 150: Generator Loss = 61.1235, Discriminator Loss = 1.3716\n",
      "Epoch 151: Generator Loss = 80.4024, Discriminator Loss = 1.1338\n",
      "Epoch 152: Generator Loss = 77.2748, Discriminator Loss = 0.5778\n",
      "Epoch 153: Generator Loss = 76.5902, Discriminator Loss = 0.7834\n",
      "Epoch 154: Generator Loss = 68.5266, Discriminator Loss = 1.6838\n",
      "Epoch 155: Generator Loss = 91.0865, Discriminator Loss = 0.9179\n",
      "Epoch 156: Generator Loss = 54.4739, Discriminator Loss = 5.9499\n",
      "Epoch 157: Generator Loss = 55.4616, Discriminator Loss = 2.9246\n",
      "Epoch 158: Generator Loss = 68.2013, Discriminator Loss = 1.4644\n",
      "Epoch 159: Generator Loss = 67.3922, Discriminator Loss = 1.2704\n",
      "Epoch 160: Generator Loss = 67.2627, Discriminator Loss = 1.1073\n",
      "Epoch 161: Generator Loss = 67.6644, Discriminator Loss = 0.9186\n",
      "Epoch 162: Generator Loss = 92.5034, Discriminator Loss = 0.7443\n",
      "Epoch 163: Generator Loss = 79.4000, Discriminator Loss = 0.5918\n",
      "Epoch 164: Generator Loss = 95.6720, Discriminator Loss = 1.1327\n",
      "Epoch 165: Generator Loss = 92.5337, Discriminator Loss = 0.6020\n",
      "Epoch 166: Generator Loss = 85.5188, Discriminator Loss = 1.3965\n",
      "Epoch 167: Generator Loss = 95.5208, Discriminator Loss = 3.2235\n",
      "Epoch 168: Generator Loss = 95.1776, Discriminator Loss = 0.7899\n",
      "Epoch 169: Generator Loss = 94.0654, Discriminator Loss = 0.9679\n",
      "Epoch 170: Generator Loss = 70.2212, Discriminator Loss = 0.3942\n",
      "Epoch 171: Generator Loss = 85.4231, Discriminator Loss = 1.0431\n",
      "Epoch 172: Generator Loss = 85.3996, Discriminator Loss = 1.1179\n",
      "Epoch 173: Generator Loss = 85.1073, Discriminator Loss = 0.5111\n",
      "Epoch 174: Generator Loss = 84.0654, Discriminator Loss = 0.4565\n",
      "Epoch 175: Generator Loss = 83.6028, Discriminator Loss = 1.1932\n",
      "Epoch 176: Generator Loss = 76.1306, Discriminator Loss = 0.4946\n",
      "Epoch 177: Generator Loss = 101.1862, Discriminator Loss = 0.4324\n",
      "Epoch 178: Generator Loss = 82.2345, Discriminator Loss = 0.6658\n",
      "Epoch 179: Generator Loss = 78.6089, Discriminator Loss = 1.7376\n",
      "Epoch 180: Generator Loss = 89.9312, Discriminator Loss = 5.7820\n",
      "Epoch 181: Generator Loss = 63.2821, Discriminator Loss = 5.3374\n",
      "Epoch 182: Generator Loss = 98.6116, Discriminator Loss = 8.4992\n",
      "Epoch 183: Generator Loss = 72.2986, Discriminator Loss = 1.8967\n",
      "Epoch 184: Generator Loss = 73.4453, Discriminator Loss = 1.1437\n",
      "Epoch 185: Generator Loss = 69.9678, Discriminator Loss = 2.0307\n",
      "Epoch 186: Generator Loss = 69.3805, Discriminator Loss = 1.6030\n",
      "Epoch 187: Generator Loss = 69.1270, Discriminator Loss = 0.6778\n",
      "Epoch 188: Generator Loss = 68.3748, Discriminator Loss = 1.4596\n",
      "Epoch 189: Generator Loss = 100.6745, Discriminator Loss = 0.7314\n",
      "Epoch 190: Generator Loss = 85.5636, Discriminator Loss = 0.9717\n",
      "Epoch 191: Generator Loss = 78.5818, Discriminator Loss = 9.1094\n",
      "Epoch 192: Generator Loss = 41.9761, Discriminator Loss = 7.5774\n",
      "Epoch 193: Generator Loss = 41.8439, Discriminator Loss = 8.3124\n",
      "Epoch 194: Generator Loss = 49.1561, Discriminator Loss = 4.1425\n",
      "Epoch 195: Generator Loss = 41.2357, Discriminator Loss = 3.2460\n",
      "Epoch 196: Generator Loss = 45.5155, Discriminator Loss = 2.2221\n",
      "Epoch 197: Generator Loss = 59.0409, Discriminator Loss = 2.4944\n",
      "Epoch 198: Generator Loss = 57.2758, Discriminator Loss = 2.5912\n",
      "Epoch 199: Generator Loss = 82.3585, Discriminator Loss = 2.2049\n",
      "Epoch 200: Generator Loss = 73.2701, Discriminator Loss = 1.3174\n",
      "Epoch 201: Generator Loss = 56.8254, Discriminator Loss = 3.2133\n",
      "Epoch 202: Generator Loss = 66.4584, Discriminator Loss = 1.4126\n",
      "Epoch 203: Generator Loss = 76.2227, Discriminator Loss = 1.1894\n",
      "Epoch 204: Generator Loss = 79.0886, Discriminator Loss = 2.6650\n",
      "Epoch 205: Generator Loss = 54.8754, Discriminator Loss = 2.3663\n",
      "Epoch 206: Generator Loss = 64.4531, Discriminator Loss = 0.6881\n",
      "Epoch 207: Generator Loss = 72.7359, Discriminator Loss = 0.8222\n",
      "Epoch 208: Generator Loss = 67.1371, Discriminator Loss = 1.1364\n",
      "Epoch 209: Generator Loss = 63.3267, Discriminator Loss = 4.0684\n",
      "Epoch 210: Generator Loss = 70.4792, Discriminator Loss = 2.0432\n",
      "Epoch 211: Generator Loss = 81.0710, Discriminator Loss = 1.0710\n",
      "Epoch 212: Generator Loss = 55.1220, Discriminator Loss = 1.5522\n",
      "Epoch 213: Generator Loss = 62.3300, Discriminator Loss = 2.3618\n",
      "Epoch 214: Generator Loss = 75.6871, Discriminator Loss = 2.1832\n",
      "Epoch 215: Generator Loss = 78.8104, Discriminator Loss = 1.8299\n",
      "Epoch 216: Generator Loss = 62.3457, Discriminator Loss = 1.4765\n",
      "Epoch 217: Generator Loss = 87.9368, Discriminator Loss = 1.0326\n",
      "Epoch 218: Generator Loss = 52.3431, Discriminator Loss = 3.9602\n",
      "Epoch 219: Generator Loss = 83.1987, Discriminator Loss = 6.6285\n",
      "Epoch 220: Generator Loss = 58.6914, Discriminator Loss = 2.5695\n",
      "Epoch 221: Generator Loss = 59.0869, Discriminator Loss = 2.3579\n",
      "Epoch 222: Generator Loss = 76.7926, Discriminator Loss = 2.6194\n",
      "Epoch 223: Generator Loss = 45.3540, Discriminator Loss = 3.0363\n",
      "Epoch 224: Generator Loss = 65.8567, Discriminator Loss = 2.5634\n",
      "Epoch 225: Generator Loss = 66.5554, Discriminator Loss = 1.3065\n",
      "Epoch 226: Generator Loss = 72.8346, Discriminator Loss = 1.5723\n",
      "Epoch 227: Generator Loss = 66.7636, Discriminator Loss = 1.2557\n",
      "Epoch 228: Generator Loss = 65.6919, Discriminator Loss = 0.7846\n",
      "Epoch 229: Generator Loss = 57.5866, Discriminator Loss = 2.8142\n",
      "Epoch 230: Generator Loss = 71.0226, Discriminator Loss = 4.8645\n",
      "Epoch 231: Generator Loss = 79.1915, Discriminator Loss = 1.7945\n",
      "Epoch 232: Generator Loss = 41.7511, Discriminator Loss = 7.6025\n",
      "Epoch 233: Generator Loss = 52.0356, Discriminator Loss = 2.1568\n",
      "Epoch 234: Generator Loss = 59.3595, Discriminator Loss = 1.7201\n",
      "Epoch 235: Generator Loss = 61.4107, Discriminator Loss = 1.9954\n",
      "Epoch 236: Generator Loss = 67.3831, Discriminator Loss = 0.9246\n",
      "Epoch 237: Generator Loss = 64.2879, Discriminator Loss = 0.9475\n",
      "Epoch 238: Generator Loss = 60.4817, Discriminator Loss = 0.6569\n",
      "Epoch 239: Generator Loss = 91.2609, Discriminator Loss = 0.5827\n",
      "Epoch 240: Generator Loss = 94.7367, Discriminator Loss = 0.7352\n",
      "Epoch 241: Generator Loss = 74.6643, Discriminator Loss = 2.2638\n",
      "Epoch 242: Generator Loss = 46.5265, Discriminator Loss = 6.4347\n",
      "Epoch 243: Generator Loss = 77.2893, Discriminator Loss = 1.3476\n",
      "Epoch 244: Generator Loss = 74.6536, Discriminator Loss = 2.1352\n",
      "Epoch 245: Generator Loss = 64.0353, Discriminator Loss = 2.0520\n",
      "Epoch 246: Generator Loss = 65.9808, Discriminator Loss = 1.6271\n",
      "Epoch 247: Generator Loss = 50.4859, Discriminator Loss = 1.7151\n",
      "Epoch 248: Generator Loss = 67.3649, Discriminator Loss = 1.6928\n",
      "Epoch 249: Generator Loss = 59.4729, Discriminator Loss = 2.0274\n",
      "Epoch 250: Generator Loss = 87.8822, Discriminator Loss = 0.9101\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Epoch 1/15 | Train Loss: 0.6169 Acc: 0.7161\n",
      "Epoch 2/15 | Train Loss: 0.4299 Acc: 0.7943\n",
      "Epoch 3/15 | Train Loss: 0.4099 Acc: 0.7656\n",
      "Epoch 4/15 | Train Loss: 0.3471 Acc: 0.8203\n",
      "Epoch 5/15 | Train Loss: 0.3346 Acc: 0.8177\n",
      "Epoch 6/15 | Train Loss: 0.3702 Acc: 0.8125\n",
      "Epoch 7/15 | Train Loss: 0.3684 Acc: 0.7865\n",
      "Epoch 8/15 | Train Loss: 0.3785 Acc: 0.8255\n",
      "Epoch 9/15 | Train Loss: 0.3080 Acc: 0.8359\n",
      "Epoch 10/15 | Train Loss: 0.2545 Acc: 0.8802\n",
      "Epoch 11/15 | Train Loss: 0.2786 Acc: 0.8568\n",
      "Epoch 12/15 | Train Loss: 0.2676 Acc: 0.8828\n",
      "Epoch 13/15 | Train Loss: 0.2773 Acc: 0.8698\n",
      "Epoch 14/15 | Train Loss: 0.2664 Acc: 0.8828\n",
      "Epoch 15/15 | Train Loss: 0.2666 Acc: 0.8776\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 3.0min\n",
      "Epoch 1/15 | Train Loss: 0.4982 Acc: 0.7344\n",
      "Epoch 2/15 | Train Loss: 0.3869 Acc: 0.7865\n",
      "Epoch 3/15 | Train Loss: 0.3626 Acc: 0.8151\n",
      "Epoch 4/15 | Train Loss: 0.3536 Acc: 0.7917\n",
      "Epoch 5/15 | Train Loss: 0.3534 Acc: 0.8021\n",
      "Epoch 6/15 | Train Loss: 0.3301 Acc: 0.8255\n",
      "Epoch 7/15 | Train Loss: 0.3394 Acc: 0.8203\n",
      "Epoch 8/15 | Train Loss: 0.3170 Acc: 0.8203\n",
      "Epoch 9/15 | Train Loss: 0.3147 Acc: 0.8385\n",
      "Epoch 10/15 | Train Loss: 0.3183 Acc: 0.8229\n",
      "Epoch 11/15 | Train Loss: 0.2897 Acc: 0.8594\n",
      "Epoch 12/15 | Train Loss: 0.3015 Acc: 0.8411\n",
      "Epoch 13/15 | Train Loss: 0.2892 Acc: 0.8542\n",
      "Epoch 14/15 | Train Loss: 0.2895 Acc: 0.8646\n",
      "Epoch 15/15 | Train Loss: 0.2740 Acc: 0.8776\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.4955 Acc: 0.7318\n",
      "Epoch 2/15 | Train Loss: 0.4133 Acc: 0.7917\n",
      "Epoch 3/15 | Train Loss: 0.3977 Acc: 0.7786\n",
      "Epoch 4/15 | Train Loss: 0.3635 Acc: 0.8073\n",
      "Epoch 5/15 | Train Loss: 0.3428 Acc: 0.7839\n",
      "Epoch 6/15 | Train Loss: 0.3399 Acc: 0.8281\n",
      "Epoch 7/15 | Train Loss: 0.3518 Acc: 0.8255\n",
      "Epoch 8/15 | Train Loss: 0.3272 Acc: 0.8177\n",
      "Epoch 9/15 | Train Loss: 0.2947 Acc: 0.8776\n",
      "Epoch 10/15 | Train Loss: 0.2914 Acc: 0.8594\n",
      "Epoch 11/15 | Train Loss: 0.3010 Acc: 0.8646\n",
      "Epoch 12/15 | Train Loss: 0.2980 Acc: 0.8438\n",
      "Epoch 13/15 | Train Loss: 0.2992 Acc: 0.8568\n",
      "Epoch 14/15 | Train Loss: 0.2765 Acc: 0.8828\n",
      "Epoch 15/15 | Train Loss: 0.2602 Acc: 0.8776\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.5583 Acc: 0.8000\n",
      "Epoch 2/15 | Train Loss: 0.4141 Acc: 0.8095\n",
      "Epoch 3/15 | Train Loss: 0.4240 Acc: 0.8159\n",
      "Epoch 4/15 | Train Loss: 0.4020 Acc: 0.8508\n",
      "Epoch 5/15 | Train Loss: 0.3761 Acc: 0.8413\n",
      "Epoch 6/15 | Train Loss: 0.3477 Acc: 0.8444\n",
      "Epoch 7/15 | Train Loss: 0.3547 Acc: 0.8349\n",
      "Epoch 8/15 | Train Loss: 0.3849 Acc: 0.8254\n",
      "Epoch 9/15 | Train Loss: 0.3227 Acc: 0.8667\n",
      "Epoch 10/15 | Train Loss: 0.3377 Acc: 0.8603\n",
      "Epoch 11/15 | Train Loss: 0.3181 Acc: 0.8794\n",
      "Epoch 12/15 | Train Loss: 0.2978 Acc: 0.8667\n",
      "Epoch 13/15 | Train Loss: 0.3319 Acc: 0.8540\n",
      "Epoch 14/15 | Train Loss: 0.3180 Acc: 0.8762\n",
      "Epoch 15/15 | Train Loss: 0.2867 Acc: 0.8730\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.4717 Acc: 0.7972\n",
      "Epoch 2/15 | Train Loss: 0.3934 Acc: 0.8683\n",
      "Epoch 3/15 | Train Loss: 0.3492 Acc: 0.8790\n",
      "Epoch 4/15 | Train Loss: 0.3090 Acc: 0.8897\n",
      "Epoch 5/15 | Train Loss: 0.3094 Acc: 0.8683\n",
      "Epoch 6/15 | Train Loss: 0.2549 Acc: 0.9039\n",
      "Epoch 7/15 | Train Loss: 0.2753 Acc: 0.9004\n",
      "Epoch 8/15 | Train Loss: 0.2759 Acc: 0.8861\n",
      "Epoch 9/15 | Train Loss: 0.2652 Acc: 0.9075\n",
      "Epoch 10/15 | Train Loss: 0.2467 Acc: 0.9146\n",
      "Epoch 11/15 | Train Loss: 0.2398 Acc: 0.8897\n",
      "Epoch 12/15 | Train Loss: 0.2213 Acc: 0.9004\n",
      "Epoch 13/15 | Train Loss: 0.2192 Acc: 0.9039\n",
      "Epoch 14/15 | Train Loss: 0.2176 Acc: 0.9146\n",
      "Epoch 15/15 | Train Loss: 0.2524 Acc: 0.9039\n",
      "[CV] END .....multiplier_generated_samples=2, scale_factor=1; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.7671 Acc: 0.6008\n",
      "Epoch 2/15 | Train Loss: 0.5954 Acc: 0.6957\n",
      "Epoch 3/15 | Train Loss: 0.4991 Acc: 0.7549\n",
      "Epoch 4/15 | Train Loss: 0.5532 Acc: 0.7154\n",
      "Epoch 5/15 | Train Loss: 0.5039 Acc: 0.7391\n",
      "Epoch 6/15 | Train Loss: 0.4155 Acc: 0.8182\n",
      "Epoch 7/15 | Train Loss: 0.4448 Acc: 0.7945\n",
      "Epoch 8/15 | Train Loss: 0.3832 Acc: 0.8182\n",
      "Epoch 9/15 | Train Loss: 0.4075 Acc: 0.8182\n",
      "Epoch 10/15 | Train Loss: 0.3623 Acc: 0.8340\n",
      "Epoch 11/15 | Train Loss: 0.3230 Acc: 0.8538\n",
      "Epoch 12/15 | Train Loss: 0.3473 Acc: 0.8656\n",
      "Epoch 13/15 | Train Loss: 0.4001 Acc: 0.7905\n",
      "Epoch 14/15 | Train Loss: 0.3362 Acc: 0.8538\n",
      "Epoch 15/15 | Train Loss: 0.3529 Acc: 0.8656\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7032 Acc: 0.6166\n",
      "Epoch 2/15 | Train Loss: 0.6178 Acc: 0.6443\n",
      "Epoch 3/15 | Train Loss: 0.5663 Acc: 0.6957\n",
      "Epoch 4/15 | Train Loss: 0.5294 Acc: 0.6838\n",
      "Epoch 5/15 | Train Loss: 0.5626 Acc: 0.7115\n",
      "Epoch 6/15 | Train Loss: 0.4867 Acc: 0.8063\n",
      "Epoch 7/15 | Train Loss: 0.4740 Acc: 0.7470\n",
      "Epoch 8/15 | Train Loss: 0.4584 Acc: 0.7668\n",
      "Epoch 9/15 | Train Loss: 0.4723 Acc: 0.7747\n",
      "Epoch 10/15 | Train Loss: 0.4645 Acc: 0.7747\n",
      "Epoch 11/15 | Train Loss: 0.4191 Acc: 0.8103\n",
      "Epoch 12/15 | Train Loss: 0.3945 Acc: 0.8300\n",
      "Epoch 13/15 | Train Loss: 0.4407 Acc: 0.7945\n",
      "Epoch 14/15 | Train Loss: 0.4662 Acc: 0.7826\n",
      "Epoch 15/15 | Train Loss: 0.3954 Acc: 0.8103\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7227 Acc: 0.6443\n",
      "Epoch 2/15 | Train Loss: 0.6297 Acc: 0.6719\n",
      "Epoch 3/15 | Train Loss: 0.5581 Acc: 0.6996\n",
      "Epoch 4/15 | Train Loss: 0.5621 Acc: 0.7194\n",
      "Epoch 5/15 | Train Loss: 0.4810 Acc: 0.7431\n",
      "Epoch 6/15 | Train Loss: 0.5086 Acc: 0.7589\n",
      "Epoch 7/15 | Train Loss: 0.4675 Acc: 0.7668\n",
      "Epoch 8/15 | Train Loss: 0.5244 Acc: 0.7668\n",
      "Epoch 9/15 | Train Loss: 0.5010 Acc: 0.7312\n",
      "Epoch 10/15 | Train Loss: 0.4567 Acc: 0.7668\n",
      "Epoch 11/15 | Train Loss: 0.4363 Acc: 0.7984\n",
      "Epoch 12/15 | Train Loss: 0.4319 Acc: 0.8063\n",
      "Epoch 13/15 | Train Loss: 0.4321 Acc: 0.7866\n",
      "Epoch 14/15 | Train Loss: 0.4461 Acc: 0.7589\n",
      "Epoch 15/15 | Train Loss: 0.3896 Acc: 0.8379\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6423 Acc: 0.7089\n",
      "Epoch 2/15 | Train Loss: 0.5215 Acc: 0.7848\n",
      "Epoch 3/15 | Train Loss: 0.4750 Acc: 0.7848\n",
      "Epoch 4/15 | Train Loss: 0.5819 Acc: 0.7173\n",
      "Epoch 5/15 | Train Loss: 0.4806 Acc: 0.8101\n",
      "Epoch 6/15 | Train Loss: 0.4597 Acc: 0.8017\n",
      "Epoch 7/15 | Train Loss: 0.4734 Acc: 0.8017\n",
      "Epoch 8/15 | Train Loss: 0.5040 Acc: 0.7764\n",
      "Epoch 9/15 | Train Loss: 0.3798 Acc: 0.8270\n",
      "Epoch 10/15 | Train Loss: 0.4544 Acc: 0.7679\n",
      "Epoch 11/15 | Train Loss: 0.3827 Acc: 0.8228\n",
      "Epoch 12/15 | Train Loss: 0.4119 Acc: 0.8101\n",
      "Epoch 13/15 | Train Loss: 0.3933 Acc: 0.8397\n",
      "Epoch 14/15 | Train Loss: 0.4002 Acc: 0.8186\n",
      "Epoch 15/15 | Train Loss: 0.3958 Acc: 0.8228\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5174 Acc: 0.7588\n",
      "Epoch 2/15 | Train Loss: 0.4718 Acc: 0.8202\n",
      "Epoch 3/15 | Train Loss: 0.4114 Acc: 0.8465\n",
      "Epoch 4/15 | Train Loss: 0.4433 Acc: 0.8289\n",
      "Epoch 5/15 | Train Loss: 0.3507 Acc: 0.8640\n",
      "Epoch 6/15 | Train Loss: 0.3930 Acc: 0.8640\n",
      "Epoch 7/15 | Train Loss: 0.2988 Acc: 0.8947\n",
      "Epoch 8/15 | Train Loss: 0.3735 Acc: 0.8553\n",
      "Epoch 9/15 | Train Loss: 0.3479 Acc: 0.8772\n",
      "Epoch 10/15 | Train Loss: 0.2872 Acc: 0.8772\n",
      "Epoch 11/15 | Train Loss: 0.2952 Acc: 0.8728\n",
      "Epoch 12/15 | Train Loss: 0.3360 Acc: 0.8728\n",
      "Epoch 13/15 | Train Loss: 0.2694 Acc: 0.8816\n",
      "Epoch 14/15 | Train Loss: 0.2541 Acc: 0.8947\n",
      "Epoch 15/15 | Train Loss: 0.2969 Acc: 0.8860\n",
      "[CV] END ...multiplier_generated_samples=0.5, scale_factor=1; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6038 Acc: 0.7003\n",
      "Epoch 2/15 | Train Loss: 0.4789 Acc: 0.7205\n",
      "Epoch 3/15 | Train Loss: 0.5394 Acc: 0.7340\n",
      "Epoch 4/15 | Train Loss: 0.4487 Acc: 0.7912\n",
      "Epoch 5/15 | Train Loss: 0.4116 Acc: 0.7845\n",
      "Epoch 6/15 | Train Loss: 0.4198 Acc: 0.8047\n",
      "Epoch 7/15 | Train Loss: 0.3816 Acc: 0.7912\n",
      "Epoch 8/15 | Train Loss: 0.3783 Acc: 0.8350\n",
      "Epoch 9/15 | Train Loss: 0.3540 Acc: 0.8384\n",
      "Epoch 10/15 | Train Loss: 0.3357 Acc: 0.8485\n",
      "Epoch 11/15 | Train Loss: 0.3599 Acc: 0.8148\n",
      "Epoch 12/15 | Train Loss: 0.2882 Acc: 0.8788\n",
      "Epoch 13/15 | Train Loss: 0.3057 Acc: 0.8485\n",
      "Epoch 14/15 | Train Loss: 0.3467 Acc: 0.8316\n",
      "Epoch 15/15 | Train Loss: 0.2783 Acc: 0.8855\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.6774 Acc: 0.6599\n",
      "Epoch 2/15 | Train Loss: 0.6192 Acc: 0.6970\n",
      "Epoch 3/15 | Train Loss: 0.4989 Acc: 0.7374\n",
      "Epoch 4/15 | Train Loss: 0.4716 Acc: 0.7172\n",
      "Epoch 5/15 | Train Loss: 0.4587 Acc: 0.7845\n",
      "Epoch 6/15 | Train Loss: 0.4515 Acc: 0.7407\n",
      "Epoch 7/15 | Train Loss: 0.4599 Acc: 0.7407\n",
      "Epoch 8/15 | Train Loss: 0.3954 Acc: 0.7879\n",
      "Epoch 9/15 | Train Loss: 0.4165 Acc: 0.7710\n",
      "Epoch 10/15 | Train Loss: 0.4395 Acc: 0.7441\n",
      "Epoch 11/15 | Train Loss: 0.3541 Acc: 0.8350\n",
      "Epoch 12/15 | Train Loss: 0.3731 Acc: 0.8215\n",
      "Epoch 13/15 | Train Loss: 0.3630 Acc: 0.8384\n",
      "Epoch 14/15 | Train Loss: 0.3621 Acc: 0.8215\n",
      "Epoch 15/15 | Train Loss: 0.3492 Acc: 0.8215\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5991 Acc: 0.6667\n",
      "Epoch 2/15 | Train Loss: 0.5397 Acc: 0.7138\n",
      "Epoch 3/15 | Train Loss: 0.4637 Acc: 0.7374\n",
      "Epoch 4/15 | Train Loss: 0.4872 Acc: 0.7273\n",
      "Epoch 5/15 | Train Loss: 0.4610 Acc: 0.7441\n",
      "Epoch 6/15 | Train Loss: 0.4190 Acc: 0.7811\n",
      "Epoch 7/15 | Train Loss: 0.4165 Acc: 0.7879\n",
      "Epoch 8/15 | Train Loss: 0.4212 Acc: 0.7845\n",
      "Epoch 9/15 | Train Loss: 0.4039 Acc: 0.7879\n",
      "Epoch 10/15 | Train Loss: 0.3705 Acc: 0.8148\n",
      "Epoch 11/15 | Train Loss: 0.3946 Acc: 0.8047\n",
      "Epoch 12/15 | Train Loss: 0.3504 Acc: 0.8418\n",
      "Epoch 13/15 | Train Loss: 0.3758 Acc: 0.8215\n",
      "Epoch 14/15 | Train Loss: 0.3495 Acc: 0.8249\n",
      "Epoch 15/15 | Train Loss: 0.3608 Acc: 0.8316\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.5083 Acc: 0.7529\n",
      "Epoch 2/15 | Train Loss: 0.5267 Acc: 0.7947\n",
      "Epoch 3/15 | Train Loss: 0.4604 Acc: 0.7871\n",
      "Epoch 4/15 | Train Loss: 0.4331 Acc: 0.7985\n",
      "Epoch 5/15 | Train Loss: 0.4365 Acc: 0.7833\n",
      "Epoch 6/15 | Train Loss: 0.3966 Acc: 0.8403\n",
      "Epoch 7/15 | Train Loss: 0.4098 Acc: 0.8099\n",
      "Epoch 8/15 | Train Loss: 0.4095 Acc: 0.8365\n",
      "Epoch 9/15 | Train Loss: 0.3632 Acc: 0.8365\n",
      "Epoch 10/15 | Train Loss: 0.3639 Acc: 0.8441\n",
      "Epoch 11/15 | Train Loss: 0.3344 Acc: 0.8555\n",
      "Epoch 12/15 | Train Loss: 0.3447 Acc: 0.8403\n",
      "Epoch 13/15 | Train Loss: 0.3548 Acc: 0.8365\n",
      "Epoch 14/15 | Train Loss: 0.3512 Acc: 0.8251\n",
      "Epoch 15/15 | Train Loss: 0.3520 Acc: 0.8441\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5157 Acc: 0.7439\n",
      "Epoch 2/15 | Train Loss: 0.4260 Acc: 0.8415\n",
      "Epoch 3/15 | Train Loss: 0.3687 Acc: 0.8333\n",
      "Epoch 4/15 | Train Loss: 0.3894 Acc: 0.8496\n",
      "Epoch 5/15 | Train Loss: 0.3430 Acc: 0.8618\n",
      "Epoch 6/15 | Train Loss: 0.3146 Acc: 0.8821\n",
      "Epoch 7/15 | Train Loss: 0.3001 Acc: 0.8740\n",
      "Epoch 8/15 | Train Loss: 0.3081 Acc: 0.8821\n",
      "Epoch 9/15 | Train Loss: 0.3214 Acc: 0.8780\n",
      "Epoch 10/15 | Train Loss: 0.2714 Acc: 0.9065\n",
      "Epoch 11/15 | Train Loss: 0.2521 Acc: 0.8984\n",
      "Epoch 12/15 | Train Loss: 0.2970 Acc: 0.8862\n",
      "Epoch 13/15 | Train Loss: 0.3139 Acc: 0.8984\n",
      "Epoch 14/15 | Train Loss: 0.2766 Acc: 0.8862\n",
      "Epoch 15/15 | Train Loss: 0.2947 Acc: 0.8780\n",
      "[CV] END ...multiplier_generated_samples=1, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7314 Acc: 0.5968\n",
      "Epoch 2/15 | Train Loss: 0.5466 Acc: 0.7273\n",
      "Epoch 3/15 | Train Loss: 0.5573 Acc: 0.7154\n",
      "Epoch 4/15 | Train Loss: 0.5052 Acc: 0.7866\n",
      "Epoch 5/15 | Train Loss: 0.4660 Acc: 0.7787\n",
      "Epoch 6/15 | Train Loss: 0.4591 Acc: 0.7708\n",
      "Epoch 7/15 | Train Loss: 0.4773 Acc: 0.7431\n",
      "Epoch 8/15 | Train Loss: 0.4181 Acc: 0.8024\n",
      "Epoch 9/15 | Train Loss: 0.4387 Acc: 0.8103\n",
      "Epoch 10/15 | Train Loss: 0.3638 Acc: 0.8379\n",
      "Epoch 11/15 | Train Loss: 0.3580 Acc: 0.8379\n",
      "Epoch 12/15 | Train Loss: 0.3949 Acc: 0.8261\n",
      "Epoch 13/15 | Train Loss: 0.3583 Acc: 0.8379\n",
      "Epoch 14/15 | Train Loss: 0.3482 Acc: 0.8458\n",
      "Epoch 15/15 | Train Loss: 0.3668 Acc: 0.8182\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7411 Acc: 0.5889\n",
      "Epoch 2/15 | Train Loss: 0.5938 Acc: 0.6957\n",
      "Epoch 3/15 | Train Loss: 0.6180 Acc: 0.6798\n",
      "Epoch 4/15 | Train Loss: 0.5055 Acc: 0.7549\n",
      "Epoch 5/15 | Train Loss: 0.5434 Acc: 0.7036\n",
      "Epoch 6/15 | Train Loss: 0.5353 Acc: 0.6957\n",
      "Epoch 7/15 | Train Loss: 0.5017 Acc: 0.7589\n",
      "Epoch 8/15 | Train Loss: 0.5017 Acc: 0.7628\n",
      "Epoch 9/15 | Train Loss: 0.4836 Acc: 0.7787\n",
      "Epoch 10/15 | Train Loss: 0.4365 Acc: 0.7905\n",
      "Epoch 11/15 | Train Loss: 0.4344 Acc: 0.7945\n",
      "Epoch 12/15 | Train Loss: 0.4468 Acc: 0.7549\n",
      "Epoch 13/15 | Train Loss: 0.4314 Acc: 0.7826\n",
      "Epoch 14/15 | Train Loss: 0.4160 Acc: 0.7984\n",
      "Epoch 15/15 | Train Loss: 0.4034 Acc: 0.8221\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6721 Acc: 0.6166\n",
      "Epoch 2/15 | Train Loss: 0.6614 Acc: 0.6443\n",
      "Epoch 3/15 | Train Loss: 0.5885 Acc: 0.6719\n",
      "Epoch 4/15 | Train Loss: 0.5400 Acc: 0.7233\n",
      "Epoch 5/15 | Train Loss: 0.5493 Acc: 0.7115\n",
      "Epoch 6/15 | Train Loss: 0.4895 Acc: 0.7549\n",
      "Epoch 7/15 | Train Loss: 0.4735 Acc: 0.7826\n",
      "Epoch 8/15 | Train Loss: 0.4594 Acc: 0.7589\n",
      "Epoch 9/15 | Train Loss: 0.4028 Acc: 0.8024\n",
      "Epoch 10/15 | Train Loss: 0.4099 Acc: 0.7984\n",
      "Epoch 11/15 | Train Loss: 0.4563 Acc: 0.7668\n",
      "Epoch 12/15 | Train Loss: 0.4096 Acc: 0.8063\n",
      "Epoch 13/15 | Train Loss: 0.3972 Acc: 0.7905\n",
      "Epoch 14/15 | Train Loss: 0.3814 Acc: 0.8221\n",
      "Epoch 15/15 | Train Loss: 0.3781 Acc: 0.8221\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7024 Acc: 0.5865\n",
      "Epoch 2/15 | Train Loss: 0.6206 Acc: 0.7722\n",
      "Epoch 3/15 | Train Loss: 0.5657 Acc: 0.7511\n",
      "Epoch 4/15 | Train Loss: 0.4674 Acc: 0.7806\n",
      "Epoch 5/15 | Train Loss: 0.5013 Acc: 0.8017\n",
      "Epoch 6/15 | Train Loss: 0.4922 Acc: 0.7637\n",
      "Epoch 7/15 | Train Loss: 0.4391 Acc: 0.7932\n",
      "Epoch 8/15 | Train Loss: 0.4355 Acc: 0.8143\n",
      "Epoch 9/15 | Train Loss: 0.3983 Acc: 0.8228\n",
      "Epoch 10/15 | Train Loss: 0.3738 Acc: 0.8439\n",
      "Epoch 11/15 | Train Loss: 0.4274 Acc: 0.8270\n",
      "Epoch 12/15 | Train Loss: 0.3663 Acc: 0.8312\n",
      "Epoch 13/15 | Train Loss: 0.3978 Acc: 0.8439\n",
      "Epoch 14/15 | Train Loss: 0.3771 Acc: 0.8270\n",
      "Epoch 15/15 | Train Loss: 0.3573 Acc: 0.8481\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6159 Acc: 0.7018\n",
      "Epoch 2/15 | Train Loss: 0.4879 Acc: 0.7982\n",
      "Epoch 3/15 | Train Loss: 0.3995 Acc: 0.8421\n",
      "Epoch 4/15 | Train Loss: 0.4078 Acc: 0.8377\n",
      "Epoch 5/15 | Train Loss: 0.4138 Acc: 0.8553\n",
      "Epoch 6/15 | Train Loss: 0.3212 Acc: 0.8991\n",
      "Epoch 7/15 | Train Loss: 0.3262 Acc: 0.8596\n",
      "Epoch 8/15 | Train Loss: 0.2827 Acc: 0.8860\n",
      "Epoch 9/15 | Train Loss: 0.2821 Acc: 0.8904\n",
      "Epoch 10/15 | Train Loss: 0.3127 Acc: 0.8684\n",
      "Epoch 11/15 | Train Loss: 0.2470 Acc: 0.9035\n",
      "Epoch 12/15 | Train Loss: 0.3007 Acc: 0.8904\n",
      "Epoch 13/15 | Train Loss: 0.2659 Acc: 0.8947\n",
      "Epoch 14/15 | Train Loss: 0.2533 Acc: 0.9035\n",
      "Epoch 15/15 | Train Loss: 0.2500 Acc: 0.9035\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=0.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.7567 Acc: 0.7266\n",
      "Epoch 2/15 | Train Loss: 0.4106 Acc: 0.7865\n",
      "Epoch 3/15 | Train Loss: 0.3968 Acc: 0.7943\n",
      "Epoch 4/15 | Train Loss: 0.3557 Acc: 0.8125\n",
      "Epoch 5/15 | Train Loss: 0.3306 Acc: 0.8281\n",
      "Epoch 6/15 | Train Loss: 0.3485 Acc: 0.8073\n",
      "Epoch 7/15 | Train Loss: 0.3031 Acc: 0.8333\n",
      "Epoch 8/15 | Train Loss: 0.3094 Acc: 0.8385\n",
      "Epoch 9/15 | Train Loss: 0.2467 Acc: 0.8724\n",
      "Epoch 10/15 | Train Loss: 0.2467 Acc: 0.9010\n",
      "Epoch 11/15 | Train Loss: 0.2690 Acc: 0.8776\n",
      "Epoch 12/15 | Train Loss: 0.2753 Acc: 0.8854\n",
      "Epoch 13/15 | Train Loss: 0.2689 Acc: 0.8776\n",
      "Epoch 14/15 | Train Loss: 0.2593 Acc: 0.8854\n",
      "Epoch 15/15 | Train Loss: 0.2384 Acc: 0.8984\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.6980 Acc: 0.7422\n",
      "Epoch 2/15 | Train Loss: 0.3967 Acc: 0.7839\n",
      "Epoch 3/15 | Train Loss: 0.4286 Acc: 0.7708\n",
      "Epoch 4/15 | Train Loss: 0.3961 Acc: 0.8021\n",
      "Epoch 5/15 | Train Loss: 0.3689 Acc: 0.7917\n",
      "Epoch 6/15 | Train Loss: 0.4005 Acc: 0.8047\n",
      "Epoch 7/15 | Train Loss: 0.3536 Acc: 0.8021\n",
      "Epoch 8/15 | Train Loss: 0.3029 Acc: 0.8333\n",
      "Epoch 9/15 | Train Loss: 0.3115 Acc: 0.8411\n",
      "Epoch 10/15 | Train Loss: 0.3277 Acc: 0.8047\n",
      "Epoch 11/15 | Train Loss: 0.2900 Acc: 0.8438\n",
      "Epoch 12/15 | Train Loss: 0.2799 Acc: 0.8698\n",
      "Epoch 13/15 | Train Loss: 0.3098 Acc: 0.8438\n",
      "Epoch 14/15 | Train Loss: 0.2893 Acc: 0.8620\n",
      "Epoch 15/15 | Train Loss: 0.3070 Acc: 0.8542\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.7357 Acc: 0.7266\n",
      "Epoch 2/15 | Train Loss: 0.4498 Acc: 0.7734\n",
      "Epoch 3/15 | Train Loss: 0.3946 Acc: 0.8177\n",
      "Epoch 4/15 | Train Loss: 0.3801 Acc: 0.7917\n",
      "Epoch 5/15 | Train Loss: 0.3962 Acc: 0.8073\n",
      "Epoch 6/15 | Train Loss: 0.3305 Acc: 0.8099\n",
      "Epoch 7/15 | Train Loss: 0.3236 Acc: 0.8438\n",
      "Epoch 8/15 | Train Loss: 0.3319 Acc: 0.8307\n",
      "Epoch 9/15 | Train Loss: 0.3192 Acc: 0.8516\n",
      "Epoch 10/15 | Train Loss: 0.2766 Acc: 0.8750\n",
      "Epoch 11/15 | Train Loss: 0.3117 Acc: 0.8411\n",
      "Epoch 12/15 | Train Loss: 0.3103 Acc: 0.8516\n",
      "Epoch 13/15 | Train Loss: 0.3040 Acc: 0.8438\n",
      "Epoch 14/15 | Train Loss: 0.2690 Acc: 0.8646\n",
      "Epoch 15/15 | Train Loss: 0.2860 Acc: 0.8438\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.9min\n",
      "Epoch 1/15 | Train Loss: 0.5775 Acc: 0.7873\n",
      "Epoch 2/15 | Train Loss: 0.4191 Acc: 0.8032\n",
      "Epoch 3/15 | Train Loss: 0.3780 Acc: 0.8381\n",
      "Epoch 4/15 | Train Loss: 0.3690 Acc: 0.8476\n",
      "Epoch 5/15 | Train Loss: 0.3473 Acc: 0.8571\n",
      "Epoch 6/15 | Train Loss: 0.3273 Acc: 0.8571\n",
      "Epoch 7/15 | Train Loss: 0.3351 Acc: 0.8540\n",
      "Epoch 8/15 | Train Loss: 0.3393 Acc: 0.8349\n",
      "Epoch 9/15 | Train Loss: 0.2933 Acc: 0.8698\n",
      "Epoch 10/15 | Train Loss: 0.3337 Acc: 0.8540\n",
      "Epoch 11/15 | Train Loss: 0.2824 Acc: 0.8667\n",
      "Epoch 12/15 | Train Loss: 0.3360 Acc: 0.8381\n",
      "Epoch 13/15 | Train Loss: 0.2760 Acc: 0.8857\n",
      "Epoch 14/15 | Train Loss: 0.3170 Acc: 0.8571\n",
      "Epoch 15/15 | Train Loss: 0.3045 Acc: 0.8603\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.8min\n",
      "Epoch 1/15 | Train Loss: 0.4630 Acc: 0.7794\n",
      "Epoch 2/15 | Train Loss: 0.3699 Acc: 0.8754\n",
      "Epoch 3/15 | Train Loss: 0.3699 Acc: 0.8577\n",
      "Epoch 4/15 | Train Loss: 0.3591 Acc: 0.8719\n",
      "Epoch 5/15 | Train Loss: 0.2996 Acc: 0.8754\n",
      "Epoch 6/15 | Train Loss: 0.2918 Acc: 0.8754\n",
      "Epoch 7/15 | Train Loss: 0.2797 Acc: 0.9004\n",
      "Epoch 8/15 | Train Loss: 0.2766 Acc: 0.8932\n",
      "Epoch 9/15 | Train Loss: 0.2513 Acc: 0.9075\n",
      "Epoch 10/15 | Train Loss: 0.2402 Acc: 0.9110\n",
      "Epoch 11/15 | Train Loss: 0.2190 Acc: 0.9110\n",
      "Epoch 12/15 | Train Loss: 0.2440 Acc: 0.9039\n",
      "Epoch 13/15 | Train Loss: 0.2562 Acc: 0.9039\n",
      "Epoch 14/15 | Train Loss: 0.2346 Acc: 0.9039\n",
      "Epoch 15/15 | Train Loss: 0.2491 Acc: 0.8897\n",
      "[CV] END ...multiplier_generated_samples=2, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6668 Acc: 0.6245\n",
      "Epoch 2/15 | Train Loss: 0.6104 Acc: 0.6798\n",
      "Epoch 3/15 | Train Loss: 0.5047 Acc: 0.7431\n",
      "Epoch 4/15 | Train Loss: 0.5172 Acc: 0.7470\n",
      "Epoch 5/15 | Train Loss: 0.5233 Acc: 0.7470\n",
      "Epoch 6/15 | Train Loss: 0.4570 Acc: 0.7747\n",
      "Epoch 7/15 | Train Loss: 0.4618 Acc: 0.7945\n",
      "Epoch 8/15 | Train Loss: 0.4224 Acc: 0.7866\n",
      "Epoch 9/15 | Train Loss: 0.4072 Acc: 0.7905\n",
      "Epoch 10/15 | Train Loss: 0.3611 Acc: 0.8340\n",
      "Epoch 11/15 | Train Loss: 0.3743 Acc: 0.8182\n",
      "Epoch 12/15 | Train Loss: 0.3764 Acc: 0.8261\n",
      "Epoch 13/15 | Train Loss: 0.3579 Acc: 0.8577\n",
      "Epoch 14/15 | Train Loss: 0.3825 Acc: 0.8340\n",
      "Epoch 15/15 | Train Loss: 0.3548 Acc: 0.8458\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6935 Acc: 0.6008\n",
      "Epoch 2/15 | Train Loss: 0.6297 Acc: 0.6957\n",
      "Epoch 3/15 | Train Loss: 0.5489 Acc: 0.7036\n",
      "Epoch 4/15 | Train Loss: 0.5589 Acc: 0.6877\n",
      "Epoch 5/15 | Train Loss: 0.5037 Acc: 0.7708\n",
      "Epoch 6/15 | Train Loss: 0.5117 Acc: 0.7549\n",
      "Epoch 7/15 | Train Loss: 0.4868 Acc: 0.7510\n",
      "Epoch 8/15 | Train Loss: 0.4788 Acc: 0.7510\n",
      "Epoch 9/15 | Train Loss: 0.5306 Acc: 0.7154\n",
      "Epoch 10/15 | Train Loss: 0.4275 Acc: 0.7866\n",
      "Epoch 11/15 | Train Loss: 0.4319 Acc: 0.7866\n",
      "Epoch 12/15 | Train Loss: 0.4576 Acc: 0.7708\n",
      "Epoch 13/15 | Train Loss: 0.4224 Acc: 0.7945\n",
      "Epoch 14/15 | Train Loss: 0.3932 Acc: 0.8063\n",
      "Epoch 15/15 | Train Loss: 0.3871 Acc: 0.8221\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6860 Acc: 0.6403\n",
      "Epoch 2/15 | Train Loss: 0.5660 Acc: 0.6640\n",
      "Epoch 3/15 | Train Loss: 0.5084 Acc: 0.7036\n",
      "Epoch 4/15 | Train Loss: 0.5692 Acc: 0.6838\n",
      "Epoch 5/15 | Train Loss: 0.5191 Acc: 0.7352\n",
      "Epoch 6/15 | Train Loss: 0.5773 Acc: 0.6798\n",
      "Epoch 7/15 | Train Loss: 0.4770 Acc: 0.7787\n",
      "Epoch 8/15 | Train Loss: 0.4867 Acc: 0.7352\n",
      "Epoch 9/15 | Train Loss: 0.4489 Acc: 0.7747\n",
      "Epoch 10/15 | Train Loss: 0.4250 Acc: 0.7945\n",
      "Epoch 11/15 | Train Loss: 0.5014 Acc: 0.7589\n",
      "Epoch 12/15 | Train Loss: 0.4176 Acc: 0.8103\n",
      "Epoch 13/15 | Train Loss: 0.4038 Acc: 0.7787\n",
      "Epoch 14/15 | Train Loss: 0.4054 Acc: 0.8261\n",
      "Epoch 15/15 | Train Loss: 0.4212 Acc: 0.7826\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.6221 Acc: 0.6751\n",
      "Epoch 2/15 | Train Loss: 0.6323 Acc: 0.7468\n",
      "Epoch 3/15 | Train Loss: 0.5868 Acc: 0.7595\n",
      "Epoch 4/15 | Train Loss: 0.5415 Acc: 0.7595\n",
      "Epoch 5/15 | Train Loss: 0.4575 Acc: 0.7890\n",
      "Epoch 6/15 | Train Loss: 0.4593 Acc: 0.8059\n",
      "Epoch 7/15 | Train Loss: 0.4242 Acc: 0.8143\n",
      "Epoch 8/15 | Train Loss: 0.5172 Acc: 0.7806\n",
      "Epoch 9/15 | Train Loss: 0.4493 Acc: 0.7932\n",
      "Epoch 10/15 | Train Loss: 0.4411 Acc: 0.8143\n",
      "Epoch 11/15 | Train Loss: 0.4228 Acc: 0.8101\n",
      "Epoch 12/15 | Train Loss: 0.3975 Acc: 0.8186\n",
      "Epoch 13/15 | Train Loss: 0.4159 Acc: 0.8143\n",
      "Epoch 14/15 | Train Loss: 0.3931 Acc: 0.8397\n",
      "Epoch 15/15 | Train Loss: 0.3784 Acc: 0.8481\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5390 Acc: 0.7895\n",
      "Epoch 2/15 | Train Loss: 0.4467 Acc: 0.8509\n",
      "Epoch 3/15 | Train Loss: 0.4240 Acc: 0.8509\n",
      "Epoch 4/15 | Train Loss: 0.3963 Acc: 0.8421\n",
      "Epoch 5/15 | Train Loss: 0.4147 Acc: 0.8465\n",
      "Epoch 6/15 | Train Loss: 0.3581 Acc: 0.8553\n",
      "Epoch 7/15 | Train Loss: 0.3593 Acc: 0.8509\n",
      "Epoch 8/15 | Train Loss: 0.3141 Acc: 0.8772\n",
      "Epoch 9/15 | Train Loss: 0.3200 Acc: 0.8772\n",
      "Epoch 10/15 | Train Loss: 0.3220 Acc: 0.8816\n",
      "Epoch 11/15 | Train Loss: 0.2985 Acc: 0.8904\n",
      "Epoch 12/15 | Train Loss: 0.2818 Acc: 0.9123\n",
      "Epoch 13/15 | Train Loss: 0.2830 Acc: 0.8816\n",
      "Epoch 14/15 | Train Loss: 0.2860 Acc: 0.8904\n",
      "Epoch 15/15 | Train Loss: 0.2716 Acc: 0.8904\n",
      "[CV] END .multiplier_generated_samples=0.5, scale_factor=1.5; total time= 2.7min\n",
      "Epoch 1/15 | Train Loss: 0.5132 Acc: 0.7712\n",
      "Epoch 2/15 | Train Loss: 0.4228 Acc: 0.8009\n",
      "Epoch 3/15 | Train Loss: 0.3697 Acc: 0.8101\n",
      "Epoch 4/15 | Train Loss: 0.3686 Acc: 0.8124\n",
      "Epoch 5/15 | Train Loss: 0.3627 Acc: 0.8238\n",
      "Epoch 6/15 | Train Loss: 0.3325 Acc: 0.8375\n",
      "Epoch 7/15 | Train Loss: 0.3589 Acc: 0.8352\n",
      "Epoch 8/15 | Train Loss: 0.2932 Acc: 0.8604\n",
      "Epoch 9/15 | Train Loss: 0.2795 Acc: 0.8604\n",
      "Epoch 10/15 | Train Loss: 0.3127 Acc: 0.8558\n",
      "Epoch 11/15 | Train Loss: 0.2857 Acc: 0.8673\n",
      "Epoch 12/15 | Train Loss: 0.2541 Acc: 0.8924\n",
      "Epoch 13/15 | Train Loss: 0.2690 Acc: 0.8787\n",
      "Epoch 14/15 | Train Loss: 0.2624 Acc: 0.8924\n",
      "Epoch 15/15 | Train Loss: 0.2749 Acc: 0.8604\n",
      "Fold 10 Test Accuracy: 0.6924\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "3775bb66b3ec0b30"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNNGAN: Generowanie jedynie syntetycznego zbioru",
   "id": "80ac9a11d58ab73b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T14:43:41.310725Z",
     "start_time": "2025-05-28T19:13:33.379630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "IMG_SIZE   = 128\n",
    "BATCH_SIZE = 16\n",
    "CHANNELS   = 3\n",
    "CLASSIFIER_EPOCHS = 20\n",
    "OVERSAMPLER_EPOCHS = 200\n",
    "\n",
    "dataset = CapsuleDataset(pos_dir=pos_folder, neg_dirs=neg_folder, transform=transform)\n",
    "print(dataset.__len__())\n",
    "\n",
    "labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(rskf.split(X=np.zeros(len(labels)), y=labels), start=1):\n",
    "    print(f\"===== Fold {fold_idx} =====\")\n",
    "\n",
    "\n",
    "    CnnGan = CNNGANWrapper(dataset,device,BATCH_SIZE,OVERSAMPLER_EPOCHS)\n",
    "\n",
    "    CnnGan.fit(train_idx)\n",
    "\n",
    "\n",
    "    estimator = CNNGANResNetEstimator(\n",
    "        dataset=dataset,\n",
    "        gan_model=CnnGan.gan_model,\n",
    "        device=device,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        classifier_epochs=CLASSIFIER_EPOCHS,\n",
    "        multiplier_generated_samples='synthetic'\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'scale_factor': [0.5, 1, 1.5]  # Czynnik skalujący szum w GAN\n",
    "    }\n",
    "\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=2,\n",
    "        cv=None,\n",
    "        verbose=2,\n",
    "        n_jobs=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    random_search.fit(train_idx)\n",
    "\n",
    "    best_estimator = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    test_ds = Subset(dataset, test_idx)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    f2, bal_acc, recall, specificity = best_estimator.trainer.validate(test_loader)\n",
    "    print(f\"Fold {fold_idx} Test Accuracy: {bal_acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'fold': fold_idx,\n",
    "        'f2_score': f2,\n",
    "        'balanced_accuracy': bal_acc,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        **best_params\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Zapis wyników z każdego folda\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('CNNGAN_synthetic_cross_validation_results.csv', index=False)"
   ],
   "id": "48063847943c17eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n",
      "===== Fold 1 =====\n",
      "Epoch 1: Generator Loss = 10.4548, Discriminator Loss = 9.1613\n",
      "Epoch 2: Generator Loss = 13.1622, Discriminator Loss = 5.4860\n",
      "Epoch 3: Generator Loss = 22.3018, Discriminator Loss = 3.5493\n",
      "Epoch 4: Generator Loss = 32.5408, Discriminator Loss = 3.3099\n",
      "Epoch 5: Generator Loss = 35.1577, Discriminator Loss = 3.9735\n",
      "Epoch 6: Generator Loss = 34.9560, Discriminator Loss = 5.2573\n",
      "Epoch 7: Generator Loss = 29.1434, Discriminator Loss = 4.0361\n",
      "Epoch 8: Generator Loss = 30.0363, Discriminator Loss = 6.0887\n",
      "Epoch 9: Generator Loss = 27.9666, Discriminator Loss = 5.1654\n",
      "Epoch 10: Generator Loss = 29.7431, Discriminator Loss = 6.3831\n",
      "Epoch 11: Generator Loss = 24.3034, Discriminator Loss = 7.0514\n",
      "Epoch 12: Generator Loss = 22.2792, Discriminator Loss = 8.6292\n",
      "Epoch 13: Generator Loss = 19.5683, Discriminator Loss = 6.9064\n",
      "Epoch 14: Generator Loss = 23.0947, Discriminator Loss = 6.2279\n",
      "Epoch 15: Generator Loss = 21.7222, Discriminator Loss = 6.3125\n",
      "Epoch 16: Generator Loss = 28.7596, Discriminator Loss = 9.8284\n",
      "Epoch 17: Generator Loss = 20.8490, Discriminator Loss = 9.4922\n",
      "Epoch 18: Generator Loss = 18.3185, Discriminator Loss = 9.3550\n",
      "Epoch 19: Generator Loss = 16.6050, Discriminator Loss = 8.3216\n",
      "Epoch 20: Generator Loss = 17.6996, Discriminator Loss = 8.6191\n",
      "Epoch 21: Generator Loss = 18.3257, Discriminator Loss = 8.8671\n",
      "Epoch 22: Generator Loss = 22.4165, Discriminator Loss = 8.8050\n",
      "Epoch 23: Generator Loss = 22.1118, Discriminator Loss = 7.3681\n",
      "Epoch 24: Generator Loss = 24.1080, Discriminator Loss = 8.2227\n",
      "Epoch 25: Generator Loss = 18.3442, Discriminator Loss = 7.3064\n",
      "Epoch 26: Generator Loss = 15.2140, Discriminator Loss = 9.3550\n",
      "Epoch 27: Generator Loss = 15.0952, Discriminator Loss = 9.4506\n",
      "Epoch 28: Generator Loss = 13.9826, Discriminator Loss = 8.7467\n",
      "Epoch 29: Generator Loss = 14.5804, Discriminator Loss = 10.2439\n",
      "Epoch 30: Generator Loss = 13.1941, Discriminator Loss = 10.1267\n",
      "Epoch 31: Generator Loss = 14.4283, Discriminator Loss = 9.4660\n",
      "Epoch 32: Generator Loss = 14.3990, Discriminator Loss = 9.8418\n",
      "Epoch 33: Generator Loss = 14.7752, Discriminator Loss = 9.1174\n",
      "Epoch 34: Generator Loss = 14.7584, Discriminator Loss = 8.6158\n",
      "Epoch 35: Generator Loss = 14.6087, Discriminator Loss = 8.4240\n",
      "Epoch 36: Generator Loss = 15.2178, Discriminator Loss = 8.6039\n",
      "Epoch 37: Generator Loss = 15.0846, Discriminator Loss = 9.0572\n",
      "Epoch 38: Generator Loss = 14.6417, Discriminator Loss = 9.0581\n",
      "Epoch 39: Generator Loss = 13.1269, Discriminator Loss = 9.1712\n",
      "Epoch 40: Generator Loss = 14.9356, Discriminator Loss = 9.5949\n",
      "Epoch 41: Generator Loss = 18.3323, Discriminator Loss = 8.6131\n",
      "Epoch 42: Generator Loss = 21.4289, Discriminator Loss = 8.2482\n",
      "Epoch 43: Generator Loss = 19.6164, Discriminator Loss = 7.1295\n",
      "Epoch 44: Generator Loss = 19.8387, Discriminator Loss = 8.2829\n",
      "Epoch 45: Generator Loss = 17.7777, Discriminator Loss = 8.5853\n",
      "Epoch 46: Generator Loss = 18.1911, Discriminator Loss = 7.7138\n",
      "Epoch 47: Generator Loss = 16.8169, Discriminator Loss = 7.5015\n",
      "Epoch 48: Generator Loss = 16.2868, Discriminator Loss = 7.9298\n",
      "Epoch 49: Generator Loss = 16.2376, Discriminator Loss = 9.7307\n",
      "Epoch 50: Generator Loss = 17.8164, Discriminator Loss = 7.0713\n",
      "Epoch 51: Generator Loss = 19.9424, Discriminator Loss = 8.4262\n",
      "Epoch 52: Generator Loss = 15.7226, Discriminator Loss = 8.4671\n",
      "Epoch 53: Generator Loss = 16.7986, Discriminator Loss = 8.8333\n",
      "Epoch 54: Generator Loss = 15.0050, Discriminator Loss = 7.3517\n",
      "Epoch 55: Generator Loss = 19.6405, Discriminator Loss = 9.1820\n",
      "Epoch 56: Generator Loss = 15.4481, Discriminator Loss = 8.8427\n",
      "Epoch 57: Generator Loss = 14.4743, Discriminator Loss = 9.0276\n",
      "Epoch 58: Generator Loss = 14.1123, Discriminator Loss = 8.6692\n",
      "Epoch 59: Generator Loss = 18.0195, Discriminator Loss = 7.8474\n",
      "Epoch 60: Generator Loss = 13.2819, Discriminator Loss = 7.2538\n",
      "Epoch 61: Generator Loss = 18.7799, Discriminator Loss = 7.3753\n",
      "Epoch 62: Generator Loss = 18.3598, Discriminator Loss = 7.9735\n",
      "Epoch 63: Generator Loss = 14.6522, Discriminator Loss = 9.2856\n",
      "Epoch 64: Generator Loss = 20.4778, Discriminator Loss = 6.4221\n",
      "Epoch 65: Generator Loss = 22.4891, Discriminator Loss = 6.4811\n",
      "Epoch 66: Generator Loss = 29.1836, Discriminator Loss = 5.5685\n",
      "Epoch 67: Generator Loss = 12.3950, Discriminator Loss = 13.0515\n",
      "Epoch 68: Generator Loss = 13.1144, Discriminator Loss = 7.7169\n",
      "Epoch 69: Generator Loss = 16.1680, Discriminator Loss = 6.8558\n",
      "Epoch 70: Generator Loss = 24.1696, Discriminator Loss = 5.8542\n",
      "Epoch 71: Generator Loss = 27.8159, Discriminator Loss = 5.0268\n",
      "Epoch 72: Generator Loss = 23.6432, Discriminator Loss = 4.8519\n",
      "Epoch 73: Generator Loss = 24.0578, Discriminator Loss = 8.2321\n",
      "Epoch 74: Generator Loss = 21.0572, Discriminator Loss = 5.8385\n",
      "Epoch 75: Generator Loss = 22.3964, Discriminator Loss = 4.5330\n",
      "Epoch 76: Generator Loss = 24.4485, Discriminator Loss = 6.0678\n",
      "Epoch 77: Generator Loss = 36.1759, Discriminator Loss = 3.7626\n",
      "Epoch 78: Generator Loss = 35.2665, Discriminator Loss = 7.4364\n",
      "Epoch 79: Generator Loss = 25.3527, Discriminator Loss = 6.9675\n",
      "Epoch 80: Generator Loss = 26.6688, Discriminator Loss = 7.8514\n",
      "Epoch 81: Generator Loss = 21.6431, Discriminator Loss = 6.3801\n",
      "Epoch 82: Generator Loss = 30.4967, Discriminator Loss = 5.2989\n",
      "Epoch 83: Generator Loss = 23.7713, Discriminator Loss = 4.7014\n",
      "Epoch 84: Generator Loss = 33.3320, Discriminator Loss = 3.5652\n",
      "Epoch 85: Generator Loss = 29.8577, Discriminator Loss = 3.5932\n",
      "Epoch 86: Generator Loss = 35.8659, Discriminator Loss = 3.6371\n",
      "Epoch 87: Generator Loss = 30.7910, Discriminator Loss = 4.5488\n",
      "Epoch 88: Generator Loss = 42.5293, Discriminator Loss = 4.7925\n",
      "Epoch 89: Generator Loss = 32.2794, Discriminator Loss = 2.9626\n",
      "Epoch 90: Generator Loss = 51.5005, Discriminator Loss = 3.9191\n",
      "Epoch 91: Generator Loss = 36.1696, Discriminator Loss = 2.2734\n",
      "Epoch 92: Generator Loss = 53.4725, Discriminator Loss = 1.9169\n",
      "Epoch 93: Generator Loss = 37.2336, Discriminator Loss = 1.9968\n",
      "Epoch 94: Generator Loss = 55.1950, Discriminator Loss = 1.5698\n",
      "Epoch 95: Generator Loss = 48.0629, Discriminator Loss = 2.5974\n",
      "Epoch 96: Generator Loss = 43.9920, Discriminator Loss = 1.5258\n",
      "Epoch 97: Generator Loss = 48.3345, Discriminator Loss = 1.6932\n",
      "Epoch 98: Generator Loss = 58.9442, Discriminator Loss = 1.8241\n",
      "Epoch 99: Generator Loss = 42.5489, Discriminator Loss = 2.2936\n",
      "Epoch 100: Generator Loss = 49.2540, Discriminator Loss = 3.3567\n",
      "Epoch 101: Generator Loss = 48.8696, Discriminator Loss = 2.1112\n",
      "Epoch 102: Generator Loss = 53.9869, Discriminator Loss = 2.7888\n",
      "Epoch 103: Generator Loss = 39.4364, Discriminator Loss = 10.8546\n",
      "Epoch 104: Generator Loss = 24.6631, Discriminator Loss = 7.4567\n",
      "Epoch 105: Generator Loss = 31.6379, Discriminator Loss = 3.6785\n",
      "Epoch 106: Generator Loss = 40.1753, Discriminator Loss = 3.2983\n",
      "Epoch 107: Generator Loss = 40.3600, Discriminator Loss = 2.4223\n",
      "Epoch 108: Generator Loss = 48.0469, Discriminator Loss = 2.1651\n",
      "Epoch 109: Generator Loss = 50.0510, Discriminator Loss = 1.7427\n",
      "Epoch 110: Generator Loss = 54.6195, Discriminator Loss = 2.1194\n",
      "Epoch 111: Generator Loss = 49.6279, Discriminator Loss = 2.6084\n",
      "Epoch 112: Generator Loss = 59.2487, Discriminator Loss = 3.7563\n",
      "Epoch 113: Generator Loss = 50.5151, Discriminator Loss = 2.0175\n",
      "Epoch 114: Generator Loss = 51.7938, Discriminator Loss = 1.7387\n",
      "Epoch 115: Generator Loss = 66.7075, Discriminator Loss = 0.9836\n",
      "Epoch 116: Generator Loss = 44.4762, Discriminator Loss = 1.1866\n",
      "Epoch 117: Generator Loss = 50.2089, Discriminator Loss = 2.7648\n",
      "Epoch 118: Generator Loss = 67.4447, Discriminator Loss = 1.3772\n",
      "Epoch 119: Generator Loss = 54.7825, Discriminator Loss = 1.9439\n",
      "Epoch 120: Generator Loss = 67.2291, Discriminator Loss = 1.5374\n",
      "Epoch 121: Generator Loss = 63.2540, Discriminator Loss = 4.0108\n",
      "Epoch 122: Generator Loss = 57.2829, Discriminator Loss = 1.3874\n",
      "Epoch 123: Generator Loss = 63.9323, Discriminator Loss = 1.7096\n",
      "Epoch 124: Generator Loss = 62.4339, Discriminator Loss = 0.9175\n",
      "Epoch 125: Generator Loss = 63.4017, Discriminator Loss = 0.8127\n",
      "Epoch 126: Generator Loss = 66.8292, Discriminator Loss = 0.9966\n",
      "Epoch 127: Generator Loss = 86.4627, Discriminator Loss = 0.5618\n",
      "Epoch 128: Generator Loss = 64.7717, Discriminator Loss = 2.2804\n",
      "Epoch 129: Generator Loss = 63.2932, Discriminator Loss = 2.0479\n",
      "Epoch 130: Generator Loss = 58.8383, Discriminator Loss = 1.0220\n",
      "Epoch 131: Generator Loss = 62.3591, Discriminator Loss = 0.8696\n",
      "Epoch 132: Generator Loss = 66.3887, Discriminator Loss = 1.2186\n",
      "Epoch 133: Generator Loss = 68.5708, Discriminator Loss = 1.1213\n",
      "Epoch 134: Generator Loss = 72.8891, Discriminator Loss = 1.0065\n",
      "Epoch 135: Generator Loss = 79.4567, Discriminator Loss = 0.7869\n",
      "Epoch 136: Generator Loss = 63.6102, Discriminator Loss = 1.3058\n",
      "Epoch 137: Generator Loss = 68.0437, Discriminator Loss = 1.7363\n",
      "Epoch 138: Generator Loss = 66.0805, Discriminator Loss = 1.2056\n",
      "Epoch 139: Generator Loss = 56.2947, Discriminator Loss = 1.1497\n",
      "Epoch 140: Generator Loss = 71.9858, Discriminator Loss = 0.7648\n",
      "Epoch 141: Generator Loss = 70.0850, Discriminator Loss = 0.5809\n",
      "Epoch 142: Generator Loss = 59.4904, Discriminator Loss = 17.1278\n",
      "Epoch 143: Generator Loss = 30.7163, Discriminator Loss = 9.0152\n",
      "Epoch 144: Generator Loss = 38.2338, Discriminator Loss = 4.3284\n",
      "Epoch 145: Generator Loss = 37.1743, Discriminator Loss = 2.9510\n",
      "Epoch 146: Generator Loss = 47.2185, Discriminator Loss = 2.7629\n",
      "Epoch 147: Generator Loss = 50.7597, Discriminator Loss = 2.7478\n",
      "Epoch 148: Generator Loss = 62.2880, Discriminator Loss = 1.8537\n",
      "Epoch 149: Generator Loss = 58.7195, Discriminator Loss = 2.1680\n",
      "Epoch 150: Generator Loss = 54.1035, Discriminator Loss = 1.3768\n",
      "Epoch 151: Generator Loss = 65.5363, Discriminator Loss = 1.0625\n",
      "Epoch 152: Generator Loss = 69.3577, Discriminator Loss = 1.1881\n",
      "Epoch 153: Generator Loss = 69.1798, Discriminator Loss = 1.2016\n",
      "Epoch 154: Generator Loss = 76.5540, Discriminator Loss = 1.0028\n",
      "Epoch 155: Generator Loss = 69.1661, Discriminator Loss = 0.9309\n",
      "Epoch 156: Generator Loss = 67.9793, Discriminator Loss = 0.4688\n",
      "Epoch 157: Generator Loss = 69.1014, Discriminator Loss = 0.5860\n",
      "Epoch 158: Generator Loss = 103.3260, Discriminator Loss = 2.6455\n",
      "Epoch 159: Generator Loss = 106.5041, Discriminator Loss = 1.5084\n",
      "Epoch 160: Generator Loss = 66.2348, Discriminator Loss = 1.3707\n",
      "Epoch 161: Generator Loss = 65.3480, Discriminator Loss = 2.8475\n",
      "Epoch 162: Generator Loss = 80.0069, Discriminator Loss = 0.6425\n",
      "Epoch 163: Generator Loss = 71.1429, Discriminator Loss = 0.8650\n",
      "Epoch 164: Generator Loss = 92.9950, Discriminator Loss = 0.3362\n",
      "Epoch 165: Generator Loss = 78.8969, Discriminator Loss = 0.6132\n",
      "Epoch 166: Generator Loss = 67.9008, Discriminator Loss = 0.7422\n",
      "Epoch 167: Generator Loss = 73.2984, Discriminator Loss = 0.9534\n",
      "Epoch 168: Generator Loss = 75.1701, Discriminator Loss = 0.3356\n",
      "Epoch 169: Generator Loss = 87.4426, Discriminator Loss = 0.6600\n",
      "Epoch 170: Generator Loss = 67.9494, Discriminator Loss = 0.9638\n",
      "Epoch 171: Generator Loss = 71.4473, Discriminator Loss = 1.9332\n",
      "Epoch 172: Generator Loss = 68.0431, Discriminator Loss = 0.9987\n",
      "Epoch 173: Generator Loss = 73.4649, Discriminator Loss = 0.6898\n",
      "Epoch 174: Generator Loss = 61.9602, Discriminator Loss = 0.5820\n",
      "Epoch 175: Generator Loss = 68.8508, Discriminator Loss = 2.1954\n",
      "Epoch 176: Generator Loss = 72.4852, Discriminator Loss = 0.9282\n",
      "Epoch 177: Generator Loss = 54.1697, Discriminator Loss = 1.0116\n",
      "Epoch 178: Generator Loss = 81.0658, Discriminator Loss = 0.5527\n",
      "Epoch 179: Generator Loss = 54.7923, Discriminator Loss = 0.9890\n",
      "Epoch 180: Generator Loss = 59.0758, Discriminator Loss = 0.8054\n",
      "Epoch 181: Generator Loss = 85.6220, Discriminator Loss = 0.8816\n",
      "Epoch 182: Generator Loss = 84.3758, Discriminator Loss = 0.7786\n",
      "Epoch 183: Generator Loss = 80.7178, Discriminator Loss = 0.5032\n",
      "Epoch 184: Generator Loss = 100.4551, Discriminator Loss = 0.6783\n",
      "Epoch 185: Generator Loss = 90.4062, Discriminator Loss = 1.0528\n",
      "Epoch 186: Generator Loss = 83.8313, Discriminator Loss = 0.6519\n",
      "Epoch 187: Generator Loss = 83.3715, Discriminator Loss = 0.4595\n",
      "Epoch 188: Generator Loss = 97.9477, Discriminator Loss = 0.6834\n",
      "Epoch 189: Generator Loss = 96.1770, Discriminator Loss = 0.2068\n",
      "Epoch 190: Generator Loss = 78.3272, Discriminator Loss = 2.2557\n",
      "Epoch 191: Generator Loss = 65.4707, Discriminator Loss = 2.5234\n",
      "Epoch 192: Generator Loss = 75.6076, Discriminator Loss = 0.9480\n",
      "Epoch 193: Generator Loss = 82.6184, Discriminator Loss = 0.4277\n",
      "Epoch 194: Generator Loss = 76.5185, Discriminator Loss = 0.7081\n",
      "Epoch 195: Generator Loss = 88.9997, Discriminator Loss = 1.0051\n",
      "Epoch 196: Generator Loss = 87.9393, Discriminator Loss = 0.4801\n",
      "Epoch 197: Generator Loss = 91.2591, Discriminator Loss = 0.9265\n",
      "Epoch 198: Generator Loss = 76.6801, Discriminator Loss = 0.6133\n",
      "Epoch 199: Generator Loss = 92.3492, Discriminator Loss = 0.8576\n",
      "Epoch 200: Generator Loss = 106.1098, Discriminator Loss = 0.7954\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/20 | Train Loss: 0.1388 Acc: 0.9385\n",
      "Epoch 2/20 | Train Loss: 0.0081 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0275 Acc: 0.9918\n",
      "Epoch 4/20 | Train Loss: 0.0032 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0026 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0233 Acc: 0.9959\n",
      "Epoch 7/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0122 Acc: 0.9918\n",
      "Epoch 11/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0023 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0054 Acc: 0.9959\n",
      "Epoch 20/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0932 Acc: 0.9426\n",
      "Epoch 2/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0022 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0206 Acc: 0.9918\n",
      "Epoch 18/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0709 Acc: 0.9634\n",
      "Epoch 2/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.7min\n",
      "Epoch 1/20 | Train Loss: 0.0494 Acc: 0.9778\n",
      "Epoch 2/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0034 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 7.2min\n",
      "Epoch 1/20 | Train Loss: 0.0561 Acc: 0.9829\n",
      "Epoch 2/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0083 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0020 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0037 Acc: 0.9971\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 8.0min\n",
      "Epoch 1/20 | Train Loss: 0.0665 Acc: 0.9713\n",
      "Epoch 2/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0168 Acc: 0.9959\n",
      "Epoch 9/20 | Train Loss: 0.0158 Acc: 0.9918\n",
      "Epoch 10/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0251 Acc: 0.9918\n",
      "Epoch 13/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0283 Acc: 0.9959\n",
      "Epoch 15/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0913 Acc: 0.9672\n",
      "Epoch 2/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0354 Acc: 0.9959\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0913 Acc: 0.9593\n",
      "Epoch 2/20 | Train Loss: 0.0021 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0061 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0031 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.1478 Acc: 0.9399\n",
      "Epoch 2/20 | Train Loss: 0.0044 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0027 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 7.2min\n",
      "Epoch 1/20 | Train Loss: 0.0694 Acc: 0.9686\n",
      "Epoch 2/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0031 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 7.9min\n",
      "Epoch 1/20 | Train Loss: 0.0392 Acc: 0.9857\n",
      "Epoch 2/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Fold 1 Test Accuracy: 0.5000\n",
      "===== Fold 2 =====\n",
      "Epoch 1: Generator Loss = 9.6672, Discriminator Loss = 9.1376\n",
      "Epoch 2: Generator Loss = 10.3151, Discriminator Loss = 8.7343\n",
      "Epoch 3: Generator Loss = 14.1003, Discriminator Loss = 6.2874\n",
      "Epoch 4: Generator Loss = 19.4307, Discriminator Loss = 5.7332\n",
      "Epoch 5: Generator Loss = 20.5600, Discriminator Loss = 5.8237\n",
      "Epoch 6: Generator Loss = 22.3791, Discriminator Loss = 6.0001\n",
      "Epoch 7: Generator Loss = 23.0516, Discriminator Loss = 5.8173\n",
      "Epoch 8: Generator Loss = 26.8528, Discriminator Loss = 6.9933\n",
      "Epoch 9: Generator Loss = 24.1549, Discriminator Loss = 7.3220\n",
      "Epoch 10: Generator Loss = 20.1811, Discriminator Loss = 6.3095\n",
      "Epoch 11: Generator Loss = 18.0453, Discriminator Loss = 8.3134\n",
      "Epoch 12: Generator Loss = 17.6545, Discriminator Loss = 8.1487\n",
      "Epoch 13: Generator Loss = 19.5388, Discriminator Loss = 9.3079\n",
      "Epoch 14: Generator Loss = 14.7982, Discriminator Loss = 9.9962\n",
      "Epoch 15: Generator Loss = 15.8764, Discriminator Loss = 8.3975\n",
      "Epoch 16: Generator Loss = 15.5564, Discriminator Loss = 8.2905\n",
      "Epoch 17: Generator Loss = 17.7823, Discriminator Loss = 8.7294\n",
      "Epoch 18: Generator Loss = 14.1308, Discriminator Loss = 8.4310\n",
      "Epoch 19: Generator Loss = 15.4786, Discriminator Loss = 8.5801\n",
      "Epoch 20: Generator Loss = 17.2122, Discriminator Loss = 8.4770\n",
      "Epoch 21: Generator Loss = 14.9890, Discriminator Loss = 9.8383\n",
      "Epoch 22: Generator Loss = 15.9605, Discriminator Loss = 8.8203\n",
      "Epoch 23: Generator Loss = 13.2436, Discriminator Loss = 8.9406\n",
      "Epoch 24: Generator Loss = 15.2179, Discriminator Loss = 8.0834\n",
      "Epoch 25: Generator Loss = 18.2497, Discriminator Loss = 7.9747\n",
      "Epoch 26: Generator Loss = 19.3272, Discriminator Loss = 8.4355\n",
      "Epoch 27: Generator Loss = 19.7150, Discriminator Loss = 7.3833\n",
      "Epoch 28: Generator Loss = 19.3714, Discriminator Loss = 9.0240\n",
      "Epoch 29: Generator Loss = 18.1533, Discriminator Loss = 8.0424\n",
      "Epoch 30: Generator Loss = 15.8173, Discriminator Loss = 8.3727\n",
      "Epoch 31: Generator Loss = 17.7413, Discriminator Loss = 6.9783\n",
      "Epoch 32: Generator Loss = 24.5035, Discriminator Loss = 8.8692\n",
      "Epoch 33: Generator Loss = 16.6364, Discriminator Loss = 8.1877\n",
      "Epoch 34: Generator Loss = 19.1033, Discriminator Loss = 7.0375\n",
      "Epoch 35: Generator Loss = 21.6359, Discriminator Loss = 6.9497\n",
      "Epoch 36: Generator Loss = 21.5454, Discriminator Loss = 8.3258\n",
      "Epoch 37: Generator Loss = 22.8920, Discriminator Loss = 7.4635\n",
      "Epoch 38: Generator Loss = 20.4227, Discriminator Loss = 7.5279\n",
      "Epoch 39: Generator Loss = 21.3702, Discriminator Loss = 7.2124\n",
      "Epoch 40: Generator Loss = 29.1362, Discriminator Loss = 5.2403\n",
      "Epoch 41: Generator Loss = 27.9440, Discriminator Loss = 6.6397\n",
      "Epoch 42: Generator Loss = 24.6697, Discriminator Loss = 6.8196\n",
      "Epoch 43: Generator Loss = 22.5387, Discriminator Loss = 7.9619\n",
      "Epoch 44: Generator Loss = 26.0146, Discriminator Loss = 6.6021\n",
      "Epoch 45: Generator Loss = 23.8437, Discriminator Loss = 6.7010\n",
      "Epoch 46: Generator Loss = 22.5825, Discriminator Loss = 7.3120\n",
      "Epoch 47: Generator Loss = 22.7572, Discriminator Loss = 6.5993\n",
      "Epoch 48: Generator Loss = 22.6129, Discriminator Loss = 5.7060\n",
      "Epoch 49: Generator Loss = 29.7652, Discriminator Loss = 6.4483\n",
      "Epoch 50: Generator Loss = 22.8530, Discriminator Loss = 5.5438\n",
      "Epoch 51: Generator Loss = 23.5818, Discriminator Loss = 5.1535\n",
      "Epoch 52: Generator Loss = 25.4316, Discriminator Loss = 7.9641\n",
      "Epoch 53: Generator Loss = 27.0287, Discriminator Loss = 5.7486\n",
      "Epoch 54: Generator Loss = 24.9848, Discriminator Loss = 5.0324\n",
      "Epoch 55: Generator Loss = 25.8431, Discriminator Loss = 5.9098\n",
      "Epoch 56: Generator Loss = 26.8780, Discriminator Loss = 6.1684\n",
      "Epoch 57: Generator Loss = 29.4819, Discriminator Loss = 5.8932\n",
      "Epoch 58: Generator Loss = 20.3738, Discriminator Loss = 6.8324\n",
      "Epoch 59: Generator Loss = 35.9570, Discriminator Loss = 4.0016\n",
      "Epoch 60: Generator Loss = 28.8330, Discriminator Loss = 5.5664\n",
      "Epoch 61: Generator Loss = 27.2887, Discriminator Loss = 4.5563\n",
      "Epoch 62: Generator Loss = 35.1687, Discriminator Loss = 5.0952\n",
      "Epoch 63: Generator Loss = 32.9816, Discriminator Loss = 4.1286\n",
      "Epoch 64: Generator Loss = 40.4978, Discriminator Loss = 3.2585\n",
      "Epoch 65: Generator Loss = 29.9505, Discriminator Loss = 6.4687\n",
      "Epoch 66: Generator Loss = 39.0594, Discriminator Loss = 3.3499\n",
      "Epoch 67: Generator Loss = 44.3631, Discriminator Loss = 2.5770\n",
      "Epoch 68: Generator Loss = 29.0010, Discriminator Loss = 8.0728\n",
      "Epoch 69: Generator Loss = 39.3553, Discriminator Loss = 3.9615\n",
      "Epoch 70: Generator Loss = 41.0377, Discriminator Loss = 1.6456\n",
      "Epoch 71: Generator Loss = 40.9831, Discriminator Loss = 3.3554\n",
      "Epoch 72: Generator Loss = 32.8463, Discriminator Loss = 3.1822\n",
      "Epoch 73: Generator Loss = 41.4373, Discriminator Loss = 3.3670\n",
      "Epoch 74: Generator Loss = 47.7341, Discriminator Loss = 3.0279\n",
      "Epoch 75: Generator Loss = 31.3710, Discriminator Loss = 2.4577\n",
      "Epoch 76: Generator Loss = 40.0910, Discriminator Loss = 3.5055\n",
      "Epoch 77: Generator Loss = 44.8518, Discriminator Loss = 2.9555\n",
      "Epoch 78: Generator Loss = 52.0653, Discriminator Loss = 2.5423\n",
      "Epoch 79: Generator Loss = 34.5677, Discriminator Loss = 5.9333\n",
      "Epoch 80: Generator Loss = 23.4423, Discriminator Loss = 10.0257\n",
      "Epoch 81: Generator Loss = 32.6904, Discriminator Loss = 5.0948\n",
      "Epoch 82: Generator Loss = 38.6420, Discriminator Loss = 4.4823\n",
      "Epoch 83: Generator Loss = 38.6955, Discriminator Loss = 2.7901\n",
      "Epoch 84: Generator Loss = 40.4941, Discriminator Loss = 2.0777\n",
      "Epoch 85: Generator Loss = 47.5704, Discriminator Loss = 2.7992\n",
      "Epoch 86: Generator Loss = 43.7721, Discriminator Loss = 2.1774\n",
      "Epoch 87: Generator Loss = 37.7832, Discriminator Loss = 7.8062\n",
      "Epoch 88: Generator Loss = 28.0805, Discriminator Loss = 6.1984\n",
      "Epoch 89: Generator Loss = 44.6868, Discriminator Loss = 4.4065\n",
      "Epoch 90: Generator Loss = 47.6184, Discriminator Loss = 2.2644\n",
      "Epoch 91: Generator Loss = 39.4357, Discriminator Loss = 2.2201\n",
      "Epoch 92: Generator Loss = 40.9154, Discriminator Loss = 2.6066\n",
      "Epoch 93: Generator Loss = 53.2828, Discriminator Loss = 2.3632\n",
      "Epoch 94: Generator Loss = 50.9074, Discriminator Loss = 3.6447\n",
      "Epoch 95: Generator Loss = 46.3510, Discriminator Loss = 2.4404\n",
      "Epoch 96: Generator Loss = 51.5922, Discriminator Loss = 3.6891\n",
      "Epoch 97: Generator Loss = 59.8936, Discriminator Loss = 2.3362\n",
      "Epoch 98: Generator Loss = 60.2546, Discriminator Loss = 1.6422\n",
      "Epoch 99: Generator Loss = 70.6920, Discriminator Loss = 1.3470\n",
      "Epoch 100: Generator Loss = 53.6960, Discriminator Loss = 1.8263\n",
      "Epoch 101: Generator Loss = 48.2023, Discriminator Loss = 1.4045\n",
      "Epoch 102: Generator Loss = 61.9470, Discriminator Loss = 1.1939\n",
      "Epoch 103: Generator Loss = 68.3771, Discriminator Loss = 1.5424\n",
      "Epoch 104: Generator Loss = 57.6516, Discriminator Loss = 1.4366\n",
      "Epoch 105: Generator Loss = 90.4309, Discriminator Loss = 2.6756\n",
      "Epoch 106: Generator Loss = 96.2888, Discriminator Loss = 0.9843\n",
      "Epoch 107: Generator Loss = 122.4899, Discriminator Loss = 1.3932\n",
      "Epoch 108: Generator Loss = 108.5893, Discriminator Loss = 0.3361\n",
      "Epoch 109: Generator Loss = 177.6408, Discriminator Loss = 0.8952\n",
      "Epoch 110: Generator Loss = 144.8349, Discriminator Loss = 0.6301\n",
      "Epoch 111: Generator Loss = 141.3733, Discriminator Loss = 2.2731\n",
      "Epoch 112: Generator Loss = 165.2531, Discriminator Loss = 0.3024\n",
      "Epoch 113: Generator Loss = 107.5804, Discriminator Loss = 1.0617\n",
      "Epoch 114: Generator Loss = 116.4080, Discriminator Loss = 0.2189\n",
      "Epoch 115: Generator Loss = 81.8772, Discriminator Loss = 0.2801\n",
      "Epoch 116: Generator Loss = 87.5688, Discriminator Loss = 0.3037\n",
      "Epoch 117: Generator Loss = 80.5688, Discriminator Loss = 0.9226\n",
      "Epoch 118: Generator Loss = 61.7725, Discriminator Loss = 10.7332\n",
      "Epoch 119: Generator Loss = 47.8321, Discriminator Loss = 9.2983\n",
      "Epoch 120: Generator Loss = 53.1485, Discriminator Loss = 3.8214\n",
      "Epoch 121: Generator Loss = 46.4640, Discriminator Loss = 2.8369\n",
      "Epoch 122: Generator Loss = 56.0647, Discriminator Loss = 2.3348\n",
      "Epoch 123: Generator Loss = 46.5645, Discriminator Loss = 1.5414\n",
      "Epoch 124: Generator Loss = 49.6973, Discriminator Loss = 2.5552\n",
      "Epoch 125: Generator Loss = 61.2242, Discriminator Loss = 2.1340\n",
      "Epoch 126: Generator Loss = 35.7343, Discriminator Loss = 4.2151\n",
      "Epoch 127: Generator Loss = 56.8416, Discriminator Loss = 2.2224\n",
      "Epoch 128: Generator Loss = 41.6120, Discriminator Loss = 3.1239\n",
      "Epoch 129: Generator Loss = 43.7168, Discriminator Loss = 6.4286\n",
      "Epoch 130: Generator Loss = 42.7235, Discriminator Loss = 3.4768\n",
      "Epoch 131: Generator Loss = 48.1727, Discriminator Loss = 1.6024\n",
      "Epoch 132: Generator Loss = 42.5492, Discriminator Loss = 3.1741\n",
      "Epoch 133: Generator Loss = 68.8824, Discriminator Loss = 1.5257\n",
      "Epoch 134: Generator Loss = 49.3878, Discriminator Loss = 3.6032\n",
      "Epoch 135: Generator Loss = 46.5339, Discriminator Loss = 1.8011\n",
      "Epoch 136: Generator Loss = 61.7529, Discriminator Loss = 2.6892\n",
      "Epoch 137: Generator Loss = 61.2405, Discriminator Loss = 1.9202\n",
      "Epoch 138: Generator Loss = 57.3017, Discriminator Loss = 1.2106\n",
      "Epoch 139: Generator Loss = 73.7429, Discriminator Loss = 1.7258\n",
      "Epoch 140: Generator Loss = 46.2357, Discriminator Loss = 2.7767\n",
      "Epoch 141: Generator Loss = 62.2416, Discriminator Loss = 1.0662\n",
      "Epoch 142: Generator Loss = 59.4528, Discriminator Loss = 0.9164\n",
      "Epoch 143: Generator Loss = 52.4995, Discriminator Loss = 1.2703\n",
      "Epoch 144: Generator Loss = 60.0861, Discriminator Loss = 0.6761\n",
      "Epoch 145: Generator Loss = 59.2872, Discriminator Loss = 0.9229\n",
      "Epoch 146: Generator Loss = 119.7786, Discriminator Loss = 0.3145\n",
      "Epoch 147: Generator Loss = 91.3072, Discriminator Loss = 0.8456\n",
      "Epoch 148: Generator Loss = 83.6860, Discriminator Loss = 0.6537\n",
      "Epoch 149: Generator Loss = 96.4108, Discriminator Loss = 0.3346\n",
      "Epoch 150: Generator Loss = 80.4774, Discriminator Loss = 0.4006\n",
      "Epoch 151: Generator Loss = 74.1962, Discriminator Loss = 0.9148\n",
      "Epoch 152: Generator Loss = 62.7603, Discriminator Loss = 1.2150\n",
      "Epoch 153: Generator Loss = 86.9690, Discriminator Loss = 0.2154\n",
      "Epoch 154: Generator Loss = 130.8086, Discriminator Loss = 1.6548\n",
      "Epoch 155: Generator Loss = 82.8457, Discriminator Loss = 0.3592\n",
      "Epoch 156: Generator Loss = 88.2056, Discriminator Loss = 0.0706\n",
      "Epoch 157: Generator Loss = 88.1404, Discriminator Loss = 0.1060\n",
      "Epoch 158: Generator Loss = 90.9009, Discriminator Loss = 0.1125\n",
      "Epoch 159: Generator Loss = 88.6118, Discriminator Loss = 0.1938\n",
      "Epoch 160: Generator Loss = 98.9572, Discriminator Loss = 0.1429\n",
      "Epoch 161: Generator Loss = 78.5991, Discriminator Loss = 0.1438\n",
      "Epoch 162: Generator Loss = 86.3823, Discriminator Loss = 3.5412\n",
      "Epoch 163: Generator Loss = 56.6316, Discriminator Loss = 22.1112\n",
      "Epoch 164: Generator Loss = 56.8933, Discriminator Loss = 3.1396\n",
      "Epoch 165: Generator Loss = 52.1508, Discriminator Loss = 3.1389\n",
      "Epoch 166: Generator Loss = 51.5467, Discriminator Loss = 2.4065\n",
      "Epoch 167: Generator Loss = 68.3151, Discriminator Loss = 3.3458\n",
      "Epoch 168: Generator Loss = 41.3494, Discriminator Loss = 3.3163\n",
      "Epoch 169: Generator Loss = 50.6506, Discriminator Loss = 2.2070\n",
      "Epoch 170: Generator Loss = 52.6826, Discriminator Loss = 1.7961\n",
      "Epoch 171: Generator Loss = 47.9756, Discriminator Loss = 2.3107\n",
      "Epoch 172: Generator Loss = 57.5358, Discriminator Loss = 1.6199\n",
      "Epoch 173: Generator Loss = 42.1757, Discriminator Loss = 2.7232\n",
      "Epoch 174: Generator Loss = 63.8439, Discriminator Loss = 1.1986\n",
      "Epoch 175: Generator Loss = 54.8382, Discriminator Loss = 1.6570\n",
      "Epoch 176: Generator Loss = 67.8959, Discriminator Loss = 1.9856\n",
      "Epoch 177: Generator Loss = 56.4261, Discriminator Loss = 1.6174\n",
      "Epoch 178: Generator Loss = 77.7270, Discriminator Loss = 1.2368\n",
      "Epoch 179: Generator Loss = 68.5835, Discriminator Loss = 1.0418\n",
      "Epoch 180: Generator Loss = 62.4384, Discriminator Loss = 0.7868\n",
      "Epoch 181: Generator Loss = 69.0581, Discriminator Loss = 1.7410\n",
      "Epoch 182: Generator Loss = 56.1436, Discriminator Loss = 2.8581\n",
      "Epoch 183: Generator Loss = 54.8561, Discriminator Loss = 2.9573\n",
      "Epoch 184: Generator Loss = 65.6892, Discriminator Loss = 1.9936\n",
      "Epoch 185: Generator Loss = 51.0888, Discriminator Loss = 2.3116\n",
      "Epoch 186: Generator Loss = 63.3155, Discriminator Loss = 1.5674\n",
      "Epoch 187: Generator Loss = 62.4966, Discriminator Loss = 1.2299\n",
      "Epoch 188: Generator Loss = 57.2942, Discriminator Loss = 1.1577\n",
      "Epoch 189: Generator Loss = 67.1905, Discriminator Loss = 1.0110\n",
      "Epoch 190: Generator Loss = 77.5656, Discriminator Loss = 0.8146\n",
      "Epoch 191: Generator Loss = 70.9576, Discriminator Loss = 1.0684\n",
      "Epoch 192: Generator Loss = 68.6149, Discriminator Loss = 0.8286\n",
      "Epoch 193: Generator Loss = 63.2952, Discriminator Loss = 0.6610\n",
      "Epoch 194: Generator Loss = 77.6773, Discriminator Loss = 0.5800\n",
      "Epoch 195: Generator Loss = 88.6509, Discriminator Loss = 0.8337\n",
      "Epoch 196: Generator Loss = 69.7807, Discriminator Loss = 0.3801\n",
      "Epoch 197: Generator Loss = 94.2439, Discriminator Loss = 0.2696\n",
      "Epoch 198: Generator Loss = 89.4808, Discriminator Loss = 0.1762\n",
      "Epoch 199: Generator Loss = 83.8177, Discriminator Loss = 0.4556\n",
      "Epoch 200: Generator Loss = 86.9183, Discriminator Loss = 0.3290\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/20 | Train Loss: 0.0761 Acc: 0.9713\n",
      "Epoch 2/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0053 Acc: 0.9959\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0268 Acc: 0.9918\n",
      "Epoch 17/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0311 Acc: 0.9918\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.7min\n",
      "Epoch 1/20 | Train Loss: 0.0731 Acc: 0.9795\n",
      "Epoch 2/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0147 Acc: 0.9959\n",
      "Epoch 5/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0025 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0417 Acc: 0.9918\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0522 Acc: 0.9837\n",
      "Epoch 2/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0185 Acc: 0.9878\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.7min\n",
      "Epoch 1/20 | Train Loss: 0.0728 Acc: 0.9557\n",
      "Epoch 2/20 | Train Loss: 0.0026 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 7.3min\n",
      "Epoch 1/20 | Train Loss: 0.0674 Acc: 0.9714\n",
      "Epoch 2/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 8.1min\n",
      "Epoch 1/20 | Train Loss: 0.0635 Acc: 0.9754\n",
      "Epoch 2/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0076 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0303 Acc: 0.9918\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0890 Acc: 0.9672\n",
      "Epoch 2/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0029 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0026 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0160 Acc: 0.9918\n",
      "Epoch 18/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0708 Acc: 0.9715\n",
      "Epoch 2/20 | Train Loss: 0.0651 Acc: 0.9878\n",
      "Epoch 3/20 | Train Loss: 0.0528 Acc: 0.9878\n",
      "Epoch 4/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0062 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0022 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0029 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0022 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.7min\n",
      "Epoch 1/20 | Train Loss: 0.0472 Acc: 0.9842\n",
      "Epoch 2/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 7.3min\n",
      "Epoch 1/20 | Train Loss: 0.0401 Acc: 0.9800\n",
      "Epoch 2/20 | Train Loss: 0.0063 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.1010 Acc: 0.9771\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 8.0min\n",
      "Epoch 1/20 | Train Loss: 0.0918 Acc: 0.9629\n",
      "Epoch 2/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0023 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Fold 2 Test Accuracy: 0.5000\n",
      "===== Fold 3 =====\n",
      "Epoch 1: Generator Loss = 9.8694, Discriminator Loss = 9.1820\n",
      "Epoch 2: Generator Loss = 11.1209, Discriminator Loss = 7.1401\n",
      "Epoch 3: Generator Loss = 16.2936, Discriminator Loss = 5.6847\n",
      "Epoch 4: Generator Loss = 24.0773, Discriminator Loss = 4.0098\n",
      "Epoch 5: Generator Loss = 32.7780, Discriminator Loss = 4.6838\n",
      "Epoch 6: Generator Loss = 31.7735, Discriminator Loss = 5.0752\n",
      "Epoch 7: Generator Loss = 34.0246, Discriminator Loss = 3.7366\n",
      "Epoch 8: Generator Loss = 33.6550, Discriminator Loss = 5.5596\n",
      "Epoch 9: Generator Loss = 31.2842, Discriminator Loss = 6.2953\n",
      "Epoch 10: Generator Loss = 25.9351, Discriminator Loss = 5.0743\n",
      "Epoch 11: Generator Loss = 27.5375, Discriminator Loss = 7.6831\n",
      "Epoch 12: Generator Loss = 23.6267, Discriminator Loss = 8.2668\n",
      "Epoch 13: Generator Loss = 26.0417, Discriminator Loss = 5.2869\n",
      "Epoch 14: Generator Loss = 24.3720, Discriminator Loss = 5.6245\n",
      "Epoch 15: Generator Loss = 31.7509, Discriminator Loss = 7.2161\n",
      "Epoch 16: Generator Loss = 20.5650, Discriminator Loss = 8.3172\n",
      "Epoch 17: Generator Loss = 28.1086, Discriminator Loss = 6.9858\n",
      "Epoch 18: Generator Loss = 27.0988, Discriminator Loss = 5.2625\n",
      "Epoch 19: Generator Loss = 23.5739, Discriminator Loss = 8.2186\n",
      "Epoch 20: Generator Loss = 26.1864, Discriminator Loss = 7.4915\n",
      "Epoch 21: Generator Loss = 25.7521, Discriminator Loss = 6.1510\n",
      "Epoch 22: Generator Loss = 23.8039, Discriminator Loss = 8.1449\n",
      "Epoch 23: Generator Loss = 18.3538, Discriminator Loss = 8.0704\n",
      "Epoch 24: Generator Loss = 18.3127, Discriminator Loss = 8.2170\n",
      "Epoch 25: Generator Loss = 16.8477, Discriminator Loss = 7.9519\n",
      "Epoch 26: Generator Loss = 19.8495, Discriminator Loss = 8.3998\n",
      "Epoch 27: Generator Loss = 21.5420, Discriminator Loss = 7.4908\n",
      "Epoch 28: Generator Loss = 25.8897, Discriminator Loss = 7.0182\n",
      "Epoch 29: Generator Loss = 24.4678, Discriminator Loss = 7.9023\n",
      "Epoch 30: Generator Loss = 17.0175, Discriminator Loss = 6.8471\n",
      "Epoch 31: Generator Loss = 19.7071, Discriminator Loss = 10.0234\n",
      "Epoch 32: Generator Loss = 16.1710, Discriminator Loss = 8.0277\n",
      "Epoch 33: Generator Loss = 21.1399, Discriminator Loss = 8.9786\n",
      "Epoch 34: Generator Loss = 22.0230, Discriminator Loss = 8.0355\n",
      "Epoch 35: Generator Loss = 17.6067, Discriminator Loss = 8.3674\n",
      "Epoch 36: Generator Loss = 18.9017, Discriminator Loss = 9.7586\n",
      "Epoch 37: Generator Loss = 19.0217, Discriminator Loss = 7.6896\n",
      "Epoch 38: Generator Loss = 19.4558, Discriminator Loss = 8.7511\n",
      "Epoch 39: Generator Loss = 17.1997, Discriminator Loss = 8.2049\n",
      "Epoch 40: Generator Loss = 19.7997, Discriminator Loss = 10.4287\n",
      "Epoch 41: Generator Loss = 16.1828, Discriminator Loss = 7.9858\n",
      "Epoch 42: Generator Loss = 15.7969, Discriminator Loss = 7.4335\n",
      "Epoch 43: Generator Loss = 15.1742, Discriminator Loss = 9.1898\n",
      "Epoch 44: Generator Loss = 20.6766, Discriminator Loss = 8.1800\n",
      "Epoch 45: Generator Loss = 13.6464, Discriminator Loss = 8.0350\n",
      "Epoch 46: Generator Loss = 17.8538, Discriminator Loss = 9.9989\n",
      "Epoch 47: Generator Loss = 14.1508, Discriminator Loss = 7.2816\n",
      "Epoch 48: Generator Loss = 15.0814, Discriminator Loss = 8.3629\n",
      "Epoch 49: Generator Loss = 16.7999, Discriminator Loss = 7.3893\n",
      "Epoch 50: Generator Loss = 16.0211, Discriminator Loss = 7.1746\n",
      "Epoch 51: Generator Loss = 18.0315, Discriminator Loss = 7.0577\n",
      "Epoch 52: Generator Loss = 19.6420, Discriminator Loss = 7.8639\n",
      "Epoch 53: Generator Loss = 23.1610, Discriminator Loss = 6.5889\n",
      "Epoch 54: Generator Loss = 14.8177, Discriminator Loss = 10.8029\n",
      "Epoch 55: Generator Loss = 14.2635, Discriminator Loss = 7.5871\n",
      "Epoch 56: Generator Loss = 17.9042, Discriminator Loss = 7.0466\n",
      "Epoch 57: Generator Loss = 17.8993, Discriminator Loss = 5.2457\n",
      "Epoch 58: Generator Loss = 18.5143, Discriminator Loss = 8.5308\n",
      "Epoch 59: Generator Loss = 19.2936, Discriminator Loss = 6.6692\n",
      "Epoch 60: Generator Loss = 23.0387, Discriminator Loss = 6.7124\n",
      "Epoch 61: Generator Loss = 24.7992, Discriminator Loss = 5.5720\n",
      "Epoch 62: Generator Loss = 25.8143, Discriminator Loss = 6.3768\n",
      "Epoch 63: Generator Loss = 25.0317, Discriminator Loss = 7.1103\n",
      "Epoch 64: Generator Loss = 22.1215, Discriminator Loss = 7.9191\n",
      "Epoch 65: Generator Loss = 19.6399, Discriminator Loss = 5.9460\n",
      "Epoch 66: Generator Loss = 25.2470, Discriminator Loss = 4.0557\n",
      "Epoch 67: Generator Loss = 29.8204, Discriminator Loss = 5.4943\n",
      "Epoch 68: Generator Loss = 25.9368, Discriminator Loss = 5.4948\n",
      "Epoch 69: Generator Loss = 31.4988, Discriminator Loss = 4.7271\n",
      "Epoch 70: Generator Loss = 28.5935, Discriminator Loss = 6.2781\n",
      "Epoch 71: Generator Loss = 33.6711, Discriminator Loss = 4.6459\n",
      "Epoch 72: Generator Loss = 28.9579, Discriminator Loss = 3.2738\n",
      "Epoch 73: Generator Loss = 36.5336, Discriminator Loss = 3.0416\n",
      "Epoch 74: Generator Loss = 24.8898, Discriminator Loss = 7.0220\n",
      "Epoch 75: Generator Loss = 27.8311, Discriminator Loss = 6.0025\n",
      "Epoch 76: Generator Loss = 30.2505, Discriminator Loss = 4.8286\n",
      "Epoch 77: Generator Loss = 39.8325, Discriminator Loss = 2.1798\n",
      "Epoch 78: Generator Loss = 43.2840, Discriminator Loss = 1.9527\n",
      "Epoch 79: Generator Loss = 37.2241, Discriminator Loss = 3.0976\n",
      "Epoch 80: Generator Loss = 40.1998, Discriminator Loss = 2.8981\n",
      "Epoch 81: Generator Loss = 48.2975, Discriminator Loss = 1.9386\n",
      "Epoch 82: Generator Loss = 46.6608, Discriminator Loss = 1.9320\n",
      "Epoch 83: Generator Loss = 54.7491, Discriminator Loss = 1.9645\n",
      "Epoch 84: Generator Loss = 40.5635, Discriminator Loss = 7.2616\n",
      "Epoch 85: Generator Loss = 54.1155, Discriminator Loss = 2.7453\n",
      "Epoch 86: Generator Loss = 37.9961, Discriminator Loss = 3.0153\n",
      "Epoch 87: Generator Loss = 44.3787, Discriminator Loss = 2.5448\n",
      "Epoch 88: Generator Loss = 41.1077, Discriminator Loss = 2.9423\n",
      "Epoch 89: Generator Loss = 49.1806, Discriminator Loss = 3.9596\n",
      "Epoch 90: Generator Loss = 34.5091, Discriminator Loss = 4.6062\n",
      "Epoch 91: Generator Loss = 49.1410, Discriminator Loss = 2.7928\n",
      "Epoch 92: Generator Loss = 47.4714, Discriminator Loss = 1.8051\n",
      "Epoch 93: Generator Loss = 51.6158, Discriminator Loss = 1.6965\n",
      "Epoch 94: Generator Loss = 54.2502, Discriminator Loss = 2.2948\n",
      "Epoch 95: Generator Loss = 38.0960, Discriminator Loss = 4.2239\n",
      "Epoch 96: Generator Loss = 50.1856, Discriminator Loss = 1.9796\n",
      "Epoch 97: Generator Loss = 56.3813, Discriminator Loss = 1.6810\n",
      "Epoch 98: Generator Loss = 46.2636, Discriminator Loss = 1.0455\n",
      "Epoch 99: Generator Loss = 59.5125, Discriminator Loss = 1.3113\n",
      "Epoch 100: Generator Loss = 59.1078, Discriminator Loss = 4.1863\n",
      "Epoch 101: Generator Loss = 61.8856, Discriminator Loss = 6.2987\n",
      "Epoch 102: Generator Loss = 43.8067, Discriminator Loss = 3.9494\n",
      "Epoch 103: Generator Loss = 50.7628, Discriminator Loss = 1.8651\n",
      "Epoch 104: Generator Loss = 60.9351, Discriminator Loss = 1.3444\n",
      "Epoch 105: Generator Loss = 62.4632, Discriminator Loss = 0.6940\n",
      "Epoch 106: Generator Loss = 61.4425, Discriminator Loss = 2.5091\n",
      "Epoch 107: Generator Loss = 57.5556, Discriminator Loss = 1.1239\n",
      "Epoch 108: Generator Loss = 62.1196, Discriminator Loss = 1.4120\n",
      "Epoch 109: Generator Loss = 67.1330, Discriminator Loss = 1.0817\n",
      "Epoch 110: Generator Loss = 63.3919, Discriminator Loss = 0.9304\n",
      "Epoch 111: Generator Loss = 60.5842, Discriminator Loss = 0.8640\n",
      "Epoch 112: Generator Loss = 65.4135, Discriminator Loss = 2.3786\n",
      "Epoch 113: Generator Loss = 56.7843, Discriminator Loss = 0.8030\n",
      "Epoch 114: Generator Loss = 56.1935, Discriminator Loss = 2.2040\n",
      "Epoch 115: Generator Loss = 59.8963, Discriminator Loss = 2.4761\n",
      "Epoch 116: Generator Loss = 65.5009, Discriminator Loss = 0.9977\n",
      "Epoch 117: Generator Loss = 63.0541, Discriminator Loss = 1.0065\n",
      "Epoch 118: Generator Loss = 73.3891, Discriminator Loss = 1.4001\n",
      "Epoch 119: Generator Loss = 89.7544, Discriminator Loss = 0.6548\n",
      "Epoch 120: Generator Loss = 72.7432, Discriminator Loss = 0.8368\n",
      "Epoch 121: Generator Loss = 67.8975, Discriminator Loss = 0.8354\n",
      "Epoch 122: Generator Loss = 68.0619, Discriminator Loss = 0.5310\n",
      "Epoch 123: Generator Loss = 98.5670, Discriminator Loss = 1.6770\n",
      "Epoch 124: Generator Loss = 73.8881, Discriminator Loss = 1.0729\n",
      "Epoch 125: Generator Loss = 70.8369, Discriminator Loss = 0.6442\n",
      "Epoch 126: Generator Loss = 72.9091, Discriminator Loss = 1.1393\n",
      "Epoch 127: Generator Loss = 66.4742, Discriminator Loss = 2.0563\n",
      "Epoch 128: Generator Loss = 64.3110, Discriminator Loss = 3.4195\n",
      "Epoch 129: Generator Loss = 66.5029, Discriminator Loss = 5.2856\n",
      "Epoch 130: Generator Loss = 62.9937, Discriminator Loss = 1.8174\n",
      "Epoch 131: Generator Loss = 56.6717, Discriminator Loss = 1.5041\n",
      "Epoch 132: Generator Loss = 60.4443, Discriminator Loss = 1.1008\n",
      "Epoch 133: Generator Loss = 77.5875, Discriminator Loss = 1.6337\n",
      "Epoch 134: Generator Loss = 66.7956, Discriminator Loss = 0.9650\n",
      "Epoch 135: Generator Loss = 77.0193, Discriminator Loss = 1.6316\n",
      "Epoch 136: Generator Loss = 67.7514, Discriminator Loss = 5.4161\n",
      "Epoch 137: Generator Loss = 54.3036, Discriminator Loss = 3.2291\n",
      "Epoch 138: Generator Loss = 72.3763, Discriminator Loss = 2.0888\n",
      "Epoch 139: Generator Loss = 56.6368, Discriminator Loss = 1.9336\n",
      "Epoch 140: Generator Loss = 72.6862, Discriminator Loss = 1.4567\n",
      "Epoch 141: Generator Loss = 77.1111, Discriminator Loss = 1.1134\n",
      "Epoch 142: Generator Loss = 83.1462, Discriminator Loss = 1.1938\n",
      "Epoch 143: Generator Loss = 86.8184, Discriminator Loss = 1.9337\n",
      "Epoch 144: Generator Loss = 69.5799, Discriminator Loss = 0.4680\n",
      "Epoch 145: Generator Loss = 71.5835, Discriminator Loss = 0.5648\n",
      "Epoch 146: Generator Loss = 82.6051, Discriminator Loss = 1.2413\n",
      "Epoch 147: Generator Loss = 68.5444, Discriminator Loss = 1.2152\n",
      "Epoch 148: Generator Loss = 80.4677, Discriminator Loss = 0.5339\n",
      "Epoch 149: Generator Loss = 75.2381, Discriminator Loss = 1.0431\n",
      "Epoch 150: Generator Loss = 66.9509, Discriminator Loss = 0.5299\n",
      "Epoch 151: Generator Loss = 88.8837, Discriminator Loss = 0.5209\n",
      "Epoch 152: Generator Loss = 77.1368, Discriminator Loss = 0.6289\n",
      "Epoch 153: Generator Loss = 86.3650, Discriminator Loss = 0.6090\n",
      "Epoch 154: Generator Loss = 91.7025, Discriminator Loss = 1.2601\n",
      "Epoch 155: Generator Loss = 79.1519, Discriminator Loss = 0.8169\n",
      "Epoch 156: Generator Loss = 83.1352, Discriminator Loss = 1.0581\n",
      "Epoch 157: Generator Loss = 94.6850, Discriminator Loss = 1.1108\n",
      "Epoch 158: Generator Loss = 81.2285, Discriminator Loss = 1.2611\n",
      "Epoch 159: Generator Loss = 85.6989, Discriminator Loss = 4.0031\n",
      "Epoch 160: Generator Loss = 70.4221, Discriminator Loss = 12.8852\n",
      "Epoch 161: Generator Loss = 62.7644, Discriminator Loss = 6.5987\n",
      "Epoch 162: Generator Loss = 69.1554, Discriminator Loss = 2.1469\n",
      "Epoch 163: Generator Loss = 61.3745, Discriminator Loss = 1.5579\n",
      "Epoch 164: Generator Loss = 74.2568, Discriminator Loss = 1.2267\n",
      "Epoch 165: Generator Loss = 76.4721, Discriminator Loss = 1.0400\n",
      "Epoch 166: Generator Loss = 73.4240, Discriminator Loss = 3.3783\n",
      "Epoch 167: Generator Loss = 61.0944, Discriminator Loss = 1.9874\n",
      "Epoch 168: Generator Loss = 81.0551, Discriminator Loss = 1.1012\n",
      "Epoch 169: Generator Loss = 72.6599, Discriminator Loss = 1.5653\n",
      "Epoch 170: Generator Loss = 66.8312, Discriminator Loss = 0.6516\n",
      "Epoch 171: Generator Loss = 69.9784, Discriminator Loss = 0.7944\n",
      "Epoch 172: Generator Loss = 72.0497, Discriminator Loss = 0.7917\n",
      "Epoch 173: Generator Loss = 79.5598, Discriminator Loss = 0.6981\n",
      "Epoch 174: Generator Loss = 88.4726, Discriminator Loss = 0.8698\n",
      "Epoch 175: Generator Loss = 79.8856, Discriminator Loss = 1.2220\n",
      "Epoch 176: Generator Loss = 86.0326, Discriminator Loss = 0.7196\n",
      "Epoch 177: Generator Loss = 71.2440, Discriminator Loss = 1.9080\n",
      "Epoch 178: Generator Loss = 47.5252, Discriminator Loss = 3.3747\n",
      "Epoch 179: Generator Loss = 72.8759, Discriminator Loss = 0.8630\n",
      "Epoch 180: Generator Loss = 64.3181, Discriminator Loss = 8.4439\n",
      "Epoch 181: Generator Loss = 52.4608, Discriminator Loss = 3.2885\n",
      "Epoch 182: Generator Loss = 63.1479, Discriminator Loss = 1.5721\n",
      "Epoch 183: Generator Loss = 63.1661, Discriminator Loss = 1.4428\n",
      "Epoch 184: Generator Loss = 59.9457, Discriminator Loss = 1.3082\n",
      "Epoch 185: Generator Loss = 63.2409, Discriminator Loss = 2.8363\n",
      "Epoch 186: Generator Loss = 63.0105, Discriminator Loss = 1.6443\n",
      "Epoch 187: Generator Loss = 80.2840, Discriminator Loss = 0.7754\n",
      "Epoch 188: Generator Loss = 59.2240, Discriminator Loss = 1.0910\n",
      "Epoch 189: Generator Loss = 81.3257, Discriminator Loss = 1.3044\n",
      "Epoch 190: Generator Loss = 62.6708, Discriminator Loss = 1.4145\n",
      "Epoch 191: Generator Loss = 71.5091, Discriminator Loss = 0.9777\n",
      "Epoch 192: Generator Loss = 75.8667, Discriminator Loss = 1.0002\n",
      "Epoch 193: Generator Loss = 83.8086, Discriminator Loss = 2.0752\n",
      "Epoch 194: Generator Loss = 85.6279, Discriminator Loss = 1.0287\n",
      "Epoch 195: Generator Loss = 87.2398, Discriminator Loss = 1.3152\n",
      "Epoch 196: Generator Loss = 80.3122, Discriminator Loss = 1.0483\n",
      "Epoch 197: Generator Loss = 77.2349, Discriminator Loss = 0.6950\n",
      "Epoch 198: Generator Loss = 92.8430, Discriminator Loss = 0.9211\n",
      "Epoch 199: Generator Loss = 77.8823, Discriminator Loss = 0.8740\n",
      "Epoch 200: Generator Loss = 81.4839, Discriminator Loss = 1.8743\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/20 | Train Loss: 0.0958 Acc: 0.9467\n",
      "Epoch 2/20 | Train Loss: 0.0217 Acc: 0.9918\n",
      "Epoch 3/20 | Train Loss: 0.0028 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0029 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0320 Acc: 0.9877\n",
      "Epoch 7/20 | Train Loss: 0.0023 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0129 Acc: 0.9959\n",
      "Epoch 9/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0091 Acc: 0.9959\n",
      "Epoch 11/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0020 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0043 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0027 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0032 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.1050 Acc: 0.9467\n",
      "Epoch 2/20 | Train Loss: 0.0057 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0184 Acc: 0.9959\n",
      "Epoch 4/20 | Train Loss: 0.0103 Acc: 0.9959\n",
      "Epoch 5/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0125 Acc: 0.9918\n",
      "Epoch 14/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0306 Acc: 0.9877\n",
      "Epoch 17/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0669 Acc: 0.9797\n",
      "Epoch 2/20 | Train Loss: 0.0021 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0042 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.7min\n",
      "Epoch 1/20 | Train Loss: 0.0609 Acc: 0.9747\n",
      "Epoch 2/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 7.2min\n",
      "Epoch 1/20 | Train Loss: 0.1198 Acc: 0.9457\n",
      "Epoch 2/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0052 Acc: 0.9971\n",
      "[CV] END ...................................scale_factor=0.5; total time= 7.9min\n",
      "Epoch 1/20 | Train Loss: 0.0677 Acc: 0.9754\n",
      "Epoch 2/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0046 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0031 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0450 Acc: 0.9959\n",
      "Epoch 8/20 | Train Loss: 0.0466 Acc: 0.9836\n",
      "Epoch 9/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0302 Acc: 0.9959\n",
      "Epoch 11/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.5min\n",
      "Epoch 1/20 | Train Loss: 0.0932 Acc: 0.9426\n",
      "Epoch 2/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0246 Acc: 0.9918\n",
      "Epoch 4/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0021 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0070 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0388 Acc: 0.9918\n",
      "Epoch 9/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0271 Acc: 0.9918\n",
      "Epoch 14/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0714 Acc: 0.9675\n",
      "Epoch 2/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0020 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0029 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0483 Acc: 0.9842\n",
      "Epoch 2/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 7.2min\n",
      "Epoch 1/20 | Train Loss: 0.0444 Acc: 0.9829\n",
      "Epoch 2/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0061 Acc: 0.9971\n",
      "Epoch 8/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0030 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 7.9min\n",
      "Epoch 1/20 | Train Loss: 0.0946 Acc: 0.9600\n",
      "Epoch 2/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0030 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Fold 3 Test Accuracy: 0.5000\n",
      "===== Fold 4 =====\n",
      "Epoch 1: Generator Loss = 10.0339, Discriminator Loss = 8.7191\n",
      "Epoch 2: Generator Loss = 13.5170, Discriminator Loss = 4.9100\n",
      "Epoch 3: Generator Loss = 19.8199, Discriminator Loss = 4.3695\n",
      "Epoch 4: Generator Loss = 25.5552, Discriminator Loss = 4.1041\n",
      "Epoch 5: Generator Loss = 29.4448, Discriminator Loss = 5.8976\n",
      "Epoch 6: Generator Loss = 35.8594, Discriminator Loss = 5.0670\n",
      "Epoch 7: Generator Loss = 29.5196, Discriminator Loss = 7.3611\n",
      "Epoch 8: Generator Loss = 26.5418, Discriminator Loss = 5.8707\n",
      "Epoch 9: Generator Loss = 28.6714, Discriminator Loss = 6.3464\n",
      "Epoch 10: Generator Loss = 28.2941, Discriminator Loss = 5.6793\n",
      "Epoch 11: Generator Loss = 23.6983, Discriminator Loss = 8.8674\n",
      "Epoch 12: Generator Loss = 21.4025, Discriminator Loss = 8.3126\n",
      "Epoch 13: Generator Loss = 25.7684, Discriminator Loss = 8.2380\n",
      "Epoch 14: Generator Loss = 23.1353, Discriminator Loss = 6.2609\n",
      "Epoch 15: Generator Loss = 18.6796, Discriminator Loss = 6.2127\n",
      "Epoch 16: Generator Loss = 20.6041, Discriminator Loss = 7.9802\n",
      "Epoch 17: Generator Loss = 18.9643, Discriminator Loss = 8.9459\n",
      "Epoch 18: Generator Loss = 19.0973, Discriminator Loss = 8.5352\n",
      "Epoch 19: Generator Loss = 21.0803, Discriminator Loss = 7.1112\n",
      "Epoch 20: Generator Loss = 17.6567, Discriminator Loss = 7.1311\n",
      "Epoch 21: Generator Loss = 20.9193, Discriminator Loss = 9.0719\n",
      "Epoch 22: Generator Loss = 27.4558, Discriminator Loss = 7.2598\n",
      "Epoch 23: Generator Loss = 23.9297, Discriminator Loss = 6.3486\n",
      "Epoch 24: Generator Loss = 23.3584, Discriminator Loss = 6.9557\n",
      "Epoch 25: Generator Loss = 23.0685, Discriminator Loss = 9.5479\n",
      "Epoch 26: Generator Loss = 21.3088, Discriminator Loss = 7.8323\n",
      "Epoch 27: Generator Loss = 17.5842, Discriminator Loss = 6.9630\n",
      "Epoch 28: Generator Loss = 24.7196, Discriminator Loss = 8.1566\n",
      "Epoch 29: Generator Loss = 21.1161, Discriminator Loss = 8.2814\n",
      "Epoch 30: Generator Loss = 22.3638, Discriminator Loss = 8.4346\n",
      "Epoch 31: Generator Loss = 19.9803, Discriminator Loss = 7.7340\n",
      "Epoch 32: Generator Loss = 21.0598, Discriminator Loss = 8.4378\n",
      "Epoch 33: Generator Loss = 19.8777, Discriminator Loss = 8.4199\n",
      "Epoch 34: Generator Loss = 17.5168, Discriminator Loss = 7.9049\n",
      "Epoch 35: Generator Loss = 20.7961, Discriminator Loss = 7.3313\n",
      "Epoch 36: Generator Loss = 18.1592, Discriminator Loss = 7.4799\n",
      "Epoch 37: Generator Loss = 18.1398, Discriminator Loss = 7.9003\n",
      "Epoch 38: Generator Loss = 19.0494, Discriminator Loss = 7.1959\n",
      "Epoch 39: Generator Loss = 18.4139, Discriminator Loss = 6.7798\n",
      "Epoch 40: Generator Loss = 18.4592, Discriminator Loss = 6.8776\n",
      "Epoch 41: Generator Loss = 23.9033, Discriminator Loss = 6.9448\n",
      "Epoch 42: Generator Loss = 22.0542, Discriminator Loss = 6.4600\n",
      "Epoch 43: Generator Loss = 18.6631, Discriminator Loss = 8.4752\n",
      "Epoch 44: Generator Loss = 20.5652, Discriminator Loss = 6.9763\n",
      "Epoch 45: Generator Loss = 29.6872, Discriminator Loss = 4.2455\n",
      "Epoch 46: Generator Loss = 26.8104, Discriminator Loss = 7.7748\n",
      "Epoch 47: Generator Loss = 29.9451, Discriminator Loss = 5.5995\n",
      "Epoch 48: Generator Loss = 32.0482, Discriminator Loss = 4.5817\n",
      "Epoch 49: Generator Loss = 31.1986, Discriminator Loss = 5.8280\n",
      "Epoch 50: Generator Loss = 25.6337, Discriminator Loss = 5.1737\n",
      "Epoch 51: Generator Loss = 29.6738, Discriminator Loss = 4.5229\n",
      "Epoch 52: Generator Loss = 31.1146, Discriminator Loss = 4.2329\n",
      "Epoch 53: Generator Loss = 34.4750, Discriminator Loss = 4.6892\n",
      "Epoch 54: Generator Loss = 35.4561, Discriminator Loss = 5.9600\n",
      "Epoch 55: Generator Loss = 40.2106, Discriminator Loss = 4.6980\n",
      "Epoch 56: Generator Loss = 35.1804, Discriminator Loss = 3.5381\n",
      "Epoch 57: Generator Loss = 35.0978, Discriminator Loss = 3.9027\n",
      "Epoch 58: Generator Loss = 42.1187, Discriminator Loss = 4.0910\n",
      "Epoch 59: Generator Loss = 41.5939, Discriminator Loss = 4.6947\n",
      "Epoch 60: Generator Loss = 45.5191, Discriminator Loss = 2.4566\n",
      "Epoch 61: Generator Loss = 39.8088, Discriminator Loss = 2.5192\n",
      "Epoch 62: Generator Loss = 40.6888, Discriminator Loss = 1.6846\n",
      "Epoch 63: Generator Loss = 54.6706, Discriminator Loss = 2.0715\n",
      "Epoch 64: Generator Loss = 41.5560, Discriminator Loss = 1.4558\n",
      "Epoch 65: Generator Loss = 56.7968, Discriminator Loss = 2.2128\n",
      "Epoch 66: Generator Loss = 55.6368, Discriminator Loss = 2.0556\n",
      "Epoch 67: Generator Loss = 59.7084, Discriminator Loss = 2.0415\n",
      "Epoch 68: Generator Loss = 61.2834, Discriminator Loss = 1.9384\n",
      "Epoch 69: Generator Loss = 51.0676, Discriminator Loss = 1.7993\n",
      "Epoch 70: Generator Loss = 57.4168, Discriminator Loss = 3.5467\n",
      "Epoch 71: Generator Loss = 51.5452, Discriminator Loss = 3.1711\n",
      "Epoch 72: Generator Loss = 56.5960, Discriminator Loss = 1.8319\n",
      "Epoch 73: Generator Loss = 66.7694, Discriminator Loss = 1.5144\n",
      "Epoch 74: Generator Loss = 59.7202, Discriminator Loss = 1.3867\n",
      "Epoch 75: Generator Loss = 63.8080, Discriminator Loss = 1.2151\n",
      "Epoch 76: Generator Loss = 63.1211, Discriminator Loss = 1.4630\n",
      "Epoch 77: Generator Loss = 58.2714, Discriminator Loss = 0.8753\n",
      "Epoch 78: Generator Loss = 61.5070, Discriminator Loss = 0.7087\n",
      "Epoch 79: Generator Loss = 64.6471, Discriminator Loss = 1.1427\n",
      "Epoch 80: Generator Loss = 70.1922, Discriminator Loss = 1.1232\n",
      "Epoch 81: Generator Loss = 72.1019, Discriminator Loss = 0.7689\n",
      "Epoch 82: Generator Loss = 66.8748, Discriminator Loss = 1.1022\n",
      "Epoch 83: Generator Loss = 70.2011, Discriminator Loss = 0.7654\n",
      "Epoch 84: Generator Loss = 63.4548, Discriminator Loss = 1.5093\n",
      "Epoch 85: Generator Loss = 78.6108, Discriminator Loss = 1.0212\n",
      "Epoch 86: Generator Loss = 73.3402, Discriminator Loss = 0.6442\n",
      "Epoch 87: Generator Loss = 71.2554, Discriminator Loss = 1.0881\n",
      "Epoch 88: Generator Loss = 81.5541, Discriminator Loss = 1.4294\n",
      "Epoch 89: Generator Loss = 60.1801, Discriminator Loss = 2.8001\n",
      "Epoch 90: Generator Loss = 78.5722, Discriminator Loss = 2.1868\n",
      "Epoch 91: Generator Loss = 74.6097, Discriminator Loss = 0.9393\n",
      "Epoch 92: Generator Loss = 71.0797, Discriminator Loss = 1.1406\n",
      "Epoch 93: Generator Loss = 68.6724, Discriminator Loss = 1.0736\n",
      "Epoch 94: Generator Loss = 75.7997, Discriminator Loss = 0.6430\n",
      "Epoch 95: Generator Loss = 71.9414, Discriminator Loss = 0.4248\n",
      "Epoch 96: Generator Loss = 66.4718, Discriminator Loss = 0.7876\n",
      "Epoch 97: Generator Loss = 80.8535, Discriminator Loss = 0.4500\n",
      "Epoch 98: Generator Loss = 71.9999, Discriminator Loss = 0.6732\n",
      "Epoch 99: Generator Loss = 77.3579, Discriminator Loss = 1.1504\n",
      "Epoch 100: Generator Loss = 79.4409, Discriminator Loss = 1.3832\n",
      "Epoch 101: Generator Loss = 84.6168, Discriminator Loss = 0.7836\n",
      "Epoch 102: Generator Loss = 89.8187, Discriminator Loss = 0.9082\n",
      "Epoch 103: Generator Loss = 86.4309, Discriminator Loss = 0.7883\n",
      "Epoch 104: Generator Loss = 75.5442, Discriminator Loss = 0.7172\n",
      "Epoch 105: Generator Loss = 93.3995, Discriminator Loss = 0.7111\n",
      "Epoch 106: Generator Loss = 74.1474, Discriminator Loss = 0.5892\n",
      "Epoch 107: Generator Loss = 85.2288, Discriminator Loss = 1.0872\n",
      "Epoch 108: Generator Loss = 68.6406, Discriminator Loss = 0.6624\n",
      "Epoch 109: Generator Loss = 77.3864, Discriminator Loss = 3.7229\n",
      "Epoch 110: Generator Loss = 73.9298, Discriminator Loss = 3.3599\n",
      "Epoch 111: Generator Loss = 71.6447, Discriminator Loss = 2.0003\n",
      "Epoch 112: Generator Loss = 85.7199, Discriminator Loss = 0.8857\n",
      "Epoch 113: Generator Loss = 90.3386, Discriminator Loss = 0.7038\n",
      "Epoch 114: Generator Loss = 85.7991, Discriminator Loss = 0.8654\n",
      "Epoch 115: Generator Loss = 89.8644, Discriminator Loss = 0.6348\n",
      "Epoch 116: Generator Loss = 79.0796, Discriminator Loss = 0.6591\n",
      "Epoch 117: Generator Loss = 84.8283, Discriminator Loss = 0.5577\n",
      "Epoch 118: Generator Loss = 85.8378, Discriminator Loss = 0.6925\n",
      "Epoch 119: Generator Loss = 60.9983, Discriminator Loss = 1.3428\n",
      "Epoch 120: Generator Loss = 81.6803, Discriminator Loss = 1.0540\n",
      "Epoch 121: Generator Loss = 72.5555, Discriminator Loss = 1.0235\n",
      "Epoch 122: Generator Loss = 75.4381, Discriminator Loss = 0.6097\n",
      "Epoch 123: Generator Loss = 81.7466, Discriminator Loss = 0.6043\n",
      "Epoch 124: Generator Loss = 86.3956, Discriminator Loss = 1.8099\n",
      "Epoch 125: Generator Loss = 92.9926, Discriminator Loss = 0.7486\n",
      "Epoch 126: Generator Loss = 80.5558, Discriminator Loss = 0.6632\n",
      "Epoch 127: Generator Loss = 70.6865, Discriminator Loss = 0.9851\n",
      "Epoch 128: Generator Loss = 66.0296, Discriminator Loss = 4.2382\n",
      "Epoch 129: Generator Loss = 96.1369, Discriminator Loss = 0.8881\n",
      "Epoch 130: Generator Loss = 62.7408, Discriminator Loss = 2.0805\n",
      "Epoch 131: Generator Loss = 87.2767, Discriminator Loss = 0.8067\n",
      "Epoch 132: Generator Loss = 85.2657, Discriminator Loss = 0.7751\n",
      "Epoch 133: Generator Loss = 69.1264, Discriminator Loss = 0.6314\n",
      "Epoch 134: Generator Loss = 75.6319, Discriminator Loss = 0.6618\n",
      "Epoch 135: Generator Loss = 74.4463, Discriminator Loss = 4.7358\n",
      "Epoch 136: Generator Loss = 90.7723, Discriminator Loss = 2.5033\n",
      "Epoch 137: Generator Loss = 69.6951, Discriminator Loss = 1.6980\n",
      "Epoch 138: Generator Loss = 79.6085, Discriminator Loss = 0.9363\n",
      "Epoch 139: Generator Loss = 69.8951, Discriminator Loss = 1.4056\n",
      "Epoch 140: Generator Loss = 92.0297, Discriminator Loss = 0.9045\n",
      "Epoch 141: Generator Loss = 80.3788, Discriminator Loss = 0.7562\n",
      "Epoch 142: Generator Loss = 84.0646, Discriminator Loss = 1.3933\n",
      "Epoch 143: Generator Loss = 89.4816, Discriminator Loss = 3.3585\n",
      "Epoch 144: Generator Loss = 102.0812, Discriminator Loss = 1.2238\n",
      "Epoch 145: Generator Loss = 86.3100, Discriminator Loss = 1.0509\n",
      "Epoch 146: Generator Loss = 79.2699, Discriminator Loss = 4.4756\n",
      "Epoch 147: Generator Loss = 74.2330, Discriminator Loss = 1.7161\n",
      "Epoch 148: Generator Loss = 85.4150, Discriminator Loss = 0.7039\n",
      "Epoch 149: Generator Loss = 88.0970, Discriminator Loss = 1.2003\n",
      "Epoch 150: Generator Loss = 71.5977, Discriminator Loss = 0.8277\n",
      "Epoch 151: Generator Loss = 75.2694, Discriminator Loss = 4.0331\n",
      "Epoch 152: Generator Loss = 74.4223, Discriminator Loss = 2.0220\n",
      "Epoch 153: Generator Loss = 75.4448, Discriminator Loss = 1.4627\n",
      "Epoch 154: Generator Loss = 76.9891, Discriminator Loss = 3.2581\n",
      "Epoch 155: Generator Loss = 66.8117, Discriminator Loss = 1.7259\n",
      "Epoch 156: Generator Loss = 68.9511, Discriminator Loss = 0.7954\n",
      "Epoch 157: Generator Loss = 78.5512, Discriminator Loss = 1.4037\n",
      "Epoch 158: Generator Loss = 98.7979, Discriminator Loss = 2.0809\n",
      "Epoch 159: Generator Loss = 101.1470, Discriminator Loss = 0.5173\n",
      "Epoch 160: Generator Loss = 65.5386, Discriminator Loss = 1.9493\n",
      "Epoch 161: Generator Loss = 79.2700, Discriminator Loss = 0.9155\n",
      "Epoch 162: Generator Loss = 70.8887, Discriminator Loss = 6.7413\n",
      "Epoch 163: Generator Loss = 74.6282, Discriminator Loss = 2.5665\n",
      "Epoch 164: Generator Loss = 75.9125, Discriminator Loss = 1.0235\n",
      "Epoch 165: Generator Loss = 80.3848, Discriminator Loss = 0.8039\n",
      "Epoch 166: Generator Loss = 65.3053, Discriminator Loss = 0.7750\n",
      "Epoch 167: Generator Loss = 96.7566, Discriminator Loss = 1.0965\n",
      "Epoch 168: Generator Loss = 74.0033, Discriminator Loss = 0.7367\n",
      "Epoch 169: Generator Loss = 94.6748, Discriminator Loss = 2.3739\n",
      "Epoch 170: Generator Loss = 77.1532, Discriminator Loss = 1.3069\n",
      "Epoch 171: Generator Loss = 98.4130, Discriminator Loss = 0.7851\n",
      "Epoch 172: Generator Loss = 80.0692, Discriminator Loss = 0.5485\n",
      "Epoch 173: Generator Loss = 66.4029, Discriminator Loss = 0.7190\n",
      "Epoch 174: Generator Loss = 96.2096, Discriminator Loss = 0.6478\n",
      "Epoch 175: Generator Loss = 77.7318, Discriminator Loss = 0.6638\n",
      "Epoch 176: Generator Loss = 85.8371, Discriminator Loss = 1.1402\n",
      "Epoch 177: Generator Loss = 70.0399, Discriminator Loss = 0.7752\n",
      "Epoch 178: Generator Loss = 102.9494, Discriminator Loss = 1.4041\n",
      "Epoch 179: Generator Loss = 53.3888, Discriminator Loss = 3.8075\n",
      "Epoch 180: Generator Loss = 59.8148, Discriminator Loss = 2.5357\n",
      "Epoch 181: Generator Loss = 67.3550, Discriminator Loss = 1.3136\n",
      "Epoch 182: Generator Loss = 78.0461, Discriminator Loss = 0.6135\n",
      "Epoch 183: Generator Loss = 76.4709, Discriminator Loss = 0.7789\n",
      "Epoch 184: Generator Loss = 78.4106, Discriminator Loss = 1.3907\n",
      "Epoch 185: Generator Loss = 72.4525, Discriminator Loss = 2.9701\n",
      "Epoch 186: Generator Loss = 75.1963, Discriminator Loss = 1.1203\n",
      "Epoch 187: Generator Loss = 76.4834, Discriminator Loss = 0.6227\n",
      "Epoch 188: Generator Loss = 89.2869, Discriminator Loss = 1.2959\n",
      "Epoch 189: Generator Loss = 92.1842, Discriminator Loss = 0.4784\n",
      "Epoch 190: Generator Loss = 89.8432, Discriminator Loss = 0.8555\n",
      "Epoch 191: Generator Loss = 82.4232, Discriminator Loss = 4.3895\n",
      "Epoch 192: Generator Loss = 61.3035, Discriminator Loss = 2.9133\n",
      "Epoch 193: Generator Loss = 89.8450, Discriminator Loss = 0.8275\n",
      "Epoch 194: Generator Loss = 90.5000, Discriminator Loss = 1.1202\n",
      "Epoch 195: Generator Loss = 96.7041, Discriminator Loss = 0.7099\n",
      "Epoch 196: Generator Loss = 91.2203, Discriminator Loss = 0.4647\n",
      "Epoch 197: Generator Loss = 97.8560, Discriminator Loss = 0.9857\n",
      "Epoch 198: Generator Loss = 95.5349, Discriminator Loss = 0.8228\n",
      "Epoch 199: Generator Loss = 68.9070, Discriminator Loss = 2.5296\n",
      "Epoch 200: Generator Loss = 75.7728, Discriminator Loss = 0.9271\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/20 | Train Loss: 0.1365 Acc: 0.9426\n",
      "Epoch 2/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0194 Acc: 0.9877\n",
      "Epoch 4/20 | Train Loss: 0.0039 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0335 Acc: 0.9959\n",
      "Epoch 6/20 | Train Loss: 0.0216 Acc: 0.9918\n",
      "Epoch 7/20 | Train Loss: 0.0065 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0248 Acc: 0.9959\n",
      "Epoch 9/20 | Train Loss: 0.0219 Acc: 0.9918\n",
      "Epoch 10/20 | Train Loss: 0.0048 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0032 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0028 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0057 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0059 Acc: 0.9959\n",
      "Epoch 15/20 | Train Loss: 0.0390 Acc: 0.9836\n",
      "Epoch 16/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0029 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0030 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0025 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0044 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0538 Acc: 0.9836\n",
      "Epoch 2/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0383 Acc: 0.9918\n",
      "Epoch 5/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0020 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0033 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0233 Acc: 0.9918\n",
      "Epoch 11/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0395 Acc: 0.9918\n",
      "Epoch 13/20 | Train Loss: 0.0097 Acc: 0.9959\n",
      "Epoch 14/20 | Train Loss: 0.0682 Acc: 0.9836\n",
      "Epoch 15/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0134 Acc: 0.9918\n",
      "Epoch 19/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.1130 Acc: 0.9385\n",
      "Epoch 2/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0023 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0193 Acc: 0.9918\n",
      "Epoch 12/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0763 Acc: 0.9686\n",
      "Epoch 2/20 | Train Loss: 0.0028 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 7.2min\n",
      "Epoch 1/20 | Train Loss: 0.0644 Acc: 0.9686\n",
      "Epoch 2/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 8.0min\n",
      "Epoch 1/20 | Train Loss: 0.0922 Acc: 0.9549\n",
      "Epoch 2/20 | Train Loss: 0.0397 Acc: 0.9918\n",
      "Epoch 3/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0091 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0174 Acc: 0.9918\n",
      "Epoch 9/20 | Train Loss: 0.0027 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0026 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0033 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0020 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0451 Acc: 0.9918\n",
      "Epoch 20/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.1107 Acc: 0.9549\n",
      "Epoch 2/20 | Train Loss: 0.0023 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0162 Acc: 0.9918\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0731 Acc: 0.9590\n",
      "Epoch 2/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0282 Acc: 0.9918\n",
      "Epoch 4/20 | Train Loss: 0.0096 Acc: 0.9959\n",
      "Epoch 5/20 | Train Loss: 0.0074 Acc: 0.9959\n",
      "Epoch 6/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0300 Acc: 0.9918\n",
      "Epoch 9/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0298 Acc: 0.9959\n",
      "Epoch 16/20 | Train Loss: 0.0026 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0023 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0711 Acc: 0.9748\n",
      "Epoch 2/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 7.2min\n",
      "Epoch 1/20 | Train Loss: 0.0639 Acc: 0.9686\n",
      "Epoch 2/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0049 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 8.0min\n",
      "Epoch 1/20 | Train Loss: 0.0472 Acc: 0.9829\n",
      "Epoch 2/20 | Train Loss: 0.0059 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Fold 4 Test Accuracy: 0.5000\n",
      "===== Fold 5 =====\n",
      "Epoch 1: Generator Loss = 9.9033, Discriminator Loss = 9.1334\n",
      "Epoch 2: Generator Loss = 11.9920, Discriminator Loss = 7.1812\n",
      "Epoch 3: Generator Loss = 18.8067, Discriminator Loss = 4.4285\n",
      "Epoch 4: Generator Loss = 25.0206, Discriminator Loss = 4.2261\n",
      "Epoch 5: Generator Loss = 27.6861, Discriminator Loss = 5.4118\n",
      "Epoch 6: Generator Loss = 31.2059, Discriminator Loss = 5.0021\n",
      "Epoch 7: Generator Loss = 30.9536, Discriminator Loss = 5.8997\n",
      "Epoch 8: Generator Loss = 25.6028, Discriminator Loss = 6.1983\n",
      "Epoch 9: Generator Loss = 29.2626, Discriminator Loss = 4.7319\n",
      "Epoch 10: Generator Loss = 22.9728, Discriminator Loss = 7.2367\n",
      "Epoch 11: Generator Loss = 28.7586, Discriminator Loss = 6.9671\n",
      "Epoch 12: Generator Loss = 20.6171, Discriminator Loss = 8.7009\n",
      "Epoch 13: Generator Loss = 27.4564, Discriminator Loss = 9.1111\n",
      "Epoch 14: Generator Loss = 19.7821, Discriminator Loss = 9.2643\n",
      "Epoch 15: Generator Loss = 19.9317, Discriminator Loss = 8.1688\n",
      "Epoch 16: Generator Loss = 18.0412, Discriminator Loss = 8.2185\n",
      "Epoch 17: Generator Loss = 17.9607, Discriminator Loss = 8.9202\n",
      "Epoch 18: Generator Loss = 17.1066, Discriminator Loss = 9.1775\n",
      "Epoch 19: Generator Loss = 17.7459, Discriminator Loss = 8.0646\n",
      "Epoch 20: Generator Loss = 15.6370, Discriminator Loss = 9.0266\n",
      "Epoch 21: Generator Loss = 15.0526, Discriminator Loss = 9.0925\n",
      "Epoch 22: Generator Loss = 14.3170, Discriminator Loss = 8.4282\n",
      "Epoch 23: Generator Loss = 16.5441, Discriminator Loss = 8.4761\n",
      "Epoch 24: Generator Loss = 15.2635, Discriminator Loss = 9.1697\n",
      "Epoch 25: Generator Loss = 17.5727, Discriminator Loss = 8.7672\n",
      "Epoch 26: Generator Loss = 17.3291, Discriminator Loss = 8.0435\n",
      "Epoch 27: Generator Loss = 14.9230, Discriminator Loss = 9.0455\n",
      "Epoch 28: Generator Loss = 19.3960, Discriminator Loss = 7.8995\n",
      "Epoch 29: Generator Loss = 17.6686, Discriminator Loss = 7.7799\n",
      "Epoch 30: Generator Loss = 19.2270, Discriminator Loss = 7.4647\n",
      "Epoch 31: Generator Loss = 18.5100, Discriminator Loss = 6.5787\n",
      "Epoch 32: Generator Loss = 20.1639, Discriminator Loss = 8.0958\n",
      "Epoch 33: Generator Loss = 20.1228, Discriminator Loss = 8.5324\n",
      "Epoch 34: Generator Loss = 18.3367, Discriminator Loss = 9.5347\n",
      "Epoch 35: Generator Loss = 15.8003, Discriminator Loss = 9.2309\n",
      "Epoch 36: Generator Loss = 18.9963, Discriminator Loss = 8.0653\n",
      "Epoch 37: Generator Loss = 18.0014, Discriminator Loss = 8.0153\n",
      "Epoch 38: Generator Loss = 16.3640, Discriminator Loss = 8.9224\n",
      "Epoch 39: Generator Loss = 19.0597, Discriminator Loss = 7.5373\n",
      "Epoch 40: Generator Loss = 20.1674, Discriminator Loss = 6.8137\n",
      "Epoch 41: Generator Loss = 22.9695, Discriminator Loss = 6.9342\n",
      "Epoch 42: Generator Loss = 22.6456, Discriminator Loss = 11.3760\n",
      "Epoch 43: Generator Loss = 17.0920, Discriminator Loss = 9.6930\n",
      "Epoch 44: Generator Loss = 15.0047, Discriminator Loss = 8.7581\n",
      "Epoch 45: Generator Loss = 17.0947, Discriminator Loss = 8.3186\n",
      "Epoch 46: Generator Loss = 13.1041, Discriminator Loss = 8.0744\n",
      "Epoch 47: Generator Loss = 15.9803, Discriminator Loss = 7.0756\n",
      "Epoch 48: Generator Loss = 20.2139, Discriminator Loss = 8.9659\n",
      "Epoch 49: Generator Loss = 16.8986, Discriminator Loss = 7.1744\n",
      "Epoch 50: Generator Loss = 17.9103, Discriminator Loss = 7.6197\n",
      "Epoch 51: Generator Loss = 15.2300, Discriminator Loss = 7.4177\n",
      "Epoch 52: Generator Loss = 18.7350, Discriminator Loss = 6.7274\n",
      "Epoch 53: Generator Loss = 20.8376, Discriminator Loss = 6.8806\n",
      "Epoch 54: Generator Loss = 22.2897, Discriminator Loss = 5.7301\n",
      "Epoch 55: Generator Loss = 22.7352, Discriminator Loss = 8.3672\n",
      "Epoch 56: Generator Loss = 24.1664, Discriminator Loss = 6.5924\n",
      "Epoch 57: Generator Loss = 26.1404, Discriminator Loss = 4.3743\n",
      "Epoch 58: Generator Loss = 22.7789, Discriminator Loss = 7.1651\n",
      "Epoch 59: Generator Loss = 29.2355, Discriminator Loss = 6.9154\n",
      "Epoch 60: Generator Loss = 44.5079, Discriminator Loss = 2.4640\n",
      "Epoch 61: Generator Loss = 32.5680, Discriminator Loss = 3.7678\n",
      "Epoch 62: Generator Loss = 34.6144, Discriminator Loss = 4.2323\n",
      "Epoch 63: Generator Loss = 27.4551, Discriminator Loss = 7.6604\n",
      "Epoch 64: Generator Loss = 25.2329, Discriminator Loss = 6.2626\n",
      "Epoch 65: Generator Loss = 26.0021, Discriminator Loss = 6.1605\n",
      "Epoch 66: Generator Loss = 36.2885, Discriminator Loss = 2.8789\n",
      "Epoch 67: Generator Loss = 34.7869, Discriminator Loss = 4.0236\n",
      "Epoch 68: Generator Loss = 53.3030, Discriminator Loss = 7.7129\n",
      "Epoch 69: Generator Loss = 27.2862, Discriminator Loss = 5.9223\n",
      "Epoch 70: Generator Loss = 33.6028, Discriminator Loss = 3.7405\n",
      "Epoch 71: Generator Loss = 34.9193, Discriminator Loss = 3.5483\n",
      "Epoch 72: Generator Loss = 30.7732, Discriminator Loss = 5.8837\n",
      "Epoch 73: Generator Loss = 29.6436, Discriminator Loss = 3.8875\n",
      "Epoch 74: Generator Loss = 37.9380, Discriminator Loss = 5.7201\n",
      "Epoch 75: Generator Loss = 28.3967, Discriminator Loss = 5.0306\n",
      "Epoch 76: Generator Loss = 32.3727, Discriminator Loss = 3.6135\n",
      "Epoch 77: Generator Loss = 35.9800, Discriminator Loss = 3.0750\n",
      "Epoch 78: Generator Loss = 32.6474, Discriminator Loss = 5.9863\n",
      "Epoch 79: Generator Loss = 40.1157, Discriminator Loss = 2.3478\n",
      "Epoch 80: Generator Loss = 36.1656, Discriminator Loss = 3.2176\n",
      "Epoch 81: Generator Loss = 42.0804, Discriminator Loss = 2.8578\n",
      "Epoch 82: Generator Loss = 49.8827, Discriminator Loss = 1.8999\n",
      "Epoch 83: Generator Loss = 45.0086, Discriminator Loss = 2.7586\n",
      "Epoch 84: Generator Loss = 45.8043, Discriminator Loss = 2.1120\n",
      "Epoch 85: Generator Loss = 49.2863, Discriminator Loss = 2.2891\n",
      "Epoch 86: Generator Loss = 50.5480, Discriminator Loss = 1.3867\n",
      "Epoch 87: Generator Loss = 44.0873, Discriminator Loss = 5.3232\n",
      "Epoch 88: Generator Loss = 50.7361, Discriminator Loss = 2.7905\n",
      "Epoch 89: Generator Loss = 53.0981, Discriminator Loss = 4.3786\n",
      "Epoch 90: Generator Loss = 56.8806, Discriminator Loss = 1.9026\n",
      "Epoch 91: Generator Loss = 49.1641, Discriminator Loss = 1.3394\n",
      "Epoch 92: Generator Loss = 51.8326, Discriminator Loss = 3.0619\n",
      "Epoch 93: Generator Loss = 48.2251, Discriminator Loss = 1.6679\n",
      "Epoch 94: Generator Loss = 58.9919, Discriminator Loss = 1.2836\n",
      "Epoch 95: Generator Loss = 61.5902, Discriminator Loss = 1.2010\n",
      "Epoch 96: Generator Loss = 70.9261, Discriminator Loss = 1.0277\n",
      "Epoch 97: Generator Loss = 66.5582, Discriminator Loss = 0.9400\n",
      "Epoch 98: Generator Loss = 63.4465, Discriminator Loss = 1.2551\n",
      "Epoch 99: Generator Loss = 69.8697, Discriminator Loss = 1.6793\n",
      "Epoch 100: Generator Loss = 52.0396, Discriminator Loss = 1.5072\n",
      "Epoch 101: Generator Loss = 67.1263, Discriminator Loss = 0.8712\n",
      "Epoch 102: Generator Loss = 60.5058, Discriminator Loss = 7.3212\n",
      "Epoch 103: Generator Loss = 47.9882, Discriminator Loss = 3.3880\n",
      "Epoch 104: Generator Loss = 50.7960, Discriminator Loss = 1.3561\n",
      "Epoch 105: Generator Loss = 67.1528, Discriminator Loss = 1.6165\n",
      "Epoch 106: Generator Loss = 61.9058, Discriminator Loss = 0.8807\n",
      "Epoch 107: Generator Loss = 68.6654, Discriminator Loss = 0.8565\n",
      "Epoch 108: Generator Loss = 70.3523, Discriminator Loss = 1.1933\n",
      "Epoch 109: Generator Loss = 58.2603, Discriminator Loss = 0.6514\n",
      "Epoch 110: Generator Loss = 65.7858, Discriminator Loss = 0.4226\n",
      "Epoch 111: Generator Loss = 75.2385, Discriminator Loss = 0.6800\n",
      "Epoch 112: Generator Loss = 62.8081, Discriminator Loss = 0.7482\n",
      "Epoch 113: Generator Loss = 75.7373, Discriminator Loss = 0.8032\n",
      "Epoch 114: Generator Loss = 66.0052, Discriminator Loss = 0.9131\n",
      "Epoch 115: Generator Loss = 58.6254, Discriminator Loss = 0.5142\n",
      "Epoch 116: Generator Loss = 83.6180, Discriminator Loss = 0.8603\n",
      "Epoch 117: Generator Loss = 74.1010, Discriminator Loss = 1.2914\n",
      "Epoch 118: Generator Loss = 72.3329, Discriminator Loss = 0.9961\n",
      "Epoch 119: Generator Loss = 72.7214, Discriminator Loss = 1.2876\n",
      "Epoch 120: Generator Loss = 75.0408, Discriminator Loss = 1.1819\n",
      "Epoch 121: Generator Loss = 59.3328, Discriminator Loss = 10.1309\n",
      "Epoch 122: Generator Loss = 56.5602, Discriminator Loss = 2.5223\n",
      "Epoch 123: Generator Loss = 64.2169, Discriminator Loss = 1.4260\n",
      "Epoch 124: Generator Loss = 61.3183, Discriminator Loss = 1.6526\n",
      "Epoch 125: Generator Loss = 54.8503, Discriminator Loss = 1.2485\n",
      "Epoch 126: Generator Loss = 78.0415, Discriminator Loss = 0.9557\n",
      "Epoch 127: Generator Loss = 61.8984, Discriminator Loss = 1.4945\n",
      "Epoch 128: Generator Loss = 63.6918, Discriminator Loss = 0.9145\n",
      "Epoch 129: Generator Loss = 75.2598, Discriminator Loss = 0.6192\n",
      "Epoch 130: Generator Loss = 82.6704, Discriminator Loss = 0.8473\n",
      "Epoch 131: Generator Loss = 80.3432, Discriminator Loss = 0.8426\n",
      "Epoch 132: Generator Loss = 68.1807, Discriminator Loss = 1.5339\n",
      "Epoch 133: Generator Loss = 72.9372, Discriminator Loss = 0.8428\n",
      "Epoch 134: Generator Loss = 89.8427, Discriminator Loss = 1.1201\n",
      "Epoch 135: Generator Loss = 79.9249, Discriminator Loss = 1.7650\n",
      "Epoch 136: Generator Loss = 68.4596, Discriminator Loss = 9.7051\n",
      "Epoch 137: Generator Loss = 68.2008, Discriminator Loss = 7.9253\n",
      "Epoch 138: Generator Loss = 55.0145, Discriminator Loss = 1.7015\n",
      "Epoch 139: Generator Loss = 57.3995, Discriminator Loss = 1.3555\n",
      "Epoch 140: Generator Loss = 62.1770, Discriminator Loss = 1.6038\n",
      "Epoch 141: Generator Loss = 58.3989, Discriminator Loss = 0.7568\n",
      "Epoch 142: Generator Loss = 60.7786, Discriminator Loss = 1.0637\n",
      "Epoch 143: Generator Loss = 66.0622, Discriminator Loss = 0.8654\n",
      "Epoch 144: Generator Loss = 57.4583, Discriminator Loss = 3.7961\n",
      "Epoch 145: Generator Loss = 69.6450, Discriminator Loss = 1.2684\n",
      "Epoch 146: Generator Loss = 73.7343, Discriminator Loss = 0.8754\n",
      "Epoch 147: Generator Loss = 64.4360, Discriminator Loss = 0.7089\n",
      "Epoch 148: Generator Loss = 57.3806, Discriminator Loss = 1.6355\n",
      "Epoch 149: Generator Loss = 65.1153, Discriminator Loss = 0.7734\n",
      "Epoch 150: Generator Loss = 67.2646, Discriminator Loss = 0.7660\n",
      "Epoch 151: Generator Loss = 71.9011, Discriminator Loss = 0.5204\n",
      "Epoch 152: Generator Loss = 76.9552, Discriminator Loss = 2.1177\n",
      "Epoch 153: Generator Loss = 69.3387, Discriminator Loss = 0.7172\n",
      "Epoch 154: Generator Loss = 64.8497, Discriminator Loss = 1.7072\n",
      "Epoch 155: Generator Loss = 55.9700, Discriminator Loss = 1.0713\n",
      "Epoch 156: Generator Loss = 59.4582, Discriminator Loss = 0.6258\n",
      "Epoch 157: Generator Loss = 83.8067, Discriminator Loss = 0.5855\n",
      "Epoch 158: Generator Loss = 77.7376, Discriminator Loss = 0.7646\n",
      "Epoch 159: Generator Loss = 82.7123, Discriminator Loss = 3.7861\n",
      "Epoch 160: Generator Loss = 70.6119, Discriminator Loss = 2.2878\n",
      "Epoch 161: Generator Loss = 67.4539, Discriminator Loss = 2.0479\n",
      "Epoch 162: Generator Loss = 67.8818, Discriminator Loss = 0.9102\n",
      "Epoch 163: Generator Loss = 70.7346, Discriminator Loss = 0.8759\n",
      "Epoch 164: Generator Loss = 60.2358, Discriminator Loss = 0.8639\n",
      "Epoch 165: Generator Loss = 65.0439, Discriminator Loss = 3.8402\n",
      "Epoch 166: Generator Loss = 80.2749, Discriminator Loss = 1.7736\n",
      "Epoch 167: Generator Loss = 71.6041, Discriminator Loss = 0.8227\n",
      "Epoch 168: Generator Loss = 72.2499, Discriminator Loss = 1.0625\n",
      "Epoch 169: Generator Loss = 79.3064, Discriminator Loss = 1.6083\n",
      "Epoch 170: Generator Loss = 66.2582, Discriminator Loss = 2.3143\n",
      "Epoch 171: Generator Loss = 85.0914, Discriminator Loss = 3.5850\n",
      "Epoch 172: Generator Loss = 66.1908, Discriminator Loss = 1.8026\n",
      "Epoch 173: Generator Loss = 82.8404, Discriminator Loss = 1.1081\n",
      "Epoch 174: Generator Loss = 75.8662, Discriminator Loss = 1.4987\n",
      "Epoch 175: Generator Loss = 71.6893, Discriminator Loss = 0.6014\n",
      "Epoch 176: Generator Loss = 75.4595, Discriminator Loss = 2.4102\n",
      "Epoch 177: Generator Loss = 75.5040, Discriminator Loss = 1.3361\n",
      "Epoch 178: Generator Loss = 69.0128, Discriminator Loss = 0.9149\n",
      "Epoch 179: Generator Loss = 77.9836, Discriminator Loss = 1.1505\n",
      "Epoch 180: Generator Loss = 79.3438, Discriminator Loss = 2.2770\n",
      "Epoch 181: Generator Loss = 61.5746, Discriminator Loss = 1.4563\n",
      "Epoch 182: Generator Loss = 74.7945, Discriminator Loss = 0.4864\n",
      "Epoch 183: Generator Loss = 67.7348, Discriminator Loss = 0.8361\n",
      "Epoch 184: Generator Loss = 81.5936, Discriminator Loss = 0.4434\n",
      "Epoch 185: Generator Loss = 75.5838, Discriminator Loss = 0.6943\n",
      "Epoch 186: Generator Loss = 69.6691, Discriminator Loss = 0.6450\n",
      "Epoch 187: Generator Loss = 65.0884, Discriminator Loss = 1.5489\n",
      "Epoch 188: Generator Loss = 76.5124, Discriminator Loss = 2.3823\n",
      "Epoch 189: Generator Loss = 76.5381, Discriminator Loss = 2.9656\n",
      "Epoch 190: Generator Loss = 82.3883, Discriminator Loss = 3.5229\n",
      "Epoch 191: Generator Loss = 60.9276, Discriminator Loss = 8.4385\n",
      "Epoch 192: Generator Loss = 61.2169, Discriminator Loss = 3.0406\n",
      "Epoch 193: Generator Loss = 54.2826, Discriminator Loss = 2.4501\n",
      "Epoch 194: Generator Loss = 67.2528, Discriminator Loss = 1.4440\n",
      "Epoch 195: Generator Loss = 56.7301, Discriminator Loss = 1.9819\n",
      "Epoch 196: Generator Loss = 55.8418, Discriminator Loss = 8.6312\n",
      "Epoch 197: Generator Loss = 54.5248, Discriminator Loss = 2.6979\n",
      "Epoch 198: Generator Loss = 56.6727, Discriminator Loss = 1.7482\n",
      "Epoch 199: Generator Loss = 72.1432, Discriminator Loss = 3.4984\n",
      "Epoch 200: Generator Loss = 57.2802, Discriminator Loss = 1.5104\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/20 | Train Loss: 0.0679 Acc: 0.9797\n",
      "Epoch 2/20 | Train Loss: 0.0074 Acc: 0.9959\n",
      "Epoch 3/20 | Train Loss: 0.0024 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.5min\n",
      "Epoch 1/20 | Train Loss: 0.0515 Acc: 0.9837\n",
      "Epoch 2/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0603 Acc: 0.9919\n",
      "Epoch 5/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0136 Acc: 0.9959\n",
      "Epoch 7/20 | Train Loss: 0.0023 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0025 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.5min\n",
      "Epoch 1/20 | Train Loss: 0.0662 Acc: 0.9837\n",
      "Epoch 2/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0047 Acc: 0.9959\n",
      "Epoch 7/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0537 Acc: 0.9959\n",
      "Epoch 11/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0039 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0029 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.5min\n",
      "Epoch 1/20 | Train Loss: 0.0534 Acc: 0.9780\n",
      "Epoch 2/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0024 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 7.1min\n",
      "Epoch 1/20 | Train Loss: 0.0441 Acc: 0.9886\n",
      "Epoch 2/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0000 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 7.9min\n",
      "Epoch 1/20 | Train Loss: 0.0629 Acc: 0.9797\n",
      "Epoch 2/20 | Train Loss: 0.0158 Acc: 0.9919\n",
      "Epoch 3/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0037 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.1248 Acc: 0.9309\n",
      "Epoch 2/20 | Train Loss: 0.0023 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0054 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0063 Acc: 0.9959\n",
      "Epoch 12/20 | Train Loss: 0.0146 Acc: 0.9959\n",
      "Epoch 13/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0927 Acc: 0.9553\n",
      "Epoch 2/20 | Train Loss: 0.0022 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0031 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0376 Acc: 0.9878\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.5min\n",
      "Epoch 1/20 | Train Loss: 0.0409 Acc: 0.9874\n",
      "Epoch 2/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0044 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 7.2min\n",
      "Epoch 1/20 | Train Loss: 0.0582 Acc: 0.9631\n",
      "Epoch 2/20 | Train Loss: 0.0038 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 8.0min\n",
      "Epoch 1/20 | Train Loss: 0.0591 Acc: 0.9716\n",
      "Epoch 2/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0088 Acc: 0.9972\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Fold 5 Test Accuracy: 0.5000\n",
      "===== Fold 6 =====\n",
      "Epoch 1: Generator Loss = 10.1054, Discriminator Loss = 9.1234\n",
      "Epoch 2: Generator Loss = 10.4545, Discriminator Loss = 9.1520\n",
      "Epoch 3: Generator Loss = 13.5146, Discriminator Loss = 7.2239\n",
      "Epoch 4: Generator Loss = 18.0827, Discriminator Loss = 4.9181\n",
      "Epoch 5: Generator Loss = 27.7016, Discriminator Loss = 4.4536\n",
      "Epoch 6: Generator Loss = 28.6086, Discriminator Loss = 4.2824\n",
      "Epoch 7: Generator Loss = 28.1890, Discriminator Loss = 6.3184\n",
      "Epoch 8: Generator Loss = 27.4859, Discriminator Loss = 6.0542\n",
      "Epoch 9: Generator Loss = 24.9474, Discriminator Loss = 4.9410\n",
      "Epoch 10: Generator Loss = 33.6189, Discriminator Loss = 4.9013\n",
      "Epoch 11: Generator Loss = 30.5807, Discriminator Loss = 8.4007\n",
      "Epoch 12: Generator Loss = 24.4019, Discriminator Loss = 8.6460\n",
      "Epoch 13: Generator Loss = 24.6600, Discriminator Loss = 6.0356\n",
      "Epoch 14: Generator Loss = 26.6201, Discriminator Loss = 6.0357\n",
      "Epoch 15: Generator Loss = 30.1288, Discriminator Loss = 6.2029\n",
      "Epoch 16: Generator Loss = 27.6670, Discriminator Loss = 8.9878\n",
      "Epoch 17: Generator Loss = 21.1188, Discriminator Loss = 7.5364\n",
      "Epoch 18: Generator Loss = 24.0840, Discriminator Loss = 8.0972\n",
      "Epoch 19: Generator Loss = 17.9817, Discriminator Loss = 7.3359\n",
      "Epoch 20: Generator Loss = 25.1723, Discriminator Loss = 9.0718\n",
      "Epoch 21: Generator Loss = 19.2070, Discriminator Loss = 8.0181\n",
      "Epoch 22: Generator Loss = 19.4425, Discriminator Loss = 7.2340\n",
      "Epoch 23: Generator Loss = 24.1250, Discriminator Loss = 8.6725\n",
      "Epoch 24: Generator Loss = 22.7427, Discriminator Loss = 7.0511\n",
      "Epoch 25: Generator Loss = 21.3103, Discriminator Loss = 6.2620\n",
      "Epoch 26: Generator Loss = 25.0749, Discriminator Loss = 5.3729\n",
      "Epoch 27: Generator Loss = 23.7853, Discriminator Loss = 6.7767\n",
      "Epoch 28: Generator Loss = 42.0372, Discriminator Loss = 7.4599\n",
      "Epoch 29: Generator Loss = 40.6897, Discriminator Loss = 5.8423\n",
      "Epoch 30: Generator Loss = 31.1267, Discriminator Loss = 6.0558\n",
      "Epoch 31: Generator Loss = 29.9273, Discriminator Loss = 5.6458\n",
      "Epoch 32: Generator Loss = 24.4917, Discriminator Loss = 9.3705\n",
      "Epoch 33: Generator Loss = 18.6987, Discriminator Loss = 7.1859\n",
      "Epoch 34: Generator Loss = 22.4789, Discriminator Loss = 7.6710\n",
      "Epoch 35: Generator Loss = 25.7316, Discriminator Loss = 7.4003\n",
      "Epoch 36: Generator Loss = 16.3201, Discriminator Loss = 9.8408\n",
      "Epoch 37: Generator Loss = 18.8397, Discriminator Loss = 6.9544\n",
      "Epoch 38: Generator Loss = 26.4550, Discriminator Loss = 7.0950\n",
      "Epoch 39: Generator Loss = 21.5860, Discriminator Loss = 6.5074\n",
      "Epoch 40: Generator Loss = 23.4906, Discriminator Loss = 9.1311\n",
      "Epoch 41: Generator Loss = 21.3040, Discriminator Loss = 7.2159\n",
      "Epoch 42: Generator Loss = 23.3658, Discriminator Loss = 7.2265\n",
      "Epoch 43: Generator Loss = 22.1423, Discriminator Loss = 7.1105\n",
      "Epoch 44: Generator Loss = 20.0566, Discriminator Loss = 6.1892\n",
      "Epoch 45: Generator Loss = 18.9675, Discriminator Loss = 7.9631\n",
      "Epoch 46: Generator Loss = 21.8605, Discriminator Loss = 6.2722\n",
      "Epoch 47: Generator Loss = 23.3558, Discriminator Loss = 8.4410\n",
      "Epoch 48: Generator Loss = 17.0613, Discriminator Loss = 8.2481\n",
      "Epoch 49: Generator Loss = 26.4654, Discriminator Loss = 5.4808\n",
      "Epoch 50: Generator Loss = 18.3445, Discriminator Loss = 8.8648\n",
      "Epoch 51: Generator Loss = 20.9048, Discriminator Loss = 6.9824\n",
      "Epoch 52: Generator Loss = 15.9132, Discriminator Loss = 7.8346\n",
      "Epoch 53: Generator Loss = 18.5079, Discriminator Loss = 7.6432\n",
      "Epoch 54: Generator Loss = 24.0153, Discriminator Loss = 8.2446\n",
      "Epoch 55: Generator Loss = 26.1773, Discriminator Loss = 6.4626\n",
      "Epoch 56: Generator Loss = 25.3338, Discriminator Loss = 5.7882\n",
      "Epoch 57: Generator Loss = 20.4964, Discriminator Loss = 5.3239\n",
      "Epoch 58: Generator Loss = 22.3417, Discriminator Loss = 7.8888\n",
      "Epoch 59: Generator Loss = 25.1117, Discriminator Loss = 5.6524\n",
      "Epoch 60: Generator Loss = 26.1955, Discriminator Loss = 5.3425\n",
      "Epoch 61: Generator Loss = 19.4311, Discriminator Loss = 7.2845\n",
      "Epoch 62: Generator Loss = 25.4988, Discriminator Loss = 6.0175\n",
      "Epoch 63: Generator Loss = 28.5300, Discriminator Loss = 6.5582\n",
      "Epoch 64: Generator Loss = 30.5722, Discriminator Loss = 3.8671\n",
      "Epoch 65: Generator Loss = 33.2426, Discriminator Loss = 3.8018\n",
      "Epoch 66: Generator Loss = 31.9779, Discriminator Loss = 5.1417\n",
      "Epoch 67: Generator Loss = 27.5941, Discriminator Loss = 4.5417\n",
      "Epoch 68: Generator Loss = 43.4749, Discriminator Loss = 2.3112\n",
      "Epoch 69: Generator Loss = 35.4823, Discriminator Loss = 6.2337\n",
      "Epoch 70: Generator Loss = 45.8384, Discriminator Loss = 2.9729\n",
      "Epoch 71: Generator Loss = 42.2268, Discriminator Loss = 8.5005\n",
      "Epoch 72: Generator Loss = 25.1352, Discriminator Loss = 7.6805\n",
      "Epoch 73: Generator Loss = 27.4293, Discriminator Loss = 5.5241\n",
      "Epoch 74: Generator Loss = 32.2351, Discriminator Loss = 6.5211\n",
      "Epoch 75: Generator Loss = 36.0912, Discriminator Loss = 2.8121\n",
      "Epoch 76: Generator Loss = 43.5084, Discriminator Loss = 2.8662\n",
      "Epoch 77: Generator Loss = 43.7056, Discriminator Loss = 5.0170\n",
      "Epoch 78: Generator Loss = 29.9090, Discriminator Loss = 4.4072\n",
      "Epoch 79: Generator Loss = 40.0973, Discriminator Loss = 3.8904\n",
      "Epoch 80: Generator Loss = 44.3454, Discriminator Loss = 2.5404\n",
      "Epoch 81: Generator Loss = 43.8304, Discriminator Loss = 2.2633\n",
      "Epoch 82: Generator Loss = 35.0535, Discriminator Loss = 3.5755\n",
      "Epoch 83: Generator Loss = 40.1835, Discriminator Loss = 2.6978\n",
      "Epoch 84: Generator Loss = 54.6964, Discriminator Loss = 1.8972\n",
      "Epoch 85: Generator Loss = 48.6145, Discriminator Loss = 2.9770\n",
      "Epoch 86: Generator Loss = 36.6451, Discriminator Loss = 3.3419\n",
      "Epoch 87: Generator Loss = 41.7118, Discriminator Loss = 4.3573\n",
      "Epoch 88: Generator Loss = 52.1729, Discriminator Loss = 2.5270\n",
      "Epoch 89: Generator Loss = 38.5965, Discriminator Loss = 2.7701\n",
      "Epoch 90: Generator Loss = 47.9253, Discriminator Loss = 2.7493\n",
      "Epoch 91: Generator Loss = 42.9373, Discriminator Loss = 4.0943\n",
      "Epoch 92: Generator Loss = 67.7003, Discriminator Loss = 1.7205\n",
      "Epoch 93: Generator Loss = 47.4091, Discriminator Loss = 2.6499\n",
      "Epoch 94: Generator Loss = 57.0903, Discriminator Loss = 1.2313\n",
      "Epoch 95: Generator Loss = 56.8544, Discriminator Loss = 4.7323\n",
      "Epoch 96: Generator Loss = 47.8791, Discriminator Loss = 2.6489\n",
      "Epoch 97: Generator Loss = 61.5355, Discriminator Loss = 1.8469\n",
      "Epoch 98: Generator Loss = 54.5320, Discriminator Loss = 1.3457\n",
      "Epoch 99: Generator Loss = 55.5453, Discriminator Loss = 1.6187\n",
      "Epoch 100: Generator Loss = 83.3397, Discriminator Loss = 0.7284\n",
      "Epoch 101: Generator Loss = 74.3899, Discriminator Loss = 0.7172\n",
      "Epoch 102: Generator Loss = 65.6905, Discriminator Loss = 1.6127\n",
      "Epoch 103: Generator Loss = 60.2434, Discriminator Loss = 1.1424\n",
      "Epoch 104: Generator Loss = 73.2770, Discriminator Loss = 1.3290\n",
      "Epoch 105: Generator Loss = 51.4613, Discriminator Loss = 1.0777\n",
      "Epoch 106: Generator Loss = 69.9909, Discriminator Loss = 1.7423\n",
      "Epoch 107: Generator Loss = 63.6709, Discriminator Loss = 2.0289\n",
      "Epoch 108: Generator Loss = 64.1938, Discriminator Loss = 1.4274\n",
      "Epoch 109: Generator Loss = 55.3025, Discriminator Loss = 5.4194\n",
      "Epoch 110: Generator Loss = 51.1586, Discriminator Loss = 2.8007\n",
      "Epoch 111: Generator Loss = 50.6653, Discriminator Loss = 1.6378\n",
      "Epoch 112: Generator Loss = 64.2921, Discriminator Loss = 1.0379\n",
      "Epoch 113: Generator Loss = 71.5173, Discriminator Loss = 0.7658\n",
      "Epoch 114: Generator Loss = 58.6788, Discriminator Loss = 1.3675\n",
      "Epoch 115: Generator Loss = 76.9498, Discriminator Loss = 0.9010\n",
      "Epoch 116: Generator Loss = 64.9390, Discriminator Loss = 1.3956\n",
      "Epoch 117: Generator Loss = 78.1123, Discriminator Loss = 2.6467\n",
      "Epoch 118: Generator Loss = 75.2324, Discriminator Loss = 4.7564\n",
      "Epoch 119: Generator Loss = 76.7485, Discriminator Loss = 2.5331\n",
      "Epoch 120: Generator Loss = 64.7115, Discriminator Loss = 0.8764\n",
      "Epoch 121: Generator Loss = 66.0085, Discriminator Loss = 1.6631\n",
      "Epoch 122: Generator Loss = 64.1533, Discriminator Loss = 0.9065\n",
      "Epoch 123: Generator Loss = 70.1934, Discriminator Loss = 0.6621\n",
      "Epoch 124: Generator Loss = 82.5279, Discriminator Loss = 1.0224\n",
      "Epoch 125: Generator Loss = 82.5673, Discriminator Loss = 1.9072\n",
      "Epoch 126: Generator Loss = 66.3229, Discriminator Loss = 0.8485\n",
      "Epoch 127: Generator Loss = 62.7278, Discriminator Loss = 0.5536\n",
      "Epoch 128: Generator Loss = 76.1990, Discriminator Loss = 0.9776\n",
      "Epoch 129: Generator Loss = 77.3675, Discriminator Loss = 0.4738\n",
      "Epoch 130: Generator Loss = 72.2621, Discriminator Loss = 1.0902\n",
      "Epoch 131: Generator Loss = 78.9728, Discriminator Loss = 0.3290\n",
      "Epoch 132: Generator Loss = 89.1798, Discriminator Loss = 1.0514\n",
      "Epoch 133: Generator Loss = 71.3653, Discriminator Loss = 1.0185\n",
      "Epoch 134: Generator Loss = 82.6113, Discriminator Loss = 0.7451\n",
      "Epoch 135: Generator Loss = 72.5457, Discriminator Loss = 0.7249\n",
      "Epoch 136: Generator Loss = 73.0524, Discriminator Loss = 0.3799\n",
      "Epoch 137: Generator Loss = 74.2572, Discriminator Loss = 0.6419\n",
      "Epoch 138: Generator Loss = 100.2000, Discriminator Loss = 0.5576\n",
      "Epoch 139: Generator Loss = 75.9027, Discriminator Loss = 0.3163\n",
      "Epoch 140: Generator Loss = 73.8892, Discriminator Loss = 0.5819\n",
      "Epoch 141: Generator Loss = 79.8135, Discriminator Loss = 0.3986\n",
      "Epoch 142: Generator Loss = 77.9579, Discriminator Loss = 0.9072\n",
      "Epoch 143: Generator Loss = 69.0102, Discriminator Loss = 3.0933\n",
      "Epoch 144: Generator Loss = 71.4556, Discriminator Loss = 11.9610\n",
      "Epoch 145: Generator Loss = 58.0379, Discriminator Loss = 5.1238\n",
      "Epoch 146: Generator Loss = 58.6547, Discriminator Loss = 1.8547\n",
      "Epoch 147: Generator Loss = 68.5422, Discriminator Loss = 2.3446\n",
      "Epoch 148: Generator Loss = 67.1987, Discriminator Loss = 1.9698\n",
      "Epoch 149: Generator Loss = 53.9617, Discriminator Loss = 1.5505\n",
      "Epoch 150: Generator Loss = 75.3983, Discriminator Loss = 1.2020\n",
      "Epoch 151: Generator Loss = 66.6297, Discriminator Loss = 1.6514\n",
      "Epoch 152: Generator Loss = 79.9884, Discriminator Loss = 0.5606\n",
      "Epoch 153: Generator Loss = 71.1366, Discriminator Loss = 1.6469\n",
      "Epoch 154: Generator Loss = 79.5268, Discriminator Loss = 1.3618\n",
      "Epoch 155: Generator Loss = 70.3989, Discriminator Loss = 1.0005\n",
      "Epoch 156: Generator Loss = 86.3485, Discriminator Loss = 0.8168\n",
      "Epoch 157: Generator Loss = 93.2063, Discriminator Loss = 0.8000\n",
      "Epoch 158: Generator Loss = 76.4990, Discriminator Loss = 0.2788\n",
      "Epoch 159: Generator Loss = 75.5362, Discriminator Loss = 1.2948\n",
      "Epoch 160: Generator Loss = 56.7647, Discriminator Loss = 0.6465\n",
      "Epoch 161: Generator Loss = 75.8980, Discriminator Loss = 0.6993\n",
      "Epoch 162: Generator Loss = 81.0249, Discriminator Loss = 0.7488\n",
      "Epoch 163: Generator Loss = 89.7428, Discriminator Loss = 0.5578\n",
      "Epoch 164: Generator Loss = 90.4456, Discriminator Loss = 0.4208\n",
      "Epoch 165: Generator Loss = 67.0321, Discriminator Loss = 1.0573\n",
      "Epoch 166: Generator Loss = 93.2845, Discriminator Loss = 0.5504\n",
      "Epoch 167: Generator Loss = 77.7276, Discriminator Loss = 0.6458\n",
      "Epoch 168: Generator Loss = 79.7214, Discriminator Loss = 1.0515\n",
      "Epoch 169: Generator Loss = 81.4576, Discriminator Loss = 0.6642\n",
      "Epoch 170: Generator Loss = 80.0239, Discriminator Loss = 0.6692\n",
      "Epoch 171: Generator Loss = 70.7622, Discriminator Loss = 17.1504\n",
      "Epoch 172: Generator Loss = 32.5568, Discriminator Loss = 5.5201\n",
      "Epoch 173: Generator Loss = 34.3839, Discriminator Loss = 3.4202\n",
      "Epoch 174: Generator Loss = 47.2006, Discriminator Loss = 2.9445\n",
      "Epoch 175: Generator Loss = 54.8158, Discriminator Loss = 2.2935\n",
      "Epoch 176: Generator Loss = 55.9193, Discriminator Loss = 1.5268\n",
      "Epoch 177: Generator Loss = 71.5980, Discriminator Loss = 2.8311\n",
      "Epoch 178: Generator Loss = 62.1208, Discriminator Loss = 1.3433\n",
      "Epoch 179: Generator Loss = 44.6613, Discriminator Loss = 3.6028\n",
      "Epoch 180: Generator Loss = 58.4939, Discriminator Loss = 1.7967\n",
      "Epoch 181: Generator Loss = 52.9704, Discriminator Loss = 1.7216\n",
      "Epoch 182: Generator Loss = 67.1832, Discriminator Loss = 0.9781\n",
      "Epoch 183: Generator Loss = 61.6336, Discriminator Loss = 3.3099\n",
      "Epoch 184: Generator Loss = 61.4033, Discriminator Loss = 2.1303\n",
      "Epoch 185: Generator Loss = 58.9013, Discriminator Loss = 1.1654\n",
      "Epoch 186: Generator Loss = 67.8488, Discriminator Loss = 0.9176\n",
      "Epoch 187: Generator Loss = 78.4756, Discriminator Loss = 0.4230\n",
      "Epoch 188: Generator Loss = 92.9598, Discriminator Loss = 0.4899\n",
      "Epoch 189: Generator Loss = 88.5740, Discriminator Loss = 0.6980\n",
      "Epoch 190: Generator Loss = 68.7364, Discriminator Loss = 0.6075\n",
      "Epoch 191: Generator Loss = 73.8867, Discriminator Loss = 0.3707\n",
      "Epoch 192: Generator Loss = 85.3946, Discriminator Loss = 0.5517\n",
      "Epoch 193: Generator Loss = 73.2668, Discriminator Loss = 0.4652\n",
      "Epoch 194: Generator Loss = 70.3557, Discriminator Loss = 0.8729\n",
      "Epoch 195: Generator Loss = 82.8755, Discriminator Loss = 1.3498\n",
      "Epoch 196: Generator Loss = 74.5168, Discriminator Loss = 1.2037\n",
      "Epoch 197: Generator Loss = 70.6035, Discriminator Loss = 0.8777\n",
      "Epoch 198: Generator Loss = 77.2452, Discriminator Loss = 0.7459\n",
      "Epoch 199: Generator Loss = 87.0110, Discriminator Loss = 0.3142\n",
      "Epoch 200: Generator Loss = 76.8888, Discriminator Loss = 0.3867\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/20 | Train Loss: 0.0789 Acc: 0.9754\n",
      "Epoch 2/20 | Train Loss: 0.0033 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0076 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0376 Acc: 0.9836\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.8min\n",
      "Epoch 1/20 | Train Loss: 0.0909 Acc: 0.9508\n",
      "Epoch 2/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0062 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0200 Acc: 0.9918\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0155 Acc: 0.9918\n",
      "Epoch 16/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.8min\n",
      "Epoch 1/20 | Train Loss: 0.1076 Acc: 0.9634\n",
      "Epoch 2/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0133 Acc: 0.9959\n",
      "Epoch 4/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.8min\n",
      "Epoch 1/20 | Train Loss: 0.0818 Acc: 0.9557\n",
      "Epoch 2/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0024 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0172 Acc: 0.9937\n",
      "Epoch 12/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 7.4min\n",
      "Epoch 1/20 | Train Loss: 0.0703 Acc: 0.9771\n",
      "Epoch 2/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 8.2min\n",
      "Epoch 1/20 | Train Loss: 0.0835 Acc: 0.9631\n",
      "Epoch 2/20 | Train Loss: 0.0030 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0232 Acc: 0.9959\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.7min\n",
      "Epoch 1/20 | Train Loss: 0.0734 Acc: 0.9672\n",
      "Epoch 2/20 | Train Loss: 0.0021 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0025 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0043 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0191 Acc: 0.9877\n",
      "Epoch 6/20 | Train Loss: 0.0064 Acc: 0.9959\n",
      "Epoch 7/20 | Train Loss: 0.0292 Acc: 0.9918\n",
      "Epoch 8/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0045 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0032 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0025 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.8min\n",
      "Epoch 1/20 | Train Loss: 0.1156 Acc: 0.9472\n",
      "Epoch 2/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0024 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.8min\n",
      "Epoch 1/20 | Train Loss: 0.0662 Acc: 0.9652\n",
      "Epoch 2/20 | Train Loss: 0.0057 Acc: 0.9968\n",
      "Epoch 3/20 | Train Loss: 0.0020 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0030 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0027 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0227 Acc: 0.9873\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 7.5min\n",
      "Epoch 1/20 | Train Loss: 0.0583 Acc: 0.9771\n",
      "Epoch 2/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 8.3min\n",
      "Epoch 1/20 | Train Loss: 0.0558 Acc: 0.9800\n",
      "Epoch 2/20 | Train Loss: 0.0050 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Fold 6 Test Accuracy: 0.5000\n",
      "===== Fold 7 =====\n",
      "Epoch 1: Generator Loss = 10.0779, Discriminator Loss = 8.7760\n",
      "Epoch 2: Generator Loss = 10.6093, Discriminator Loss = 7.8969\n",
      "Epoch 3: Generator Loss = 13.4302, Discriminator Loss = 6.7760\n",
      "Epoch 4: Generator Loss = 17.7897, Discriminator Loss = 5.2076\n",
      "Epoch 5: Generator Loss = 23.6564, Discriminator Loss = 5.1010\n",
      "Epoch 6: Generator Loss = 25.6121, Discriminator Loss = 4.5631\n",
      "Epoch 7: Generator Loss = 31.2908, Discriminator Loss = 4.7897\n",
      "Epoch 8: Generator Loss = 28.1901, Discriminator Loss = 4.4153\n",
      "Epoch 9: Generator Loss = 32.2621, Discriminator Loss = 3.7237\n",
      "Epoch 10: Generator Loss = 34.9474, Discriminator Loss = 3.5591\n",
      "Epoch 11: Generator Loss = 37.9522, Discriminator Loss = 6.1203\n",
      "Epoch 12: Generator Loss = 30.1775, Discriminator Loss = 8.5956\n",
      "Epoch 13: Generator Loss = 24.6008, Discriminator Loss = 7.2370\n",
      "Epoch 14: Generator Loss = 29.6853, Discriminator Loss = 9.8703\n",
      "Epoch 15: Generator Loss = 18.1527, Discriminator Loss = 6.9427\n",
      "Epoch 16: Generator Loss = 33.5404, Discriminator Loss = 7.9324\n",
      "Epoch 17: Generator Loss = 35.8040, Discriminator Loss = 7.4732\n",
      "Epoch 18: Generator Loss = 20.3209, Discriminator Loss = 8.1332\n",
      "Epoch 19: Generator Loss = 20.2369, Discriminator Loss = 8.3280\n",
      "Epoch 20: Generator Loss = 22.0707, Discriminator Loss = 7.0007\n",
      "Epoch 21: Generator Loss = 16.4368, Discriminator Loss = 7.2612\n",
      "Epoch 22: Generator Loss = 21.6927, Discriminator Loss = 9.2344\n",
      "Epoch 23: Generator Loss = 19.0086, Discriminator Loss = 7.6012\n",
      "Epoch 24: Generator Loss = 21.3455, Discriminator Loss = 8.4630\n",
      "Epoch 25: Generator Loss = 20.0746, Discriminator Loss = 9.8331\n",
      "Epoch 26: Generator Loss = 18.2847, Discriminator Loss = 10.8388\n",
      "Epoch 27: Generator Loss = 14.2786, Discriminator Loss = 8.2133\n",
      "Epoch 28: Generator Loss = 14.3554, Discriminator Loss = 8.0152\n",
      "Epoch 29: Generator Loss = 14.3068, Discriminator Loss = 8.3963\n",
      "Epoch 30: Generator Loss = 19.1055, Discriminator Loss = 8.1671\n",
      "Epoch 31: Generator Loss = 17.6528, Discriminator Loss = 8.7247\n",
      "Epoch 32: Generator Loss = 15.8458, Discriminator Loss = 9.5431\n",
      "Epoch 33: Generator Loss = 15.6521, Discriminator Loss = 8.7539\n",
      "Epoch 34: Generator Loss = 16.8692, Discriminator Loss = 7.5359\n",
      "Epoch 35: Generator Loss = 16.0428, Discriminator Loss = 8.9260\n",
      "Epoch 36: Generator Loss = 19.0269, Discriminator Loss = 7.4838\n",
      "Epoch 37: Generator Loss = 19.7521, Discriminator Loss = 7.4103\n",
      "Epoch 38: Generator Loss = 20.4170, Discriminator Loss = 7.4968\n",
      "Epoch 39: Generator Loss = 21.3660, Discriminator Loss = 8.8988\n",
      "Epoch 40: Generator Loss = 16.2451, Discriminator Loss = 8.2674\n",
      "Epoch 41: Generator Loss = 17.2973, Discriminator Loss = 8.3084\n",
      "Epoch 42: Generator Loss = 15.2026, Discriminator Loss = 9.8003\n",
      "Epoch 43: Generator Loss = 15.5227, Discriminator Loss = 9.1308\n",
      "Epoch 44: Generator Loss = 16.5441, Discriminator Loss = 10.2011\n",
      "Epoch 45: Generator Loss = 13.0580, Discriminator Loss = 8.3646\n",
      "Epoch 46: Generator Loss = 13.3353, Discriminator Loss = 7.9118\n",
      "Epoch 47: Generator Loss = 15.9331, Discriminator Loss = 8.1551\n",
      "Epoch 48: Generator Loss = 19.7368, Discriminator Loss = 8.2282\n",
      "Epoch 49: Generator Loss = 26.1600, Discriminator Loss = 8.4364\n",
      "Epoch 50: Generator Loss = 20.5251, Discriminator Loss = 7.2390\n",
      "Epoch 51: Generator Loss = 18.5174, Discriminator Loss = 7.5346\n",
      "Epoch 52: Generator Loss = 19.1909, Discriminator Loss = 7.2951\n",
      "Epoch 53: Generator Loss = 19.8279, Discriminator Loss = 7.4584\n",
      "Epoch 54: Generator Loss = 19.9294, Discriminator Loss = 8.4598\n",
      "Epoch 55: Generator Loss = 18.3917, Discriminator Loss = 6.1113\n",
      "Epoch 56: Generator Loss = 26.2665, Discriminator Loss = 9.4887\n",
      "Epoch 57: Generator Loss = 20.4680, Discriminator Loss = 6.7552\n",
      "Epoch 58: Generator Loss = 19.4249, Discriminator Loss = 7.0544\n",
      "Epoch 59: Generator Loss = 21.0250, Discriminator Loss = 6.8767\n",
      "Epoch 60: Generator Loss = 18.4551, Discriminator Loss = 7.1855\n",
      "Epoch 61: Generator Loss = 24.1352, Discriminator Loss = 6.8868\n",
      "Epoch 62: Generator Loss = 21.9230, Discriminator Loss = 6.7550\n",
      "Epoch 63: Generator Loss = 23.8612, Discriminator Loss = 6.1489\n",
      "Epoch 64: Generator Loss = 22.3482, Discriminator Loss = 7.3020\n",
      "Epoch 65: Generator Loss = 21.0275, Discriminator Loss = 5.7913\n",
      "Epoch 66: Generator Loss = 38.9812, Discriminator Loss = 4.5896\n",
      "Epoch 67: Generator Loss = 24.5350, Discriminator Loss = 8.0318\n",
      "Epoch 68: Generator Loss = 27.0213, Discriminator Loss = 6.4241\n",
      "Epoch 69: Generator Loss = 26.9093, Discriminator Loss = 4.8843\n",
      "Epoch 70: Generator Loss = 27.9767, Discriminator Loss = 4.9389\n",
      "Epoch 71: Generator Loss = 31.8455, Discriminator Loss = 4.4949\n",
      "Epoch 72: Generator Loss = 30.9533, Discriminator Loss = 6.0287\n",
      "Epoch 73: Generator Loss = 26.4589, Discriminator Loss = 5.9100\n",
      "Epoch 74: Generator Loss = 27.5599, Discriminator Loss = 4.9752\n",
      "Epoch 75: Generator Loss = 32.4440, Discriminator Loss = 4.9562\n",
      "Epoch 76: Generator Loss = 30.6631, Discriminator Loss = 8.2910\n",
      "Epoch 77: Generator Loss = 17.9662, Discriminator Loss = 8.3111\n",
      "Epoch 78: Generator Loss = 24.6119, Discriminator Loss = 7.0317\n",
      "Epoch 79: Generator Loss = 29.2630, Discriminator Loss = 4.7095\n",
      "Epoch 80: Generator Loss = 32.0755, Discriminator Loss = 4.2828\n",
      "Epoch 81: Generator Loss = 29.6408, Discriminator Loss = 4.9171\n",
      "Epoch 82: Generator Loss = 33.6193, Discriminator Loss = 6.2043\n",
      "Epoch 83: Generator Loss = 30.8359, Discriminator Loss = 4.4549\n",
      "Epoch 84: Generator Loss = 39.1628, Discriminator Loss = 3.5691\n",
      "Epoch 85: Generator Loss = 31.2839, Discriminator Loss = 4.2655\n",
      "Epoch 86: Generator Loss = 39.7925, Discriminator Loss = 3.4446\n",
      "Epoch 87: Generator Loss = 39.4451, Discriminator Loss = 2.2204\n",
      "Epoch 88: Generator Loss = 38.1553, Discriminator Loss = 6.1141\n",
      "Epoch 89: Generator Loss = 30.3022, Discriminator Loss = 4.0155\n",
      "Epoch 90: Generator Loss = 53.2673, Discriminator Loss = 3.2143\n",
      "Epoch 91: Generator Loss = 32.3810, Discriminator Loss = 4.5952\n",
      "Epoch 92: Generator Loss = 33.2943, Discriminator Loss = 5.9116\n",
      "Epoch 93: Generator Loss = 26.3492, Discriminator Loss = 8.3998\n",
      "Epoch 94: Generator Loss = 36.2986, Discriminator Loss = 4.1973\n",
      "Epoch 95: Generator Loss = 33.9948, Discriminator Loss = 3.2257\n",
      "Epoch 96: Generator Loss = 44.2365, Discriminator Loss = 3.0516\n",
      "Epoch 97: Generator Loss = 42.8929, Discriminator Loss = 2.1526\n",
      "Epoch 98: Generator Loss = 50.6800, Discriminator Loss = 2.0808\n",
      "Epoch 99: Generator Loss = 46.5790, Discriminator Loss = 1.7617\n",
      "Epoch 100: Generator Loss = 41.5484, Discriminator Loss = 1.9052\n",
      "Epoch 101: Generator Loss = 53.4345, Discriminator Loss = 4.1015\n",
      "Epoch 102: Generator Loss = 45.5319, Discriminator Loss = 6.2243\n",
      "Epoch 103: Generator Loss = 46.6640, Discriminator Loss = 3.8824\n",
      "Epoch 104: Generator Loss = 33.7037, Discriminator Loss = 7.3482\n",
      "Epoch 105: Generator Loss = 40.2055, Discriminator Loss = 2.5192\n",
      "Epoch 106: Generator Loss = 38.6088, Discriminator Loss = 2.7479\n",
      "Epoch 107: Generator Loss = 42.4383, Discriminator Loss = 2.2181\n",
      "Epoch 108: Generator Loss = 53.7082, Discriminator Loss = 2.4283\n",
      "Epoch 109: Generator Loss = 51.9632, Discriminator Loss = 1.3139\n",
      "Epoch 110: Generator Loss = 52.3322, Discriminator Loss = 3.6097\n",
      "Epoch 111: Generator Loss = 54.3270, Discriminator Loss = 1.7782\n",
      "Epoch 112: Generator Loss = 52.3163, Discriminator Loss = 1.9307\n",
      "Epoch 113: Generator Loss = 22.0876, Discriminator Loss = 13.0669\n",
      "Epoch 114: Generator Loss = 38.4563, Discriminator Loss = 3.0825\n",
      "Epoch 115: Generator Loss = 41.8404, Discriminator Loss = 3.5137\n",
      "Epoch 116: Generator Loss = 44.5773, Discriminator Loss = 2.3349\n",
      "Epoch 117: Generator Loss = 56.4714, Discriminator Loss = 2.0150\n",
      "Epoch 118: Generator Loss = 51.8791, Discriminator Loss = 1.6900\n",
      "Epoch 119: Generator Loss = 43.5020, Discriminator Loss = 4.9726\n",
      "Epoch 120: Generator Loss = 43.5727, Discriminator Loss = 2.8265\n",
      "Epoch 121: Generator Loss = 38.2991, Discriminator Loss = 2.8976\n",
      "Epoch 122: Generator Loss = 47.0564, Discriminator Loss = 1.6050\n",
      "Epoch 123: Generator Loss = 45.5575, Discriminator Loss = 4.1003\n",
      "Epoch 124: Generator Loss = 47.3934, Discriminator Loss = 4.7764\n",
      "Epoch 125: Generator Loss = 43.3921, Discriminator Loss = 2.2071\n",
      "Epoch 126: Generator Loss = 47.7424, Discriminator Loss = 1.4731\n",
      "Epoch 127: Generator Loss = 41.3763, Discriminator Loss = 6.2212\n",
      "Epoch 128: Generator Loss = 47.0132, Discriminator Loss = 2.6934\n",
      "Epoch 129: Generator Loss = 48.6588, Discriminator Loss = 2.1904\n",
      "Epoch 130: Generator Loss = 54.2150, Discriminator Loss = 1.3501\n",
      "Epoch 131: Generator Loss = 54.6473, Discriminator Loss = 1.9586\n",
      "Epoch 132: Generator Loss = 52.4499, Discriminator Loss = 1.3607\n",
      "Epoch 133: Generator Loss = 55.0868, Discriminator Loss = 1.9001\n",
      "Epoch 134: Generator Loss = 52.5302, Discriminator Loss = 1.4386\n",
      "Epoch 135: Generator Loss = 47.1166, Discriminator Loss = 2.0330\n",
      "Epoch 136: Generator Loss = 86.2449, Discriminator Loss = 1.5194\n",
      "Epoch 137: Generator Loss = 58.7679, Discriminator Loss = 1.9003\n",
      "Epoch 138: Generator Loss = 69.6415, Discriminator Loss = 2.6500\n",
      "Epoch 139: Generator Loss = 51.6044, Discriminator Loss = 2.2851\n",
      "Epoch 140: Generator Loss = 62.5189, Discriminator Loss = 2.1472\n",
      "Epoch 141: Generator Loss = 43.5847, Discriminator Loss = 4.2487\n",
      "Epoch 142: Generator Loss = 55.1410, Discriminator Loss = 1.3114\n",
      "Epoch 143: Generator Loss = 56.6524, Discriminator Loss = 2.1614\n",
      "Epoch 144: Generator Loss = 51.4752, Discriminator Loss = 1.4515\n",
      "Epoch 145: Generator Loss = 58.0659, Discriminator Loss = 2.6338\n",
      "Epoch 146: Generator Loss = 70.3077, Discriminator Loss = 1.8405\n",
      "Epoch 147: Generator Loss = 52.8140, Discriminator Loss = 2.2155\n",
      "Epoch 148: Generator Loss = 50.8990, Discriminator Loss = 1.5621\n",
      "Epoch 149: Generator Loss = 63.4990, Discriminator Loss = 1.2336\n",
      "Epoch 150: Generator Loss = 66.2959, Discriminator Loss = 3.8503\n",
      "Epoch 151: Generator Loss = 58.7281, Discriminator Loss = 3.2862\n",
      "Epoch 152: Generator Loss = 61.4126, Discriminator Loss = 1.5084\n",
      "Epoch 153: Generator Loss = 54.1096, Discriminator Loss = 2.2883\n",
      "Epoch 154: Generator Loss = 64.4065, Discriminator Loss = 1.7873\n",
      "Epoch 155: Generator Loss = 66.0816, Discriminator Loss = 0.8245\n",
      "Epoch 156: Generator Loss = 58.0477, Discriminator Loss = 2.0608\n",
      "Epoch 157: Generator Loss = 75.2788, Discriminator Loss = 1.3300\n",
      "Epoch 158: Generator Loss = 64.0792, Discriminator Loss = 1.1058\n",
      "Epoch 159: Generator Loss = 70.7100, Discriminator Loss = 2.9423\n",
      "Epoch 160: Generator Loss = 78.3961, Discriminator Loss = 1.1205\n",
      "Epoch 161: Generator Loss = 75.2794, Discriminator Loss = 1.1650\n",
      "Epoch 162: Generator Loss = 73.5720, Discriminator Loss = 1.2560\n",
      "Epoch 163: Generator Loss = 69.7376, Discriminator Loss = 0.9993\n",
      "Epoch 164: Generator Loss = 76.5241, Discriminator Loss = 0.8774\n",
      "Epoch 165: Generator Loss = 70.6715, Discriminator Loss = 1.0580\n",
      "Epoch 166: Generator Loss = 85.7928, Discriminator Loss = 1.4392\n",
      "Epoch 167: Generator Loss = 71.7099, Discriminator Loss = 0.8672\n",
      "Epoch 168: Generator Loss = 73.6859, Discriminator Loss = 1.2844\n",
      "Epoch 169: Generator Loss = 56.6047, Discriminator Loss = 2.2020\n",
      "Epoch 170: Generator Loss = 55.2414, Discriminator Loss = 2.2074\n",
      "Epoch 171: Generator Loss = 66.0013, Discriminator Loss = 3.5143\n",
      "Epoch 172: Generator Loss = 63.6790, Discriminator Loss = 0.8952\n",
      "Epoch 173: Generator Loss = 62.9983, Discriminator Loss = 1.0728\n",
      "Epoch 174: Generator Loss = 81.1904, Discriminator Loss = 1.4753\n",
      "Epoch 175: Generator Loss = 68.4934, Discriminator Loss = 1.3540\n",
      "Epoch 176: Generator Loss = 54.2526, Discriminator Loss = 5.9288\n",
      "Epoch 177: Generator Loss = 59.7765, Discriminator Loss = 2.8829\n",
      "Epoch 178: Generator Loss = 57.2004, Discriminator Loss = 2.1394\n",
      "Epoch 179: Generator Loss = 42.5508, Discriminator Loss = 8.8820\n",
      "Epoch 180: Generator Loss = 52.9364, Discriminator Loss = 3.2235\n",
      "Epoch 181: Generator Loss = 68.6254, Discriminator Loss = 1.4558\n",
      "Epoch 182: Generator Loss = 56.0122, Discriminator Loss = 1.4752\n",
      "Epoch 183: Generator Loss = 61.1787, Discriminator Loss = 4.7071\n",
      "Epoch 184: Generator Loss = 46.4434, Discriminator Loss = 2.3494\n",
      "Epoch 185: Generator Loss = 63.0530, Discriminator Loss = 1.6746\n",
      "Epoch 186: Generator Loss = 69.3741, Discriminator Loss = 1.9002\n",
      "Epoch 187: Generator Loss = 80.8127, Discriminator Loss = 1.1123\n",
      "Epoch 188: Generator Loss = 64.1482, Discriminator Loss = 0.9338\n",
      "Epoch 189: Generator Loss = 65.8544, Discriminator Loss = 0.9433\n",
      "Epoch 190: Generator Loss = 57.0853, Discriminator Loss = 5.1796\n",
      "Epoch 191: Generator Loss = 74.7263, Discriminator Loss = 2.7246\n",
      "Epoch 192: Generator Loss = 76.2850, Discriminator Loss = 1.0395\n",
      "Epoch 193: Generator Loss = 76.9732, Discriminator Loss = 1.5728\n",
      "Epoch 194: Generator Loss = 64.9445, Discriminator Loss = 1.6216\n",
      "Epoch 195: Generator Loss = 63.6572, Discriminator Loss = 0.8532\n",
      "Epoch 196: Generator Loss = 66.5268, Discriminator Loss = 9.0204\n",
      "Epoch 197: Generator Loss = 24.2762, Discriminator Loss = 12.3906\n",
      "Epoch 198: Generator Loss = 32.1180, Discriminator Loss = 7.8099\n",
      "Epoch 199: Generator Loss = 45.5084, Discriminator Loss = 5.9388\n",
      "Epoch 200: Generator Loss = 39.5769, Discriminator Loss = 4.1021\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/20 | Train Loss: 0.1043 Acc: 0.9590\n",
      "Epoch 2/20 | Train Loss: 0.0031 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0373 Acc: 0.9877\n",
      "Epoch 4/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0351 Acc: 0.9918\n",
      "Epoch 8/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0027 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0220 Acc: 0.9877\n",
      "Epoch 16/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0257 Acc: 0.9877\n",
      "Epoch 18/20 | Train Loss: 0.0021 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.1077 Acc: 0.9549\n",
      "Epoch 2/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0029 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.1200 Acc: 0.9431\n",
      "Epoch 2/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0000 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.0643 Acc: 0.9684\n",
      "Epoch 2/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0020 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0031 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0838 Acc: 0.9657\n",
      "Epoch 2/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0028 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 6.2min\n",
      "Epoch 1/20 | Train Loss: 0.0965 Acc: 0.9508\n",
      "Epoch 2/20 | Train Loss: 0.0265 Acc: 0.9877\n",
      "Epoch 3/20 | Train Loss: 0.0057 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0076 Acc: 0.9959\n",
      "Epoch 5/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0045 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0021 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0020 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0339 Acc: 0.9918\n",
      "[CV] END .....................................scale_factor=1; total time= 4.3min\n",
      "Epoch 1/20 | Train Loss: 0.1182 Acc: 0.9590\n",
      "Epoch 2/20 | Train Loss: 0.0038 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0097 Acc: 0.9959\n",
      "Epoch 4/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0380 Acc: 0.9877\n",
      "Epoch 6/20 | Train Loss: 0.0076 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0029 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0030 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0071 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0057 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0457 Acc: 0.9836\n",
      "Epoch 19/20 | Train Loss: 0.0020 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 4.3min\n",
      "Epoch 1/20 | Train Loss: 0.1326 Acc: 0.9431\n",
      "Epoch 2/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.0643 Acc: 0.9715\n",
      "Epoch 2/20 | Train Loss: 0.0050 Acc: 0.9968\n",
      "Epoch 3/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0027 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0332 Acc: 0.9914\n",
      "Epoch 2/20 | Train Loss: 0.0030 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0000 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 6.2min\n",
      "Epoch 1/20 | Train Loss: 0.0772 Acc: 0.9629\n",
      "Epoch 2/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Fold 7 Test Accuracy: 0.5000\n",
      "===== Fold 8 =====\n",
      "Epoch 1: Generator Loss = 9.9186, Discriminator Loss = 9.0292\n",
      "Epoch 2: Generator Loss = 12.0071, Discriminator Loss = 5.6195\n",
      "Epoch 3: Generator Loss = 18.5083, Discriminator Loss = 4.7100\n",
      "Epoch 4: Generator Loss = 21.8743, Discriminator Loss = 4.4368\n",
      "Epoch 5: Generator Loss = 35.0962, Discriminator Loss = 4.5920\n",
      "Epoch 6: Generator Loss = 28.7880, Discriminator Loss = 5.9145\n",
      "Epoch 7: Generator Loss = 29.0601, Discriminator Loss = 5.3359\n",
      "Epoch 8: Generator Loss = 27.1638, Discriminator Loss = 6.4491\n",
      "Epoch 9: Generator Loss = 26.9435, Discriminator Loss = 7.4808\n",
      "Epoch 10: Generator Loss = 23.5881, Discriminator Loss = 5.9945\n",
      "Epoch 11: Generator Loss = 23.9153, Discriminator Loss = 5.4095\n",
      "Epoch 12: Generator Loss = 27.8679, Discriminator Loss = 5.5089\n",
      "Epoch 13: Generator Loss = 30.8909, Discriminator Loss = 7.5018\n",
      "Epoch 14: Generator Loss = 25.9609, Discriminator Loss = 7.6238\n",
      "Epoch 15: Generator Loss = 27.8283, Discriminator Loss = 5.6399\n",
      "Epoch 16: Generator Loss = 33.3918, Discriminator Loss = 8.1181\n",
      "Epoch 17: Generator Loss = 24.2794, Discriminator Loss = 9.1006\n",
      "Epoch 18: Generator Loss = 26.5317, Discriminator Loss = 8.8604\n",
      "Epoch 19: Generator Loss = 16.8977, Discriminator Loss = 8.0471\n",
      "Epoch 20: Generator Loss = 17.1836, Discriminator Loss = 8.3432\n",
      "Epoch 21: Generator Loss = 15.6674, Discriminator Loss = 9.4827\n",
      "Epoch 22: Generator Loss = 15.3560, Discriminator Loss = 7.9093\n",
      "Epoch 23: Generator Loss = 17.1566, Discriminator Loss = 7.9357\n",
      "Epoch 24: Generator Loss = 12.2611, Discriminator Loss = 8.1069\n",
      "Epoch 25: Generator Loss = 18.4286, Discriminator Loss = 10.2339\n",
      "Epoch 26: Generator Loss = 15.4584, Discriminator Loss = 7.6469\n",
      "Epoch 27: Generator Loss = 14.9505, Discriminator Loss = 8.3328\n",
      "Epoch 28: Generator Loss = 21.2521, Discriminator Loss = 7.6628\n",
      "Epoch 29: Generator Loss = 16.5825, Discriminator Loss = 7.1022\n",
      "Epoch 30: Generator Loss = 23.0730, Discriminator Loss = 7.3989\n",
      "Epoch 31: Generator Loss = 20.1133, Discriminator Loss = 6.1407\n",
      "Epoch 32: Generator Loss = 23.5387, Discriminator Loss = 6.7165\n",
      "Epoch 33: Generator Loss = 24.3304, Discriminator Loss = 6.2724\n",
      "Epoch 34: Generator Loss = 34.7182, Discriminator Loss = 5.4663\n",
      "Epoch 35: Generator Loss = 34.8512, Discriminator Loss = 3.9836\n",
      "Epoch 36: Generator Loss = 30.5840, Discriminator Loss = 5.9963\n",
      "Epoch 37: Generator Loss = 31.4135, Discriminator Loss = 5.5331\n",
      "Epoch 38: Generator Loss = 43.3766, Discriminator Loss = 17.0338\n",
      "Epoch 39: Generator Loss = 28.2710, Discriminator Loss = 8.5804\n",
      "Epoch 40: Generator Loss = 26.1539, Discriminator Loss = 5.6190\n",
      "Epoch 41: Generator Loss = 31.5706, Discriminator Loss = 8.8176\n",
      "Epoch 42: Generator Loss = 18.0276, Discriminator Loss = 5.5784\n",
      "Epoch 43: Generator Loss = 25.0928, Discriminator Loss = 6.9401\n",
      "Epoch 44: Generator Loss = 19.3478, Discriminator Loss = 7.4133\n",
      "Epoch 45: Generator Loss = 20.1306, Discriminator Loss = 5.8496\n",
      "Epoch 46: Generator Loss = 24.3772, Discriminator Loss = 11.2378\n",
      "Epoch 47: Generator Loss = 19.6226, Discriminator Loss = 7.0162\n",
      "Epoch 48: Generator Loss = 24.2386, Discriminator Loss = 7.7277\n",
      "Epoch 49: Generator Loss = 19.8665, Discriminator Loss = 5.4880\n",
      "Epoch 50: Generator Loss = 27.9521, Discriminator Loss = 7.5554\n",
      "Epoch 51: Generator Loss = 22.9927, Discriminator Loss = 5.3794\n",
      "Epoch 52: Generator Loss = 24.3181, Discriminator Loss = 7.6123\n",
      "Epoch 53: Generator Loss = 26.2928, Discriminator Loss = 6.1431\n",
      "Epoch 54: Generator Loss = 28.6623, Discriminator Loss = 7.2868\n",
      "Epoch 55: Generator Loss = 25.0109, Discriminator Loss = 5.8089\n",
      "Epoch 56: Generator Loss = 25.5836, Discriminator Loss = 6.8743\n",
      "Epoch 57: Generator Loss = 26.5710, Discriminator Loss = 4.5837\n",
      "Epoch 58: Generator Loss = 29.7799, Discriminator Loss = 6.5288\n",
      "Epoch 59: Generator Loss = 30.2754, Discriminator Loss = 6.9500\n",
      "Epoch 60: Generator Loss = 27.8689, Discriminator Loss = 4.8023\n",
      "Epoch 61: Generator Loss = 30.0092, Discriminator Loss = 3.8462\n",
      "Epoch 62: Generator Loss = 33.4861, Discriminator Loss = 4.5974\n",
      "Epoch 63: Generator Loss = 43.3178, Discriminator Loss = 3.0996\n",
      "Epoch 64: Generator Loss = 33.5467, Discriminator Loss = 3.7418\n",
      "Epoch 65: Generator Loss = 34.8493, Discriminator Loss = 3.3008\n",
      "Epoch 66: Generator Loss = 31.3995, Discriminator Loss = 4.9926\n",
      "Epoch 67: Generator Loss = 37.4437, Discriminator Loss = 5.9655\n",
      "Epoch 68: Generator Loss = 28.6486, Discriminator Loss = 3.5559\n",
      "Epoch 69: Generator Loss = 28.1644, Discriminator Loss = 3.1500\n",
      "Epoch 70: Generator Loss = 40.4780, Discriminator Loss = 3.5268\n",
      "Epoch 71: Generator Loss = 33.0173, Discriminator Loss = 4.8987\n",
      "Epoch 72: Generator Loss = 38.6318, Discriminator Loss = 4.8883\n",
      "Epoch 73: Generator Loss = 33.8654, Discriminator Loss = 2.6222\n",
      "Epoch 74: Generator Loss = 55.5953, Discriminator Loss = 2.4700\n",
      "Epoch 75: Generator Loss = 40.6119, Discriminator Loss = 2.5531\n",
      "Epoch 76: Generator Loss = 37.9263, Discriminator Loss = 2.5164\n",
      "Epoch 77: Generator Loss = 56.2798, Discriminator Loss = 2.1175\n",
      "Epoch 78: Generator Loss = 46.8921, Discriminator Loss = 1.8148\n",
      "Epoch 79: Generator Loss = 51.0940, Discriminator Loss = 1.5429\n",
      "Epoch 80: Generator Loss = 47.4929, Discriminator Loss = 2.9879\n",
      "Epoch 81: Generator Loss = 43.0363, Discriminator Loss = 1.4775\n",
      "Epoch 82: Generator Loss = 58.6628, Discriminator Loss = 1.0342\n",
      "Epoch 83: Generator Loss = 50.4939, Discriminator Loss = 1.9719\n",
      "Epoch 84: Generator Loss = 52.1727, Discriminator Loss = 1.6259\n",
      "Epoch 85: Generator Loss = 49.8101, Discriminator Loss = 2.7344\n",
      "Epoch 86: Generator Loss = 47.4667, Discriminator Loss = 2.4236\n",
      "Epoch 87: Generator Loss = 54.2368, Discriminator Loss = 1.7169\n",
      "Epoch 88: Generator Loss = 52.8049, Discriminator Loss = 1.4853\n",
      "Epoch 89: Generator Loss = 55.8413, Discriminator Loss = 2.2110\n",
      "Epoch 90: Generator Loss = 44.3592, Discriminator Loss = 2.9154\n",
      "Epoch 91: Generator Loss = 60.5414, Discriminator Loss = 0.9995\n",
      "Epoch 92: Generator Loss = 50.6367, Discriminator Loss = 1.2894\n",
      "Epoch 93: Generator Loss = 63.7424, Discriminator Loss = 4.5657\n",
      "Epoch 94: Generator Loss = 60.5390, Discriminator Loss = 4.2970\n",
      "Epoch 95: Generator Loss = 47.3701, Discriminator Loss = 1.9617\n",
      "Epoch 96: Generator Loss = 66.5084, Discriminator Loss = 1.8044\n",
      "Epoch 97: Generator Loss = 52.2977, Discriminator Loss = 2.2605\n",
      "Epoch 98: Generator Loss = 76.6913, Discriminator Loss = 1.0673\n",
      "Epoch 99: Generator Loss = 69.3717, Discriminator Loss = 0.9574\n",
      "Epoch 100: Generator Loss = 70.8332, Discriminator Loss = 1.1262\n",
      "Epoch 101: Generator Loss = 88.8729, Discriminator Loss = 0.5334\n",
      "Epoch 102: Generator Loss = 79.4181, Discriminator Loss = 0.6150\n",
      "Epoch 103: Generator Loss = 123.4874, Discriminator Loss = 2.6401\n",
      "Epoch 104: Generator Loss = 113.4867, Discriminator Loss = 0.7472\n",
      "Epoch 105: Generator Loss = 138.4197, Discriminator Loss = 3.9095\n",
      "Epoch 106: Generator Loss = 170.8733, Discriminator Loss = 0.5938\n",
      "Epoch 107: Generator Loss = 139.8208, Discriminator Loss = 0.4630\n",
      "Epoch 108: Generator Loss = 135.1334, Discriminator Loss = 0.1667\n",
      "Epoch 109: Generator Loss = 109.0256, Discriminator Loss = 0.0511\n",
      "Epoch 110: Generator Loss = 112.5811, Discriminator Loss = 0.1596\n",
      "Epoch 111: Generator Loss = 117.1743, Discriminator Loss = 0.3664\n",
      "Epoch 112: Generator Loss = 120.7229, Discriminator Loss = 0.0360\n",
      "Epoch 113: Generator Loss = 108.4864, Discriminator Loss = 0.0535\n",
      "Epoch 114: Generator Loss = 75.6333, Discriminator Loss = 0.1292\n",
      "Epoch 115: Generator Loss = 92.3914, Discriminator Loss = 0.0753\n",
      "Epoch 116: Generator Loss = 104.1953, Discriminator Loss = 0.1824\n",
      "Epoch 117: Generator Loss = 108.5729, Discriminator Loss = 0.0764\n",
      "Epoch 118: Generator Loss = 103.0508, Discriminator Loss = 0.0964\n",
      "Epoch 119: Generator Loss = 90.6457, Discriminator Loss = 0.3070\n",
      "Epoch 120: Generator Loss = 109.6363, Discriminator Loss = 12.5061\n",
      "Epoch 121: Generator Loss = 79.5387, Discriminator Loss = 2.5027\n",
      "Epoch 122: Generator Loss = 73.5508, Discriminator Loss = 1.1207\n",
      "Epoch 123: Generator Loss = 83.5842, Discriminator Loss = 11.0449\n",
      "Epoch 124: Generator Loss = 46.5793, Discriminator Loss = 4.3858\n",
      "Epoch 125: Generator Loss = 42.7447, Discriminator Loss = 4.4760\n",
      "Epoch 126: Generator Loss = 61.1042, Discriminator Loss = 4.5191\n",
      "Epoch 127: Generator Loss = 57.3557, Discriminator Loss = 1.0169\n",
      "Epoch 128: Generator Loss = 50.0149, Discriminator Loss = 1.0591\n",
      "Epoch 129: Generator Loss = 65.1434, Discriminator Loss = 1.2919\n",
      "Epoch 130: Generator Loss = 61.1424, Discriminator Loss = 1.4099\n",
      "Epoch 131: Generator Loss = 65.2591, Discriminator Loss = 1.3290\n",
      "Epoch 132: Generator Loss = 61.2770, Discriminator Loss = 1.8147\n",
      "Epoch 133: Generator Loss = 55.1181, Discriminator Loss = 1.2540\n",
      "Epoch 134: Generator Loss = 59.3355, Discriminator Loss = 0.8148\n",
      "Epoch 135: Generator Loss = 62.7518, Discriminator Loss = 2.0816\n",
      "Epoch 136: Generator Loss = 62.6162, Discriminator Loss = 1.2455\n",
      "Epoch 137: Generator Loss = 65.8807, Discriminator Loss = 1.2747\n",
      "Epoch 138: Generator Loss = 68.3219, Discriminator Loss = 0.9358\n",
      "Epoch 139: Generator Loss = 57.3319, Discriminator Loss = 0.8507\n",
      "Epoch 140: Generator Loss = 63.1399, Discriminator Loss = 0.5353\n",
      "Epoch 141: Generator Loss = 75.7085, Discriminator Loss = 1.2708\n",
      "Epoch 142: Generator Loss = 70.0067, Discriminator Loss = 0.8756\n",
      "Epoch 143: Generator Loss = 67.4117, Discriminator Loss = 1.2507\n",
      "Epoch 144: Generator Loss = 61.1595, Discriminator Loss = 1.7127\n",
      "Epoch 145: Generator Loss = 67.8210, Discriminator Loss = 1.6506\n",
      "Epoch 146: Generator Loss = 61.2013, Discriminator Loss = 0.8761\n",
      "Epoch 147: Generator Loss = 68.3807, Discriminator Loss = 1.0036\n",
      "Epoch 148: Generator Loss = 68.5384, Discriminator Loss = 1.1145\n",
      "Epoch 149: Generator Loss = 65.1573, Discriminator Loss = 0.7984\n",
      "Epoch 150: Generator Loss = 61.1187, Discriminator Loss = 0.8600\n",
      "Epoch 151: Generator Loss = 73.0579, Discriminator Loss = 1.2072\n",
      "Epoch 152: Generator Loss = 67.1313, Discriminator Loss = 1.1015\n",
      "Epoch 153: Generator Loss = 72.8529, Discriminator Loss = 0.7519\n",
      "Epoch 154: Generator Loss = 83.1073, Discriminator Loss = 0.6491\n",
      "Epoch 155: Generator Loss = 80.2437, Discriminator Loss = 0.7288\n",
      "Epoch 156: Generator Loss = 74.1184, Discriminator Loss = 0.6370\n",
      "Epoch 157: Generator Loss = 73.0054, Discriminator Loss = 3.5812\n",
      "Epoch 158: Generator Loss = 71.6701, Discriminator Loss = 1.2915\n",
      "Epoch 159: Generator Loss = 79.9424, Discriminator Loss = 0.9324\n",
      "Epoch 160: Generator Loss = 68.9823, Discriminator Loss = 0.8610\n",
      "Epoch 161: Generator Loss = 64.0197, Discriminator Loss = 0.8393\n",
      "Epoch 162: Generator Loss = 76.9878, Discriminator Loss = 1.3269\n",
      "Epoch 163: Generator Loss = 80.5578, Discriminator Loss = 4.6249\n",
      "Epoch 164: Generator Loss = 57.6364, Discriminator Loss = 1.8434\n",
      "Epoch 165: Generator Loss = 70.8583, Discriminator Loss = 1.4370\n",
      "Epoch 166: Generator Loss = 74.3852, Discriminator Loss = 0.6504\n",
      "Epoch 167: Generator Loss = 86.2277, Discriminator Loss = 0.7904\n",
      "Epoch 168: Generator Loss = 76.8866, Discriminator Loss = 0.5404\n",
      "Epoch 169: Generator Loss = 75.9128, Discriminator Loss = 0.7634\n",
      "Epoch 170: Generator Loss = 67.0707, Discriminator Loss = 0.6245\n",
      "Epoch 171: Generator Loss = 83.3913, Discriminator Loss = 0.5422\n",
      "Epoch 172: Generator Loss = 83.5494, Discriminator Loss = 0.9483\n",
      "Epoch 173: Generator Loss = 73.6724, Discriminator Loss = 0.5870\n",
      "Epoch 174: Generator Loss = 88.2352, Discriminator Loss = 0.2924\n",
      "Epoch 175: Generator Loss = 82.1726, Discriminator Loss = 1.0603\n",
      "Epoch 176: Generator Loss = 108.8898, Discriminator Loss = 1.3210\n",
      "Epoch 177: Generator Loss = 81.6944, Discriminator Loss = 0.5125\n",
      "Epoch 178: Generator Loss = 97.5508, Discriminator Loss = 0.3501\n",
      "Epoch 179: Generator Loss = 108.7930, Discriminator Loss = 0.3139\n",
      "Epoch 180: Generator Loss = 113.0628, Discriminator Loss = 0.1477\n",
      "Epoch 181: Generator Loss = 92.9509, Discriminator Loss = 0.2225\n",
      "Epoch 182: Generator Loss = 74.5045, Discriminator Loss = 0.6600\n",
      "Epoch 183: Generator Loss = 71.7927, Discriminator Loss = 0.8233\n",
      "Epoch 184: Generator Loss = 91.4445, Discriminator Loss = 0.8862\n",
      "Epoch 185: Generator Loss = 83.1480, Discriminator Loss = 0.9080\n",
      "Epoch 186: Generator Loss = 75.2960, Discriminator Loss = 1.2377\n",
      "Epoch 187: Generator Loss = 71.8344, Discriminator Loss = 1.8645\n",
      "Epoch 188: Generator Loss = 101.9436, Discriminator Loss = 1.5601\n",
      "Epoch 189: Generator Loss = 61.3005, Discriminator Loss = 4.2685\n",
      "Epoch 190: Generator Loss = 78.8082, Discriminator Loss = 0.7856\n",
      "Epoch 191: Generator Loss = 80.7836, Discriminator Loss = 1.2524\n",
      "Epoch 192: Generator Loss = 82.3703, Discriminator Loss = 0.9722\n",
      "Epoch 193: Generator Loss = 74.1177, Discriminator Loss = 0.6375\n",
      "Epoch 194: Generator Loss = 76.1509, Discriminator Loss = 0.7560\n",
      "Epoch 195: Generator Loss = 74.2618, Discriminator Loss = 0.5728\n",
      "Epoch 196: Generator Loss = 88.4378, Discriminator Loss = 0.2544\n",
      "Epoch 197: Generator Loss = 88.0605, Discriminator Loss = 0.6673\n",
      "Epoch 198: Generator Loss = 81.6413, Discriminator Loss = 0.3016\n",
      "Epoch 199: Generator Loss = 88.3236, Discriminator Loss = 0.2793\n",
      "Epoch 200: Generator Loss = 92.4665, Discriminator Loss = 0.5913\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/20 | Train Loss: 0.0958 Acc: 0.9549\n",
      "Epoch 2/20 | Train Loss: 0.0023 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0132 Acc: 0.9918\n",
      "Epoch 17/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.0754 Acc: 0.9631\n",
      "Epoch 2/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0083 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0120 Acc: 0.9877\n",
      "Epoch 9/20 | Train Loss: 0.0342 Acc: 0.9959\n",
      "Epoch 10/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.1025 Acc: 0.9390\n",
      "Epoch 2/20 | Train Loss: 0.0032 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0057 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0440 Acc: 0.9797\n",
      "Epoch 6/20 | Train Loss: 0.0040 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0632 Acc: 0.9919\n",
      "Epoch 13/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0299 Acc: 0.9878\n",
      "Epoch 15/20 | Train Loss: 0.0031 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.0716 Acc: 0.9652\n",
      "Epoch 2/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0023 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0889 Acc: 0.9514\n",
      "Epoch 2/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0031 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 6.2min\n",
      "Epoch 1/20 | Train Loss: 0.0851 Acc: 0.9754\n",
      "Epoch 2/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0277 Acc: 0.9918\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0172 Acc: 0.9877\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 4.3min\n",
      "Epoch 1/20 | Train Loss: 0.0667 Acc: 0.9795\n",
      "Epoch 2/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0205 Acc: 0.9959\n",
      "Epoch 6/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0063 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 4.3min\n",
      "Epoch 1/20 | Train Loss: 0.1234 Acc: 0.9431\n",
      "Epoch 2/20 | Train Loss: 0.0037 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0316 Acc: 0.9919\n",
      "Epoch 13/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.0576 Acc: 0.9778\n",
      "Epoch 2/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0025 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0165 Acc: 0.9937\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0055 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0024 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.7min\n",
      "Epoch 1/20 | Train Loss: 0.0600 Acc: 0.9743\n",
      "Epoch 2/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 6.3min\n",
      "Epoch 1/20 | Train Loss: 0.0504 Acc: 0.9829\n",
      "Epoch 2/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Fold 8 Test Accuracy: 0.5000\n",
      "===== Fold 9 =====\n",
      "Epoch 1: Generator Loss = 10.0428, Discriminator Loss = 8.7734\n",
      "Epoch 2: Generator Loss = 12.3795, Discriminator Loss = 6.4689\n",
      "Epoch 3: Generator Loss = 15.3983, Discriminator Loss = 5.8713\n",
      "Epoch 4: Generator Loss = 23.0303, Discriminator Loss = 4.9119\n",
      "Epoch 5: Generator Loss = 32.1053, Discriminator Loss = 3.7722\n",
      "Epoch 6: Generator Loss = 35.0106, Discriminator Loss = 4.5917\n",
      "Epoch 7: Generator Loss = 35.8968, Discriminator Loss = 3.6854\n",
      "Epoch 8: Generator Loss = 29.8426, Discriminator Loss = 4.6036\n",
      "Epoch 9: Generator Loss = 27.7931, Discriminator Loss = 5.2695\n",
      "Epoch 10: Generator Loss = 27.7914, Discriminator Loss = 10.4863\n",
      "Epoch 11: Generator Loss = 24.0225, Discriminator Loss = 7.6952\n",
      "Epoch 12: Generator Loss = 23.1413, Discriminator Loss = 6.5943\n",
      "Epoch 13: Generator Loss = 29.6464, Discriminator Loss = 7.1505\n",
      "Epoch 14: Generator Loss = 25.3910, Discriminator Loss = 7.8225\n",
      "Epoch 15: Generator Loss = 25.6102, Discriminator Loss = 8.6928\n",
      "Epoch 16: Generator Loss = 22.1904, Discriminator Loss = 6.9386\n",
      "Epoch 17: Generator Loss = 28.0459, Discriminator Loss = 5.9379\n",
      "Epoch 18: Generator Loss = 21.0348, Discriminator Loss = 6.3389\n",
      "Epoch 19: Generator Loss = 26.5157, Discriminator Loss = 7.4987\n",
      "Epoch 20: Generator Loss = 20.3300, Discriminator Loss = 7.1497\n",
      "Epoch 21: Generator Loss = 28.5604, Discriminator Loss = 6.6149\n",
      "Epoch 22: Generator Loss = 29.7275, Discriminator Loss = 6.2857\n",
      "Epoch 23: Generator Loss = 27.0313, Discriminator Loss = 7.3772\n",
      "Epoch 24: Generator Loss = 27.1527, Discriminator Loss = 6.9999\n",
      "Epoch 25: Generator Loss = 22.9671, Discriminator Loss = 8.0253\n",
      "Epoch 26: Generator Loss = 24.9560, Discriminator Loss = 8.1628\n",
      "Epoch 27: Generator Loss = 25.9689, Discriminator Loss = 7.8330\n",
      "Epoch 28: Generator Loss = 17.7248, Discriminator Loss = 8.5318\n",
      "Epoch 29: Generator Loss = 18.4770, Discriminator Loss = 8.7516\n",
      "Epoch 30: Generator Loss = 18.2410, Discriminator Loss = 8.5860\n",
      "Epoch 31: Generator Loss = 17.3047, Discriminator Loss = 6.3280\n",
      "Epoch 32: Generator Loss = 24.9039, Discriminator Loss = 7.3722\n",
      "Epoch 33: Generator Loss = 21.3908, Discriminator Loss = 6.9753\n",
      "Epoch 34: Generator Loss = 26.5859, Discriminator Loss = 8.0811\n",
      "Epoch 35: Generator Loss = 20.0371, Discriminator Loss = 7.6854\n",
      "Epoch 36: Generator Loss = 22.9005, Discriminator Loss = 7.9002\n",
      "Epoch 37: Generator Loss = 20.9541, Discriminator Loss = 6.5140\n",
      "Epoch 38: Generator Loss = 25.7069, Discriminator Loss = 7.1864\n",
      "Epoch 39: Generator Loss = 19.7244, Discriminator Loss = 8.4300\n",
      "Epoch 40: Generator Loss = 21.8590, Discriminator Loss = 10.1537\n",
      "Epoch 41: Generator Loss = 24.4392, Discriminator Loss = 7.8853\n",
      "Epoch 42: Generator Loss = 22.2542, Discriminator Loss = 8.2071\n",
      "Epoch 43: Generator Loss = 18.0080, Discriminator Loss = 7.4704\n",
      "Epoch 44: Generator Loss = 19.1468, Discriminator Loss = 7.9440\n",
      "Epoch 45: Generator Loss = 20.1375, Discriminator Loss = 9.1927\n",
      "Epoch 46: Generator Loss = 18.1546, Discriminator Loss = 7.0913\n",
      "Epoch 47: Generator Loss = 15.9429, Discriminator Loss = 8.6284\n",
      "Epoch 48: Generator Loss = 18.7155, Discriminator Loss = 8.7886\n",
      "Epoch 49: Generator Loss = 15.7827, Discriminator Loss = 7.9705\n",
      "Epoch 50: Generator Loss = 16.8002, Discriminator Loss = 7.9124\n",
      "Epoch 51: Generator Loss = 16.9527, Discriminator Loss = 7.9351\n",
      "Epoch 52: Generator Loss = 17.7285, Discriminator Loss = 7.2517\n",
      "Epoch 53: Generator Loss = 20.5982, Discriminator Loss = 7.7028\n",
      "Epoch 54: Generator Loss = 21.1013, Discriminator Loss = 6.9289\n",
      "Epoch 55: Generator Loss = 23.8165, Discriminator Loss = 5.7957\n",
      "Epoch 56: Generator Loss = 25.6639, Discriminator Loss = 5.4305\n",
      "Epoch 57: Generator Loss = 25.6168, Discriminator Loss = 8.5865\n",
      "Epoch 58: Generator Loss = 25.3686, Discriminator Loss = 5.9770\n",
      "Epoch 59: Generator Loss = 23.0747, Discriminator Loss = 6.4568\n",
      "Epoch 60: Generator Loss = 26.5294, Discriminator Loss = 6.1681\n",
      "Epoch 61: Generator Loss = 26.3484, Discriminator Loss = 4.7649\n",
      "Epoch 62: Generator Loss = 39.6347, Discriminator Loss = 4.1034\n",
      "Epoch 63: Generator Loss = 26.7309, Discriminator Loss = 6.2571\n",
      "Epoch 64: Generator Loss = 25.2139, Discriminator Loss = 5.9285\n",
      "Epoch 65: Generator Loss = 27.1016, Discriminator Loss = 4.8526\n",
      "Epoch 66: Generator Loss = 22.5514, Discriminator Loss = 4.3992\n",
      "Epoch 67: Generator Loss = 39.8282, Discriminator Loss = 3.4977\n",
      "Epoch 68: Generator Loss = 33.3508, Discriminator Loss = 3.2514\n",
      "Epoch 69: Generator Loss = 40.0279, Discriminator Loss = 3.4655\n",
      "Epoch 70: Generator Loss = 36.2306, Discriminator Loss = 2.7950\n",
      "Epoch 71: Generator Loss = 44.8598, Discriminator Loss = 2.8247\n",
      "Epoch 72: Generator Loss = 57.2950, Discriminator Loss = 2.3866\n",
      "Epoch 73: Generator Loss = 41.9017, Discriminator Loss = 3.8513\n",
      "Epoch 74: Generator Loss = 46.5500, Discriminator Loss = 2.3525\n",
      "Epoch 75: Generator Loss = 51.7834, Discriminator Loss = 2.0667\n",
      "Epoch 76: Generator Loss = 53.9893, Discriminator Loss = 1.8812\n",
      "Epoch 77: Generator Loss = 60.2626, Discriminator Loss = 1.0856\n",
      "Epoch 78: Generator Loss = 59.8354, Discriminator Loss = 1.0762\n",
      "Epoch 79: Generator Loss = 77.5633, Discriminator Loss = 1.3371\n",
      "Epoch 80: Generator Loss = 139.9721, Discriminator Loss = 0.8202\n",
      "Epoch 81: Generator Loss = 120.0440, Discriminator Loss = 0.3311\n",
      "Epoch 82: Generator Loss = 129.7433, Discriminator Loss = 0.7133\n",
      "Epoch 83: Generator Loss = 125.4696, Discriminator Loss = 0.9277\n",
      "Epoch 84: Generator Loss = 155.1063, Discriminator Loss = 0.4384\n",
      "Epoch 85: Generator Loss = 120.7315, Discriminator Loss = 0.4985\n",
      "Epoch 86: Generator Loss = 99.1016, Discriminator Loss = 0.1748\n",
      "Epoch 87: Generator Loss = 93.9286, Discriminator Loss = 0.2846\n",
      "Epoch 88: Generator Loss = 101.3776, Discriminator Loss = 0.3544\n",
      "Epoch 89: Generator Loss = 88.3354, Discriminator Loss = 0.4342\n",
      "Epoch 90: Generator Loss = 77.4630, Discriminator Loss = 16.1508\n",
      "Epoch 91: Generator Loss = 56.1472, Discriminator Loss = 0.9763\n",
      "Epoch 92: Generator Loss = 70.4282, Discriminator Loss = 0.6451\n",
      "Epoch 93: Generator Loss = 81.5081, Discriminator Loss = 2.3761\n",
      "Epoch 94: Generator Loss = 79.2797, Discriminator Loss = 1.5511\n",
      "Epoch 95: Generator Loss = 61.8904, Discriminator Loss = 1.3525\n",
      "Epoch 96: Generator Loss = 73.7735, Discriminator Loss = 1.0148\n",
      "Epoch 97: Generator Loss = 54.7389, Discriminator Loss = 4.5600\n",
      "Epoch 98: Generator Loss = 57.9953, Discriminator Loss = 2.0238\n",
      "Epoch 99: Generator Loss = 69.5340, Discriminator Loss = 4.4232\n",
      "Epoch 100: Generator Loss = 55.4586, Discriminator Loss = 2.1201\n",
      "Epoch 101: Generator Loss = 59.4649, Discriminator Loss = 1.7145\n",
      "Epoch 102: Generator Loss = 58.8960, Discriminator Loss = 1.2008\n",
      "Epoch 103: Generator Loss = 51.7364, Discriminator Loss = 2.1716\n",
      "Epoch 104: Generator Loss = 69.4774, Discriminator Loss = 2.5326\n",
      "Epoch 105: Generator Loss = 72.0920, Discriminator Loss = 0.8163\n",
      "Epoch 106: Generator Loss = 67.8125, Discriminator Loss = 1.0712\n",
      "Epoch 107: Generator Loss = 67.5768, Discriminator Loss = 1.3055\n",
      "Epoch 108: Generator Loss = 69.4746, Discriminator Loss = 1.1367\n",
      "Epoch 109: Generator Loss = 60.4921, Discriminator Loss = 0.6140\n",
      "Epoch 110: Generator Loss = 73.3107, Discriminator Loss = 0.7156\n",
      "Epoch 111: Generator Loss = 77.6232, Discriminator Loss = 1.4317\n",
      "Epoch 112: Generator Loss = 66.4121, Discriminator Loss = 1.3106\n",
      "Epoch 113: Generator Loss = 67.8227, Discriminator Loss = 0.9918\n",
      "Epoch 114: Generator Loss = 59.6307, Discriminator Loss = 1.4195\n",
      "Epoch 115: Generator Loss = 67.6237, Discriminator Loss = 3.1652\n",
      "Epoch 116: Generator Loss = 77.6781, Discriminator Loss = 1.5972\n",
      "Epoch 117: Generator Loss = 62.7190, Discriminator Loss = 3.5746\n",
      "Epoch 118: Generator Loss = 62.6425, Discriminator Loss = 1.1538\n",
      "Epoch 119: Generator Loss = 66.1445, Discriminator Loss = 0.9930\n",
      "Epoch 120: Generator Loss = 69.8494, Discriminator Loss = 1.3845\n",
      "Epoch 121: Generator Loss = 80.2115, Discriminator Loss = 0.8622\n",
      "Epoch 122: Generator Loss = 73.2852, Discriminator Loss = 2.8082\n",
      "Epoch 123: Generator Loss = 63.5130, Discriminator Loss = 0.7931\n",
      "Epoch 124: Generator Loss = 67.1847, Discriminator Loss = 0.7118\n",
      "Epoch 125: Generator Loss = 70.4111, Discriminator Loss = 1.0752\n",
      "Epoch 126: Generator Loss = 84.0555, Discriminator Loss = 0.8214\n",
      "Epoch 127: Generator Loss = 64.5426, Discriminator Loss = 1.4914\n",
      "Epoch 128: Generator Loss = 77.4376, Discriminator Loss = 3.2283\n",
      "Epoch 129: Generator Loss = 54.8047, Discriminator Loss = 2.1859\n",
      "Epoch 130: Generator Loss = 71.1629, Discriminator Loss = 2.1543\n",
      "Epoch 131: Generator Loss = 85.6894, Discriminator Loss = 1.0062\n",
      "Epoch 132: Generator Loss = 86.3274, Discriminator Loss = 3.0900\n",
      "Epoch 133: Generator Loss = 67.7979, Discriminator Loss = 1.3195\n",
      "Epoch 134: Generator Loss = 74.4942, Discriminator Loss = 1.1138\n",
      "Epoch 135: Generator Loss = 74.7776, Discriminator Loss = 0.9971\n",
      "Epoch 136: Generator Loss = 73.2195, Discriminator Loss = 1.8381\n",
      "Epoch 137: Generator Loss = 84.4631, Discriminator Loss = 0.7364\n",
      "Epoch 138: Generator Loss = 82.6787, Discriminator Loss = 0.3163\n",
      "Epoch 139: Generator Loss = 76.8194, Discriminator Loss = 0.9708\n",
      "Epoch 140: Generator Loss = 70.2806, Discriminator Loss = 1.5456\n",
      "Epoch 141: Generator Loss = 76.9357, Discriminator Loss = 0.6517\n",
      "Epoch 142: Generator Loss = 80.0139, Discriminator Loss = 0.7378\n",
      "Epoch 143: Generator Loss = 72.7442, Discriminator Loss = 1.2470\n",
      "Epoch 144: Generator Loss = 63.3978, Discriminator Loss = 1.9355\n",
      "Epoch 145: Generator Loss = 75.1540, Discriminator Loss = 0.5108\n",
      "Epoch 146: Generator Loss = 82.4630, Discriminator Loss = 0.6259\n",
      "Epoch 147: Generator Loss = 80.6377, Discriminator Loss = 1.4356\n",
      "Epoch 148: Generator Loss = 72.5181, Discriminator Loss = 0.9534\n",
      "Epoch 149: Generator Loss = 68.4636, Discriminator Loss = 0.8047\n",
      "Epoch 150: Generator Loss = 71.3235, Discriminator Loss = 0.6287\n",
      "Epoch 151: Generator Loss = 75.9345, Discriminator Loss = 1.8550\n",
      "Epoch 152: Generator Loss = 55.6787, Discriminator Loss = 0.8643\n",
      "Epoch 153: Generator Loss = 78.7858, Discriminator Loss = 0.6249\n",
      "Epoch 154: Generator Loss = 64.9169, Discriminator Loss = 1.0077\n",
      "Epoch 155: Generator Loss = 77.7923, Discriminator Loss = 0.4846\n",
      "Epoch 156: Generator Loss = 102.0275, Discriminator Loss = 0.6518\n",
      "Epoch 157: Generator Loss = 69.2857, Discriminator Loss = 0.9077\n",
      "Epoch 158: Generator Loss = 79.3542, Discriminator Loss = 1.0303\n",
      "Epoch 159: Generator Loss = 61.2783, Discriminator Loss = 9.2945\n",
      "Epoch 160: Generator Loss = 50.4664, Discriminator Loss = 5.4052\n",
      "Epoch 161: Generator Loss = 68.8463, Discriminator Loss = 8.2440\n",
      "Epoch 162: Generator Loss = 47.1600, Discriminator Loss = 1.5957\n",
      "Epoch 163: Generator Loss = 58.5337, Discriminator Loss = 1.4857\n",
      "Epoch 164: Generator Loss = 56.0780, Discriminator Loss = 1.1159\n",
      "Epoch 165: Generator Loss = 62.7898, Discriminator Loss = 1.8949\n",
      "Epoch 166: Generator Loss = 62.2209, Discriminator Loss = 0.9668\n",
      "Epoch 167: Generator Loss = 82.1559, Discriminator Loss = 1.0394\n",
      "Epoch 168: Generator Loss = 70.1617, Discriminator Loss = 1.5023\n",
      "Epoch 169: Generator Loss = 82.0733, Discriminator Loss = 2.5367\n",
      "Epoch 170: Generator Loss = 54.9271, Discriminator Loss = 2.1135\n",
      "Epoch 171: Generator Loss = 75.8455, Discriminator Loss = 1.2899\n",
      "Epoch 172: Generator Loss = 71.5329, Discriminator Loss = 0.7799\n",
      "Epoch 173: Generator Loss = 64.7493, Discriminator Loss = 1.1688\n",
      "Epoch 174: Generator Loss = 68.0309, Discriminator Loss = 0.6558\n",
      "Epoch 175: Generator Loss = 81.3967, Discriminator Loss = 0.6038\n",
      "Epoch 176: Generator Loss = 67.9723, Discriminator Loss = 2.2456\n",
      "Epoch 177: Generator Loss = 71.6244, Discriminator Loss = 4.8446\n",
      "Epoch 178: Generator Loss = 76.3515, Discriminator Loss = 2.3645\n",
      "Epoch 179: Generator Loss = 68.4901, Discriminator Loss = 2.5532\n",
      "Epoch 180: Generator Loss = 69.4674, Discriminator Loss = 0.9116\n",
      "Epoch 181: Generator Loss = 63.4206, Discriminator Loss = 2.0323\n",
      "Epoch 182: Generator Loss = 56.2032, Discriminator Loss = 6.1160\n",
      "Epoch 183: Generator Loss = 67.9811, Discriminator Loss = 1.3083\n",
      "Epoch 184: Generator Loss = 77.9297, Discriminator Loss = 0.8433\n",
      "Epoch 185: Generator Loss = 73.3924, Discriminator Loss = 0.9324\n",
      "Epoch 186: Generator Loss = 77.0431, Discriminator Loss = 0.7820\n",
      "Epoch 187: Generator Loss = 85.2185, Discriminator Loss = 0.9360\n",
      "Epoch 188: Generator Loss = 67.3887, Discriminator Loss = 1.1708\n",
      "Epoch 189: Generator Loss = 69.6315, Discriminator Loss = 2.5237\n",
      "Epoch 190: Generator Loss = 60.4710, Discriminator Loss = 7.5614\n",
      "Epoch 191: Generator Loss = 45.8586, Discriminator Loss = 8.6401\n",
      "Epoch 192: Generator Loss = 51.2734, Discriminator Loss = 6.8248\n",
      "Epoch 193: Generator Loss = 51.8082, Discriminator Loss = 4.4425\n",
      "Epoch 194: Generator Loss = 60.7173, Discriminator Loss = 1.8859\n",
      "Epoch 195: Generator Loss = 54.5370, Discriminator Loss = 1.3504\n",
      "Epoch 196: Generator Loss = 68.8294, Discriminator Loss = 1.6458\n",
      "Epoch 197: Generator Loss = 73.4294, Discriminator Loss = 1.0973\n",
      "Epoch 198: Generator Loss = 78.3246, Discriminator Loss = 0.9587\n",
      "Epoch 199: Generator Loss = 71.8632, Discriminator Loss = 0.8543\n",
      "Epoch 200: Generator Loss = 71.8595, Discriminator Loss = 0.9729\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/20 | Train Loss: 0.1010 Acc: 0.9549\n",
      "Epoch 2/20 | Train Loss: 0.0025 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0463 Acc: 0.9918\n",
      "Epoch 5/20 | Train Loss: 0.0020 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0029 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0272 Acc: 0.9877\n",
      "Epoch 8/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0020 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0028 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0040 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0038 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.0800 Acc: 0.9713\n",
      "Epoch 2/20 | Train Loss: 0.0254 Acc: 0.9877\n",
      "Epoch 3/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0081 Acc: 0.9959\n",
      "Epoch 5/20 | Train Loss: 0.0052 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0275 Acc: 0.9959\n",
      "Epoch 15/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.1312 Acc: 0.9426\n",
      "Epoch 2/20 | Train Loss: 0.0104 Acc: 0.9959\n",
      "Epoch 3/20 | Train Loss: 0.0026 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0214 Acc: 0.9918\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0243 Acc: 0.9918\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.0702 Acc: 0.9654\n",
      "Epoch 2/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0064 Acc: 0.9969\n",
      "Epoch 4/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.7min\n",
      "Epoch 1/20 | Train Loss: 0.0483 Acc: 0.9743\n",
      "Epoch 2/20 | Train Loss: 0.0042 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 6.2min\n",
      "Epoch 1/20 | Train Loss: 0.1181 Acc: 0.9262\n",
      "Epoch 2/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0025 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0067 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0021 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0020 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0304 Acc: 0.9877\n",
      "[CV] END .....................................scale_factor=1; total time= 4.3min\n",
      "Epoch 1/20 | Train Loss: 0.1195 Acc: 0.9467\n",
      "Epoch 2/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0283 Acc: 0.9959\n",
      "Epoch 6/20 | Train Loss: 0.0028 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0034 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0254 Acc: 0.9918\n",
      "Epoch 9/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0363 Acc: 0.9918\n",
      "Epoch 11/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0025 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0083 Acc: 0.9959\n",
      "Epoch 14/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0387 Acc: 0.9918\n",
      "Epoch 19/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.0725 Acc: 0.9672\n",
      "Epoch 2/20 | Train Loss: 0.0036 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0028 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0235 Acc: 0.9918\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0104 Acc: 0.9959\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 4.3min\n",
      "Epoch 1/20 | Train Loss: 0.0589 Acc: 0.9780\n",
      "Epoch 2/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0128 Acc: 0.9969\n",
      "Epoch 5/20 | Train Loss: 0.0031 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.6min\n",
      "Epoch 1/20 | Train Loss: 0.0570 Acc: 0.9771\n",
      "Epoch 2/20 | Train Loss: 0.0030 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0023 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0024 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 6.2min\n",
      "Epoch 1/20 | Train Loss: 0.0558 Acc: 0.9771\n",
      "Epoch 2/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0090 Acc: 0.9971\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Fold 9 Test Accuracy: 0.5000\n",
      "===== Fold 10 =====\n",
      "Epoch 1: Generator Loss = 10.1781, Discriminator Loss = 8.7936\n",
      "Epoch 2: Generator Loss = 11.6741, Discriminator Loss = 6.6595\n",
      "Epoch 3: Generator Loss = 15.3149, Discriminator Loss = 6.6711\n",
      "Epoch 4: Generator Loss = 19.4225, Discriminator Loss = 4.9572\n",
      "Epoch 5: Generator Loss = 24.6279, Discriminator Loss = 5.0425\n",
      "Epoch 6: Generator Loss = 27.3742, Discriminator Loss = 5.0796\n",
      "Epoch 7: Generator Loss = 31.6395, Discriminator Loss = 3.7603\n",
      "Epoch 8: Generator Loss = 27.0654, Discriminator Loss = 5.8989\n",
      "Epoch 9: Generator Loss = 26.5605, Discriminator Loss = 6.4118\n",
      "Epoch 10: Generator Loss = 24.9846, Discriminator Loss = 7.0628\n",
      "Epoch 11: Generator Loss = 22.6227, Discriminator Loss = 6.6701\n",
      "Epoch 12: Generator Loss = 23.4230, Discriminator Loss = 8.5070\n",
      "Epoch 13: Generator Loss = 20.6586, Discriminator Loss = 6.5483\n",
      "Epoch 14: Generator Loss = 21.8930, Discriminator Loss = 8.0498\n",
      "Epoch 15: Generator Loss = 19.6635, Discriminator Loss = 7.8944\n",
      "Epoch 16: Generator Loss = 17.6628, Discriminator Loss = 9.7817\n",
      "Epoch 17: Generator Loss = 21.5210, Discriminator Loss = 8.3600\n",
      "Epoch 18: Generator Loss = 16.1562, Discriminator Loss = 9.5131\n",
      "Epoch 19: Generator Loss = 18.2010, Discriminator Loss = 9.5891\n",
      "Epoch 20: Generator Loss = 13.8322, Discriminator Loss = 8.6713\n",
      "Epoch 21: Generator Loss = 16.6634, Discriminator Loss = 8.4488\n",
      "Epoch 22: Generator Loss = 18.1395, Discriminator Loss = 9.1050\n",
      "Epoch 23: Generator Loss = 15.6104, Discriminator Loss = 9.8773\n",
      "Epoch 24: Generator Loss = 15.0005, Discriminator Loss = 9.7926\n",
      "Epoch 25: Generator Loss = 12.3137, Discriminator Loss = 9.6294\n",
      "Epoch 26: Generator Loss = 12.9849, Discriminator Loss = 8.2181\n",
      "Epoch 27: Generator Loss = 14.2998, Discriminator Loss = 8.3314\n",
      "Epoch 28: Generator Loss = 15.0533, Discriminator Loss = 8.7716\n",
      "Epoch 29: Generator Loss = 14.8581, Discriminator Loss = 8.9630\n",
      "Epoch 30: Generator Loss = 16.3467, Discriminator Loss = 9.1045\n",
      "Epoch 31: Generator Loss = 16.0238, Discriminator Loss = 8.9061\n",
      "Epoch 32: Generator Loss = 13.5859, Discriminator Loss = 8.4101\n",
      "Epoch 33: Generator Loss = 15.7612, Discriminator Loss = 8.4305\n",
      "Epoch 34: Generator Loss = 15.1826, Discriminator Loss = 9.0091\n",
      "Epoch 35: Generator Loss = 16.8158, Discriminator Loss = 9.4674\n",
      "Epoch 36: Generator Loss = 17.2332, Discriminator Loss = 8.4058\n",
      "Epoch 37: Generator Loss = 16.4320, Discriminator Loss = 9.1972\n",
      "Epoch 38: Generator Loss = 14.9711, Discriminator Loss = 8.7887\n",
      "Epoch 39: Generator Loss = 16.5319, Discriminator Loss = 7.8154\n",
      "Epoch 40: Generator Loss = 16.8788, Discriminator Loss = 8.1311\n",
      "Epoch 41: Generator Loss = 16.0807, Discriminator Loss = 8.2274\n",
      "Epoch 42: Generator Loss = 18.7204, Discriminator Loss = 7.7841\n",
      "Epoch 43: Generator Loss = 18.9299, Discriminator Loss = 8.5066\n",
      "Epoch 44: Generator Loss = 19.4099, Discriminator Loss = 7.1281\n",
      "Epoch 45: Generator Loss = 18.9208, Discriminator Loss = 7.5766\n",
      "Epoch 46: Generator Loss = 19.1648, Discriminator Loss = 6.6053\n",
      "Epoch 47: Generator Loss = 18.3966, Discriminator Loss = 8.6185\n",
      "Epoch 48: Generator Loss = 19.9741, Discriminator Loss = 7.4640\n",
      "Epoch 49: Generator Loss = 23.0283, Discriminator Loss = 5.6867\n",
      "Epoch 50: Generator Loss = 23.4758, Discriminator Loss = 5.5383\n",
      "Epoch 51: Generator Loss = 24.0266, Discriminator Loss = 7.6209\n",
      "Epoch 52: Generator Loss = 26.9349, Discriminator Loss = 6.7014\n",
      "Epoch 53: Generator Loss = 26.0169, Discriminator Loss = 7.4947\n",
      "Epoch 54: Generator Loss = 30.4143, Discriminator Loss = 6.1742\n",
      "Epoch 55: Generator Loss = 16.3293, Discriminator Loss = 7.5809\n",
      "Epoch 56: Generator Loss = 26.5593, Discriminator Loss = 6.1473\n",
      "Epoch 57: Generator Loss = 22.6091, Discriminator Loss = 5.1245\n",
      "Epoch 58: Generator Loss = 22.4258, Discriminator Loss = 5.4275\n",
      "Epoch 59: Generator Loss = 28.9759, Discriminator Loss = 5.8961\n",
      "Epoch 60: Generator Loss = 28.1013, Discriminator Loss = 5.9863\n",
      "Epoch 61: Generator Loss = 28.0921, Discriminator Loss = 4.8142\n",
      "Epoch 62: Generator Loss = 41.1275, Discriminator Loss = 4.1896\n",
      "Epoch 63: Generator Loss = 30.4572, Discriminator Loss = 3.8656\n",
      "Epoch 64: Generator Loss = 37.2830, Discriminator Loss = 4.8260\n",
      "Epoch 65: Generator Loss = 37.8133, Discriminator Loss = 3.6735\n",
      "Epoch 66: Generator Loss = 32.6923, Discriminator Loss = 3.7841\n",
      "Epoch 67: Generator Loss = 50.5286, Discriminator Loss = 4.1432\n",
      "Epoch 68: Generator Loss = 41.4670, Discriminator Loss = 3.0220\n",
      "Epoch 69: Generator Loss = 40.3394, Discriminator Loss = 4.8050\n",
      "Epoch 70: Generator Loss = 40.6180, Discriminator Loss = 4.0863\n",
      "Epoch 71: Generator Loss = 36.6402, Discriminator Loss = 3.7096\n",
      "Epoch 72: Generator Loss = 38.2963, Discriminator Loss = 2.5779\n",
      "Epoch 73: Generator Loss = 45.3813, Discriminator Loss = 3.6073\n",
      "Epoch 74: Generator Loss = 43.6619, Discriminator Loss = 4.8459\n",
      "Epoch 75: Generator Loss = 35.1368, Discriminator Loss = 3.3069\n",
      "Epoch 76: Generator Loss = 41.7373, Discriminator Loss = 5.0338\n",
      "Epoch 77: Generator Loss = 49.0289, Discriminator Loss = 2.4633\n",
      "Epoch 78: Generator Loss = 41.6583, Discriminator Loss = 2.0677\n",
      "Epoch 79: Generator Loss = 41.9707, Discriminator Loss = 1.8453\n",
      "Epoch 80: Generator Loss = 46.7120, Discriminator Loss = 2.1504\n",
      "Epoch 81: Generator Loss = 56.0772, Discriminator Loss = 2.2299\n",
      "Epoch 82: Generator Loss = 38.9228, Discriminator Loss = 2.4338\n",
      "Epoch 83: Generator Loss = 60.8968, Discriminator Loss = 2.5488\n",
      "Epoch 84: Generator Loss = 52.2654, Discriminator Loss = 4.9941\n",
      "Epoch 85: Generator Loss = 40.5705, Discriminator Loss = 3.6071\n",
      "Epoch 86: Generator Loss = 48.8353, Discriminator Loss = 1.5651\n",
      "Epoch 87: Generator Loss = 53.2514, Discriminator Loss = 1.3240\n",
      "Epoch 88: Generator Loss = 65.5027, Discriminator Loss = 0.8564\n",
      "Epoch 89: Generator Loss = 71.9850, Discriminator Loss = 1.0353\n",
      "Epoch 90: Generator Loss = 53.4209, Discriminator Loss = 1.1723\n",
      "Epoch 91: Generator Loss = 78.4427, Discriminator Loss = 0.9359\n",
      "Epoch 92: Generator Loss = 75.3917, Discriminator Loss = 0.7383\n",
      "Epoch 93: Generator Loss = 77.7092, Discriminator Loss = 0.7701\n",
      "Epoch 94: Generator Loss = 70.5034, Discriminator Loss = 0.8289\n",
      "Epoch 95: Generator Loss = 64.2922, Discriminator Loss = 0.7499\n",
      "Epoch 96: Generator Loss = 70.0182, Discriminator Loss = 0.5967\n",
      "Epoch 97: Generator Loss = 81.2386, Discriminator Loss = 0.6278\n",
      "Epoch 98: Generator Loss = 70.7269, Discriminator Loss = 0.7519\n",
      "Epoch 99: Generator Loss = 80.0132, Discriminator Loss = 1.1579\n",
      "Epoch 100: Generator Loss = 50.1208, Discriminator Loss = 2.9876\n",
      "Epoch 101: Generator Loss = 63.4310, Discriminator Loss = 1.4335\n",
      "Epoch 102: Generator Loss = 71.6532, Discriminator Loss = 0.9731\n",
      "Epoch 103: Generator Loss = 69.2179, Discriminator Loss = 2.2915\n",
      "Epoch 104: Generator Loss = 67.3704, Discriminator Loss = 2.0734\n",
      "Epoch 105: Generator Loss = 66.9154, Discriminator Loss = 0.6694\n",
      "Epoch 106: Generator Loss = 68.0963, Discriminator Loss = 0.7114\n",
      "Epoch 107: Generator Loss = 68.6488, Discriminator Loss = 0.8310\n",
      "Epoch 108: Generator Loss = 73.0563, Discriminator Loss = 0.5806\n",
      "Epoch 109: Generator Loss = 75.7972, Discriminator Loss = 0.5815\n",
      "Epoch 110: Generator Loss = 82.5418, Discriminator Loss = 1.5504\n",
      "Epoch 111: Generator Loss = 64.1842, Discriminator Loss = 0.8740\n",
      "Epoch 112: Generator Loss = 85.8851, Discriminator Loss = 1.2882\n",
      "Epoch 113: Generator Loss = 81.2208, Discriminator Loss = 1.1519\n",
      "Epoch 114: Generator Loss = 66.5849, Discriminator Loss = 1.1883\n",
      "Epoch 115: Generator Loss = 69.9386, Discriminator Loss = 0.3911\n",
      "Epoch 116: Generator Loss = 72.0649, Discriminator Loss = 0.5913\n",
      "Epoch 117: Generator Loss = 79.7951, Discriminator Loss = 1.9489\n",
      "Epoch 118: Generator Loss = 66.9489, Discriminator Loss = 0.6184\n",
      "Epoch 119: Generator Loss = 73.5409, Discriminator Loss = 0.6747\n",
      "Epoch 120: Generator Loss = 76.2164, Discriminator Loss = 0.3009\n",
      "Epoch 121: Generator Loss = 70.8442, Discriminator Loss = 1.0179\n",
      "Epoch 122: Generator Loss = 90.3500, Discriminator Loss = 1.4652\n",
      "Epoch 123: Generator Loss = 81.7572, Discriminator Loss = 1.1926\n",
      "Epoch 124: Generator Loss = 79.0976, Discriminator Loss = 1.3285\n",
      "Epoch 125: Generator Loss = 81.7414, Discriminator Loss = 0.4233\n",
      "Epoch 126: Generator Loss = 79.1420, Discriminator Loss = 0.5769\n",
      "Epoch 127: Generator Loss = 80.6125, Discriminator Loss = 0.4004\n",
      "Epoch 128: Generator Loss = 82.0856, Discriminator Loss = 0.3958\n",
      "Epoch 129: Generator Loss = 78.3851, Discriminator Loss = 1.1889\n",
      "Epoch 130: Generator Loss = 77.1239, Discriminator Loss = 0.8610\n",
      "Epoch 131: Generator Loss = 89.3082, Discriminator Loss = 0.6696\n",
      "Epoch 132: Generator Loss = 76.9401, Discriminator Loss = 0.6374\n",
      "Epoch 133: Generator Loss = 77.8199, Discriminator Loss = 0.6378\n",
      "Epoch 134: Generator Loss = 73.4746, Discriminator Loss = 1.9909\n",
      "Epoch 135: Generator Loss = 53.0695, Discriminator Loss = 10.6340\n",
      "Epoch 136: Generator Loss = 40.0529, Discriminator Loss = 6.2889\n",
      "Epoch 137: Generator Loss = 46.2331, Discriminator Loss = 3.4568\n",
      "Epoch 138: Generator Loss = 61.9311, Discriminator Loss = 1.4860\n",
      "Epoch 139: Generator Loss = 68.0345, Discriminator Loss = 1.5281\n",
      "Epoch 140: Generator Loss = 65.8145, Discriminator Loss = 0.7554\n",
      "Epoch 141: Generator Loss = 71.7852, Discriminator Loss = 0.9381\n",
      "Epoch 142: Generator Loss = 74.8834, Discriminator Loss = 0.5003\n",
      "Epoch 143: Generator Loss = 68.9021, Discriminator Loss = 0.6056\n",
      "Epoch 144: Generator Loss = 83.5154, Discriminator Loss = 0.8594\n",
      "Epoch 145: Generator Loss = 91.1727, Discriminator Loss = 0.7078\n",
      "Epoch 146: Generator Loss = 92.7120, Discriminator Loss = 0.6207\n",
      "Epoch 147: Generator Loss = 67.3356, Discriminator Loss = 0.7463\n",
      "Epoch 148: Generator Loss = 93.5384, Discriminator Loss = 1.1371\n",
      "Epoch 149: Generator Loss = 93.3719, Discriminator Loss = 0.3798\n",
      "Epoch 150: Generator Loss = 86.2082, Discriminator Loss = 0.3572\n",
      "Epoch 151: Generator Loss = 76.8391, Discriminator Loss = 0.4277\n",
      "Epoch 152: Generator Loss = 93.7582, Discriminator Loss = 0.3902\n",
      "Epoch 153: Generator Loss = 68.0510, Discriminator Loss = 0.7512\n",
      "Epoch 154: Generator Loss = 80.2784, Discriminator Loss = 0.4027\n",
      "Epoch 155: Generator Loss = 84.3286, Discriminator Loss = 0.6316\n",
      "Epoch 156: Generator Loss = 95.6093, Discriminator Loss = 0.4957\n",
      "Epoch 157: Generator Loss = 90.0615, Discriminator Loss = 0.4010\n",
      "Epoch 158: Generator Loss = 94.5085, Discriminator Loss = 0.3428\n",
      "Epoch 159: Generator Loss = 93.0992, Discriminator Loss = 1.5754\n",
      "Epoch 160: Generator Loss = 68.7779, Discriminator Loss = 0.5361\n",
      "Epoch 161: Generator Loss = 90.2358, Discriminator Loss = 1.6944\n",
      "Epoch 162: Generator Loss = 75.1658, Discriminator Loss = 1.6410\n",
      "Epoch 163: Generator Loss = 84.9869, Discriminator Loss = 1.2131\n",
      "Epoch 164: Generator Loss = 73.8484, Discriminator Loss = 5.9110\n",
      "Epoch 165: Generator Loss = 81.0570, Discriminator Loss = 2.9569\n",
      "Epoch 166: Generator Loss = 73.5141, Discriminator Loss = 1.1554\n",
      "Epoch 167: Generator Loss = 63.9300, Discriminator Loss = 1.0880\n",
      "Epoch 168: Generator Loss = 78.3612, Discriminator Loss = 0.4308\n",
      "Epoch 169: Generator Loss = 73.7839, Discriminator Loss = 0.9398\n",
      "Epoch 170: Generator Loss = 83.7869, Discriminator Loss = 0.4558\n",
      "Epoch 171: Generator Loss = 91.9530, Discriminator Loss = 1.2350\n",
      "Epoch 172: Generator Loss = 70.2278, Discriminator Loss = 0.3408\n",
      "Epoch 173: Generator Loss = 87.0445, Discriminator Loss = 0.5601\n",
      "Epoch 174: Generator Loss = 101.0072, Discriminator Loss = 0.6130\n",
      "Epoch 175: Generator Loss = 81.5213, Discriminator Loss = 0.7202\n",
      "Epoch 176: Generator Loss = 73.2667, Discriminator Loss = 0.6976\n",
      "Epoch 177: Generator Loss = 90.3335, Discriminator Loss = 0.7643\n",
      "Epoch 178: Generator Loss = 70.6568, Discriminator Loss = 1.5578\n",
      "Epoch 179: Generator Loss = 78.1330, Discriminator Loss = 0.9136\n",
      "Epoch 180: Generator Loss = 73.5134, Discriminator Loss = 1.5300\n",
      "Epoch 181: Generator Loss = 75.3075, Discriminator Loss = 0.7219\n",
      "Epoch 182: Generator Loss = 71.2897, Discriminator Loss = 0.6379\n",
      "Epoch 183: Generator Loss = 85.5295, Discriminator Loss = 0.6083\n",
      "Epoch 184: Generator Loss = 89.2912, Discriminator Loss = 1.0698\n",
      "Epoch 185: Generator Loss = 81.1210, Discriminator Loss = 1.3918\n",
      "Epoch 186: Generator Loss = 78.6833, Discriminator Loss = 1.1275\n",
      "Epoch 187: Generator Loss = 97.1736, Discriminator Loss = 1.6020\n",
      "Epoch 188: Generator Loss = 96.5227, Discriminator Loss = 0.9400\n",
      "Epoch 189: Generator Loss = 83.5726, Discriminator Loss = 0.8570\n",
      "Epoch 190: Generator Loss = 84.4815, Discriminator Loss = 0.7596\n",
      "Epoch 191: Generator Loss = 93.7089, Discriminator Loss = 1.6729\n",
      "Epoch 192: Generator Loss = 79.9986, Discriminator Loss = 1.4266\n",
      "Epoch 193: Generator Loss = 61.0854, Discriminator Loss = 0.7554\n",
      "Epoch 194: Generator Loss = 65.9150, Discriminator Loss = 1.2988\n",
      "Epoch 195: Generator Loss = 88.2654, Discriminator Loss = 3.5726\n",
      "Epoch 196: Generator Loss = 61.6965, Discriminator Loss = 1.4870\n",
      "Epoch 197: Generator Loss = 70.8495, Discriminator Loss = 0.7056\n",
      "Epoch 198: Generator Loss = 83.9228, Discriminator Loss = 1.0093\n",
      "Epoch 199: Generator Loss = 64.4176, Discriminator Loss = 2.5694\n",
      "Epoch 200: Generator Loss = 82.2044, Discriminator Loss = 2.9400\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/20 | Train Loss: 0.1308 Acc: 0.9390\n",
      "Epoch 2/20 | Train Loss: 0.0136 Acc: 0.9959\n",
      "Epoch 3/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0026 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0023 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 4.5min\n",
      "Epoch 1/20 | Train Loss: 0.0829 Acc: 0.9675\n",
      "Epoch 2/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0037 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 4.5min\n",
      "Epoch 1/20 | Train Loss: 0.0846 Acc: 0.9553\n",
      "Epoch 2/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0036 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.0492 Acc: 0.9717\n",
      "Epoch 2/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0032 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 5.7min\n",
      "Epoch 1/20 | Train Loss: 0.0433 Acc: 0.9773\n",
      "Epoch 2/20 | Train Loss: 0.0044 Acc: 0.9972\n",
      "Epoch 3/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0030 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0000 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "[CV] END ...................................scale_factor=0.5; total time= 6.3min\n",
      "Epoch 1/20 | Train Loss: 0.0680 Acc: 0.9634\n",
      "Epoch 2/20 | Train Loss: 0.0028 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0029 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0047 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0021 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0339 Acc: 0.9878\n",
      "Epoch 10/20 | Train Loss: 0.0054 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.0795 Acc: 0.9593\n",
      "Epoch 2/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0335 Acc: 0.9919\n",
      "Epoch 4/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0777 Acc: 0.9797\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.0775 Acc: 0.9634\n",
      "Epoch 2/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0380 Acc: 0.9837\n",
      "Epoch 4/20 | Train Loss: 0.0071 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0581 Acc: 0.9878\n",
      "Epoch 6/20 | Train Loss: 0.0034 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0101 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0021 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0039 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0036 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0232 Acc: 0.9878\n",
      "Epoch 13/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 4.4min\n",
      "Epoch 1/20 | Train Loss: 0.1295 Acc: 0.9371\n",
      "Epoch 2/20 | Train Loss: 0.0024 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0087 Acc: 0.9969\n",
      "Epoch 11/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 5.8min\n",
      "Epoch 1/20 | Train Loss: 0.0940 Acc: 0.9545\n",
      "Epoch 2/20 | Train Loss: 0.0047 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0064 Acc: 0.9943\n",
      "Epoch 14/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0021 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "[CV] END .....................................scale_factor=1; total time= 6.3min\n",
      "Epoch 1/20 | Train Loss: 0.0758 Acc: 0.9716\n",
      "Epoch 2/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0001 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0215 Acc: 0.9943\n",
      "Epoch 7/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Fold 10 Test Accuracy: 0.5000\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T14:43:41.320458Z",
     "start_time": "2025-05-29T14:43:41.314732Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 8,
   "source": "",
   "id": "f86383a2cbf6728a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNNVAE: Generowanie jedynie syntetycznego zbioru",
   "id": "5384aeb89d42b6ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T15:21:09.952375Z",
     "start_time": "2025-05-29T14:43:41.321466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "IMG_SIZE   = 128\n",
    "BATCH_SIZE = 16\n",
    "CHANNELS   = 3\n",
    "CLASSIFIER_EPOCHS = 20\n",
    "OVERSAMPLER_EPOCHS = 200\n",
    "\n",
    "dataset = CapsuleDataset(pos_dir=pos_folder, neg_dirs=neg_folder, transform=transform)\n",
    "print(dataset.__len__())\n",
    "\n",
    "labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(rskf.split(X=np.zeros(len(labels)), y=labels), start=1):\n",
    "    print(f\"===== Fold {fold_idx} =====\")\n",
    "\n",
    "\n",
    "    CnnVae = CNNVAEWrapper(dataset,device,BATCH_SIZE,OVERSAMPLER_EPOCHS)\n",
    "\n",
    "    CnnVae.fit(train_idx)\n",
    "\n",
    "\n",
    "    estimator = CNNVAEResNetEstimator(\n",
    "        dataset=dataset,\n",
    "        vae_model=CnnVae.vae_model,\n",
    "        device=device,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        classifier_epochs=CLASSIFIER_EPOCHS,\n",
    "        multiplier_generated_samples='synthetic'\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'mu_multiplier': [0.8, 1.2],\n",
    "        'logvar_multiplier': [0.5, 1.5]\n",
    "    }\n",
    "\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=3,\n",
    "        cv=None,\n",
    "        verbose=2,\n",
    "        n_jobs=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    random_search.fit(train_idx)\n",
    "\n",
    "    best_estimator = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    test_ds = Subset(dataset, test_idx)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    f2, bal_acc, recall, specificity = best_estimator.trainer.validate(test_loader)\n",
    "    print(f\"Fold {fold_idx} Test Accuracy: {bal_acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'fold': fold_idx,\n",
    "        'f2_score': f2,\n",
    "        'balanced_accuracy': bal_acc,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        **best_params\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Zapis wyników z każdego folda\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('CNNVAE_synthetic_cross_validation_results.csv', index=False)"
   ],
   "id": "5326b7fac0e68825",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n",
      "===== Fold 1 =====\n",
      "Train Epoch: 1 | Loss: 2286.4898\n",
      "Train Epoch: 2 | Loss: 2069.6775\n",
      "Train Epoch: 3 | Loss: 2025.7096\n",
      "Train Epoch: 4 | Loss: 2057.5924\n",
      "Train Epoch: 5 | Loss: 1985.3303\n",
      "Train Epoch: 6 | Loss: 1909.5665\n",
      "Train Epoch: 7 | Loss: 1942.2949\n",
      "Train Epoch: 8 | Loss: 1957.7975\n",
      "Train Epoch: 9 | Loss: 1889.5994\n",
      "Train Epoch: 10 | Loss: 1872.8415\n",
      "Train Epoch: 11 | Loss: 1786.6735\n",
      "Train Epoch: 12 | Loss: 1746.9870\n",
      "Train Epoch: 13 | Loss: 1819.9660\n",
      "Train Epoch: 14 | Loss: 1735.7154\n",
      "Train Epoch: 15 | Loss: 1762.4043\n",
      "Train Epoch: 16 | Loss: 1812.3532\n",
      "Train Epoch: 17 | Loss: 1791.9655\n",
      "Train Epoch: 18 | Loss: 1740.2554\n",
      "Train Epoch: 19 | Loss: 1798.1621\n",
      "Train Epoch: 20 | Loss: 1712.5966\n",
      "Train Epoch: 21 | Loss: 1770.6167\n",
      "Train Epoch: 22 | Loss: 1724.4459\n",
      "Train Epoch: 23 | Loss: 1729.1468\n",
      "Train Epoch: 24 | Loss: 1780.5416\n",
      "Train Epoch: 25 | Loss: 1753.7760\n",
      "Train Epoch: 26 | Loss: 1791.9717\n",
      "Train Epoch: 27 | Loss: 1767.8451\n",
      "Train Epoch: 28 | Loss: 1773.9280\n",
      "Train Epoch: 29 | Loss: 1747.9425\n",
      "Train Epoch: 30 | Loss: 1707.6574\n",
      "Train Epoch: 31 | Loss: 1730.3292\n",
      "Train Epoch: 32 | Loss: 1745.6406\n",
      "Train Epoch: 33 | Loss: 1645.1513\n",
      "Train Epoch: 34 | Loss: 1725.8918\n",
      "Train Epoch: 35 | Loss: 1666.7814\n",
      "Train Epoch: 36 | Loss: 1746.4036\n",
      "Train Epoch: 37 | Loss: 1665.9020\n",
      "Train Epoch: 38 | Loss: 1682.8189\n",
      "Train Epoch: 39 | Loss: 1707.7696\n",
      "Train Epoch: 40 | Loss: 1721.7193\n",
      "Train Epoch: 41 | Loss: 1684.2934\n",
      "Train Epoch: 42 | Loss: 1652.4450\n",
      "Train Epoch: 43 | Loss: 1663.4367\n",
      "Train Epoch: 44 | Loss: 1635.6929\n",
      "Train Epoch: 45 | Loss: 1654.7103\n",
      "Train Epoch: 46 | Loss: 1661.0965\n",
      "Train Epoch: 47 | Loss: 1675.0646\n",
      "Train Epoch: 48 | Loss: 1641.1951\n",
      "Train Epoch: 49 | Loss: 1668.9300\n",
      "Train Epoch: 50 | Loss: 1676.3410\n",
      "Train Epoch: 51 | Loss: 1660.9060\n",
      "Train Epoch: 52 | Loss: 1616.8912\n",
      "Train Epoch: 53 | Loss: 1630.6515\n",
      "Train Epoch: 54 | Loss: 1693.5722\n",
      "Train Epoch: 55 | Loss: 1667.0574\n",
      "Train Epoch: 56 | Loss: 1678.5222\n",
      "Train Epoch: 57 | Loss: 1658.9442\n",
      "Train Epoch: 58 | Loss: 1640.0492\n",
      "Train Epoch: 59 | Loss: 1687.5588\n",
      "Train Epoch: 60 | Loss: 1656.3700\n",
      "Train Epoch: 61 | Loss: 1624.0774\n",
      "Train Epoch: 62 | Loss: 1633.7106\n",
      "Train Epoch: 63 | Loss: 1692.0649\n",
      "Train Epoch: 64 | Loss: 1773.9309\n",
      "Train Epoch: 65 | Loss: 1652.6455\n",
      "Train Epoch: 66 | Loss: 1634.8244\n",
      "Train Epoch: 67 | Loss: 1662.8983\n",
      "Train Epoch: 68 | Loss: 1703.4518\n",
      "Train Epoch: 69 | Loss: 1613.3734\n",
      "Train Epoch: 70 | Loss: 1609.2060\n",
      "Train Epoch: 71 | Loss: 1612.0309\n",
      "Train Epoch: 72 | Loss: 1673.0113\n",
      "Train Epoch: 73 | Loss: 1618.2477\n",
      "Train Epoch: 74 | Loss: 1669.1281\n",
      "Train Epoch: 75 | Loss: 1735.3653\n",
      "Train Epoch: 76 | Loss: 1648.4496\n",
      "Train Epoch: 77 | Loss: 1720.9445\n",
      "Train Epoch: 78 | Loss: 1680.0731\n",
      "Train Epoch: 79 | Loss: 1677.0554\n",
      "Train Epoch: 80 | Loss: 1625.1212\n",
      "Train Epoch: 81 | Loss: 1626.7126\n",
      "Train Epoch: 82 | Loss: 1616.7008\n",
      "Train Epoch: 83 | Loss: 1639.6271\n",
      "Train Epoch: 84 | Loss: 1564.5235\n",
      "Train Epoch: 85 | Loss: 1662.8215\n",
      "Train Epoch: 86 | Loss: 1731.2052\n",
      "Train Epoch: 87 | Loss: 1620.3411\n",
      "Train Epoch: 88 | Loss: 1624.7488\n",
      "Train Epoch: 89 | Loss: 1656.4553\n",
      "Train Epoch: 90 | Loss: 1672.8235\n",
      "Train Epoch: 91 | Loss: 1665.7654\n",
      "Train Epoch: 92 | Loss: 1657.6834\n",
      "Train Epoch: 93 | Loss: 1646.8418\n",
      "Train Epoch: 94 | Loss: 1594.0956\n",
      "Train Epoch: 95 | Loss: 1703.7186\n",
      "Train Epoch: 96 | Loss: 1628.2138\n",
      "Train Epoch: 97 | Loss: 1674.1464\n",
      "Train Epoch: 98 | Loss: 1607.1283\n",
      "Train Epoch: 99 | Loss: 1649.1012\n",
      "Train Epoch: 100 | Loss: 1679.8205\n",
      "Train Epoch: 101 | Loss: 1592.9824\n",
      "Train Epoch: 102 | Loss: 1682.8215\n",
      "Train Epoch: 103 | Loss: 1640.8322\n",
      "Train Epoch: 104 | Loss: 1625.5955\n",
      "Train Epoch: 105 | Loss: 1634.5483\n",
      "Train Epoch: 106 | Loss: 1643.6263\n",
      "Train Epoch: 107 | Loss: 1654.8175\n",
      "Train Epoch: 108 | Loss: 1651.1835\n",
      "Train Epoch: 109 | Loss: 1692.7855\n",
      "Train Epoch: 110 | Loss: 1591.2390\n",
      "Train Epoch: 111 | Loss: 1636.4085\n",
      "Train Epoch: 112 | Loss: 1659.2700\n",
      "Train Epoch: 113 | Loss: 1629.1030\n",
      "Train Epoch: 114 | Loss: 1693.1434\n",
      "Train Epoch: 115 | Loss: 1609.1067\n",
      "Train Epoch: 116 | Loss: 1607.1257\n",
      "Train Epoch: 117 | Loss: 1618.5467\n",
      "Train Epoch: 118 | Loss: 1604.9140\n",
      "Train Epoch: 119 | Loss: 1658.7868\n",
      "Train Epoch: 120 | Loss: 1664.8126\n",
      "Train Epoch: 121 | Loss: 1653.3314\n",
      "Train Epoch: 122 | Loss: 1659.6686\n",
      "Train Epoch: 123 | Loss: 1611.3513\n",
      "Train Epoch: 124 | Loss: 1612.3445\n",
      "Train Epoch: 125 | Loss: 1666.1756\n",
      "Train Epoch: 126 | Loss: 1690.7581\n",
      "Train Epoch: 127 | Loss: 1609.5524\n",
      "Train Epoch: 128 | Loss: 1662.1869\n",
      "Train Epoch: 129 | Loss: 1617.0557\n",
      "Train Epoch: 130 | Loss: 1631.3941\n",
      "Train Epoch: 131 | Loss: 1648.4116\n",
      "Train Epoch: 132 | Loss: 1595.1943\n",
      "Train Epoch: 133 | Loss: 1696.8477\n",
      "Train Epoch: 134 | Loss: 1674.9530\n",
      "Train Epoch: 135 | Loss: 1648.9727\n",
      "Train Epoch: 136 | Loss: 1605.8681\n",
      "Train Epoch: 137 | Loss: 1690.8693\n",
      "Train Epoch: 138 | Loss: 1607.8068\n",
      "Train Epoch: 139 | Loss: 1704.2851\n",
      "Train Epoch: 140 | Loss: 1661.1660\n",
      "Train Epoch: 141 | Loss: 1633.6327\n",
      "Train Epoch: 142 | Loss: 1619.7023\n",
      "Train Epoch: 143 | Loss: 1623.4111\n",
      "Train Epoch: 144 | Loss: 1615.3745\n",
      "Train Epoch: 145 | Loss: 1630.6330\n",
      "Train Epoch: 146 | Loss: 1653.7539\n",
      "Train Epoch: 147 | Loss: 1610.5543\n",
      "Train Epoch: 148 | Loss: 1596.0812\n",
      "Train Epoch: 149 | Loss: 1612.0571\n",
      "Train Epoch: 150 | Loss: 1669.2026\n",
      "Train Epoch: 151 | Loss: 1652.1036\n",
      "Train Epoch: 152 | Loss: 1671.8882\n",
      "Train Epoch: 153 | Loss: 1665.3629\n",
      "Train Epoch: 154 | Loss: 1668.2458\n",
      "Train Epoch: 155 | Loss: 1617.9812\n",
      "Train Epoch: 156 | Loss: 1632.3314\n",
      "Train Epoch: 157 | Loss: 1625.4645\n",
      "Train Epoch: 158 | Loss: 1644.4659\n",
      "Train Epoch: 159 | Loss: 1615.4020\n",
      "Train Epoch: 160 | Loss: 1658.5061\n",
      "Train Epoch: 161 | Loss: 1672.2110\n",
      "Train Epoch: 162 | Loss: 1669.0725\n",
      "Train Epoch: 163 | Loss: 1621.7531\n",
      "Train Epoch: 164 | Loss: 1629.6729\n",
      "Train Epoch: 165 | Loss: 1643.9058\n",
      "Train Epoch: 166 | Loss: 1688.3858\n",
      "Train Epoch: 167 | Loss: 1607.2666\n",
      "Train Epoch: 168 | Loss: 1636.7454\n",
      "Train Epoch: 169 | Loss: 1674.1197\n",
      "Train Epoch: 170 | Loss: 1672.5662\n",
      "Train Epoch: 171 | Loss: 1634.7060\n",
      "Train Epoch: 172 | Loss: 1625.7457\n",
      "Train Epoch: 173 | Loss: 1651.3011\n",
      "Train Epoch: 174 | Loss: 1635.6844\n",
      "Train Epoch: 175 | Loss: 1634.2241\n",
      "Train Epoch: 176 | Loss: 1686.1965\n",
      "Train Epoch: 177 | Loss: 1639.8890\n",
      "Train Epoch: 178 | Loss: 1684.2317\n",
      "Train Epoch: 179 | Loss: 1707.6245\n",
      "Train Epoch: 180 | Loss: 1674.0986\n",
      "Train Epoch: 181 | Loss: 1613.5983\n",
      "Train Epoch: 182 | Loss: 1652.9848\n",
      "Train Epoch: 183 | Loss: 1608.0609\n",
      "Train Epoch: 184 | Loss: 1638.8582\n",
      "Train Epoch: 185 | Loss: 1581.1391\n",
      "Train Epoch: 186 | Loss: 1620.7053\n",
      "Train Epoch: 187 | Loss: 1595.9889\n",
      "Train Epoch: 188 | Loss: 1681.1078\n",
      "Train Epoch: 189 | Loss: 1638.8558\n",
      "Train Epoch: 190 | Loss: 1620.2059\n",
      "Train Epoch: 191 | Loss: 1597.2708\n",
      "Train Epoch: 192 | Loss: 1626.8777\n",
      "Train Epoch: 193 | Loss: 1641.6855\n",
      "Train Epoch: 194 | Loss: 1620.0662\n",
      "Train Epoch: 195 | Loss: 1626.6066\n",
      "Train Epoch: 196 | Loss: 1553.9571\n",
      "Train Epoch: 197 | Loss: 1644.1054\n",
      "Train Epoch: 198 | Loss: 1645.2597\n",
      "Train Epoch: 199 | Loss: 1637.7556\n",
      "Train Epoch: 200 | Loss: 1635.0764\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Epoch 1/20 | Train Loss: 0.0862 Acc: 0.9713\n",
      "Epoch 2/20 | Train Loss: 0.0035 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0075 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0027 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0238 Acc: 0.9918\n",
      "Epoch 8/20 | Train Loss: 0.0028 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0273 Acc: 0.9918\n",
      "Epoch 10/20 | Train Loss: 0.0451 Acc: 0.9918\n",
      "Epoch 11/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0324 Acc: 0.9959\n",
      "[CV] END ...........logvar_multiplier=0.5, mu_multiplier=1.2; total time= 4.3min\n",
      "Epoch 1/20 | Train Loss: 0.0798 Acc: 0.9672\n",
      "Epoch 2/20 | Train Loss: 0.0020 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0143 Acc: 0.9918\n",
      "Epoch 4/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0012 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0055 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0018 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0708 Acc: 0.9918\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0015 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0274 Acc: 0.9918\n",
      "Epoch 14/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0021 Acc: 1.0000\n",
      "[CV] END ...........logvar_multiplier=0.5, mu_multiplier=1.2; total time= 4.2min\n",
      "Epoch 1/20 | Train Loss: 0.1043 Acc: 0.9512\n",
      "Epoch 2/20 | Train Loss: 0.0037 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0230 Acc: 0.9959\n",
      "Epoch 4/20 | Train Loss: 0.0074 Acc: 0.9959\n",
      "Epoch 5/20 | Train Loss: 0.0027 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0421 Acc: 0.9837\n",
      "Epoch 8/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0011 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0007 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0026 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0291 Acc: 0.9959\n",
      "[CV] END ...........logvar_multiplier=0.5, mu_multiplier=1.2; total time= 4.3min\n",
      "Epoch 1/20 | Train Loss: 0.0976 Acc: 0.9557\n",
      "Epoch 2/20 | Train Loss: 0.0077 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0047 Acc: 1.0000\n",
      "Epoch 4/20 | Train Loss: 0.0009 Acc: 1.0000\n",
      "Epoch 5/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 6/20 | Train Loss: 0.0016 Acc: 1.0000\n",
      "Epoch 7/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 8/20 | Train Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 9/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 10/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 11/20 | Train Loss: 0.0014 Acc: 1.0000\n",
      "Epoch 12/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 13/20 | Train Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 14/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 15/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 16/20 | Train Loss: 0.0002 Acc: 1.0000\n",
      "Epoch 17/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 18/20 | Train Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 19/20 | Train Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 20/20 | Train Loss: 0.0005 Acc: 1.0000\n",
      "[CV] END ...........logvar_multiplier=0.5, mu_multiplier=1.2; total time= 5.4min\n",
      "Epoch 1/20 | Train Loss: 0.0978 Acc: 0.9600\n",
      "Epoch 2/20 | Train Loss: 0.0029 Acc: 1.0000\n",
      "Epoch 3/20 | Train Loss: 0.0012 Acc: 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 48\u001B[39m\n\u001B[32m     32\u001B[39m param_grid = {\n\u001B[32m     33\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mmu_multiplier\u001B[39m\u001B[33m'\u001B[39m: [\u001B[32m0.8\u001B[39m, \u001B[32m1.2\u001B[39m],\n\u001B[32m     34\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mlogvar_multiplier\u001B[39m\u001B[33m'\u001B[39m: [\u001B[32m0.5\u001B[39m, \u001B[32m1.5\u001B[39m]\n\u001B[32m     35\u001B[39m }\n\u001B[32m     38\u001B[39m random_search = RandomizedSearchCV(\n\u001B[32m     39\u001B[39m     estimator=estimator,\n\u001B[32m     40\u001B[39m     param_distributions=param_grid,\n\u001B[32m   (...)\u001B[39m\u001B[32m     45\u001B[39m     random_state=\u001B[32m42\u001B[39m\n\u001B[32m     46\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m \u001B[43mrandom_search\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_idx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     50\u001B[39m best_estimator = random_search.best_estimator_\n\u001B[32m     51\u001B[39m best_params = random_search.best_params_\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001B[39m, in \u001B[36mBaseSearchCV.fit\u001B[39m\u001B[34m(self, X, y, **params)\u001B[39m\n\u001B[32m   1018\u001B[39m     results = \u001B[38;5;28mself\u001B[39m._format_results(\n\u001B[32m   1019\u001B[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[32m   1020\u001B[39m     )\n\u001B[32m   1022\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[32m-> \u001B[39m\u001B[32m1024\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1026\u001B[39m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[32m   1027\u001B[39m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[32m   1028\u001B[39m first_test_score = all_out[\u001B[32m0\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mtest_scores\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001B[39m, in \u001B[36mRandomizedSearchCV._run_search\u001B[39m\u001B[34m(self, evaluate_candidates)\u001B[39m\n\u001B[32m   1949\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[32m   1950\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1951\u001B[39m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1952\u001B[39m \u001B[43m        \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1953\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrandom_state\u001B[49m\n\u001B[32m   1954\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1955\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001B[39m, in \u001B[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[39m\u001B[34m(candidate_params, cv, more_results)\u001B[39m\n\u001B[32m    962\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.verbose > \u001B[32m0\u001B[39m:\n\u001B[32m    963\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[32m    964\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[33m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[33m candidates,\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    965\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[33m fits\u001B[39m\u001B[33m\"\u001B[39m.format(\n\u001B[32m    966\u001B[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001B[32m    967\u001B[39m         )\n\u001B[32m    968\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m970\u001B[39m out = \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    971\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    972\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    973\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    974\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    975\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    976\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    977\u001B[39m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    978\u001B[39m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    979\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    980\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    981\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    982\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    983\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    984\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplitter\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    985\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    986\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    988\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) < \u001B[32m1\u001B[39m:\n\u001B[32m    989\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    990\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mNo fits were performed. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    991\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mWas the CV iterator empty? \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    992\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mWere there no candidates?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    993\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     72\u001B[39m config = get_config()\n\u001B[32m     73\u001B[39m iterable_with_config = (\n\u001B[32m     74\u001B[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     76\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m77\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1986\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1984\u001B[39m     output = \u001B[38;5;28mself\u001B[39m._get_sequential_output(iterable)\n\u001B[32m   1985\u001B[39m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m1986\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1988\u001B[39m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[32m   1989\u001B[39m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[32m   1990\u001B[39m \u001B[38;5;66;03m# reused, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[32m   1991\u001B[39m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[32m   1992\u001B[39m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[32m   1993\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1914\u001B[39m, in \u001B[36mParallel._get_sequential_output\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1912\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_batches += \u001B[32m1\u001B[39m\n\u001B[32m   1913\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_tasks += \u001B[32m1\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1914\u001B[39m res = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1915\u001B[39m \u001B[38;5;28mself\u001B[39m.n_completed_tasks += \u001B[32m1\u001B[39m\n\u001B[32m   1916\u001B[39m \u001B[38;5;28mself\u001B[39m.print_progress()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001B[39m, in \u001B[36m_FuncWrapper.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    137\u001B[39m     config = {}\n\u001B[32m    138\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(**config):\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:864\u001B[39m, in \u001B[36m_fit_and_score\u001B[39m\u001B[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[39m\n\u001B[32m    862\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    863\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m y_train \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m864\u001B[39m         \u001B[43mestimator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    865\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    866\u001B[39m         estimator.fit(X_train, y_train, **fit_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ImbalancedDatasetProblem\\wrappers.py:103\u001B[39m, in \u001B[36mCNNVAEResNetEstimator.fit\u001B[39m\u001B[34m(self, X, y)\u001B[39m\n\u001B[32m    100\u001B[39m \u001B[38;5;66;03m# 3. Trening ResNet na wygenerowanych danych\u001B[39;00m\n\u001B[32m    101\u001B[39m \u001B[38;5;28mself\u001B[39m.trainer = ResNetTrainer()\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    104\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclassifier_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    105\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclassifier_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    106\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    108\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ImbalancedDatasetProblem\\ResNet34.py:87\u001B[39m, in \u001B[36mResNetTrainer.train\u001B[39m\u001B[34m(self, train_loader, num_epochs)\u001B[39m\n\u001B[32m     85\u001B[39m outputs = \u001B[38;5;28mself\u001B[39m.model(inputs_resnet)\n\u001B[32m     86\u001B[39m loss = \u001B[38;5;28mself\u001B[39m.criterion(outputs, labels)\n\u001B[32m---> \u001B[39m\u001B[32m87\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     88\u001B[39m \u001B[38;5;28mself\u001B[39m.optimizer.step()\n\u001B[32m     90\u001B[39m running_loss += loss.item() * inputs.size(\u001B[32m0\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:522\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    512\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    513\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    514\u001B[39m         Tensor.backward,\n\u001B[32m    515\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    520\u001B[39m         inputs=inputs,\n\u001B[32m    521\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m522\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    523\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    524\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    261\u001B[39m     retain_graph = create_graph\n\u001B[32m    263\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    264\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    265\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m266\u001B[39m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    267\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    268\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    269\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    270\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    271\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    272\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    273\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    274\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bd00a2c6ac1af0ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
